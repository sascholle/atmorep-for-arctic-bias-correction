0: Wandb run: atmorep-lp1k3018-17543657
0: l50039:1056045:1056045 [0] NCCL INFO Bootstrap : Using ib0:10.128.11.132<0>
0: l50039:1056045:1056045 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
0: l50039:1056045:1056045 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
0: l50039:1056045:1056045 [0] NCCL INFO NET/Plugin: Using internal network plugin.
0: l50039:1056045:1056045 [0] NCCL INFO cudaDriverVersion 12050
0: NCCL version 2.21.5+cuda12.4
0: l50039:1056045:1056289 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:10.128.11.132<0>
0: l50039:1056045:1056289 [0] NCCL INFO Using non-device net plugin version 0
0: l50039:1056045:1056289 [0] NCCL INFO Using network IB
0: l50039:1056045:1056289 [0] NCCL INFO ncclCommInitRank comm 0x55555f269260 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 3000 commId 0xf7a4e328593d6ba5 - Init START
0: l50039:1056045:1056289 [0] NCCL INFO Setting affinity for GPU 0 to 0f0000,00000000,00000000,00000000,000f0000,00000000
0: l50039:1056045:1056289 [0] NCCL INFO comm 0x55555f269260 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 00/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 01/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 02/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 03/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 04/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 05/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 06/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 07/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 08/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 09/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 10/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 11/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 12/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 13/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 14/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 15/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 16/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 17/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 18/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 19/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 20/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 21/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 22/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 23/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 24/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 25/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 26/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 27/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 28/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 29/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 30/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Channel 31/32 :    0
0: l50039:1056045:1056289 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
0: l50039:1056045:1056289 [0] NCCL INFO P2P Chunksize set to 131072
0: l50039:1056045:1056289 [0] NCCL INFO Connected all rings
0: l50039:1056045:1056289 [0] NCCL INFO Connected all trees
0: l50039:1056045:1056289 [0] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
0: l50039:1056045:1056289 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
0: l50039:1056045:1056289 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
0: l50039:1056045:1056289 [0] NCCL INFO ncclCommInitRank comm 0x55555f269260 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 3000 commId 0xf7a4e328593d6ba5 - Init COMPLETE
0: with_ddp : True
0: num_accs_per_task : 4
0: par_rank : 0
0: par_size : 1
0: fields : [['velocity_u', [1, 1024, ['velocity_v', 'temperature'], 0, ['j8dwr5qj', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.1, 0, 0, 0]], ['velocity_v', [1, 1024, ['velocity_u', 'temperature'], 1, ['0tlnm5up', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.1, 0, 0, 0]], ['specific_humidity', [1, 1024, ['velocity_u', 'velocity_v', 'temperature'], 2, ['v63l01zu', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.1, 0, 0, 0]], ['velocity_z', [1, 1024, ['velocity_u', 'velocity_v', 'temperature'], 3, ['9l1errbo', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.1, 0, 0, 0]], ['temperature', [1, 1024, ['velocity_u', 'velocity_v', 'specific_humidity'], 3, ['7ojls62c', -2]], [96, 105, 114, 123, 137], [12, 2, 4], [3, 27, 27], [0.1, 0, 0, 0], 'Local'], ['total_precip', [1, 1024, ['velocity_u', 'velocity_v', 'velocity_z', 'specific_humidity'], 0], [0], [12, 6, 12], [3, 9, 9], [1, 0, 0, 0]]]
0: fields_prediction : [['velocity_u', 0.0], ['velocity_v', 0.0], ['specific_humidity', 0.0], ['velocity_z', 0.0], ['temperature', 0.0], ['total_precip', 1.0]]
0: fields_targets : ['total_precip']
0: years_train : [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]
0: years_val : [2021]
0: month : None
0: geo_range_sampling : [[70.0, 90.0], [0.0, 360.0]]
0: time_sampling : 1
0: torch_seed : 5521420987310380410
0: batch_size_validation : 1
0: batch_size : 96
0: num_epochs : 50
0: num_samples_per_epoch : 480
0: num_samples_validate : 96
0: num_loader_workers : 5
0: size_token_info : 8
0: size_token_info_net : 16
0: grad_checkpointing : True
0: with_cls : False
0: with_mixed_precision : True
0: with_layernorm : True
0: coupling_num_heads_per_field : 1
0: dropout_rate : 0.05
0: with_qk_lnorm : True
0: encoder_num_layers : 6
0: encoder_num_heads : 16
0: encoder_num_mlp_layers : 2
0: encoder_att_type : dense
0: decoder_num_layers : 6
0: decoder_num_heads : 16
0: decoder_num_mlp_layers : 2
0: decoder_self_att : False
0: decoder_cross_att_ratio : 0.5
0: decoder_cross_att_rate : 1.0
0: decoder_att_type : dense
0: net_tail_num_nets : 16
0: net_tail_num_layers : 0
0: losses : ['mse_ensemble']
0: optimizer_zero : False
0: lr_start : 1e-05
0: lr_max : 2e-05
0: lr_min : 1e-05
0: weight_decay : 0.025
0: lr_decay_rate : 1.025
0: lr_start_epochs : 3
0: model_log_frequency : 256
0: BERT_strategy : forecast
0: forecast_num_tokens : 2
0: BERT_fields_synced : False
0: BERT_mr_max : 2
0: log_test_num_ranks : 0
0: save_grads : False
0: profile : False
0: test_initial : False
0: attention : False
0: rng_seed : None
0: with_wandb : True
0: slurm_job_id : 17543657
0: wandb_id : lp1k3018
0: file_path : /work/ab1412/atmorep/data/era5_y2010_2020_res25.zarr
0: n_size : [36, 13.5, 27.0]
0: model_id : wc5e2i3t
0: sparse_target : True
0: sparse_target_field : total_precip
0: sparse_target_sparsity : 0.9
0: mask_input_field : total_precip
0: mask_input_value : nan
0: years_test : [2021]
0: Available keys in the Zarr dataset: ['data', 'data_sfc', 'lats', 'lons', 'time']
0: self.ds['data'] : (105192, 7, 5, 721, 1440) :: (105192,)
0: self.lats : (721,)
0: self.lons : (1440,)
0: Available keys in the Zarr dataset: ['data', 'data_sfc', 'lats', 'lons', 'time']
0: self.ds['data'] : (105192, 7, 5, 721, 1440) :: (105192,)
0: self.lats : (721,)
0: self.lons : (1440,)
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 1
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 2
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 3
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 3
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: Loaded model id = wc5e2i3t at epoch = 0.
0: Loaded run 'wc5e2i3t' at epoch 0.
0: l50039:1056045:1056430 [1] NCCL INFO Using non-device net plugin version 0
0: l50039:1056045:1056430 [1] NCCL INFO Using network IB
0: l50039:1056045:1056430 [1] NCCL INFO ncclCommInitRank comm 0x55557511d6e0 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 44000 commId 0x199e84a1e43563be - Init START
0: l50039:1056045:1056430 [1] NCCL INFO Setting affinity for GPU 1 to 0f0000,00000000,00000000,00000000,000f0000
0: l50039:1056045:1056430 [1] NCCL INFO comm 0x55557511d6e0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 00/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 01/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 02/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 03/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 04/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 05/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 06/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 07/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 08/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 09/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 10/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 11/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 12/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 13/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 14/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 15/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 16/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 17/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 18/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 19/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 20/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 21/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 22/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 23/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 24/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 25/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 26/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 27/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 28/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 29/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 30/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Channel 31/32 :    0
0: l50039:1056045:1056430 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
0: l50039:1056045:1056430 [1] NCCL INFO P2P Chunksize set to 131072
0: l50039:1056045:1056430 [1] NCCL INFO Connected all rings
0: l50039:1056045:1056430 [1] NCCL INFO Connected all trees
0: l50039:1056045:1056430 [1] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
0: l50039:1056045:1056430 [1] NCCL INFO ncclCommInitRank comm 0x55557511d6e0 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 44000 commId 0x199e84a1e43563be - Init COMPLETE
0: l50039:1056045:1056435 [2] NCCL INFO Using non-device net plugin version 0
0: l50039:1056045:1056435 [2] NCCL INFO Using network IB
0: l50039:1056045:1056435 [2] NCCL INFO ncclCommInitRank comm 0x55557eb2d4e0 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 84000 commId 0x4ece9f777dc5063c - Init START
0: l50039:1056045:1056435 [2] NCCL INFO Setting affinity for GPU 2 to 1f0000,00000000,00000000,00000000,001f0000,00000000,00000000,00000000
0: l50039:1056045:1056435 [2] NCCL INFO comm 0x55557eb2d4e0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 00/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 01/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 02/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 03/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 04/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 05/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 06/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 07/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 08/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 09/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 10/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 11/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 12/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 13/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 14/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 15/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 16/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 17/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 18/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 19/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 20/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 21/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 22/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 23/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 24/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 25/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 26/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 27/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 28/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 29/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 30/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Channel 31/32 :    0
0: l50039:1056045:1056435 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
0: l50039:1056045:1056435 [2] NCCL INFO P2P Chunksize set to 131072
0: l50039:1056045:1056435 [2] NCCL INFO Connected all rings
0: l50039:1056045:1056435 [2] NCCL INFO Connected all trees
0: l50039:1056045:1056435 [2] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
0: l50039:1056045:1056435 [2] NCCL INFO ncclCommInitRank comm 0x55557eb2d4e0 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 84000 commId 0x4ece9f777dc5063c - Init COMPLETE
0: l50039:1056045:1056440 [3] NCCL INFO Using non-device net plugin version 0
0: l50039:1056045:1056440 [3] NCCL INFO Using network IB
0: l50039:1056045:1056440 [3] NCCL INFO ncclCommInitRank comm 0x5555876fb580 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId c4000 commId 0x6ebeeba59ecfac2a - Init START
0: l50039:1056045:1056440 [3] NCCL INFO Setting affinity for GPU 3 to 0f0000,00000000,00000000,00000000,000f0000,00000000,00000000
0: l50039:1056045:1056440 [3] NCCL INFO comm 0x5555876fb580 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 00/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 01/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 02/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 03/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 04/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 05/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 06/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 07/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 08/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 09/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 10/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 11/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 12/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 13/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 14/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 15/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 16/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 17/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 18/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 19/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 20/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 21/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 22/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 23/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 24/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 25/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 26/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 27/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 28/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 29/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 30/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Channel 31/32 :    0
0: l50039:1056045:1056440 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
0: l50039:1056045:1056440 [3] NCCL INFO P2P Chunksize set to 131072
0: l50039:1056045:1056440 [3] NCCL INFO Connected all rings
0: l50039:1056045:1056440 [3] NCCL INFO Connected all trees
0: l50039:1056045:1056440 [3] NCCL INFO 32 coll channels, 32 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
0: l50039:1056045:1056440 [3] NCCL INFO ncclCommInitRank comm 0x5555876fb580 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId c4000 commId 0x6ebeeba59ecfac2a - Init COMPLETE
0: Number of trainable parameters: 741,136,272
0: 1 : 09:50:26 :: batch_size = 96, lr = 1.5000000000000002e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 1, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2739, 0.2783, 0.2824, 0.2867, 0.2909, 0.2952, 0.2994, 0.3036, 0.3077, 0.3119, 0.3159, 0.3201, 0.3242, 0.3284,
0:         0.3324, 0.3366, 0.3407, 0.3447, 0.1113, 0.1156, 0.1197, 0.1239, 0.1281, 0.1324, 0.1366], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.0447, 1.0356, 1.0266, 1.0177, 1.0086, 0.9998, 0.9907, 0.9819, 0.9728, 0.9640, 0.9549, 0.9461, 0.9372, 0.9282,
0:         0.9193, 0.9102, 0.9014, 0.8923, 1.0889, 1.0815, 1.0743, 1.0669, 1.0597, 1.0523, 1.0451], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.5252, -0.5250, -0.5250, -0.5249, -0.5248, -0.5247, -0.5247, -0.5246, -0.5245, -0.5245, -0.5244, -0.5244,
0:         -0.5243, -0.5243, -0.5243, -0.5243, -0.5244, -0.5244, -0.5250, -0.5252, -0.5252, -0.5253, -0.5254, -0.5254,
0:         -0.5254], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1379, -0.1466, -0.1532, -0.1619, -0.1707, -0.1816, -0.1904, -0.2013, -0.2101, -0.2188, -0.2298, -0.2386,
0:         -0.2473, -0.2539, -0.2626, -0.2692, -0.2758, -0.2801, -0.3502, -0.3568, -0.3633, -0.3721, -0.3808, -0.3896,
0:         -0.3984], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([1.3512, 1.3529, 1.3546, 1.3564, 1.3579, 1.3597, 1.3610, 1.3625, 1.3638, 1.3651, 1.3664, 1.3674, 1.3683, 1.3694,
0:         1.3703, 1.3713, 1.3720, 1.3729, 1.3735, 1.3742, 1.3748, 1.3751, 1.3756, 1.3759, 1.3762], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 1, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan, -0.2284,     nan,     nan,     nan, -0.2237,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2331,     nan,     nan,     nan, -0.2331,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2319,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2331,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2190,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2331,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2331,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2307,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2331, -0.2354,     nan, -0.2307,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2213,     nan,     nan,     nan, -0.2331,
0:             nan,     nan, -0.2260,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2389,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2378,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2389,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2366,     nan,     nan,     nan, -0.2378,     nan,
0:         -0.2389,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2389,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2401,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2401])
0: [DEBUG] Epoch 1, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.0500, -0.0586, -0.0674, -0.0758, -0.0840, -0.0924, -0.0994, -0.1097, -0.1190, -0.1263, -0.1353, -0.1441,
0:         -0.1505, -0.1563, -0.1592, -0.1621, -0.1627, -0.1612, -0.0967, -0.1073, -0.1190, -0.1292, -0.1394, -0.1495,
0:         -0.1598], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.3837, 0.3614, 0.3431, 0.3263, 0.3090, 0.2986, 0.2881, 0.2778, 0.2689, 0.2640, 0.2542, 0.2475, 0.2407, 0.2365,
0:         0.2396, 0.2445, 0.2551, 0.2607, 0.2706, 0.2431, 0.2276, 0.2120, 0.1999, 0.1905, 0.1847], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.4767, -0.4778, -0.4818, -0.4824, -0.4864, -0.4893, -0.4932, -0.4946, -0.4961, -0.4951, -0.4930, -0.4902,
0:         -0.4885, -0.4865, -0.4859, -0.4864, -0.4882, -0.4905, -0.4817, -0.4831, -0.4851, -0.4863, -0.4898, -0.4937,
0:         -0.4951], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.0464, -0.0727, -0.0638, -0.0437, -0.0285, -0.0184, -0.0396, -0.0492, -0.0149, -0.0054, -0.0040,  0.0435,
0:          0.0460,  0.0052, -0.0172, -0.0328, -0.0048,  0.0641,  0.0125,  0.0066,  0.0110,  0.0185,  0.0197,  0.0238,
0:         -0.0038], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([2.3929, 2.3981, 2.4025, 2.4000, 2.3967, 2.3996, 2.4048, 2.4063, 2.4067, 2.4039, 2.4013, 2.4025, 2.4103, 2.4130,
0:         2.4138, 2.4080, 2.4051, 2.4050, 2.4090, 2.4139, 2.4187, 2.4216, 2.4227, 2.4260, 2.4231], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.05448943004012108; velocity_v: 0.09274062514305115; specific_humidity: 0.04173935949802399; velocity_z: 0.5832030177116394; temperature: 0.10881241410970688; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05804161727428436; velocity_v: 0.09092727303504944; specific_humidity: 0.04018343985080719; velocity_z: 0.396676242351532; temperature: 0.09268917888402939; total_precip: nan; 
0: epoch: 1 [1/5 (20%)]	Loss: nan : nan :: 0.14747 (1.82 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05762827768921852; velocity_v: 0.09163583815097809; specific_humidity: 0.030728762969374657; velocity_z: 0.396011084318161; temperature: 0.07173769921064377; total_precip: nan; 
0: epoch: 1 [2/5 (40%)]	Loss: nan : nan :: 0.14673 (16.11 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.054189059883356094; velocity_v: 0.09818455576896667; specific_humidity: 0.04232575371861458; velocity_z: 0.4666786193847656; temperature: 0.11689773947000504; total_precip: nan; 
0: epoch: 1 [3/5 (60%)]	Loss: nan : nan :: 0.14298 (16.07 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.0567813478410244; velocity_v: 0.09362807869911194; specific_humidity: 0.03412002697587013; velocity_z: 0.4235001802444458; temperature: 0.08450882136821747; total_precip: nan; 
0: epoch: 1 [4/5 (80%)]	Loss: nan : nan :: 0.14131 (16.07 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [4.27246094e-04 2.83241272e-04 1.84059143e-04 1.13487244e-04
0:  7.43865967e-05 4.29153442e-05 2.57492065e-05 1.43051147e-05
0:  6.67572021e-06 3.81469727e-06 9.53674316e-07 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 9.53674316e-07 9.53674316e-07 9.53674316e-07
0:  2.86102295e-06 5.72204590e-06 8.58306885e-06 9.53674316e-06
0:  9.53674316e-06 7.62939453e-06 7.62939453e-06 8.58306885e-06
0:  1.23977661e-05 1.71661377e-05 1.05857849e-04 1.62124634e-04
0:  1.16348267e-04 8.10623169e-05 4.57763672e-05 6.58035278e-05
0:  9.44137573e-05 1.69754028e-04 1.85966492e-04 8.96453857e-05
0:  1.08718872e-04 1.09672546e-04 6.86645508e-05 1.21116638e-04
0:  2.00271606e-04 1.77383423e-04 1.69754028e-04 9.34600830e-05
0:  4.57763672e-05 2.86102295e-05 3.43322754e-05 8.67843628e-05
0:  1.08718872e-04 9.05990601e-05 8.77380371e-05 6.77108765e-05
0:  5.62667847e-05 9.25064087e-05 1.34468079e-04 1.50680542e-04
0:  2.56538391e-04 3.36647034e-04 4.27246094e-04 4.84466553e-04
0:  5.17845154e-04 6.56127930e-04 5.38825989e-04 1.01089478e-04
0:  5.24520874e-05 7.53402710e-05 1.01089478e-04 1.17301941e-04
0:  5.81741333e-05 3.33786011e-05 1.04904175e-05 2.09808350e-05
0:  2.19345093e-05 2.38418579e-05 4.57763672e-05 8.01086426e-05
0:  4.19616699e-05 3.24249268e-05 7.34329224e-05 6.29425049e-05
0:  7.34329224e-05 7.72476196e-05 4.48226929e-05 5.43594360e-05
0:  3.24249268e-05 3.71932983e-05 2.09808350e-05 1.14440918e-05
0:  1.23977661e-05 9.53674316e-06 5.72204590e-06 4.76837158e-06
0:  3.81469727e-06 9.53674316e-07 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.90734863e-06
0:  5.49316406e-04 3.49998474e-04 2.46047974e-04 1.60217285e-04
0:  1.04904175e-04 6.96182251e-05 4.19616699e-05 2.67028809e-05
0:  1.62124634e-05 7.62939453e-06 3.81469727e-06 1.90734863e-06
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 9.53674316e-07
0:  9.53674316e-07 1.90734863e-06 2.86102295e-06 5.72204590e-06
0:  1.14440918e-05 1.33514404e-05 1.33514404e-05 1.23977661e-05
0:  1.33514404e-05 1.71661377e-05 8.20159912e-05 1.17301941e-04
0:  1.15394592e-04 9.63211060e-05 8.01086426e-05 5.34057617e-05
0:  3.71932983e-05 3.05175781e-05 2.02178955e-04 2.77519226e-04
0:  1.90734863e-04 1.36375427e-04 9.34600830e-05 1.65939331e-04
0:  1.48773193e-04 1.00135803e-04 1.86920166e-04 2.06947327e-04
0:  1.13487244e-04 6.77108765e-05 6.86645508e-05 2.49862671e-04
0:  2.60353088e-04 1.62124634e-04 1.36375427e-04 1.01089478e-04
0:  5.14984131e-05 1.25885010e-04 2.08854675e-04 2.13623047e-04
0:  2.23159790e-04 2.21252441e-04 3.44276428e-04 4.35829163e-04
0:  5.05447388e-04 3.63349915e-04 1.89781189e-04 8.96453857e-05
0:  3.24249268e-05 4.76837158e-06 4.76837158e-06 4.76837158e-06
0:  5.72204590e-06 2.00271606e-05 3.71932983e-05 4.57763672e-05
0:  3.33786011e-05 7.62939453e-06 2.67028809e-05 4.19616699e-05
0:  5.72204590e-05 1.07765198e-04 1.47819519e-04 6.67572021e-05
0:  1.52587891e-04 3.39508057e-04 2.58445740e-04 1.61170959e-04]
0: Target values (first 200):
0: [3.71932983e-05 4.86373901e-05 5.62667847e-05 7.05718994e-05
0:  7.00950623e-05 6.72340393e-05 6.34193420e-05 6.29425049e-05
0:  6.53266907e-05 7.15255737e-05 7.72476196e-05 8.34465027e-05
0:  8.86917114e-05 9.77516174e-05 7.34329224e-05 8.86917114e-05
0:  2.15530396e-04 2.40802765e-04 2.33173370e-04 2.25067139e-04
0:  1.83582306e-04 1.62124634e-04 1.41143799e-04 1.29699707e-04
0:  1.34944916e-04 1.38759613e-04 1.38759613e-04 1.32560730e-04
0:  1.25885010e-04 1.44481659e-04 1.60217285e-04 1.74522400e-04
0:  1.85489655e-04 1.90258026e-04 1.81674957e-04 1.70230865e-04
0:  1.82151794e-04 1.49726868e-04 9.05990601e-05 7.96318054e-05
0:  7.20024109e-05 7.53402710e-05 9.29832458e-05 1.19209290e-04
0:  8.29696655e-05 5.05447388e-05 2.05039978e-05 9.53674316e-06
0:  4.76837158e-06 1.43051147e-05 1.85966492e-05 8.58306885e-06
0:  4.14848364e-05 1.16348267e-04 3.82900238e-04 6.29425049e-04
0:  8.35895538e-04 1.14107132e-03 1.36470795e-03 1.27458572e-03
0:  1.17206573e-03 1.06287014e-03 9.21249390e-04 8.21590424e-04
0:  8.59737396e-04 8.51631165e-04 7.54356384e-04 9.02652740e-04
0:  4.68254089e-04 6.17980957e-04 5.15937863e-04 6.96182251e-05
0:  5.24520874e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 9.53674316e-07
0:  1.38282776e-05 2.71797180e-05 4.52995337e-05 2.86102295e-05
0:  1.03473663e-04 1.18255615e-04 1.04904175e-04 9.34600830e-05
0:  8.53538513e-05 7.43865967e-05 6.38961792e-05 5.91278076e-05
0:  5.67436218e-05 5.57899475e-05 5.62667847e-05 5.48362732e-05
0:  5.14984131e-05 6.48498535e-05 8.15391541e-05 9.34600830e-05
0:  1.37329102e-04 2.01702118e-04 3.03268433e-04 3.18527222e-04
0:  2.03132629e-04 1.54495239e-04 1.34944916e-04 1.49726868e-04
0:  1.59740448e-04 1.64985657e-04 1.53064728e-04 1.40666962e-04
0:  1.28269196e-04 1.33991241e-04 1.47819519e-04 1.78337097e-04
0:  1.95026398e-04 2.04563141e-04 1.97887421e-04 1.81198120e-04
0:  1.51634216e-04 1.15871429e-04 8.34465027e-05 7.10487366e-05
0:  6.10351562e-05 5.29289246e-05 6.38961792e-05 6.15119934e-05
0:  4.00543213e-05 2.14576721e-05 7.15255737e-06 6.19888306e-06
0:  4.29153442e-06 1.90734863e-06 2.38418579e-06 1.14440918e-05
0:  3.24249268e-05 2.09331512e-04 4.32968140e-04 6.56604767e-04
0:  1.06525433e-03 1.59931183e-03 1.66320801e-03 1.66606903e-03
0:  1.57546997e-03 1.35278702e-03 1.13773346e-03 1.07908249e-03
0:  1.06000900e-03 1.05285656e-03 2.21347809e-03 2.27594376e-03
0:  7.46250153e-04 2.53677368e-04 6.48498535e-05 2.24113464e-05
0:  3.33786011e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]
0: Prediction values (first 20):
0: [25.921162 26.341043 26.71019  27.01974  27.261051 27.4551   27.670616
0:  27.778229 27.829863 27.77441  27.551027 27.222961 26.853197 26.445457
0:  26.106012 25.775702 25.427286 25.035316 24.128767 23.629929]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -1.144, max = 3.143, mean = 1.356
0:          sample (first 20): tensor([1.4721, 1.5047, 1.5333, 1.5574, 1.5761, 1.5912, 1.6079, 1.6163, 1.6203, 1.6160, 1.5986, 1.5732, 1.5445, 1.5128,
0:         1.4864, 1.4608, 1.4337, 1.4033, 1.4256, 1.4592])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.84781  26.768265 26.660004 26.45775  26.168125 25.817545 25.486385
0:  25.05898  24.704382 24.338493 23.889147 23.387934 22.85896  22.31084
0:  21.782682 21.297522 20.872278 20.526508 19.98101  19.637636]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.857325 25.922075 25.913458 25.797215 25.633972 25.46461  25.330334
0:  25.207718 25.157547 25.17155  25.217007 25.256613 25.304932 25.338642
0:  25.351152 25.339603 25.369644 25.410048 25.563856 25.535547]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.5632477  7.75642    7.9566755  8.121483   8.29098    8.451701
0:   8.639902   8.827887   9.069416   9.35346    9.677753  10.0064
0:  10.33404   10.663904  10.966114  11.266132  11.564913  11.853835
0:  11.99199   12.24366  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [28.305723 27.9286   27.603764 27.258883 26.877218 26.41936  25.920702
0:  25.319075 24.748571 24.175756 23.572594 22.947538 22.323336 21.72203
0:  21.113733 20.569447 20.071852 19.641127 19.935036 19.570253]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.289085 14.83345  14.330987 13.709807 13.112663 12.738822 12.686962
0:  12.929461 13.372968 13.868429 14.304731 14.597834 14.884041 15.264706
0:  15.745028 16.335066 17.002523 17.550608 18.773733 17.784637]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-18.915703 -19.093868 -19.123405 -19.057632 -19.027508 -19.139977
0:  -19.270378 -19.518028 -19.713108 -19.79884  -19.79181  -19.765541
0:  -19.697063 -19.561577 -19.446526 -19.278854 -19.151165 -19.036846
0:  -18.779808 -18.6604  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.6542826 7.658023  7.6656256 7.6743913 7.672348  7.6503215 7.6391315
0:  7.6019926 7.5804763 7.558359  7.5381103 7.5007663 7.4640026 7.422805
0:  7.3623843 7.3260746 7.302573  7.3088193 6.8765283 6.866023 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.719364  16.69382   16.604969  16.419136  16.16581   15.8459635
0:  15.45902   15.047093  14.654306  14.33104   14.1019535 13.981254
0:  13.991481  14.120007  14.3492    14.623752  14.939716  15.267092
0:  16.11109   16.1223   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.992138 17.06784  17.109108 17.101044 17.07324  17.039606 17.032654
0:  17.014776 17.024605 17.034933 17.044813 17.032219 17.021473 17.00018
0:  16.971596 16.958862 16.9716   17.01445  16.724857 16.777153]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.40181   -8.986095  -8.463053  -7.939297  -7.461987  -7.043506
0:  -6.6518645 -6.342093  -6.0981603 -5.927031  -5.862532  -5.880399
0:  -5.939961  -6.008838  -6.087869  -6.112595  -6.112491  -6.040396
0:  -6.061337  -5.784307 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.9024739 1.8193369 1.7187529 1.6294794 1.5789237 1.5229745 1.5092745
0:  1.5463395 1.6622534 1.8820033 2.1822472 2.5074587 2.834221  3.1048265
0:  3.2907383 3.4490254 3.592721  3.7673097 3.0492718 3.3142781]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.914251 12.789692 12.645121 12.437313 12.205613 11.953545 11.67093
0:  11.376112 11.075697 10.790382 10.505376 10.191734  9.890045  9.597286
0:   9.294689  9.02865   8.801473  8.621505  8.20336   8.007567]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.5396237 -1.5361724 -1.5223985 -1.5124927 -1.5239553 -1.5468845
0:  -1.5465517 -1.6045895 -1.6153193 -1.6860762 -1.7452927 -1.8218789
0:  -1.8402023 -1.8157048 -1.7784152 -1.726018  -1.6598964 -1.537734
0:  -1.8959947 -1.8812046]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -0.66810703  -1.137752    -1.6006932   -1.9985337   -2.368195
0:   -2.6851258   -2.9347987   -3.1651778   -3.403276    -3.687262
0:   -4.0623536   -4.551003    -5.136764    -5.8324275   -6.617745
0:   -7.452578    -8.277195    -8.972843   -11.048357   -11.92288   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.959482 10.121245 10.261405 10.396786 10.528754 10.673488 10.835191
0:  10.970659 11.100145 11.193554 11.240404 11.255558 11.269226 11.284965
0:  11.31728  11.369774 11.490015 11.662676 12.172182 12.511307]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.430498  -10.955679  -11.155525  -11.240213  -11.050711  -10.690485
0:  -10.329519  -10.035963   -9.927101   -9.914461   -9.825893   -9.791269
0:   -9.50724    -9.014032   -8.513512   -7.8140397  -6.9923425  -6.1357093
0:   -7.173887   -7.488932 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.25477   10.319353  10.421335  10.562525  10.6438875 10.710254
0:  10.800029  10.8130455 10.855631  10.894482  10.88188   10.824534
0:  10.743174  10.630198  10.517693  10.394257  10.254394  10.184355
0:   9.592779   9.601081 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.971695 22.05688  22.120247 22.086727 21.947634 21.718393 21.49445
0:  21.183304 20.88712  20.559952 20.17707  19.706753 19.230467 18.762007
0:  18.322834 17.96798  17.693323 17.47088  17.293259 16.995722]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.49495  23.873943 24.240551 24.547974 24.809725 24.99334  25.21333
0:  25.309744 25.44117  25.489744 25.45509  25.359041 25.212345 25.062138
0:  24.969044 24.871405 24.894043 24.948845 26.353535 26.468874]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.123042  5.1417584 5.1403055 5.1221776 5.0903416 5.0284305 4.9585834
0:  4.8574386 4.7584267 4.6939616 4.6576543 4.6300664 4.6291265 4.6635504
0:  4.6927385 4.7655635 4.869159  5.0028133 4.9972067 5.0160074]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.181379  6.2306128 6.3189864 6.4348545 6.545146  6.6407914 6.7474213
0:  6.815656  6.885565  6.969275  7.0374603 7.1249194 7.236727  7.3428316
0:  7.4593267 7.564632  7.680011  7.8130846 7.7825913 7.8646135]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.47616863 -0.2820387   0.00658035  0.36613035  0.7331319   1.0438943
0:   1.3009896   1.4532285   1.5446138   1.6213527   1.6942668   1.792903
0:   1.941812    2.154519    2.3927398   2.6531682   2.9377553   3.2702782
0:   3.5764458   3.6207314 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.766916  15.39896   15.092327  14.853748  14.7653265 14.85818
0:  15.202976  15.782564  16.60737   17.52474   18.505722  19.388308
0:  20.23427   21.04136   21.77462   22.42298   22.913172  23.193283
0:  22.614855  22.518974 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.020124   -4.0017133  -3.9867196  -3.8625789  -3.6173701  -3.3047185
0:  -2.91402    -2.5699553  -2.2547927  -1.9618783  -1.6901746  -1.4235749
0:  -1.1416392  -0.8552222  -0.5759978  -0.28139305  0.02180576  0.3352399
0:   0.56308126  0.5958543 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.227537 16.089905 15.970007 15.90024  15.911007 15.993565 16.206926
0:  16.302513 16.352453 16.27364  16.07808  15.912489 15.86833  16.081245
0:  16.49062  17.147097 17.906414 18.635633 19.823114 20.044453]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.842302  18.757689  18.534288  18.143822  17.698534  17.239613
0:  16.777822  16.350473  15.997227  15.716843  15.486448  15.237438
0:  15.010294  14.7512455 14.48189   14.252737  14.054106  13.85994
0:  13.295555  13.375132 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.274662  -7.1921005 -7.1009817 -6.9936304 -6.8725615 -6.7806787
0:  -6.659629  -6.574979  -6.467799  -6.3454895 -6.197566  -6.04659
0:  -5.8903084 -5.705636  -5.5449133 -5.3623276 -5.182481  -4.979109
0:  -5.048541  -4.8654203]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.7491808  0.7445674  0.74942017 0.76286745 0.7788234  0.7824569
0:  0.8215947  0.8397541  0.8969674  0.97846794 1.0761056  1.1983485
0:  1.356751   1.5409117  1.7320862  1.9297576  2.1158752  2.3095942
0:  2.5373406  2.7344718 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.616455  10.472013  10.277639  10.054932   9.8305235  9.635269
0:   9.496046   9.404846   9.385027   9.427506   9.522871   9.674414
0:   9.87524   10.102833  10.3113365 10.466665  10.533659  10.542374
0:  10.851434  10.843821 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.827596  11.931629  12.034917  12.105011  12.165081  12.205889
0:  12.271209  12.315746  12.383026  12.469784  12.512852  12.546291
0:  12.573711  12.559277  12.549643  12.54546   12.5943365 12.6714
0:  12.602892  12.750437 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.06959   -3.1230931 -3.118301  -3.0502057 -2.9652658 -2.8894877
0:  -2.78198   -2.7345748 -2.695538  -2.674684  -2.673306  -2.6668468
0:  -2.6043725 -2.4668489 -2.2565694 -1.9683394 -1.6766067 -1.4123445
0:  -1.404428  -1.2151637]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.43383074  0.4085741   0.37535906  0.33702707  0.27378416  0.15202427
0:   0.05523014 -0.07096863 -0.15734148 -0.20342445 -0.20796537 -0.18753624
0:  -0.13986588 -0.07218313 -0.02819538  0.02032137  0.05776215  0.07970381
0:  -0.370183   -0.37372732]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.5158825 15.522287  15.464216  15.334911  15.161557  14.949366
0:  14.737939  14.493393  14.326038  14.233939  14.230975  14.323556
0:  14.542281  14.840055  15.248964  15.717855  16.25129   16.818897
0:  17.669344  18.166332 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.164219  13.035898  12.999108  12.981233  12.966288  12.965505
0:  12.939782  12.883787  12.81126   12.680121  12.562609  12.4051285
0:  12.244497  12.108464  11.91607   11.711582  11.46247   11.222576
0:  11.022025  10.982353 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.2588859  -2.4129443  -2.5083232  -2.508202   -2.3547597  -2.1474857
0:  -1.8693185  -1.6437311  -1.4545684  -1.285944   -1.1137495  -0.95846415
0:  -0.8089123  -0.62090874 -0.48143625 -0.30174398 -0.14062738 -0.0223465
0:  -0.44401932 -0.3106165 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.774818 24.033827 24.194319 24.168674 24.079609 23.943329 23.813248
0:  23.65225  23.531107 23.40921  23.262386 23.071062 22.851528 22.643875
0:  22.397703 22.183865 21.97868  21.732647 21.528625 21.658758]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.693565 22.36804  21.987495 21.532038 20.962065 20.32019  19.670206
0:  18.944294 18.293531 17.730318 17.209248 16.836208 16.63959  16.5465
0:  16.616283 16.736145 16.880787 17.010166 16.89457  16.94222 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.0028558  1.9874487  1.9901662  1.8743095  1.6900992  1.4011278
0:   1.030199   0.5777588  0.0217948 -0.595304  -1.2468057 -1.9329295
0:  -2.5618072 -3.1030316 -3.6887097 -4.3161836 -5.1029677 -5.9596057
0:  -8.0403805 -8.415232 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.0680203  -2.17668    -2.1497283  -1.9593544  -1.6564784  -1.3247533
0:  -0.9456382  -0.6303115  -0.2958536   0.02577972  0.38815498  0.82163525
0:   1.3845448   1.9806428   2.5787597   3.1177776   3.5198324   3.8603277
0:   3.9041848   4.090047  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.3456807  0.5129509  0.67119217 0.81811905 0.99959564 1.1722088
0:  1.3645048  1.539434   1.7305865  1.938559   2.1720042  2.4020033
0:  2.6306548  2.8737955  3.0776515  3.300689   3.5636117  3.8665435
0:  4.260118   4.462593  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.995605 12.189772 12.391149 12.569363 12.7283   12.891486 13.028761
0:  13.109491 13.180922 13.261963 13.326254 13.345507 13.398386 13.435732
0:  13.506643 13.63007  13.844169 14.123383 14.006803 14.336857]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.884687  8.829022  8.850403  8.871227  8.867251  8.861371  8.820646
0:  8.742737  8.708416  8.666833  8.629023  8.5872135 8.570677  8.59446
0:  8.603391  8.608704  8.615115  8.64126   9.0117235 9.186188 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.199827   5.629983   6.20438    6.9004292  7.7486496  8.5981865
0:   9.455093  10.192857  10.791924  11.2066345 11.352289  11.232983
0:  10.9441805 10.641485  10.403259  10.363588  10.563209  10.854127
0:  10.920588  11.164452 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-14.2733965 -14.380521  -14.474427  -14.476573  -14.435851  -14.442132
0:  -14.405534  -14.481946  -14.632394  -14.784167  -14.928393  -15.0476885
0:  -15.131429  -15.159392  -15.133594  -15.039088  -14.937093  -14.697753
0:  -14.622207  -14.498208 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.5294948 -2.6736264 -2.710525  -2.668013  -2.5999389 -2.5876975
0:  -2.6348052 -2.824555  -3.0720105 -3.3670373 -3.6462054 -3.9132276
0:  -4.1169305 -4.2122664 -4.257088  -4.2139897 -4.1520085 -4.071053
0:  -4.290832  -4.273724 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.0880833 -2.1599789 -2.276246  -2.482933  -2.75066   -3.0959682
0:  -3.4101162 -3.721651  -3.9814682 -4.1865396 -4.3428497 -4.4926195
0:  -4.6081247 -4.6525497 -4.702715  -4.7012777 -4.7090473 -4.7294054
0:  -5.2698126 -5.4881697]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.0224924 6.0588264 6.0988007 6.119641  6.143969  6.1413264 6.1412005
0:  6.121793  6.120945  6.1465287 6.1737022 6.171125  6.1611066 6.1383653
0:  6.081554  6.063772  6.0740294 6.1024995 6.0414877 6.145698 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.460329  -5.1875916 -4.9076157 -4.626973  -4.3898153 -4.2479067
0:  -4.1348276 -4.0801744 -4.022085  -3.9255524 -3.7773323 -3.5821466
0:  -3.2967682 -3.0105562 -2.6958485 -2.395337  -2.1352654 -1.8197098
0:  -1.862061  -1.4364576]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.4208584 7.5011826 7.569803  7.546222  7.3529205 6.932679  6.372179
0:  5.578865  4.6726136 3.758608  2.881894  2.1388311 1.6815238 1.5430026
0:  1.7475386 2.3386672 3.1458461 4.084705  6.0925803 6.643143 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.6601906  -3.0653849  -3.4616585  -3.8100767  -4.142744   -4.4484673
0:  -4.6326876  -4.739683   -4.661216   -4.4103518  -4.00618    -3.4995604
0:  -2.855774   -2.2096052  -1.5576715  -0.93295    -0.3773899   0.10794449
0:  -0.07722139  0.07020998]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.2470536   1.043675    0.7516794   0.41117287 -0.01010323 -0.54689264
0:  -1.1698294  -1.9199715  -2.7065825  -3.4986577  -4.251474   -4.98103
0:  -5.6352725  -6.1863008  -6.700522   -7.0937037  -7.3928304  -7.612249
0:  -8.077528   -7.97432   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.3581567 6.6803684 7.0398655 7.4159575 7.80598   8.184475  8.546303
0:  8.815598  9.001049  9.102196  9.111543  9.066252  8.984468  8.901958
0:  8.855095  8.848154  8.90249   9.021414  8.47307   8.543569 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.5883908 2.3959737 2.2572331 2.1589718 2.0793762 1.9831862 1.9095702
0:  1.818553  1.7972202 1.8020649 1.8333015 1.8311167 1.8379102 1.8564205
0:  1.8626838 1.9379773 2.0674891 2.2327437 1.9520321 2.0937629]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -8.005526   -8.100796   -8.206827   -8.321821   -8.469471   -8.718798
0:   -8.909723   -9.156282   -9.352926   -9.528589   -9.7199135  -9.970528
0:  -10.232431  -10.460695  -10.69385   -10.805241  -10.919075  -10.976599
0:  -11.71525   -11.791811 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.33884907 -0.2893901  -0.25543833 -0.23363066 -0.22581434 -0.25801086
0:  -0.27296972 -0.335526   -0.38837767 -0.43531084 -0.49708843 -0.5869279
0:  -0.7086539  -0.8370962  -1.0163422  -1.1846886  -1.3476105  -1.4557133
0:  -1.7330465  -1.6460371 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.586427 14.852496 15.174412 15.511745 15.877644 16.242903 16.644566
0:  17.015116 17.41911  17.865555 18.348967 18.778278 19.183584 19.533827
0:  19.81487  20.10162  20.400005 20.742754 20.577805 20.780579]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.9157147 7.1130466 7.381675  7.6997685 7.9797063 8.255618  8.509075
0:  8.674813  8.79251   8.860796  8.8535385 8.837383  8.837477  8.817687
0:  8.859783  8.890648  8.957392  9.126201  8.557785  8.6779585]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.4654813 6.5832853 6.651993  6.620942  6.586243  6.5304985 6.4698534
0:  6.391343  6.311585  6.233659  6.1744328 6.1018763 6.0402946 5.9980354
0:  5.915002  5.8645754 5.8174105 5.7714686 5.5573244 5.499051 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.754834  -5.7322435 -5.719717  -5.7260294 -5.733547  -5.7648735
0:  -5.7535276 -5.784999  -5.7999554 -5.7988415 -5.81686   -5.849677
0:  -5.8701477 -5.8868513 -5.8990173 -5.8647537 -5.826391  -5.764488
0:  -5.834215  -5.7668095]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.059828 20.122904 20.312042 20.60637  20.958666 21.232544 21.544064
0:  21.571764 21.580519 21.44761  21.184885 20.965372 20.843569 20.739147
0:  20.699305 20.713503 20.683819 20.643135 19.739813 19.676355]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.3524704 5.300142  5.242748  5.1270957 5.012894  4.853897  4.693702
0:  4.4872704 4.325212  4.2178245 4.193816  4.225793  4.331642  4.5103455
0:  4.717923  5.016522  5.3904667 5.8170867 6.629325  6.7528048]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [28.901897 28.887714 28.981146 29.005575 28.966679 28.782326 28.481138
0:  27.98734  27.448023 26.78045  26.043083 25.199144 24.231134 23.051056
0:  21.574816 19.97582  18.312689 16.793444 14.148954 13.918097]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.723728   8.819675   8.974066   9.19306    9.457964   9.676399
0:   9.870819   9.97201   10.014002   9.990868   9.922611   9.794397
0:   9.632448   9.456256   9.2213335  8.962302   8.702304   8.422877
0:   7.26379    6.7613096]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.2893205 -3.5252624 -3.6520934 -3.658957  -3.5344787 -3.349895
0:  -3.0829778 -2.9242473 -2.8302655 -2.8005948 -2.7750459 -2.731956
0:  -2.5544705 -2.1989703 -1.8033128 -1.3882928 -1.1242881 -1.0386109
0:  -2.9975991 -3.4823642]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.275906 24.853184 24.163115 23.184744 22.035458 20.795301 19.569572
0:  18.420431 17.461506 16.696266 16.08079  15.585642 15.191874 14.857267
0:  14.530008 14.242329 14.024084 13.890425 13.765698 13.787163]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.277854  8.439101  8.568862  8.664655  8.696732  8.642636  8.528201
0:  8.36245   8.174886  8.023813  7.9048448 7.838374  7.8400717 7.8986893
0:  8.029628  8.231923  8.500652  8.791815  9.256783  9.340372 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.719683  -8.61694   -8.344358  -8.00997   -7.635535  -7.277928
0:  -6.983745  -6.762427  -6.556124  -6.384707  -6.174669  -6.010308
0:  -5.8377175 -5.6610713 -5.5075517 -5.34833   -5.1660733 -4.9134526
0:  -4.879767  -4.8095374]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.4855657 -7.4195294 -7.338712  -7.2642627 -7.180492  -7.1238303
0:  -7.0695558 -7.050546  -7.028749  -7.0002713 -6.9628997 -6.95149
0:  -6.9427285 -6.9108768 -6.907717  -6.866878  -6.786903  -6.6617103
0:  -6.71664   -6.6323085]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.2943816 -4.271853  -4.220165  -4.164662  -4.1049075 -4.1040597
0:  -4.083431  -4.0967546 -4.06233   -3.966436  -3.8183103 -3.656898
0:  -3.4892535 -3.3056064 -3.1677508 -3.0050426 -2.8420177 -2.6989646
0:  -2.9594607 -2.9248948]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.018046  -4.999972  -4.9037995 -4.6855617 -4.4306197 -4.1893153
0:  -3.8942027 -3.6646419 -3.4290195 -3.211165  -3.0164866 -2.847402
0:  -2.659906  -2.4484544 -2.229796  -2.0110583 -1.8654971 -1.7138009
0:  -1.3472137 -1.3017578]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.6793585 15.074139  15.504733  15.924898  16.354351  16.77074
0:  17.174692  17.531992  17.91665   18.270084  18.66565   19.0148
0:  19.394108  19.742044  20.020178  20.279148  20.530052  20.773645
0:  21.643528  22.025248 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-18.573553 -18.483011 -18.441887 -18.226116 -18.028349 -17.90257
0:  -17.657785 -17.55024  -17.488678 -17.36653  -17.266819 -17.141985
0:  -16.978136 -16.784964 -16.552536 -16.32315  -16.12754  -15.908588
0:  -16.744164 -16.626284]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.834511 11.50989  11.162411 10.696266 10.330861  9.897486  9.683147
0:   9.561409  9.924927 10.431421 11.128498 11.899546 12.602373 13.162572
0:  13.468136 13.574001 13.42868  13.187363 10.560671 10.584703]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.690258 14.007276 14.314556 14.60075  14.890052 15.170038 15.42602
0:  15.591595 15.708126 15.806795 15.888592 15.948212 16.028559 16.061804
0:  16.072071 16.06388  16.117495 16.225422 16.173296 16.074625]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.6374307 -5.5837874 -5.435806  -5.211081  -4.9248834 -4.6187005
0:  -4.302916  -4.048325  -3.8153605 -3.6400228 -3.5052161 -3.4555163
0:  -3.4756675 -3.5338693 -3.6937394 -3.9016223 -4.123799  -4.314854
0:  -5.019402  -4.9648976]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.47271  13.429031 13.427542 13.409359 13.392376 13.335006 13.232441
0:  13.061403 12.871588 12.646906 12.413905 12.148193 11.907021 11.722742
0:  11.5536   11.4454   11.342663 11.258666 11.13486  11.189098]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.92062  18.055607 18.213848 18.360817 18.571278 18.839073 19.158512
0:  19.480377 19.878822 20.300549 20.73474  21.108067 21.460934 21.764494
0:  21.940823 22.049948 22.186825 22.32931  22.466003 22.615776]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.043957 16.10498  16.201366 16.261948 16.322773 16.3698   16.388763
0:  16.394976 16.412346 16.472464 16.582352 16.708614 16.866102 17.044193
0:  17.237816 17.475687 17.781998 18.133913 18.994705 19.387804]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.175071  -4.03876   -3.9560337 -3.8767042 -3.766718  -3.7240992
0:  -3.6113815 -3.5446558 -3.4775152 -3.4005995 -3.3299417 -3.2960367
0:  -3.2518778 -3.203188  -3.1736908 -3.0767288 -2.9940243 -2.859146
0:  -3.0960655 -2.985282 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.197254  6.0338507 5.8899136 5.7596974 5.603674  5.4289374 5.2706876
0:  5.0857553 4.957263  4.7892356 4.6136246 4.3766546 4.142522  3.8890688
0:  3.6373894 3.395102  3.1771507 2.9976034 2.4165616 2.2056708]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.235088   9.254344   9.22464    9.163047   9.051588   8.950552
0:   8.866049   8.7666     8.697392   8.658704   8.6300125  8.617966
0:   8.669842   8.761047   8.934593   9.13591    9.385499   9.666846
0:  10.156619  10.437821 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.422443  18.18917   17.949574  17.642614  17.299824  16.926678
0:  16.536692  16.141258  15.796204  15.509483  15.247301  15.005878
0:  14.763272  14.520521  14.25928   14.015005  13.80109   13.63649
0:  12.9880705 12.797471 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.7768092  -2.7307706  -2.6348662  -2.5034757  -2.3576846  -2.2159963
0:  -2.0849042  -1.9848313  -1.8750081  -1.7447114  -1.5781093  -1.4264855
0:  -1.2702413  -1.1190629  -1.0257001  -0.9530978  -0.92826986 -0.891767
0:  -1.3308158  -1.3270354 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.529908  -8.405409  -8.276508  -8.175395  -8.098608  -8.07974
0:  -8.051429  -8.077086  -8.087784  -8.1091175 -8.137221  -8.185828
0:  -8.22263   -8.249272  -8.321694  -8.369174  -8.432732  -8.447069
0:  -8.921126  -8.92584  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -8.893687  -8.844871  -8.751464  -8.660938  -8.570705  -8.567671
0:   -8.596288  -8.69576   -8.847127  -8.997916  -9.151416  -9.339875
0:   -9.521979  -9.680474  -9.859122  -9.973361 -10.036548 -10.040833
0:  -10.601813 -10.604102]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.5340686  1.8837442  2.4342446  3.232607   4.29331    5.5318327
0:   6.909807   8.231062   9.474302  10.533019  11.434768  12.163572
0:  12.824028  13.411161  13.922106  14.345599  14.658447  14.85191
0:  15.078612  15.269661 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.4512987 4.683344  4.8935337 5.0353584 5.1640725 5.249136  5.3394537
0:  5.4218125 5.524152  5.6506824 5.782007  5.892167  6.01687   6.1257668
0:  6.243053  6.392374  6.5858536 6.814381  7.1678495 7.5143886]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.249401 15.304046 15.392126 15.4721   15.563809 15.660591 15.806415
0:  15.934605 16.14806  16.347992 16.496056 16.57836  16.621254 16.675991
0:  16.736567 16.879602 17.119726 17.409607 18.524294 18.402561]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.168345  -10.491143  -10.8050375 -11.058438  -11.217505  -11.35119
0:  -11.367267  -11.385798  -11.32022   -11.164283  -10.892455  -10.565993
0:  -10.177705   -9.7035265  -9.297873   -8.896022   -8.61875    -8.541477
0:   -9.255364   -9.379668 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.855685  -5.7168264 -5.485387  -5.2186766 -4.9071455 -4.6178074
0:  -4.331689  -4.0937366 -3.887786  -3.7165651 -3.5861683 -3.5273209
0:  -3.549282  -3.6500082 -3.8860083 -4.1963778 -4.5770836 -4.9828157
0:  -6.664321  -6.9570217]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.276878 22.259901 22.038923 21.5943   21.067781 20.498348 19.963118
0:  19.481379 19.09693  18.832533 18.64039  18.443445 18.229795 18.006506
0:  17.738125 17.494873 17.2712   17.037552 16.716352 16.653028]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.0884895   3.1224458   3.1782787   3.1762886   3.120315    2.9499812
0:   2.6941533   2.3337836   1.9430208   1.5399413   1.1135993   0.62889194
0:   0.12322617 -0.37324333 -0.8815241  -1.3127937  -1.6882687  -2.0009146
0:  -2.6794462  -2.9489317 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -8.38685    -8.259844   -8.190914   -8.286636   -8.532158   -8.929199
0:   -9.357672   -9.837225  -10.262964  -10.628628  -10.939211  -11.2345085
0:  -11.477381  -11.635557  -11.764551  -11.808418  -11.817326  -11.811422
0:  -12.352013  -12.357485 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.4654293 1.5723062 1.6423349 1.7105012 1.7634988 1.7904592 1.8232722
0:  1.8315358 1.8642297 1.9187965 1.9900565 2.0663023 2.1454778 2.226602
0:  2.285818  2.3453288 2.4139967 2.5149293 2.5066128 2.6181974]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.894749  -5.9699807 -5.9833283 -5.904925  -5.719929  -5.505983
0:  -5.2448297 -5.0436463 -4.890491  -4.748135  -4.610562  -4.483505
0:  -4.3407397 -4.1272197 -3.9179797 -3.6310372 -3.3267112 -3.075791
0:  -2.5485568 -2.3708081]
0: validation loss for strategy=forecast at epoch 1 : nan
0: validation loss for velocity_u : 0.03351373225450516
0: validation loss for velocity_v : 0.06433255225419998
0: validation loss for specific_humidity : 0.0254441499710083
0: validation loss for velocity_z : 0.4373336732387543
0: validation loss for temperature : 0.0623546801507473
0: validation loss for total_precip : nan
0: 2 : 09:54:32 :: batch_size = 96, lr = 2e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 2, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.4948, -1.4947, -1.4944, -1.4941, -1.4938, -1.4935, -1.4930, -1.4927, -1.4922, -1.4918, -1.4913, -1.4909,
0:         -1.4902, -1.4896, -1.4892, -1.4884, -1.4878, -1.4872, -1.4875, -1.4864, -1.4852, -1.4841, -1.4829, -1.4819,
0:         -1.4806], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.7941, -0.7881, -0.7821, -0.7761, -0.7702, -0.7642, -0.7582, -0.7522, -0.7462, -0.7402, -0.7344, -0.7284,
0:         -0.7224, -0.7164, -0.7106, -0.7047, -0.6989, -0.6931, -0.7231, -0.7169, -0.7104, -0.7040, -0.6978, -0.6914,
0:         -0.6852], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6711, -0.6711, -0.6712, -0.6712, -0.6712, -0.6713, -0.6713, -0.6713, -0.6713, -0.6714, -0.6714, -0.6715,
0:         -0.6715, -0.6715, -0.6716, -0.6716, -0.6717, -0.6717, -0.6712, -0.6712, -0.6712, -0.6713, -0.6713, -0.6714,
0:         -0.6714], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.1776, 0.1799, 0.1821, 0.1844, 0.1866, 0.1889, 0.1934, 0.1979, 0.2002, 0.2047, 0.2092, 0.2137, 0.2182, 0.2204,
0:         0.2249, 0.2272, 0.2294, 0.2317, 0.2835, 0.2835, 0.2857, 0.2857, 0.2857, 0.2880, 0.2880], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0.9245, -0.9249, -0.9253, -0.9254, -0.9258, -0.9261, -0.9265, -0.9269, -0.9271, -0.9272, -0.9275, -0.9278,
0:         -0.9282, -0.9285, -0.9288, -0.9291, -0.9291, -0.9294, -0.9297, -0.9300, -0.9300, -0.9303, -0.9304, -0.9307,
0:         -0.9307], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 2, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([-0.2426,     nan,     nan,     nan,     nan, -0.2426,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2415,
0:             nan,     nan,     nan,     nan, -0.2415,     nan,     nan,     nan,     nan, -0.2415,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2426,     nan,     nan,
0:             nan,     nan,     nan, -0.2426,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2380,     nan,     nan,     nan,     nan,     nan, -0.2380,     nan, -0.2380,
0:         -0.2356,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2426,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2426,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2415,     nan, -0.2415,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2426,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2380,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2356, -0.2356,     nan,     nan,     nan,     nan,     nan, -0.2426,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2426,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2415, -0.2403,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2426,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2426,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2380,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 2, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-1.6444, -1.6276, -1.6107, -1.6004, -1.5969, -1.6031, -1.6080, -1.6174, -1.6213, -1.6191, -1.6118, -1.6073,
0:         -1.5979, -1.5916, -1.5950, -1.5946, -1.5988, -1.6014, -1.5485, -1.5404, -1.5285, -1.5206, -1.5188, -1.5206,
0:         -1.5247], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.3330, -0.3328, -0.3343, -0.3354, -0.3313, -0.3232, -0.3105, -0.2980, -0.2854, -0.2830, -0.2869, -0.2924,
0:         -0.2981, -0.3010, -0.3017, -0.2952, -0.2871, -0.2753, -0.3259, -0.3237, -0.3240, -0.3248, -0.3222, -0.3176,
0:         -0.3088], device='cuda:1', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.7076, -0.7071, -0.7078, -0.7041, -0.7045, -0.7031, -0.7031, -0.7014, -0.7016, -0.7019, -0.6997, -0.6983,
0:         -0.6972, -0.6970, -0.6987, -0.7013, -0.7045, -0.7066, -0.7102, -0.7110, -0.7097, -0.7083, -0.7054, -0.7039,
0:         -0.7011], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.4439, 0.4243, 0.4504, 0.4783, 0.5042, 0.5134, 0.5245, 0.5372, 0.5260, 0.4993, 0.4783, 0.5042, 0.5498, 0.5475,
0:         0.5225, 0.5169, 0.5252, 0.5135, 0.4163, 0.3826, 0.4076, 0.4247, 0.4304, 0.4152, 0.3947], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([-0.1550, -0.1508, -0.1447, -0.1415, -0.1395, -0.1420, -0.1437, -0.1442, -0.1443, -0.1453, -0.1489, -0.1543,
0:         -0.1565, -0.1539, -0.1476, -0.1419, -0.1403, -0.1448, -0.1505, -0.1536, -0.1535, -0.1505, -0.1470, -0.1460,
0:         -0.1472], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.04606270045042038; velocity_v: 0.08601897209882736; specific_humidity: 0.04443105310201645; velocity_z: 0.4594050943851471; temperature: 0.12688912451267242; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.048701897263526917; velocity_v: 0.07984497398138046; specific_humidity: 0.03752181679010391; velocity_z: 0.4171038269996643; temperature: 0.09667930006980896; total_precip: nan; 
0: epoch: 2 [1/5 (20%)]	Loss: nan : nan :: 0.13832 (2.77 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05347411707043648; velocity_v: 0.08561632037162781; specific_humidity: 0.03714042901992798; velocity_z: 0.5277015566825867; temperature: 0.08798681944608688; total_precip: nan; 
0: epoch: 2 [2/5 (40%)]	Loss: nan : nan :: 0.13879 (16.00 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.055733826011419296; velocity_v: 0.09547437727451324; specific_humidity: 0.0366714745759964; velocity_z: 0.5373618006706238; temperature: 0.0959012508392334; total_precip: nan; 
0: epoch: 2 [3/5 (60%)]	Loss: nan : nan :: 0.14329 (16.14 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06950676441192627; velocity_v: 0.0972428172826767; specific_humidity: 0.04187279939651489; velocity_z: 0.5558164119720459; temperature: 0.11866337060928345; total_precip: nan; 
0: epoch: 2 [4/5 (80%)]	Loss: nan : nan :: 0.15821 (16.36 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [4.29153442e-05 3.52859497e-05 2.76565552e-05 1.33514404e-05
0:  5.72204590e-06 5.72204590e-06 8.58306885e-06 1.33514404e-05
0:  2.28881836e-05 2.86102295e-05 4.57763635e-05 5.81741333e-05
0:  7.34329224e-05 9.91821289e-05 1.17301941e-04 2.20298767e-04
0:  3.20434599e-04 4.18663025e-04 5.49316406e-04 6.25610352e-04
0:  6.80923462e-04 6.54220581e-04 5.99861145e-04 5.10215759e-04
0:  3.77655029e-04 2.57492065e-04 2.43186951e-04 2.26020813e-04
0:  4.32968140e-04 2.75611877e-04 3.71932983e-05 5.24520874e-05
0:  6.38961792e-05 6.86645508e-05 3.91006470e-05 3.52859497e-05
0:  3.43322754e-05 3.43322754e-05 3.52859497e-05 3.43322754e-05
0:  3.43322754e-05 3.52859497e-05 3.91006470e-05 6.38961792e-05
0:  1.03950500e-04 1.59263611e-04 2.16484070e-04 2.91824341e-04
0:  3.52859497e-04 4.38690186e-04 5.04493713e-04 7.78198242e-04
0:  9.11712646e-04 9.25064087e-04 8.90731812e-04 8.09669495e-04
0:  1.32179260e-03 1.11389160e-03 8.74519348e-04 9.44137515e-04
0:  1.00326538e-03 7.98225403e-04 5.44548035e-04 4.99725342e-04
0:  4.52995300e-04 3.77655029e-04 3.02314758e-04 2.16484070e-04
0:  1.55448914e-04 9.63211060e-05 6.29425049e-05 3.14712524e-05
0:  1.71661377e-05 5.72204590e-06 1.90734863e-06 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 4.76837158e-06 5.72204590e-06
0:  7.62939453e-06 1.52587891e-05 1.04904175e-05 7.62939453e-06
0:  8.58306885e-06 5.72204590e-06 5.72204590e-06 4.76837158e-06
0:  7.62939453e-06 1.81198120e-05 2.57492065e-05 9.05990601e-05
0:  1.44004822e-04 1.48773193e-04 1.54495239e-04 1.08718872e-04
0:  3.52859497e-05 9.25064087e-05 1.90734863e-04 5.13076782e-04
0:  4.57763672e-04 8.86917114e-05 0.00000000e+00 0.00000000e+00
0:  7.34329224e-05 6.48498535e-05 5.05447388e-05 3.05175781e-05
0:  2.00271606e-05 1.71661377e-05 2.09808350e-05 2.09808350e-05
0:  3.81469727e-05 5.43594360e-05 8.01086426e-05 1.35421753e-04
0:  1.57356262e-04 1.89781189e-04 2.12669373e-04 3.95774841e-04
0:  5.43594360e-04 6.13212585e-04 7.53402710e-04 8.22067261e-04
0:  8.59260559e-04 8.56399536e-04 7.67707825e-04 6.98089600e-04
0:  5.60760556e-04 4.23431396e-04 3.15666228e-04 2.23159790e-04
0:  1.77383423e-04 8.58306885e-05 1.21116638e-04 1.48773193e-04
0:  1.61170959e-04 9.82284546e-05 4.57763635e-05 4.48226929e-05
0:  5.05447388e-05 5.91278076e-05 6.48498535e-05 7.24792480e-05
0:  1.02996826e-04 1.08718872e-04 1.33514404e-04 1.55448914e-04
0:  2.12669373e-04 2.71797180e-04 3.42369080e-04 3.80516052e-04
0:  4.10079956e-04 4.42504883e-04 4.72068787e-04 5.65528928e-04
0:  6.94274902e-04 8.82148743e-04 1.10721588e-03 1.68323517e-03
0:  1.73664093e-03 7.57217407e-04 7.20024109e-04 9.17434692e-04
0:  7.71522522e-04 6.21795654e-04 4.79698181e-04 4.19616699e-04
0:  3.43322783e-04 2.55584717e-04 1.79290771e-04 1.18255615e-04
0:  7.05718994e-05 4.76837195e-05 1.90734863e-05 8.58306885e-06
0:  2.86102295e-06 9.53674316e-07 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 9.53674316e-07
0:  3.81469727e-06 6.67572021e-06 1.71661377e-05 1.71661377e-05
0:  1.90734863e-05 1.52587891e-05 9.53674316e-06 9.53674316e-06
0:  1.33514404e-05 8.58306885e-06 7.62939453e-06 6.67572021e-06]
0: Target values (first 200):
0: [7.48634338e-05 4.57763635e-05 3.57627869e-05 3.29017639e-05
0:  2.90870667e-05 4.38690149e-05 6.48498535e-05 1.02519989e-04
0:  9.63211060e-05 5.19752466e-05 4.10079956e-05 4.24385071e-05
0:  3.00407410e-05 2.00271606e-05 6.53266907e-05 8.44001770e-05
0:  5.72204590e-05 8.58306885e-05 1.08718872e-04 1.03473663e-04
0:  1.01566315e-04 1.30176544e-04 1.43527985e-04 1.02519989e-04
0:  9.20295715e-05 7.20024109e-05 5.48362732e-05 2.19345093e-05
0:  1.23977661e-05 5.72204590e-06 3.81469727e-06 4.76844434e-07
0:  9.53674316e-07 4.29153442e-06 5.72204590e-06 1.43050420e-06
0:  2.38418579e-06 8.10623169e-06 3.14712524e-05 6.53266907e-05
0:  7.86781311e-05 1.09195709e-04 1.21593475e-04 1.28269196e-04
0:  1.18732452e-04 1.23023987e-04 1.21593475e-04 1.22070312e-04
0:  1.18255615e-04 1.08718872e-04 8.96453857e-05 7.91549683e-05
0:  5.48362732e-05 2.47955322e-05 1.09672546e-05 6.19888306e-06
0:  9.53674316e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 4.76844434e-07 1.43050420e-06
0:  4.29153442e-06 8.58306885e-06 4.38690149e-05 8.20159912e-05
0:  2.05516815e-04 3.19004059e-04 3.91960144e-04 5.24520874e-04
0:  6.76631927e-04 7.10010529e-04 7.40528107e-04 1.04808807e-03
0:  1.03187561e-03 6.31332397e-04 4.70161438e-04 4.81128693e-04
0:  4.94003296e-04 4.22477722e-04 3.53336334e-04 3.46660614e-04
0:  3.18050414e-04 2.89916992e-04 2.59876251e-04 2.20298767e-04
0:  1.56879425e-04 1.33037567e-04 1.23977661e-04 1.21593475e-04
0:  1.09195709e-04 1.29699707e-04 2.51293182e-04 6.35147095e-04
0:  4.84943390e-04 1.89304352e-04 8.20159912e-05 2.52723694e-05
0:  9.58442688e-05 5.67436218e-05 3.09944153e-05 2.95639038e-05
0:  1.95503235e-05 1.47819519e-05 3.05175781e-05 4.57763635e-05
0:  4.95910681e-05 4.72068787e-05 2.43186951e-05 1.33514404e-05
0:  1.66893005e-05 1.76429749e-05 1.76429749e-05 2.38418579e-05
0:  3.95774841e-05 7.62939453e-05 1.08242035e-04 1.06811523e-04
0:  1.07765198e-04 1.14917755e-04 1.12056732e-04 1.10626221e-04
0:  1.14917755e-04 1.27792358e-04 9.48905945e-05 5.38825989e-05
0:  4.19616699e-05 2.09808350e-05 1.14440918e-05 7.62939453e-06
0:  6.19888306e-06 3.33786011e-06 3.81469727e-06 3.81469727e-06
0:  3.33786011e-06 4.76837158e-06 1.00135803e-05 1.85966492e-05
0:  3.52859497e-05 8.10623169e-05 9.77516174e-05 1.02996826e-04
0:  1.20639801e-04 1.32083893e-04 1.42574310e-04 1.61170959e-04
0:  1.63555145e-04 1.49726868e-04 1.42574310e-04 1.39236450e-04
0:  1.12056732e-04 8.91685486e-05 3.71932983e-05 2.14576721e-05
0:  1.14440918e-05 1.00135803e-05 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 1.90734863e-06 1.52587891e-05 4.52995300e-05
0:  1.02043152e-04 2.29835510e-04 3.59058380e-04 5.07831573e-04
0:  7.64846802e-04 9.58442630e-04 1.08861923e-03 1.25169754e-03
0:  1.10244751e-03 9.19818878e-04 6.69479370e-04 5.68866730e-04
0:  6.26564026e-04 4.55379486e-04 2.97069550e-04 3.03745270e-04]
0: Prediction values (first 20):
0: [12.012175 11.948903 11.867384 11.811626 11.792366 11.861933 12.024185
0:  12.20718  12.508991 12.930605 13.444878 14.028323 14.735844 15.471788
0:  16.267868 17.055408 17.858679 18.602533 18.733408 19.402279]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -0.737, max = 2.613, mean = 0.859
0:          sample (first 20): tensor([0.4963, 0.4909, 0.4841, 0.4794, 0.4778, 0.4836, 0.4973, 0.5127, 0.5381, 0.5736, 0.6169, 0.6660, 0.7256, 0.7875,
0:         0.8545, 0.9208, 0.9885, 1.0511, 0.5016, 0.4990])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.5665708 -4.4902406 -4.3943257 -4.2768254 -4.162331  -4.0323844
0:  -3.8903003 -3.7548966 -3.6093602 -3.4675107 -3.32622   -3.1958175
0:  -3.0506864 -2.8804193 -2.7021632 -2.519833  -2.3640504 -2.209516
0:  -2.1767573 -1.9698033]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.0079625 2.928287  2.920954  2.9899752 3.121239  3.265661  3.4300601
0:  3.5620973 3.690957  3.8123431 3.947145  4.062586  4.199756  4.325192
0:  4.440907  4.5756435 4.744253  4.9170465 4.447858  4.578282 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.280185  -4.2764106 -4.2283273 -4.1829953 -4.1677537 -4.2444053
0:  -4.383387  -4.6050982 -4.831633  -5.0281262 -5.1185946 -5.125379
0:  -5.0298696 -4.80119   -4.5129323 -4.153314  -3.7761483 -3.4158797
0:  -3.2566009 -3.064776 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.7608466  -1.3505058  -0.96213007 -0.79212713 -0.87358713 -1.1895995
0:  -1.7158847  -2.3622127  -3.0886035  -3.8631473  -4.5991225  -5.3738923
0:  -6.049935   -6.5246015  -6.8368583  -6.8983283  -6.7881103  -6.5607057
0:  -6.7035403  -6.571964  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.897407  12.670712  12.425234  12.1672    11.944584  11.733973
0:  11.592875  11.496896  11.486979  11.540792  11.594311  11.590227
0:  11.5049515 11.354507  11.146813  10.961174  10.831087  10.759995
0:  10.771502  10.801163 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.8354545 5.9868503 6.091241  6.100949  6.125054  6.243863  6.529439
0:  6.864113  7.200658  7.492822  7.7115197 7.9136386 8.087902  8.149465
0:  7.976861  7.448035  6.5665135 5.550754  2.4092999 1.774921 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.153534 13.362987 13.672779 14.03336  14.431183 14.827948 15.170471
0:  15.459934 15.685942 15.881939 16.10182  16.341448 16.632273 16.905596
0:  17.230265 17.54038  17.875057 18.172417 18.01793  17.980047]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.9829912 -2.634922  -2.2416115 -1.9257259 -1.7070723 -1.627389
0:  -1.6395912 -1.76968   -1.9267521 -2.0969353 -2.237546  -2.4160929
0:  -2.6088924 -2.7984352 -3.03259   -3.205099  -3.3108253 -3.3338957
0:  -4.117962  -4.0728283]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.453815  13.398605  13.398217  13.350161  13.295452  13.229776
0:  13.1456585 13.029888  12.94511   12.891786  12.870924  12.814528
0:  12.771891  12.73001   12.645105  12.590574  12.580685  12.593315
0:  12.479628  12.407258 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.7432113 -4.7906632 -4.8477206 -4.888102  -4.860554  -4.781384
0:  -4.619638  -4.458732  -4.2910647 -4.155768  -4.035505  -3.954104
0:  -3.897781  -3.865025  -3.924027  -4.0276237 -4.142511  -4.2569413
0:  -5.281053  -5.3878894]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.74271  17.80431  17.859901 17.857925 17.837086 17.804205 17.796606
0:  17.724104 17.67854  17.633402 17.539633 17.398882 17.235533 17.049713
0:  16.83768  16.634624 16.458975 16.306217 15.787058 15.572903]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.20452881 -0.3432908  -0.49464798 -0.70753145 -0.9786253  -1.3608875
0:  -1.812396   -2.3155384  -2.7685995  -3.1362305  -3.4162483  -3.6612625
0:  -3.8764582  -4.058202   -4.266466   -4.4445972  -4.5856504  -4.6924906
0:  -4.7679367  -4.8998594 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.250661  5.3085995 5.382532  5.4611177 5.4953413 5.508282  5.5318704
0:  5.5228853 5.5560923 5.589209  5.591184  5.5726147 5.550711  5.531243
0:  5.532711  5.561939  5.5899844 5.6352677 5.475387  5.552318 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.206005 10.339872 10.505205 10.700597 10.881492 11.031091 11.181747
0:  11.268583 11.367041 11.473583 11.56848  11.668074 11.763439 11.86231
0:  11.946237 12.041009 12.141805 12.255093 12.357523 12.384461]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.968603  17.00204   17.014421  16.99527   17.026432  17.028347
0:  17.049057  17.007904  16.962118  16.904991  16.87609   16.81708
0:  16.72392   16.616674  16.439796  16.262154  16.132885  16.06865
0:  15.573316  15.5265045]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.4765234  0.47537708 0.50382376 0.5812869  0.67746925 0.7335
0:  0.76553583 0.71700335 0.66564894 0.64424753 0.67425394 0.734931
0:  0.83050346 0.94283104 1.0161757  1.1129375  1.2387347  1.4279423
0:  1.2431355  1.1918445 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.9349024 3.886537  3.8158345 3.709488  3.608865  3.5242424 3.461431
0:  3.3649538 3.2921221 3.1853268 3.0641885 2.8834686 2.6666093 2.4821825
0:  2.2942543 2.2292738 2.2558432 2.3690572 2.1309605 2.0357623]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.332558 8.373983 8.436155 8.538192 8.613185 8.642431 8.684122 8.651945
0:  8.620113 8.60109  8.559932 8.549597 8.611675 8.691833 8.767114 8.800683
0:  8.781192 8.762594 8.62352  8.495918]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.93706894 -0.646327   -0.39613485 -0.276268   -0.29372025 -0.49696255
0:  -0.8704586  -1.3833575  -1.9785829  -2.6179595  -3.28412    -3.9691157
0:  -4.5989356  -5.174805   -5.6890836  -6.0929847  -6.396177   -6.5765395
0:  -7.142469   -7.420426  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.1473224 3.1215575 3.1645553 3.2619176 3.4000285 3.5398777 3.692382
0:  3.8155131 3.9564278 4.107293  4.27287   4.422594  4.5696816 4.71251
0:  4.836067  4.9670205 5.1167765 5.2858486 5.3765726 5.5679145]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.8691216 -5.0572767 -5.1453047 -5.0900936 -4.8966675 -4.680973
0:  -4.495658  -4.4184446 -4.4507008 -4.598528  -4.750004  -4.967844
0:  -5.1032677 -5.047349  -4.9305773 -4.671646  -4.3713627 -4.100937
0:  -4.1885233 -4.239974 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.40279007  0.2265234   0.01266098 -0.18448591 -0.37634182 -0.5740223
0:  -0.7364211  -0.89144564 -1.0007758  -1.0519986  -1.0643182  -1.0199423
0:  -0.91985226 -0.7948656  -0.6511359  -0.50688887 -0.37239695 -0.23004246
0:  -0.08189344  0.09833717]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.319218 18.509304 18.772905 19.053246 19.349981 19.62701  19.950184
0:  20.14783  20.31696  20.364117 20.19712  19.846285 19.311451 18.670757
0:  17.91816  17.124329 16.305737 15.585519 13.692713 13.060669]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.5818167  -0.58341455 -0.5912781  -0.61949635 -0.6570449  -0.7284298
0:  -0.7977085  -0.90381336 -0.9953294  -1.0623598  -1.1038318  -1.1479721
0:  -1.1918797  -1.2157831  -1.2596531  -1.2658305  -1.2316909  -1.1456776
0:  -1.1944323  -1.2039571 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [37.81546  37.3751   37.017784 36.693733 36.32009  35.91771  35.511612
0:  35.090836 34.7616   34.43442  34.006485 33.616985 33.318512 33.198086
0:  33.24601  33.35535  33.46944  33.408245 34.49451  34.24979 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.547159 12.097303 11.955643 12.113808 12.465654 12.972076 13.721724
0:  14.627189 15.793386 17.136707 18.564043 20.09426  21.759073 23.626062
0:  25.738941 27.898453 30.075775 32.045746 33.64038  34.01415 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.950178  12.165414  12.510651  12.925398  13.359636  13.745963
0:  14.069515  14.244408  14.302214  14.225555  14.035371  13.79108
0:  13.557115  13.382677  13.3209505 13.374302  13.554598  13.835849
0:  14.235456  14.269945 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.675371 19.965096 20.27489  20.594078 20.935127 21.27755  21.615059
0:  21.83271  22.044462 22.195503 22.21944  22.138338 22.000656 21.832716
0:  21.713764 21.666718 21.75816  21.958733 23.52222  24.437393]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.5561304 -6.6455345 -6.7546864 -6.8664646 -6.9463243 -7.018487
0:  -7.0323944 -7.050853  -7.0086327 -6.896721  -6.70444   -6.4851084
0:  -6.280245  -6.107994  -6.068328  -6.0811195 -6.102786  -6.076763
0:  -6.33447   -6.4093685]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.818648 -11.0887   -11.233922 -11.277965 -11.311414 -11.385604
0:  -11.553624 -11.899537 -12.353045 -12.836043 -13.263118 -13.645883
0:  -13.881015 -13.951726 -13.959113 -13.862157 -13.76155  -13.65113
0:  -13.937505 -14.017106]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [37.712704 37.473465 37.105537 36.476063 35.702976 34.91461  34.2073
0:  33.592026 33.200436 32.901886 32.649586 32.362404 32.09579  31.777369
0:  31.43412  31.091711 30.745476 30.43494  30.712154 31.141165]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.056892   9.9024315  9.561965   9.120185   8.62896    8.175086
0:   7.7746267  7.43981    7.2290444  7.1018066  7.039567   7.007818
0:   6.9835443  6.924292   6.8153515  6.6152167  6.393251   6.179658
0:   6.050596   5.8779364]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.8333125 7.736919  7.660426  7.5811076 7.490844  7.381839  7.2776923
0:  7.1512985 7.0496426 6.95524   6.8486023 6.7088895 6.559716  6.4006224
0:  6.245213  6.1251335 6.0235043 5.943345  5.5788183 5.488582 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.824287 17.794518 17.737549 17.595152 17.44141  17.32921  17.26009
0:  17.161114 17.132788 17.102139 17.076387 17.08289  17.149296 17.250278
0:  17.387781 17.526846 17.616198 17.588598 17.238426 17.217844]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.5865755 13.230198  12.995525  12.991375  13.174797  13.451176
0:  13.932309  14.401729  14.97653   15.543694  15.996661  16.380257
0:  16.730022  16.89996   16.962067  16.938896  16.761944  16.53865
0:  15.251842  14.926177 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.303016    5.1587076   5.1461744   5.1725917   5.2083      5.094067
0:   4.7128997   4.086874    3.1843462   2.210688    1.2176967   0.19519567
0:  -0.7650323  -1.6097455  -2.3559222  -2.8606172  -3.0534606  -2.9326444
0:  -3.1387715  -2.7497697 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.1627355  -2.2360406  -2.2713017  -2.2306752  -2.1315274  -2.017446
0:  -1.8516927  -1.6955819  -1.5023141  -1.2541213  -0.9624839  -0.7123728
0:  -0.5080247  -0.3556571  -0.3713193  -0.47942162 -0.6872592  -0.9554391
0:  -1.4168477  -1.7975421 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.679335  16.673983  16.628489  16.52731   16.406109  16.223688
0:  16.018     15.788483  15.5965805 15.429527  15.281698  15.107814
0:  14.926245  14.721519  14.504382  14.337782  14.260996  14.241436
0:  13.771721  13.8405   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.635788  10.451672  10.421334  10.502251  10.780216  11.200053
0:  11.667034  12.00683   12.091772  11.782024  11.140881  10.280443
0:   9.455027   8.808118   8.385546   8.159401   8.001283   7.8398714
0:   7.6735215  7.418207 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.494025   9.587301   9.676523   9.757923   9.847498   9.911451
0:   9.989192  10.040505  10.1138735 10.197191  10.277824  10.334494
0:  10.394517  10.439119  10.475361  10.53691   10.655577  10.808551
0:  10.700233  10.857296 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.338008 11.544409 11.922106 12.42059  12.967421 13.446786 13.909182
0:  14.1453   14.413114 14.677938 14.942699 15.317471 15.776323 16.21217
0:  16.621893 16.917614 17.179186 17.458134 18.246052 18.5034  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.302567  -9.108183  -8.937893  -8.824892  -8.772837  -8.826767
0:  -8.865555  -8.965134  -9.021317  -9.082178  -9.151659  -9.288815
0:  -9.474821  -9.586611  -9.7655735 -9.821074  -9.837065  -9.783873
0:  -9.963625  -9.890406 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.2194376 5.1008434 5.009255  4.9405107 4.877243  4.7959375 4.74934
0:  4.6988745 4.7470765 4.90334   5.1762004 5.512518  5.924837  6.357197
0:  6.7472324 7.1240225 7.4653974 7.740561  8.056499  8.103786 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.668648 14.629475 14.609215 14.584528 14.562893 14.555391 14.571804
0:  14.54774  14.529127 14.46682  14.362944 14.186155 13.994737 13.795985
0:  13.566816 13.304858 13.040798 12.757907 11.981207 11.847269]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.685778 21.58255  21.459505 21.25254  20.980446 20.6026   20.122684
0:  19.557085 18.93866  18.325954 17.69989  17.086628 16.47221  15.899933
0:  15.361111 14.928442 14.634051 14.449399 14.235583 13.799013]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.3835368 -3.3745828 -3.3654704 -3.3464837 -3.2960324 -3.2617621
0:  -3.1843152 -3.1329103 -3.046496  -2.9507813 -2.848947  -2.769569
0:  -2.6964307 -2.6024766 -2.5381875 -2.4476304 -2.329821  -2.192779
0:  -2.393516  -2.2424912]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.340705  6.507344  6.691104  6.814211  6.9760613 7.1243253 7.313374
0:  7.482376  7.6429677 7.7822914 7.921546  7.9961286 8.067157  8.180279
0:  8.283654  8.459198  8.647574  8.837606  9.049384  9.167278 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.353657 21.0694   20.889366 20.728947 20.58456  20.441425 20.366777
0:  20.19495  20.083103 19.963602 19.79576  19.627182 19.491585 19.382648
0:  19.379555 19.42543  19.476564 19.562859 19.573084 19.55185 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.9920063 4.315673  4.7020664 5.049933  5.339608  5.5290604 5.6720104
0:  5.7044477 5.6898046 5.607041  5.48487   5.322536  5.1622753 5.0730515
0:  4.9710646 4.9375315 4.877054  4.7883925 5.095532  5.129065 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.331215  18.129255  17.929708  17.66248   17.380926  17.112637
0:  16.881208  16.702644  16.636997  16.664814  16.784071  16.930582
0:  17.091085  17.185287  17.19002   17.108103  16.978062  16.809671
0:  15.9781685 15.753492 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.175995   -8.105778   -7.9319043  -7.5790133  -7.084018   -6.563683
0:  -6.0048556  -5.5430417  -5.1543612  -4.7676425  -4.325482   -3.8690143
0:  -3.2703948  -2.674088   -2.062283   -1.4419122  -0.78137493 -0.12046289
0:   0.3975997   1.05868   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.132067 12.162563 12.132028 12.045336 11.940277 11.824149 11.734148
0:  11.671366 11.669769 11.732803 11.855841 12.01819  12.232712 12.487822
0:  12.767383 13.079519 13.433233 13.793358 14.305889 14.348   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.6702814 5.7912226 5.9043703 5.9195676 5.9279127 5.91454   5.8623657
0:  5.809781  5.748422  5.716998  5.710275  5.698969  5.7254114 5.777373
0:  5.7951884 5.8342047 5.861124  5.8696976 5.740073  5.9721966]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.157798  5.2126904 5.252598  5.2700973 5.2823486 5.2633886 5.265195
0:  5.2376065 5.2311535 5.225715  5.214254  5.170594  5.1372337 5.0891304
0:  5.0344615 5.0262213 5.0364356 5.0824194 4.822467  4.85028  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [30.591822 30.751688 30.93747  31.092302 31.197668 31.317627 31.538265
0:  31.731428 32.07079  32.38341  32.613083 32.6735   32.648647 32.6215
0:  32.61492  32.700222 32.80827  32.844807 31.782003 31.218027]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.813238 14.724623 14.632075 14.491686 14.37195  14.248781 14.133989
0:  14.007227 13.901487 13.818119 13.755611 13.68554  13.623381 13.555096
0:  13.471812 13.401049 13.378199 13.374009 13.465343 13.524854]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [37.071255 37.20318  37.329567 37.431778 37.477177 37.41455  37.30357
0:  36.995453 36.695343 36.23593  35.64294  34.92983  34.22328  33.514282
0:  32.87341  32.357517 31.902946 31.522766 31.944546 31.66687 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.829283   9.216543   9.6483965 10.217232  10.911779  11.650568
0:  12.522131  13.346579  14.219032  15.075525  15.904131  16.72315
0:  17.504095  18.30409   19.036903  19.718475  20.352324  20.877855
0:  20.639503  21.096317 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.3642569 -1.6247644 -1.8770094 -2.0885158 -2.262086  -2.416451
0:  -2.5062099 -2.6067843 -2.6774526 -2.7389436 -2.8104281 -2.941648
0:  -3.1202378 -3.3064284 -3.5333047 -3.7315116 -3.8866372 -3.9854674
0:  -4.077084  -4.243131 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.8906107  -1.629693   -1.3178129  -0.8860817  -0.36664677  0.19734001
0:   0.8796978   1.5469823   2.2436671   2.9102569   3.510204    4.032171
0:   4.4990954   4.8690443   5.1554737   5.3342648   5.3735714   5.2139597
0:   3.7703738   3.4131322 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 6.0398846  6.334269   6.624918   6.773385   6.806322   6.583345
0:   6.16049    5.523513   4.704915   3.7858517  2.825965   1.7971945
0:   0.6742649 -0.5144787 -1.8115602 -3.0285277 -4.158973  -5.005749
0:  -5.9469485 -5.694883 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.8453727 -4.8888707 -4.9626594 -5.1055017 -5.2910285 -5.5311227
0:  -5.76808   -6.0192933 -6.205437  -6.303762  -6.317082  -6.281628
0:  -6.195501  -6.064697  -5.9597898 -5.822248  -5.6708884 -5.521662
0:  -5.8597198 -5.9333797]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.099697 12.308912 12.46499  12.601635 12.687095 12.747509 12.856186
0:  12.900931 12.98785  13.083601 13.123167 13.165701 13.209509 13.268016
0:  13.331352 13.370521 13.42391  13.482309 13.778021 13.930643]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.7321773 -4.769178  -4.7862983 -4.7980456 -4.811361  -4.892489
0:  -4.9719977 -5.1128583 -5.2387853 -5.319117  -5.3457856 -5.3667445
0:  -5.3626065 -5.298516  -5.241986  -5.115031  -4.964065  -4.805177
0:  -4.802318  -4.710524 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.797531 12.917925 13.046114 13.15294  13.27539  13.373568 13.456369
0:  13.475845 13.481733 13.442699 13.35093  13.220642 13.080257 12.946967
0:  12.855141 12.807451 12.806771 12.839153 12.507213 12.446245]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.1497655 -2.2936559 -2.484242  -2.798368  -3.2302203 -3.77844
0:  -4.312572  -4.83898   -5.282372  -5.6142116 -5.8605437 -6.068561
0:  -6.2227407 -6.3252807 -6.4574647 -6.591965  -6.7826457 -7.0023856
0:  -7.557237  -7.9890647]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.94770527 -0.7524986  -0.45516968 -0.05117512  0.4023466   0.8447547
0:   1.2545714   1.5450225   1.758651    1.879756    1.9055259   1.8121533
0:   1.6111631   1.3080554   0.86961555  0.3662777  -0.14935064 -0.626925
0:  -2.3527331  -2.9196267 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.9014587 6.700423  6.5089774 6.394077  6.3434973 6.331552  6.372098
0:  6.3741503 6.404042  6.4089723 6.395658  6.349717  6.284627  6.200894
0:  6.0828166 5.9604597 5.8457813 5.748466  5.603195  5.528514 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.0498614 -2.8620944 -2.571651  -2.2632165 -1.9431672 -1.6906524
0:  -1.5129046 -1.4814143 -1.5504355 -1.698648  -1.8412528 -1.9642358
0:  -2.0080914 -1.9324012 -1.8344903 -1.6806903 -1.5670819 -1.4986892
0:  -2.0463557 -2.0848765]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.383621 29.304417 29.166176 28.997261 28.849392 28.763565 28.722477
0:  28.616417 28.540321 28.387348 28.13792  27.770794 27.390064 26.980537
0:  26.566933 26.18576  25.831135 25.484516 25.020199 24.749992]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.280023  -2.2638059 -2.1812644 -2.1538444 -2.1907983 -2.355186
0:  -2.6261783 -2.9943175 -3.4391418 -3.9165568 -4.407906  -4.948029
0:  -5.454765  -5.9204507 -6.324118  -6.641723  -6.9055686 -7.090182
0:  -6.983912  -7.144405 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.5074868 -2.706533  -2.8821397 -3.0042167 -3.1199489 -3.2470937
0:  -3.35255   -3.4454637 -3.5007405 -3.4676423 -3.3795123 -3.3106074
0:  -3.2508063 -3.2323432 -3.271647  -3.3047595 -3.34337   -3.3370557
0:  -3.6837583 -3.6627955]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.18245745  0.18356037  0.26158905  0.3585496   0.47891903  0.5861716
0:   0.6805577   0.66671133  0.6410928   0.6147909   0.61607075  0.6352682
0:   0.6835389   0.7399602   0.6505251   0.4715972   0.15494537 -0.2004404
0:  -1.9290881  -2.2086759 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.594508  13.533161  13.531849  13.54769   13.578865  13.61361
0:  13.680064  13.72266   13.794739  13.860795  13.900179  13.903297
0:  13.894958  13.860043  13.775263  13.62723   13.4374695 13.208891
0:  11.291037  11.034893 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.12758398 -0.01208544 -0.02699804 -0.18458986 -0.44412088 -0.7405591
0:  -0.9912677  -1.2202821  -1.4174209  -1.5819688  -1.6966691  -1.767179
0:  -1.7422748  -1.6291852  -1.5503373  -1.527472   -1.6704144  -1.9128785
0:  -2.798759   -2.7781196 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.452524  11.464788  11.455595  11.413093  11.331226  11.178169
0:  11.026384  10.795084  10.649675  10.517338  10.390034  10.273133
0:  10.180296  10.120301  10.050711   9.988742   9.928222   9.90757
0:   9.357248   9.5328045]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.280057  1.3366418 1.3817639 1.4230294 1.443932  1.4150167 1.3908706
0:  1.3201051 1.2630935 1.2270908 1.2289739 1.2462587 1.303834  1.3947887
0:  1.4661365 1.5578351 1.63167   1.6840281 1.3272543 1.2372837]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.77921  26.470512 26.1287   25.728523 25.37453  25.03165  24.898655
0:  24.783173 24.86111  25.028126 25.13467  25.19743  25.123425 24.857185
0:  24.402603 23.796738 23.108826 22.464748 22.953678 22.801401]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.760954 18.899094 19.125042 19.3559   19.525782 19.61765  19.69276
0:  19.750048 19.894567 20.153492 20.40783  20.6654   20.903118 21.048733
0:  21.108986 21.106676 21.050339 20.965517 20.55815  20.815481]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.240438  -7.4271865 -7.551844  -7.632117  -7.676924  -7.764807
0:  -7.8421044 -7.948746  -8.02499   -8.006029  -7.936237  -7.8804326
0:  -7.8283277 -7.759971  -7.7292237 -7.6078544 -7.451593  -7.2409396
0:  -7.477753  -7.279654 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-12.166676  -12.197334  -12.140976  -12.024378  -11.9219475 -11.892874
0:  -11.886387  -11.952066  -11.99695   -11.989647  -11.918982  -11.823759
0:  -11.69561   -11.537165  -11.392599  -11.225128  -11.062813  -10.887402
0:  -11.50227   -11.549664 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.324818 12.671782 13.006231 13.317341 13.642784 13.964328 14.316696
0:  14.651073 15.010586 15.401184 15.797041 16.223799 16.686247 17.140486
0:  17.547598 17.88378  18.160467 18.378077 17.587093 17.903452]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.675065   8.882328   9.188399   9.472065   9.774393  10.086462
0:  10.352884  10.507067  10.552568  10.453811  10.28023   10.0249605
0:   9.809441   9.642848   9.487574   9.399284   9.190603   8.835819
0:   6.826627   6.206345 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.079292 22.083988 22.184042 22.293045 22.33205  22.26284  22.221748
0:  21.950094 21.653177 21.242798 20.60341  19.98809  19.452145 18.937267
0:  18.517138 18.1319   17.709442 17.374832 16.704199 16.24547 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.624187  -4.531155  -4.351521  -4.17944   -4.009151  -3.9146218
0:  -3.8230004 -3.8028607 -3.7625117 -3.7165627 -3.6535172 -3.6286092
0:  -3.6325717 -3.6441789 -3.742784  -3.834374  -3.951095  -4.041594
0:  -4.489734  -4.639026 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.922277 12.740671 12.617336 12.509407 12.395615 12.27025  12.139687
0:  11.965158 11.802025 11.619179 11.410177 11.178139 10.959861 10.729519
0:  10.508459 10.258367  9.962754  9.654872  9.095644  8.815734]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -7.279195   -7.428178   -7.5363474  -7.6180925  -7.667507   -7.743891
0:   -7.827423   -7.9725513  -8.144721   -8.30691    -8.465816   -8.662007
0:   -8.851377   -9.023452   -9.176103   -9.289632   -9.372987   -9.352363
0:  -10.083827  -10.295859 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.2000432  -2.1593356  -2.2048087  -2.225306   -2.160417   -2.065783
0:  -1.8871274  -1.7364144  -1.5419545  -1.3206916  -1.0413384  -0.70341444
0:  -0.31170845  0.12748003  0.5325928   0.92806435  1.2745857   1.5667086
0:   0.9867053   0.9207578 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -9.932695  -10.232126  -10.516878  -10.772779  -11.073263  -11.4111595
0:  -11.731274  -12.050367  -12.322727  -12.524494  -12.6780815 -12.753353
0:  -12.719658  -12.595997  -12.3910885 -12.133627  -11.8855915 -11.628569
0:  -10.538128  -10.164095 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.7525649  0.5536084  0.38047743 0.27350616 0.25021553 0.2411995
0:  0.29544067 0.32735205 0.3843732  0.49330187 0.684433   0.8985839
0:  1.1478028  1.3651705  1.474082   1.5305338  1.4930267  1.4381924
0:  0.79661465 0.4265957 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.9944696 5.915105  5.908442  5.910067  5.926947  5.8902245 5.8541737
0:  5.8245935 5.836412  5.9109263 6.010875  6.09338   6.1666718 6.2568345
0:  6.33402   6.450424  6.5854554 6.6992826 6.1054187 6.245003 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.2020035  5.4914956  5.790642   6.095932   6.4252667  6.7540746
0:   7.096582   7.418545   7.758472   8.102756   8.475035   8.827198
0:   9.202218   9.572823   9.936256  10.295409  10.649267  10.99662
0:  11.241646  11.536999 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.2686448  -0.32363272 -0.41807747 -0.533659   -0.69560194 -0.9045272
0:  -1.1344652  -1.4039497  -1.6348882  -1.8230667  -1.9636722  -2.0826974
0:  -2.152019   -2.181272   -2.18607    -2.151544   -2.0829692  -2.0028338
0:  -2.0898366  -2.0719295 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.206326 17.259096 17.318188 17.341703 17.356934 17.367126 17.378975
0:  17.376621 17.400164 17.435701 17.47676  17.498062 17.526722 17.535799
0:  17.526276 17.521095 17.541945 17.58961  17.405571 17.472324]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.152462 23.220078 23.270212 23.269787 23.243216 23.202124 23.105576
0:  22.932245 22.788836 22.622244 22.446192 22.241838 22.041737 21.826677
0:  21.604462 21.358868 21.164728 21.011713 20.457554 20.447643]
0: validation loss for strategy=forecast at epoch 2 : nan
0: validation loss for velocity_u : 0.03357846289873123
0: validation loss for velocity_v : 0.06895653158426285
0: validation loss for specific_humidity : 0.028767677024006844
0: validation loss for velocity_z : 0.552240252494812
0: validation loss for temperature : 0.08442002534866333
0: validation loss for total_precip : nan
0: 3 : 09:58:35 :: batch_size = 96, lr = 1.9512195121951222e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 3, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.7153, 0.7703, 0.8345, 0.8900, 0.9091, 0.8608, 0.7296, 0.5356, 0.3302, 0.1677, 0.0782, 0.0576, 0.0796, 0.1156,
0:         0.1482, 0.1702, 0.1815, 0.1861, 0.7324, 0.8013, 0.8682, 0.9055, 0.8869, 0.7939, 0.6284], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6256, -0.5738, -0.5210, -0.4819, -0.4682, -0.4939, -0.5651, -0.6634, -0.7423, -0.7539, -0.6836, -0.5580,
0:         -0.4195, -0.2993, -0.2092, -0.1478, -0.1106, -0.0948, -0.6545, -0.5965, -0.5426, -0.5062, -0.5023, -0.5470,
0:         -0.6374], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 2.2528,  2.2623,  2.2639,  2.2662,  2.2450,  2.2036,  2.0323,  1.7417,  1.3388,  0.8728,  0.4970,  0.2042,
0:          0.0887,  0.0032, -0.0581, -0.1338, -0.2156, -0.3017,  2.2236,  2.2369,  2.2492,  2.2404,  2.2084,  2.1341,
0:          1.8863], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.3824,  0.4556,  0.3824,  0.1008, -0.2829, -0.6266, -0.6820, -0.2962,  0.2804,  0.7106,  0.9035,  0.8237,
0:          0.5243,  0.2649,  0.1207, -0.0345, -0.1454, -0.1321,  0.4001,  0.3713,  0.1185, -0.3161, -0.6665, -0.7640,
0:         -0.5290], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0.8664, 0.9073, 0.9577, 0.9957, 0.9913, 0.9298, 0.8285, 0.7317, 0.6732, 0.6491, 0.6459, 0.6644, 0.7045, 0.7577,
0:         0.8182, 0.8813, 0.9403, 0.9939, 1.0415, 1.0793, 1.1064, 1.1266, 1.1414, 1.1528, 1.1643], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 3, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.1751,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,  5.7495,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,  6.4478,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  3.0260,     nan,
0:             nan,     nan,     nan, -0.1919,     nan, -0.2135,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0287,     nan,     nan,  8.0220,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,  7.9836,  8.7754,     nan,     nan,     nan,
0:             nan,  3.2707,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:          4.0218,     nan,     nan,     nan,     nan,  8.5763,     nan,     nan,     nan,  2.9972,     nan,     nan,
0:             nan,  6.6038,     nan,  8.2499,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0407,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  8.7203,     nan,     nan,     nan,
0:             nan,     nan,  2.7332,     nan,     nan,     nan,     nan,     nan,  8.0340,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,  8.8426,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,  9.6393,     nan])
0: [DEBUG] Epoch 3, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([1.4414, 1.4225, 1.4038, 1.3868, 1.3720, 1.3630, 1.3716, 1.3771, 1.3871, 1.3907, 1.3768, 1.3566, 1.3372, 1.3173,
0:         1.3004, 1.2873, 1.2676, 1.2430, 1.5532, 1.5440, 1.5339, 1.5181, 1.4940, 1.4785, 1.4653], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-1.3873, -1.4067, -1.4268, -1.4444, -1.4543, -1.4475, -1.4339, -1.4053, -1.3770, -1.3474, -1.3214, -1.2979,
0:         -1.2765, -1.2435, -1.2090, -1.1704, -1.1283, -1.0868, -1.4157, -1.4203, -1.4368, -1.4472, -1.4534, -1.4501,
0:         -1.4345], device='cuda:1', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([1.9789, 1.9603, 1.9327, 1.8912, 1.8294, 1.7837, 1.7305, 1.7121, 1.7170, 1.7315, 1.7460, 1.7590, 1.7464, 1.7108,
0:         1.6666, 1.6145, 1.5649, 1.5475, 2.1282, 2.1001, 2.0762, 2.0292, 1.9715, 1.9043, 1.8456], device='cuda:2',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([ 0.8704,  0.8939,  0.8118,  0.7771,  0.7511,  0.6602,  0.6571,  0.5594,  0.4053,  0.3797,  0.2929,  0.1918,
0:          0.1414,  0.0224,  0.0058,  0.0626,  0.0086, -0.0479,  0.8274,  0.9381,  0.9115,  0.8809,  0.9156,  0.8838,
0:          0.8754], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([1.0056, 1.0078, 1.0110, 1.0133, 1.0208, 1.0330, 1.0498, 1.0705, 1.0932, 1.1170, 1.1388, 1.1576, 1.1756, 1.1923,
0:         1.2097, 1.2283, 1.2453, 1.2603, 1.2717, 1.2812, 1.2903, 1.3003, 1.3118, 1.3243, 1.3368], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.059479549527168274; velocity_v: 0.09068261831998825; specific_humidity: 0.03683964163064957; velocity_z: 0.5211440920829773; temperature: 0.07213720679283142; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.0709395557641983; velocity_v: 0.11894380301237106; specific_humidity: 0.04871051385998726; velocity_z: 0.5364394187927246; temperature: 0.11866171658039093; total_precip: nan; 
0: epoch: 3 [1/5 (20%)]	Loss: nan : nan :: 0.16213 (2.49 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05319006368517876; velocity_v: 0.0896674171090126; specific_humidity: 0.042096491903066635; velocity_z: 0.5524277687072754; temperature: 0.1277480125427246; total_precip: nan; 
0: epoch: 3 [2/5 (40%)]	Loss: nan : nan :: 0.13871 (15.72 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.07418555021286011; velocity_v: 0.1168474480509758; specific_humidity: 0.04893288388848305; velocity_z: 0.636785626411438; temperature: 0.1267155259847641; total_precip: nan; 
0: epoch: 3 [3/5 (60%)]	Loss: nan : nan :: 0.15937 (16.14 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05215281993150711; velocity_v: 0.08325556665658951; specific_humidity: 0.03820184990763664; velocity_z: 0.43207645416259766; temperature: 0.09265917539596558; total_precip: nan; 
0: epoch: 3 [4/5 (80%)]	Loss: nan : nan :: 0.13702 (16.26 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [1.52587891e-05 1.90734863e-06 1.90734863e-06 9.53674316e-07
0:  1.90734863e-06 2.86102295e-06 8.58306885e-06 1.62124634e-05
0:  2.47955322e-05 3.81469690e-05 3.33786011e-05 6.58035278e-05
0:  1.03950500e-04 8.29696655e-05 7.24792480e-05 5.81741333e-05
0:  5.72204590e-05 3.05175781e-05 2.86102295e-05 2.47955322e-05
0:  1.90734863e-05 1.14440918e-05 5.72204590e-06 5.72204590e-06
0:  5.72204590e-06 8.58306885e-06 1.43051147e-05 1.71661377e-05
0:  1.33514404e-05 1.14440918e-05 8.58306885e-06 9.53674316e-06
0:  9.53674316e-06 9.53674316e-06 8.58306885e-06 1.43051147e-05
0:  1.81198120e-05 1.43051147e-05 9.53674316e-06 9.53674316e-06
0:  8.58306885e-06 9.53674316e-06 1.14440918e-05 1.33514404e-05
0:  1.43051147e-05 2.19345093e-05 2.38418579e-05 2.19345093e-05
0:  1.52587891e-05 1.71661377e-05 8.58306885e-06 7.62939453e-06
0:  5.72204590e-06 6.67572021e-06 6.67572021e-06 5.72204590e-06
0:  4.76837158e-06 4.76837158e-06 4.76837158e-06 4.76837158e-06
0:  4.76837158e-06 4.76837158e-06 7.62939453e-06 1.33514404e-05
0:  1.23977661e-05 9.53674316e-06 9.53674316e-06 9.53674316e-06
0:  8.58306885e-06 9.53674316e-06 9.53674316e-06 1.33514404e-05
0:  1.14440918e-05 1.33514404e-05 1.43051147e-05 1.52587891e-05
0:  1.33514404e-05 1.33514404e-05 1.52587891e-05 1.62124634e-05
0:  1.90734863e-05 2.09808350e-05 1.81198120e-05 1.43051147e-05
0:  9.53674316e-06 7.62939453e-06 7.62939453e-06 1.43051147e-05
0:  2.28881836e-05 2.47955322e-05 2.47955322e-05 2.09808350e-05
0:  1.90734863e-05 1.81198120e-05 1.43051147e-05 1.90734863e-05
0:  2.28881836e-05 2.38418579e-05 1.81198120e-05 2.00271606e-05
0:  2.38418579e-05 2.95639038e-05 2.76565552e-05 2.19345093e-05
0:  1.62124634e-05 1.33514404e-05 1.14440918e-05 9.53674316e-06
0:  1.71661377e-05 4.76837158e-06 2.86102295e-06 9.53674316e-07
0:  1.90734863e-06 1.90734863e-06 1.90734863e-06 4.76837158e-06
0:  1.43051147e-05 1.90734863e-05 2.19345093e-05 5.43594360e-05
0:  8.86917114e-05 7.43865967e-05 6.48498535e-05 6.86645508e-05
0:  7.34329224e-05 4.76837158e-05 4.48226929e-05 2.76565552e-05
0:  2.19345093e-05 1.43051147e-05 1.04904175e-05 6.67572021e-06
0:  6.67572021e-06 5.72204590e-06 8.58306885e-06 1.14440918e-05
0:  1.90734863e-05 1.33514404e-05 1.04904175e-05 9.53674316e-06
0:  9.53674316e-06 9.53674316e-06 8.58306885e-06 7.62939453e-06
0:  9.53674316e-06 6.67572021e-06 1.04904175e-05 1.23977661e-05
0:  1.14440918e-05 9.53674316e-06 1.14440918e-05 1.23977661e-05
0:  1.52587891e-05 1.62124634e-05 1.81198120e-05 1.81198120e-05
0:  1.90734863e-05 2.09808350e-05 1.14440918e-05 1.52587891e-05
0:  1.33514404e-05 1.43051147e-05 8.58306885e-06 6.67572021e-06
0:  6.67572021e-06 4.76837158e-06 4.76837158e-06 4.76837158e-06
0:  4.76837158e-06 4.76837158e-06 7.62939453e-06 1.33514404e-05
0:  1.14440918e-05 9.53674316e-06 8.58306885e-06 1.04904175e-05
0:  8.58306885e-06 9.53674316e-06 8.58306885e-06 1.04904175e-05
0:  8.58306885e-06 8.58306885e-06 8.58306885e-06 9.53674316e-06
0:  1.23977661e-05 1.52587891e-05 1.71661377e-05 2.00271606e-05
0:  1.81198120e-05 1.90734863e-05 2.00271606e-05 2.57492065e-05
0:  2.09808350e-05 1.81198120e-05 1.71661377e-05 3.05175781e-05
0:  3.91006470e-05 4.00543213e-05 3.91006470e-05 3.43322754e-05]
0: Target values (first 200):
0: [0.00000000e+00 0.00000000e+00 5.72204590e-06 2.53677368e-04
0:  4.32968140e-04 1.35421753e-03 2.05326080e-03 2.57110596e-03
0:  2.62641907e-03 2.05135345e-03 1.58786774e-03 1.03378296e-03
0:  6.02722168e-04 3.50952148e-04 2.48908997e-04 1.69754028e-04
0:  2.26020813e-04 2.40325928e-04 2.77519226e-04 2.64167786e-04
0:  2.62260437e-04 1.77383423e-04 1.02996826e-04 3.52859497e-05
0:  1.04904175e-05 1.14440918e-05 1.43051147e-05 1.90734863e-05
0:  1.71661377e-05 1.43051147e-05 9.53674316e-06 7.62939453e-06
0:  9.53674316e-06 9.53674316e-06 9.53674316e-06 1.14440918e-05
0:  1.14440918e-05 1.52587891e-05 2.19345093e-05 2.67028809e-05
0:  3.14712524e-05 2.67028809e-05 1.81198120e-05 1.43051147e-05
0:  1.23977661e-05 1.43051147e-05 1.33514404e-05 1.14440918e-05
0:  9.53674316e-06 7.62939453e-06 5.72204590e-06 4.76837158e-06
0:  5.72204590e-06 1.04904175e-05 1.52587891e-05 1.71661377e-05
0:  1.62124634e-05 1.62124634e-05 9.53674316e-06 8.58306885e-06
0:  7.62939453e-06 8.58306885e-06 1.04904175e-05 1.62124634e-05
0:  2.95639038e-05 3.62396240e-05 1.81198120e-05 7.62939453e-06
0:  5.72204590e-06 7.62939453e-06 9.53674316e-06 1.33514404e-05
0:  9.53674316e-06 7.62939453e-06 6.67572021e-06 5.72204590e-06
0:  6.67572021e-06 9.53674316e-06 1.14440918e-05 1.33514404e-05
0:  1.90734863e-05 2.47955322e-05 1.81198120e-05 1.52587891e-05
0:  1.33514404e-05 9.53674316e-06 5.72204590e-06 3.81469727e-06
0:  2.86102295e-06 1.90734863e-06 1.90734863e-06 9.53674316e-07
0:  9.53674316e-07 1.90734863e-06 1.90734863e-06 1.90734863e-06
0:  1.90734863e-06 3.81469727e-06 7.62939453e-06 1.52587891e-05
0:  2.57492065e-05 3.91006470e-05 5.05447388e-05 6.29425049e-05
0:  6.96182251e-05 6.19888306e-05 5.62667847e-05 5.34057617e-05
0:  0.00000000e+00 0.00000000e+00 9.53674316e-07 3.81469727e-06
0:  1.29699707e-04 1.00421906e-03 1.61743164e-03 2.35557556e-03
0:  2.41184235e-03 2.52914429e-03 1.84059131e-03 1.28841400e-03
0:  6.42776489e-04 5.76973020e-04 4.75883484e-04 3.51905823e-04
0:  2.81333923e-04 2.95639038e-04 2.79426575e-04 3.01361084e-04
0:  3.19480896e-04 2.45094299e-04 1.85012817e-04 8.10623169e-05
0:  5.72204590e-05 2.00271606e-05 4.00543213e-05 4.48226929e-05
0:  2.19345093e-05 2.00271606e-05 1.52587891e-05 1.04904175e-05
0:  8.58306885e-06 8.58306885e-06 9.53674316e-06 7.62939453e-06
0:  7.62939453e-06 9.53674316e-06 1.14440918e-05 1.43051147e-05
0:  1.90734863e-05 2.19345093e-05 2.09808350e-05 1.62124634e-05
0:  1.62124634e-05 1.23977661e-05 1.14440918e-05 1.14440918e-05
0:  1.14440918e-05 9.53674316e-06 9.53674316e-06 1.04904175e-05
0:  1.14440918e-05 1.71661377e-05 1.62124634e-05 1.43051147e-05
0:  1.33514404e-05 1.04904175e-05 9.53674316e-06 8.58306885e-06
0:  1.04904175e-05 9.53674316e-06 1.04904175e-05 1.33514404e-05
0:  1.90734863e-05 2.57492065e-05 1.43051147e-05 9.53674316e-06
0:  7.62939453e-06 1.04904175e-05 1.71661377e-05 2.28881836e-05
0:  1.90734863e-05 8.58306885e-06 8.58306885e-06 7.62939453e-06
0:  6.67572021e-06 9.53674316e-06 1.14440918e-05 1.14440918e-05
0:  1.71661377e-05 2.19345093e-05 1.71661377e-05 1.62124634e-05
0:  1.33514404e-05 9.53674316e-06 6.67572021e-06 4.76837158e-06
0:  2.86102295e-06 1.90734863e-06 1.90734863e-06 1.90734863e-06]
0: Prediction values (first 20):
0: [10.857374  10.5035095 10.166172   9.921575   9.796629   9.845882
0:  10.10302   10.462429  10.933761  11.414008  11.829718  12.146867
0:  12.342369  12.433588  12.393475  12.241071  12.025911  11.828251
0:  11.77336   11.483488 ]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -0.995, max = 3.733, mean = 1.223
0:          sample (first 20): tensor([0.3024, 0.2750, 0.2488, 0.2298, 0.2201, 0.2239, 0.2439, 0.2718, 0.3084, 0.3457, 0.3779, 0.4026, 0.4177, 0.4248,
0:         0.4217, 0.4099, 0.3932, 0.3778, 0.3612, 0.3349])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.0763822 -3.1418204 -3.2017856 -3.235064  -3.2783666 -3.341539
0:  -3.3934054 -3.476132  -3.5578656 -3.6241107 -3.707974  -3.8035655
0:  -3.8786817 -3.9258952 -3.956839  -3.9388556 -3.9206452 -3.8762565
0:  -4.1787314 -4.1613183]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.5208879  2.722786   2.929627   3.1383586  3.370914   3.6038315
0:   3.923886   4.282112   4.741106   5.3308887  6.031125   6.8091884
0:   7.6459007  8.51591    9.380395  10.259885  11.117343  11.912674
0:  12.80088   13.359009 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.8214417 4.8512077 4.924387  5.034645  5.172217  5.3266754 5.5335474
0:  5.743298  6.0222588 6.290358  6.5257454 6.7132998 6.870168  6.964906
0:  6.998315  6.97206   6.9237523 6.9291105 6.6662154 6.8429193]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.003372 18.127302 18.250822 18.323092 18.374796 18.432209 18.509857
0:  18.593807 18.693655 18.815176 18.89852  18.93694  18.97078  18.972706
0:  18.993263 19.018244 19.065617 19.073256 18.490429 18.574331]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.8683171 -2.8234916 -2.7645392 -2.6994042 -2.6696334 -2.6938634
0:  -2.7326417 -2.8199182 -2.9149022 -2.9957404 -3.0962129 -3.2221284
0:  -3.353397  -3.490437  -3.647015  -3.8016448 -3.9812322 -4.1442943
0:  -5.2472215 -5.616979 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.9709826   2.0235457   2.0785604   2.1199985   2.1353006   2.0975904
0:   2.0457788   1.9315891   1.787005    1.6043911   1.3578858   1.0290012
0:   0.65985346  0.27312946 -0.14262009 -0.5061312  -0.81685257 -1.0379248
0:  -1.5797815  -1.7781324 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.6610184 -7.6333485 -7.6532106 -7.680684  -7.738126  -7.8828278
0:  -8.012419  -8.2216835 -8.416444  -8.584663  -8.685418  -8.748803
0:  -8.752002  -8.673065  -8.603077  -8.468449  -8.312861  -8.118527
0:  -7.882141  -7.7338476]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.481615  5.196392  4.8207026 4.384412  3.9852886 3.5876057 3.2672136
0:  2.9945524 2.8260968 2.7701986 2.7725327 2.7832408 2.7555838 2.7295084
0:  2.6312575 2.554443  2.501121  2.406858  1.4356475 1.2426805]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.97827  34.204987 34.406662 34.607643 34.866627 35.134468 35.330967
0:  35.451992 35.547844 35.62955  35.6759   35.547455 35.31999  35.04972
0:  34.7293   34.552864 34.583057 34.662407 34.102764 34.637375]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.253574  8.442236  8.57749   8.627812  8.667056  8.663408  8.66638
0:  8.655565  8.663277  8.695484  8.758366  8.791447  8.779635  8.740423
0:  8.621557  8.5194435 8.463868  8.473142  7.986387  7.977407 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.303835 20.282356 20.233315 20.106857 19.958157 19.749119 19.512337
0:  19.242985 18.9855   18.730297 18.485268 18.194542 17.885086 17.565546
0:  17.211723 16.893208 16.647198 16.435438 15.726107 15.507569]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.46606  21.64111  21.807089 21.969913 22.077843 22.176838 22.264065
0:  22.23473  22.250507 22.253937 22.244324 22.241055 22.282288 22.305454
0:  22.353733 22.398586 22.464016 22.563484 22.5914   22.76868 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.0361886   0.72434807  1.5689812   2.3263354   2.9389403   3.3781013
0:   3.6427765   3.8068109   3.820872    3.783004    3.644033    3.3559282
0:   3.0284066   2.6365933   2.2463737   1.9377918   1.764092    1.7129321
0:   0.53133106  0.84127283]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 4.474847   4.704255   4.9859266  5.301582   5.5986166  5.9151597
0:   6.229888   6.487246   6.7551174  7.050526   7.356683   7.6779413
0:   8.043937   8.401701   8.747426   9.076594   9.4263935  9.793837
0:   9.900031  10.231903 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.502348 10.537322 10.576094 10.616638 10.653423 10.656912 10.639248
0:  10.518318 10.393087 10.243043 10.081546  9.950977  9.921237  9.97833
0:  10.168733 10.47496  10.909607 11.438202 12.100174 12.430618]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.9060955 -8.745869  -8.482161  -8.172857  -7.8640695 -7.6083503
0:  -7.39731   -7.246267  -7.0919576 -6.923123  -6.7091365 -6.5204787
0:  -6.3260255 -6.1289363 -5.9797025 -5.800901  -5.584967  -5.334801
0:  -5.3076825 -5.1029754]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.14570045  0.1133194   0.10338402  0.07015181 -0.03263617 -0.28061247
0:  -0.6684942  -1.1823611  -1.6772885  -2.1047683  -2.4223466  -2.6578631
0:  -2.8267941  -2.92835    -3.0035605  -2.9816022  -2.878017   -2.6949325
0:  -2.4326062  -2.3949485 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.5379243 1.8566542 2.1877837 2.5876813 3.0030925 3.3818936 3.7785208
0:  4.050268  4.293851  4.4723516 4.665996  4.8754206 5.149246  5.4197273
0:  5.6393304 5.8145456 5.896485  5.9724474 5.3893824 5.4164963]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.187073 16.147055 16.155752 16.270924 16.436016 16.575993 16.721182
0:  16.841248 16.99907  17.164225 17.348679 17.492407 17.607399 17.687622
0:  17.675966 17.609247 17.514008 17.402958 16.67818  16.632496]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.324761  -2.4088283 -2.4876132 -2.545527  -2.5949874 -2.698769
0:  -2.8013635 -2.9565063 -3.0714765 -3.170878  -3.2023263 -3.207255
0:  -3.1668534 -3.0647092 -2.961821  -2.8075566 -2.6356483 -2.4356456
0:  -2.2941823 -2.349769 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.8338404 -1.9239788 -2.0024204 -2.179245  -2.3662348 -2.563898
0:  -2.7043705 -2.8184862 -2.8488092 -2.865551  -2.8561144 -2.8802767
0:  -2.8455477 -2.8031616 -2.7583103 -2.6387033 -2.4206629 -2.250764
0:  -2.308797  -2.3607893]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.3399737 3.3875253 3.4756112 3.633831  3.8386703 4.062392  4.3113756
0:  4.4710493 4.665474  4.8295302 5.0282974 5.2520356 5.5670605 5.909655
0:  6.309326  6.7225666 7.188002  7.7332926 8.214914  8.776354 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.4433546 -4.565916  -4.636818  -4.6611834 -4.704955  -4.757248
0:  -4.7947073 -4.85184   -4.8772097 -4.8922644 -4.8965282 -4.915677
0:  -4.9067974 -4.92161   -4.9431753 -5.00086   -5.092286  -5.1576242
0:  -5.508771  -5.639365 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.3044715  -0.04756117  0.801651    2.1027684   3.4768052   4.514573
0:   4.9400826   4.8699694   4.5710483   4.359501    4.3519197   4.3895965
0:   4.3410854   4.1176653   3.7605646   3.5265048   3.560753    3.8000765
0:   3.0796027   3.2007415 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.93444    8.048562   8.244334   8.481599   8.730798   8.953728
0:   9.093756   9.143053   9.126278   9.04416    8.969557   8.910899
0:   8.909411   8.970318   9.122318   9.335267   9.581585   9.7929945
0:  10.163285  10.327459 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.1909566 4.4993696 4.837383  5.1319876 5.391554  5.6302013 5.8788943
0:  6.0404277 6.183172  6.2799444 6.314932  6.316924  6.3463717 6.4090567
0:  6.498605  6.6085987 6.7594285 6.973938  6.911651  7.2282777]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-11.311422  -11.234987  -11.167255  -11.101234  -11.000801  -10.916662
0:  -10.852154  -10.892595  -10.973364  -11.080166  -11.177305  -11.277657
0:  -11.353706  -11.406279  -11.515984  -11.603725  -11.659615  -11.6282425
0:  -11.964771  -11.757879 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.9190464 -1.919672  -1.907898  -1.8531866 -1.7567749 -1.7111053
0:  -1.6759977 -1.7214508 -1.7533207 -1.7536325 -1.7134533 -1.6932907
0:  -1.6944141 -1.6808758 -1.7177343 -1.7062674 -1.630866  -1.5071735
0:  -1.6962337 -1.6058397]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -7.6945386  -7.8051867  -8.02338    -8.343866   -8.688063   -9.063614
0:   -9.397982   -9.724398   -9.965885  -10.094294  -10.115595  -10.067209
0:   -9.988512   -9.866804   -9.80098    -9.735058   -9.656979   -9.502012
0:   -9.368467   -9.121979 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.428664  4.537714  4.598204  4.6166897 4.6188307 4.565785  4.5341716
0:  4.472228  4.4272547 4.395548  4.386917  4.3692355 4.367297  4.3756905
0:  4.368863  4.383508  4.382037  4.360504  3.9784496 4.136798 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.7312088 2.9990897 3.238336  3.4273186 3.505991  3.4587388 3.363771
0:  3.1559644 2.9786272 2.839069  2.7352405 2.7533765 2.9400048 3.2209902
0:  3.6061926 4.016794  4.4154854 4.8194675 5.5581536 5.6854405]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.622356   8.8309765  9.118112   9.437737   9.768842  10.101096
0:  10.389708  10.615032  10.85235   11.057179  11.249371  11.349993
0:  11.397875  11.4314    11.38161   11.337474  11.320082  11.319301
0:  10.987675  11.249218 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.75637  16.179829 15.719818 15.574255 15.684675 15.932409 16.157532
0:  16.316305 16.475534 16.803925 17.193506 17.392216 17.247374 16.57705
0:  15.4016   14.140863 13.134905 12.469765 13.05159  12.919756]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.831175  3.9829044 4.2000704 4.455139  4.693497  4.9059305 5.171153
0:  5.454338  5.8299    6.270753  6.7886705 7.3557014 7.942685  8.4932995
0:  8.938758  9.256992  9.415421  9.441798  8.524591  8.527326 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.7665935 6.492522  6.1873536 5.8282833 5.461256  5.061447  4.6503105
0:  4.2406826 3.9164104 3.6581094 3.4820764 3.3322742 3.2203903 3.1746063
0:  3.1612275 3.213815  3.3095057 3.418396  3.457701  3.5103045]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.3862267 4.41658   4.4966345 4.611025  4.744356  4.8657584 4.9995837
0:  5.0956345 5.2201567 5.3572927 5.5135527 5.640163  5.7519703 5.832558
0:  5.8531466 5.84218   5.8130655 5.7959905 5.4452977 5.3337765]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.114174 24.395391 24.767166 25.195477 25.671228 26.148455 26.654772
0:  27.023752 27.398323 27.728516 27.992434 28.231768 28.496033 28.740448
0:  29.016277 29.282621 29.543972 29.80554  30.16256  30.513186]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.9585598   4.2217946   4.371193    4.3635483   4.2260923   3.953447
0:   3.5962284   3.167355    2.7693703   2.410747    2.156723    1.9420924
0:   1.7726736   1.6261296   1.3977909   1.1376219   0.84598017  0.5610056
0:  -0.23619747 -0.2429471 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.409979 18.099377 17.851421 17.552948 17.31826  17.078217 16.92622
0:  16.74097  16.620197 16.501787 16.357998 16.219872 16.082102 15.959787
0:  15.832409 15.739954 15.705895 15.709662 16.075382 15.920562]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.6780882 1.7676907 1.91015   2.0419154 2.1927576 2.3270574 2.4767394
0:  2.608892  2.7420068 2.8520737 2.9365869 2.9549952 2.9495788 2.9200315
0:  2.8349075 2.7370481 2.6141524 2.4512606 1.7354808 1.4872746]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.2631097 7.368693  7.490938  7.5876455 7.695685  7.7900305 7.914863
0:  8.060095  8.243982  8.472197  8.718498  8.932109  9.093916  9.173249
0:  9.1365595 9.025008  8.838361  8.636057  8.200568  8.089515 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.42707   3.4544392 3.4086108 3.284485  3.1522949 2.978852  2.7817738
0:  2.553832  2.3356323 2.1288166 1.9391088 1.7440639 1.576438  1.4790897
0:  1.4433064 1.5229754 1.7124329 1.9505072 2.5746596 2.8138099]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-11.011831  -10.784378  -10.567608  -10.224884   -9.790421   -9.413353
0:   -8.9854145  -8.677439   -8.379011   -8.08527    -7.747968   -7.388286
0:   -6.9204288  -6.3737855  -5.7885213  -5.061355   -4.2614627  -3.4003043
0:   -4.1093764  -3.485826 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.014144  7.817393  7.6626997 7.548385  7.474941  7.437378  7.4696856
0:  7.526467  7.6602077 7.795809  7.923102  7.9964695 8.045336  8.149569
0:  8.299482  8.517854  8.787688  9.065521  9.414703  9.537534 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.223302  14.257914  14.298372  14.350149  14.386934  14.428579
0:  14.506246  14.5272255 14.584105  14.641505  14.6294365 14.588675
0:  14.532471  14.471832  14.442146  14.404125  14.383263  14.346848
0:  14.348623  14.422086 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [38.494404 38.622875 38.821507 39.07007  39.31815  39.58507  39.867554
0:  39.97076  40.1517   40.287193 40.390102 40.420544 40.52881  40.601856
0:  40.691837 40.822525 40.94593  41.06474  41.464233 41.85524 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.25013   4.2961044 4.3732176 4.414877  4.434586  4.375009  4.2755423
0:  4.110307  3.9441564 3.8092232 3.7308426 3.6872008 3.6625712 3.6859357
0:  3.698996  3.7484734 3.8562455 4.017503  4.4038825 4.526855 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.459787 17.631207 17.810165 17.988352 18.172024 18.35283  18.544939
0:  18.654898 18.753895 18.799276 18.82338  18.833015 18.889715 18.964834
0:  19.08886  19.244267 19.422499 19.627375 19.828527 20.000929]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.877035 13.910286 13.918938 13.916777 13.863832 13.775962 13.699095
0:  13.587187 13.537546 13.571606 13.660402 13.798424 13.969774 14.119893
0:  14.246325 14.323467 14.38972  14.488435 14.241207 14.334569]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.445627 21.585356 21.728914 21.871939 21.968481 22.032108 22.131203
0:  22.143532 22.176311 22.224167 22.227045 22.249065 22.306078 22.349957
0:  22.396982 22.38857  22.350117 22.291288 21.889439 21.923817]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.152501   9.949155   9.67451    9.318902   8.915364   8.46671
0:   7.997144   7.5143075  7.079914   6.6965694  6.36579    6.0517654
0:   5.7503114  5.485585   5.2561617  5.1332498  5.1298656  5.221901
0:   5.4612703  5.688941 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.7270446 -2.7573218 -2.7577739 -2.7332997 -2.7439313 -2.834866
0:  -2.8974347 -3.0138783 -3.10428   -3.1409907 -3.1183    -3.090819
0:  -2.9948153 -2.7919602 -2.6236167 -2.4698339 -2.3986135 -2.410809
0:  -1.8349214 -1.7849183]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.110059  5.9296975 5.792386  5.720949  5.644601  5.588283  5.591502
0:  5.5197635 5.47654   5.3487673 5.1628857 4.9380293 4.7464304 4.5737143
0:  4.4425154 4.381941  4.28824   4.2292404 3.53137   3.3504288]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.1264839  -0.98719215 -0.69440603 -0.22210455  0.3354807   0.9267044
0:   1.5731153   2.1428533   2.65632     3.10289     3.4748368   3.763006
0:   3.9943843   4.1863546   4.2991486   4.4029503   4.4609914   4.507555
0:   4.329151    4.3543262 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.165663 8.218122 8.309629 8.381473 8.454569 8.485443 8.488978 8.456828
0:  8.43275  8.442935 8.484073 8.524823 8.571225 8.618133 8.616748 8.6194
0:  8.628025 8.641179 8.13623  7.995734]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.418664  8.593665  8.68038   8.730187  8.737894  8.747221  8.797279
0:   8.81942   8.85892   8.908324  8.944469  8.988225  9.068188  9.146787
0:   9.26707   9.380048  9.516982  9.6962    9.989429 10.355326]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.780966 20.837732 20.949352 21.029926 21.091885 21.06089  21.113632
0:  21.019413 21.029278 21.067535 21.029505 20.849697 20.656548 20.34943
0:  20.053795 19.806774 19.676836 19.605982 18.642776 18.342793]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.2494373 -4.1486273 -4.0698185 -4.167677  -4.4485407 -4.9267673
0:  -5.519578  -6.1873713 -6.7805033 -7.2600718 -7.6328754 -7.945178
0:  -8.191185  -8.344498  -8.474141  -8.528948  -8.51784   -8.417749
0:  -8.69148   -8.590463 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.5911407 1.7199335 1.8638501 1.9881945 2.1088471 2.1890678 2.243485
0:  2.2361927 2.2213564 2.2206998 2.2761822 2.3446364 2.4449058 2.5684204
0:  2.5999389 2.60069   2.5605402 2.5384192 2.1429558 2.086038 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.9392571  -1.6482415  -1.2542591  -0.80196095 -0.32753658 -0.00465298
0:   0.21312141  0.19013596  0.04805374 -0.1380167  -0.33298635 -0.54386044
0:  -0.69634485 -0.70152426 -0.55607176 -0.20883751  0.38356924  1.0408869
0:  -0.08596563  0.11853695]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.252727  10.082351  10.005668  10.013146  10.103145  10.187019
0:  10.154852   9.996639   9.791546   9.532639   9.300269   9.041973
0:   8.808283   8.571953   8.3289795  8.117246   8.018426   8.004731
0:   7.9383636  8.110318 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.3047256 -4.958061  -4.614002  -4.285302  -4.022422  -3.7873535
0:  -3.5459747 -3.3966265 -3.3157396 -3.3688593 -3.5528545 -3.8691473
0:  -4.1964407 -4.480214  -4.732991  -4.9474697 -5.2247868 -5.462386
0:  -5.7648745 -5.822562 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.779194  7.809147  7.8560305 7.9075775 7.9227076 7.9314685 7.9581842
0:  7.939868  7.963825  7.994766  7.9983587 7.977578  7.9765882 7.9745874
0:  7.9890494 8.013115  8.08782   8.187362  8.369593  8.432398 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.458698  -10.48707   -10.508133  -10.52943   -10.551823  -10.614706
0:  -10.662867  -10.775133  -10.889404  -11.012529  -11.1307335 -11.261642
0:  -11.368465  -11.415613  -11.450571  -11.427174  -11.356594  -11.257128
0:  -11.561623  -11.564013 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.778192  13.5051365 13.301153  13.108139  12.824383  12.381753
0:  11.875471  11.199412  10.491032   9.793539   9.060845   8.402348
0:   7.921828   7.51605    7.2792845  7.1858892  7.1911526  7.3950834
0:   9.075958   9.661375 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.21316  10.455567 10.70163  10.891973 11.065252 11.213781 11.359438
0:  11.471444 11.578833 11.695557 11.784149 11.813757 11.817217 11.790998
0:  11.713959 11.622288 11.561403 11.501184 11.036453 11.148286]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.2797766 -6.2261524 -6.1510916 -6.0784225 -5.9993467 -5.9653425
0:  -5.921892  -5.9118147 -5.88365   -5.8255577 -5.757168  -5.71918
0:  -5.70685   -5.695135  -5.726467  -5.7167826 -5.6682262 -5.584754
0:  -5.7605486 -5.7512608]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.0128894  -0.94709826 -0.75621367 -0.57444096 -0.43662548 -0.37415457
0:  -0.34739828 -0.39987087 -0.4155016  -0.40887022 -0.3763795  -0.3587532
0:  -0.29715014 -0.2548051  -0.24480724 -0.19499254 -0.20389557 -0.19096422
0:  -0.4629917  -0.36895323]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.20036  33.259716 33.374374 33.43091  33.482937 33.487705 33.518665
0:  33.525486 33.60591  33.72156  33.853413 33.92803  34.006203 34.07488
0:  34.09197  34.146645 34.19055  34.232723 33.8082   33.85085 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.175003 24.77993  25.429653 26.268127 27.270409 28.388832 29.529232
0:  30.469982 31.221947 31.715805 31.98043  32.040527 32.0211   31.835518
0:  31.59002  31.252811 30.868729 30.529419 29.807    29.69756 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [42.698235 42.835464 42.934185 42.973232 42.9948   43.024605 43.13468
0:  43.164803 43.29151  43.3505   43.29374  43.11631  42.907246 42.681396
0:  42.4582   42.25289  42.03668  41.74558  41.394234 41.452843]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.200678  9.156364  9.158656  9.103726  9.0662    9.006786  8.924151
0:  8.7922125 8.671027  8.560589  8.441463  8.238314  7.996258  7.774324
0:  7.509406  7.3086348 7.1916428 7.117395  6.6167045 6.326807 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.6405907 2.7400699 2.9938903 3.3713365 3.7836256 4.070218  4.364609
0:  4.5241814 4.6684694 4.789037  4.910553  4.9552956 4.9092493 4.7847276
0:  4.5134916 4.269186  4.024596  3.8008177 3.3792462 3.000701 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.7198195 -6.68868   -6.6442122 -6.5666003 -6.472404  -6.418219
0:  -6.3634095 -6.3571744 -6.340981  -6.290794  -6.1980205 -6.0896993
0:  -5.961492  -5.794128  -5.6443715 -5.4569135 -5.247727  -5.0367093
0:  -5.1284366 -5.121472 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.491962  -2.492354  -2.496325  -2.4814487 -2.4764104 -2.5390954
0:  -2.6025891 -2.7359824 -2.8551936 -2.9515662 -3.0310817 -3.1125207
0:  -3.1610265 -3.2157035 -3.2754312 -3.3266273 -3.3712058 -3.3733296
0:  -3.8463607 -3.8745704]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.562408 15.611496 15.743305 15.906912 16.171011 16.454374 16.951906
0:  17.334028 17.781157 18.10421  18.223722 18.153772 17.999475 17.894114
0:  17.840933 17.931412 17.965942 17.955393 17.905289 17.979025]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.3419223  -3.0720067  -2.616941   -2.0765805  -1.4857707  -0.8986616
0:  -0.29352856  0.21377897  0.7258792   1.1389918   1.4846902   1.7056742
0:   1.8465328   1.8934593   1.879242    1.8862715   1.957633    2.218639
0:   2.735406    2.8281999 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.120161 21.591797 22.081564 22.534498 22.992973 23.426765 23.864452
0:  24.207127 24.454609 24.576427 24.579613 24.500008 24.433212 24.431183
0:  24.503647 24.62106  24.735786 24.810238 23.660553 23.358913]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.043686 26.150318 26.251427 26.3158   26.336506 26.321754 26.307255
0:  26.197865 26.097889 25.958572 25.73906  25.507877 25.314735 25.140118
0:  24.980892 24.799335 24.597588 24.379833 24.146362 24.234459]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.934167  4.943181  4.961629  5.002332  5.0093203 4.966506  4.913623
0:  4.8035045 4.703595  4.592128  4.4578347 4.2818775 4.0815516 3.864032
0:  3.6070666 3.3666549 3.140016  2.9359465 2.4352074 2.2574067]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.4923897 5.5986876 5.7157063 5.7784953 5.846484  5.882806  5.916054
0:  5.930228  5.975798  6.034431  6.107846  6.140228  6.156315  6.149767
0:  6.0975046 6.0723085 6.08153   6.1098957 5.855199  5.932436 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.167643 19.46828  19.763071 20.013584 20.268192 20.493105 20.728718
0:  20.930386 21.138813 21.351849 21.549803 21.745306 21.930578 22.090622
0:  22.18107  22.250498 22.27715  22.26421  21.83141  21.880318]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.7581227 2.7301733 2.7636056 2.8388348 2.9782226 3.1338613 3.2952218
0:  3.428077  3.559572  3.6914728 3.83139   3.9448216 4.0385737 4.122594
0:  4.1570787 4.198707  4.2599053 4.339239  3.9752612 3.928533 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.497124  7.467275  7.420837  7.3351026 7.2180285 7.0577235 6.8509045
0:  6.6156864 6.373344  6.157053  5.964775  5.7683105 5.6129494 5.4646387
0:  5.3110113 5.176202  5.0743303 5.019594  4.419993  4.561494 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.591373  4.716537  4.8925633 5.1128144 5.3134174 5.483988  5.6689086
0:  5.8090844 5.952611  6.060493  6.1376224 6.1883264 6.2316384 6.2536345
0:  6.282037  6.274481  6.225993  6.146982  5.3754854 5.2624583]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.43422   8.530473  8.663741  8.816638  8.952545  9.093954  9.266536
0:   9.409828  9.574175  9.714026  9.827389  9.922737 10.031504 10.147248
0:  10.271443 10.404516 10.537956 10.650835 10.816326 11.014242]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -1.1589699   -1.0982685   -0.95744467  -0.8753061   -0.8911786
0:   -1.1263366   -1.5514736   -2.1684995   -2.8930488   -3.6386495
0:   -4.332093    -4.9886727   -5.5682654   -6.077892    -6.6332326
0:   -7.167648    -7.7466207   -8.216642   -10.241957   -10.819971  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.5838156  1.3977437  1.2570896  1.1171217  1.0326843  0.9688177
0:  0.93748474 0.96106815 1.0216818  1.1688333  1.3510737  1.569273
0:  1.7652526  1.9189863  1.9808683  1.9740691  1.8998137  1.8624754
0:  1.4674182  1.2844524 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.261455  -2.242968  -2.2280812 -2.2450624 -2.3146758 -2.4512925
0:  -2.619969  -2.814752  -2.9253602 -2.911591  -2.7679133 -2.5919394
0:  -2.406424  -2.2260356 -2.1445737 -2.051825  -1.952498  -1.8553767
0:  -1.9469943 -2.3004975]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.9902606 7.0244107 7.0749736 7.1208677 7.172044  7.208172  7.230662
0:  7.21856   7.2088633 7.1934977 7.1917562 7.1729975 7.152982  7.126741
0:  7.0842724 7.040546  6.9815426 6.936248  6.3867135 6.323217 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -9.271608   -9.396086   -9.522438   -9.635576   -9.734842   -9.851793
0:   -9.949209  -10.073885  -10.17355   -10.248579  -10.280161  -10.297958
0:  -10.265566  -10.179405  -10.093899   -9.974184   -9.841764   -9.6565895
0:   -9.924101   -9.72826  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.40841  25.194733 24.907585 24.535671 24.107449 23.670914 23.281975
0:  22.808033 22.448086 22.067955 21.638227 21.216698 20.799337 20.428253
0:  20.151833 19.916134 19.699902 19.4711   19.144585 18.953934]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.140287  -3.1333861 -3.1179032 -3.1636167 -3.2381043 -3.4140515
0:  -3.6425252 -3.9655442 -4.3500285 -4.761274  -5.197167  -5.693971
0:  -6.197203  -6.649876  -7.095198  -7.4078526 -7.6101623 -7.7249618
0:  -8.029978  -7.903916 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.0750208 -2.0899343 -2.0729904 -2.0335073 -1.949729  -1.8510342
0:  -1.7248869 -1.6158609 -1.4923925 -1.3662148 -1.2446108 -1.1822062
0:  -1.174756  -1.2087793 -1.330718  -1.4570541 -1.5822973 -1.6790838
0:  -2.7251692 -3.018343 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.923105  16.743244  16.623463  16.511711  16.389124  16.260254
0:  16.131317  15.947566  15.788362  15.627985  15.423905  15.184166
0:  14.952326  14.712741  14.498824  14.295496  14.110689  13.944223
0:  13.430332  13.1898155]
0: validation loss for strategy=forecast at epoch 3 : nan
0: validation loss for velocity_u : 0.029165931046009064
0: validation loss for velocity_v : 0.05996488034725189
0: validation loss for specific_humidity : 0.023858239874243736
0: validation loss for velocity_z : 0.40183618664741516
0: validation loss for temperature : 0.06408150494098663
0: validation loss for total_precip : nan
0: 4 : 10:02:33 :: batch_size = 96, lr = 1.903628792385485e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 4, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.0554, -1.0462, -1.0372, -1.0287, -1.0204, -1.0123, -1.0041, -0.9963, -0.9884, -0.9808, -0.9734, -0.9662,
0:         -0.9592, -0.9521, -0.9449, -0.9379, -0.9309, -0.9238, -1.0781, -1.0674, -1.0572, -1.0474, -1.0378, -1.0286,
0:         -1.0196], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.7966, 0.7959, 0.7945, 0.7923, 0.7896, 0.7858, 0.7816, 0.7767, 0.7710, 0.7646, 0.7577, 0.7496, 0.7410, 0.7314,
0:         0.7213, 0.7105, 0.6991, 0.6868, 0.8198, 0.8188, 0.8169, 0.8141, 0.8105, 0.8063, 0.8014], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1403, -0.1374, -0.1332, -0.1297, -0.1270, -0.1241, -0.1207, -0.1174, -0.1136, -0.1099, -0.1059, -0.1020,
0:         -0.0978, -0.0937, -0.0889, -0.0841, -0.0801, -0.0766, -0.1178, -0.1139, -0.1093, -0.1053, -0.1011, -0.0968,
0:         -0.0920], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0737, -0.1014, -0.1291, -0.1590, -0.1900, -0.2233, -0.2554, -0.2843, -0.3064, -0.3219, -0.3319, -0.3397,
0:         -0.3474, -0.3574, -0.3685, -0.3762, -0.3751, -0.3618, -0.0770, -0.1069, -0.1357, -0.1623, -0.1878, -0.2111,
0:         -0.2333], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0.1197, 0.1279, 0.1354, 0.1422, 0.1483, 0.1536, 0.1585, 0.1629, 0.1663, 0.1691, 0.1712, 0.1727, 0.1732, 0.1736,
0:         0.1739, 0.1738, 0.1743, 0.1746, 0.1750, 0.1754, 0.1755, 0.1756, 0.1756, 0.1757, 0.1764], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 4, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan, -0.1927,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1927,     nan,     nan,     nan, -0.1882,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1793,     nan,
0:             nan,     nan, -0.1525, -0.1525,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,  0.0483,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.1882,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.1905,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.1882,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.1481,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1481,     nan,
0:             nan,     nan, -0.1592,     nan,  0.0461,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,  0.1756,     nan,     nan,     nan,     nan,
0:             nan,     nan,  0.3608,     nan,  0.3295,     nan,     nan,     nan, -0.1927,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.1827,     nan,     nan,     nan,     nan,     nan, -0.1804, -0.1804,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1804,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.1525,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.1670,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  0.1845,
0:          0.1800,     nan,     nan,     nan,     nan,     nan,     nan,  0.2537,     nan,     nan,     nan,     nan,
0:          0.3117,     nan,     nan])
0: [DEBUG] Epoch 4, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-1.1281, -1.1160, -1.1027, -1.0884, -1.0706, -1.0566, -1.0399, -1.0315, -1.0236, -1.0156, -1.0113, -1.0080,
0:         -1.0029, -0.9924, -0.9796, -0.9592, -0.9407, -0.9247, -1.1072, -1.0983, -1.0914, -1.0776, -1.0671, -1.0537,
0:         -1.0388], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.1226, 0.1471, 0.1626, 0.1721, 0.1739, 0.1787, 0.1830, 0.1897, 0.1976, 0.2025, 0.2091, 0.2136, 0.2143, 0.2135,
0:         0.2146, 0.2159, 0.2208, 0.2296, 0.1478, 0.1777, 0.1970, 0.2114, 0.2194, 0.2274, 0.2360], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.2648, -0.2650, -0.2671, -0.2662, -0.2673, -0.2676, -0.2673, -0.2669, -0.2683, -0.2653, -0.2625, -0.2608,
0:         -0.2601, -0.2620, -0.2658, -0.2677, -0.2707, -0.2715, -0.2743, -0.2775, -0.2775, -0.2740, -0.2740, -0.2737,
0:         -0.2712], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.2704, -0.2793, -0.2909, -0.2860, -0.2730, -0.2678, -0.2617, -0.2806, -0.2875, -0.2720, -0.2584, -0.2380,
0:         -0.2299, -0.2359, -0.2206, -0.1931, -0.1595, -0.1308, -0.3069, -0.2960, -0.2805, -0.2631, -0.2554, -0.2660,
0:         -0.2741], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([-0.6244, -0.6181, -0.6123, -0.6095, -0.6087, -0.6108, -0.6133, -0.6154, -0.6166, -0.6167, -0.6172, -0.6154,
0:         -0.6124, -0.6098, -0.6089, -0.6118, -0.6162, -0.6189, -0.6171, -0.6112, -0.6050, -0.6014, -0.6016, -0.6057,
0:         -0.6120], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.06008373945951462; velocity_v: 0.09783913940191269; specific_humidity: 0.036490440368652344; velocity_z: 0.550960123538971; temperature: 0.09607324749231339; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.056873563677072525; velocity_v: 0.09632470458745956; specific_humidity: 0.03846276178956032; velocity_z: 0.5969387888908386; temperature: 0.1135060265660286; total_precip: nan; 
0: epoch: 4 [1/5 (20%)]	Loss: nan : nan :: 0.14405 (2.31 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.054259639233350754; velocity_v: 0.0840257853269577; specific_humidity: 0.04868597164750099; velocity_z: 0.6130107045173645; temperature: 0.11581790447235107; total_precip: nan; 
0: epoch: 4 [2/5 (40%)]	Loss: nan : nan :: 0.14060 (16.16 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.0608600452542305; velocity_v: 0.102037213742733; specific_humidity: 0.04039173200726509; velocity_z: 0.5753499269485474; temperature: 0.10563904047012329; total_precip: nan; 
0: epoch: 4 [3/5 (60%)]	Loss: nan : nan :: 0.14489 (16.16 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05422722548246384; velocity_v: 0.09846021980047226; specific_humidity: 0.037177953869104385; velocity_z: 0.6493443846702576; temperature: 0.09504837542772293; total_precip: nan; 
0: epoch: 4 [4/5 (80%)]	Loss: nan : nan :: 0.14130 (16.26 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0.]
0: Target values (first 200):
0: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0.]
0: Prediction values (first 20):
0: [14.433828 14.264385 14.101597 13.919573 13.743702 13.543863 13.321564
0:  13.066018 12.846213 12.669411 12.552401 12.463295 12.430447 12.404575
0:  12.36537  12.340439 12.364443 12.424305 12.308651 12.356889]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -1.588, max = 1.756, mean = -0.019
0:          sample (first 20): tensor([0.5801, 0.5670, 0.5543, 0.5402, 0.5265, 0.5110, 0.4938, 0.4739, 0.4569, 0.4431, 0.4340, 0.4271, 0.4246, 0.4226,
0:         0.4195, 0.4176, 0.4195, 0.4241, 0.6068, 0.5906])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.5449033 -7.5132594 -7.4096723 -7.246989  -7.033939  -6.839745
0:  -6.6659513 -6.6082406 -6.6377397 -6.7502036 -6.9204583 -7.1342187
0:  -7.357843  -7.566624  -7.8200555 -8.059702  -8.274412  -8.429094
0:  -9.078941  -9.309921 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.81055593 -0.9951725  -1.1478877  -1.2748752  -1.4165626  -1.6103964
0:  -1.8211441  -2.0658689  -2.321115   -2.5244508  -2.7026763  -2.8871722
0:  -3.0374646  -3.1464334  -3.2702003  -3.3278966  -3.366404   -3.3556428
0:  -3.5496736  -3.6099772 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-17.663885 -17.790329 -17.844124 -17.840578 -17.82042  -17.836843
0:  -17.853231 -17.908253 -17.966965 -18.051987 -18.134346 -18.22751
0:  -18.293413 -18.317387 -18.287842 -18.262234 -18.279459 -18.313025
0:  -18.798487 -18.949696]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.07466   9.001502  8.900236  8.746278  8.596123  8.441541  8.335672
0:  8.163664  8.013847  7.8521986 7.66506   7.4041877 7.115182  6.7983613
0:  6.422471  6.1097884 5.8205647 5.5059195 4.60959   4.327197 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-18.776339 -18.6399   -18.446815 -18.204498 -17.94464  -17.72292
0:  -17.481796 -17.333838 -17.211882 -17.080372 -16.962156 -16.830454
0:  -16.697428 -16.539585 -16.388662 -16.218027 -16.015896 -15.786547
0:  -15.972818 -15.679895]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.520515 19.733444 19.952486 20.123764 20.277943 20.428408 20.543226
0:  20.63733  20.7766   20.919891 21.104813 21.241222 21.348217 21.44531
0:  21.493835 21.538076 21.5616   21.567186 21.460056 21.633867]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.493699  -6.3340673 -6.1509113 -5.955742  -5.728816  -5.5127153
0:  -5.268564  -5.096779  -4.9364996 -4.792351  -4.668579  -4.584193
0:  -4.5303497 -4.4681463 -4.468096  -4.455763  -4.444376  -4.404991
0:  -5.016699  -5.057271 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.8093514 -2.7857003 -2.8025699 -2.8341374 -2.8451247 -2.8811946
0:  -2.8881555 -2.9396987 -2.9693484 -2.9864612 -2.99439   -3.0406356
0:  -3.091827  -3.2051396 -3.307055  -3.3556037 -3.342218  -3.2797437
0:  -3.2019982 -3.0003858]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.9662695 -6.069544  -6.198963  -6.343092  -6.5112915 -6.729643
0:  -6.927699  -7.195198  -7.4606028 -7.705758  -7.931571  -8.150223
0:  -8.328167  -8.484487  -8.664153  -8.825969  -8.998448  -9.127023
0:  -9.319484  -9.411726 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.5343776  5.5090904  5.5213137  5.5368404  5.4679384  5.253478
0:  4.9118276  4.384606   3.7264626  2.963952   2.1577606  1.4074144
0:  0.8535209  0.505394   0.3680873  0.3945999  0.4770069  0.58183765
0:  0.1844039  0.25097942]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.8342209 2.1954656 2.5968542 3.039581  3.487831  3.9127471 4.3354073
0:  4.6809254 4.9950666 5.2425423 5.42198   5.501901  5.5159388 5.4501734
0:  5.3099356 5.131437  4.941682  4.778779  4.1960096 4.060984 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.7323003  -2.384458   -1.9229131  -1.3387399  -0.66453934  0.02210474
0:   0.69542646  1.2492256   1.7125359   2.0810065   2.3784282   2.594846
0:   2.7543058   2.8485649   2.8362463   2.7716293   2.6820421   2.6027262
0:   2.0759635   2.2568698 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.9285197 -6.9249425 -6.904817  -6.870218  -6.837298  -6.838897
0:  -6.8367295 -6.9136596 -7.004107  -7.1346    -7.252292  -7.3730264
0:  -7.4327197 -7.390928  -7.3342204 -7.2161603 -7.083059  -6.9567475
0:  -6.8459964 -6.8713384]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.551235  8.693775  8.907653  9.193983  9.50165   9.810584 10.168211
0:  10.462919 10.730949 10.912945 10.984396 10.943512 10.841099 10.633027
0:  10.350951 10.004486  9.594124  9.191755  8.193435  7.687487]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.1432705 15.343435  15.468094  15.554825  15.620487  15.689777
0:  15.769064  15.751207  15.781603  15.831331  15.988058  16.263592
0:  16.665823  17.17356   17.71223   18.265135  18.836637  19.427723
0:  20.695978  21.218542 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.771936 23.973064 24.103382 24.176105 24.142963 24.043266 23.94385
0:  23.71017  23.481731 23.202751 22.846937 22.440748 22.049469 21.643564
0:  21.288578 20.961525 20.681047 20.430653 20.1675   20.011486]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -7.3818517  -7.8007884  -8.286648   -8.779587   -9.274281   -9.792019
0:  -10.257233  -10.681849  -11.046389  -11.286381  -11.402184  -11.4570465
0:  -11.4506855 -11.406351  -11.312073  -11.167482  -11.035385  -10.902258
0:  -10.117886  -10.035099 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.267736 15.225731 15.371025 15.602947 15.953897 16.407589 16.878706
0:  17.3781   17.890427 18.364376 18.79918  19.12223  19.405575 19.63796
0:  19.830778 20.009718 20.238935 20.486044 20.34988  20.480122]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.11433411  0.42281723  0.653996    0.74958086  0.73017406  0.55066633
0:   0.29246235 -0.0568738  -0.38316584 -0.6315217  -0.7776542  -0.8601589
0:  -0.8486171  -0.7457442  -0.6781583  -0.6256552  -0.5936842  -0.62164164
0:  -1.0385823  -1.2849135 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.154574   -7.871082   -8.433298   -8.647469   -8.384388   -7.7004123
0:  -6.6379476  -5.460983   -4.3534455  -3.4892335  -2.9317718  -2.7054524
0:  -2.6775327  -2.7069287  -2.7312093  -2.5577788  -2.2066607  -1.7360044
0:  -1.0338016  -0.78652716]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.831928  16.867256  16.868816  16.822437  16.742008  16.63102
0:  16.539135  16.38712   16.230911  16.01587   15.751248  15.46263
0:  15.179739  14.894222  14.622938  14.309404  13.927134  13.513104
0:  11.9861145 11.548826 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.470586   7.464314   7.507359   7.606955   7.688479   7.7692523
0:   7.88303    7.9409785  8.03572    8.16648    8.29941    8.470539
0:   8.706721   8.928791   9.198751   9.4184475  9.640836   9.873007
0:  10.033553  10.273861 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.1278186 -2.2071939 -2.1888757 -2.0265594 -1.7931218 -1.5586162
0:  -1.3459792 -1.2160544 -1.1637874 -1.1983628 -1.3034139 -1.4801507
0:  -1.7017303 -1.948914  -2.211947  -2.4406266 -2.6148143 -2.7103038
0:  -3.251144  -3.4096675]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.4496665 -2.6376948 -2.7931714 -2.9276843 -3.0354762 -3.1792035
0:  -3.288278  -3.443934  -3.5991998 -3.7274337 -3.8406568 -3.9297252
0:  -3.982633  -3.9946694 -4.009681  -3.9968133 -3.9949994 -4.006578
0:  -4.0190187 -3.9640937]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.351275  -4.197968  -4.0295405 -3.942799  -3.9461694 -4.114801
0:  -4.40142   -4.789847  -5.2005115 -5.548119  -5.779596  -5.9019523
0:  -5.8932586 -5.8010488 -5.734962  -5.7073483 -5.7964835 -5.9648147
0:  -7.085318  -7.2595973]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.200778   3.9744534  3.854631   3.8199782  3.8636017  3.9279923
0:  3.9794474  3.9201803  3.744058   3.4613369  3.1408188  2.7753966
0:  2.4509013  2.2028205  1.9561563  1.7484536  1.5562239  1.3641958
0:  0.87476015 0.19156742]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.874313  -5.888725  -5.876909  -5.8408732 -5.819118  -5.8647723
0:  -5.9554505 -6.131552  -6.3324113 -6.5425057 -6.731071  -6.924072
0:  -7.081673  -7.18362   -7.251145  -7.2635045 -7.2347894 -7.1300836
0:  -7.5591493 -7.5955644]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.290537 22.799126 22.29897  21.729286 21.177416 20.671213 20.26131
0:  19.984253 19.885738 19.972109 20.176842 20.482084 20.9389   21.524683
0:  22.373253 23.438606 24.673483 25.82691  27.72288  28.426416]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.646536  15.643909  15.635382  15.562613  15.448639  15.303648
0:  15.138893  14.961029  14.824972  14.7230015 14.633621  14.560123
0:  14.463259  14.378208  14.268289  14.173733  14.085329  13.970453
0:  13.976404  13.862964 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.9521813 -5.7960544 -5.572849  -5.334864  -5.105972  -4.9409547
0:  -4.817227  -4.800488  -4.824678  -4.8558946 -4.880608  -4.9315763
0:  -4.97895   -5.011452  -5.0880218 -5.131639  -5.13623   -5.0686593
0:  -5.1179147 -4.917537 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.698137   12.643569   12.601801   12.541498   12.402003   12.205124
0:  11.99318    11.681211   11.292753   10.774916   10.086723    9.27717
0:   8.421485    7.531897    6.596286    5.605781    4.562668    3.5854173
0:   1.681139    0.91013527]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.642986  -5.50901   -5.319613  -5.13611   -5.007668  -4.9578795
0:  -4.9366164 -5.045751  -5.22374   -5.5052915 -5.86815   -6.3344874
0:  -6.78919   -7.1773953 -7.490909  -7.6574397 -7.725572  -7.685983
0:  -7.4329486 -7.426785 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.428204  9.443158  9.418906  9.3849535 9.333161  9.29455   9.28668
0:  9.2448845 9.228933  9.213293  9.170225  9.12962   9.109263  9.087853
0:  9.073721  9.034394  9.011246  9.007311  8.891032  8.965172 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.820426  6.864694  6.905715  6.91656   6.9291344 6.9230123 6.9258504
0:  6.897821  6.8783994 6.8667455 6.849393  6.8222165 6.7857356 6.755817
0:  6.704399  6.6824284 6.6859283 6.724913  6.2635965 6.2828646]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.069758  14.096834  14.12557   14.085634  13.970938  13.676571
0:  13.191487  12.473105  11.65453   10.786547   9.965603   9.165497
0:   8.476322   7.906986   7.4352107  7.177951   7.165722   7.34023
0:   7.358377   7.337978 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.4223733 5.3550625 5.3158593 5.291978  5.243139  5.1296844 5.009736
0:  4.8452067 4.7011495 4.555728  4.4037476 4.216176  4.011877  3.819872
0:  3.6179748 3.4634998 3.334377  3.239127  2.665244  2.4683633]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.1708817 -3.0731606 -2.986754  -2.8716807 -2.7454352 -2.6433434
0:  -2.502481  -2.4000325 -2.2867303 -2.173244  -2.0381017 -1.900639
0:  -1.7151303 -1.5272613 -1.3304429 -1.1580434 -1.0490823 -0.9493365
0:  -1.3015685 -1.1688142]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.752115 12.882271 13.119996 13.270834 13.203086 12.848159 12.356005
0:  12.073873 12.445238 13.711828 15.696151 17.822372 19.442165 20.06446
0:  19.539764 18.252914 16.726841 15.398326 13.366716 13.018694]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.8476896  -1.7461824  -1.597908   -1.3982487  -1.1969633  -1.0238647
0:  -0.86271095 -0.76098394 -0.6131458  -0.4506774  -0.28044605 -0.08034563
0:   0.1455679   0.3759117   0.6070051   0.819046    1.0334382   1.2691712
0:   1.5272355   1.7920861 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.386228  11.059065  11.1168    11.209166  11.355495  11.355263
0:  11.173187  10.826819  10.450264  10.021829   9.648721   9.324665
0:   9.066515   8.895962   8.7154455  8.500284   8.315232   8.048561
0:   7.2911305  6.945737 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.668348  -9.551855  -9.400431  -9.233067  -9.042971  -8.878998
0:  -8.67749   -8.527376  -8.377266  -8.201973  -8.005508  -7.7845807
0:  -7.5068545 -7.2243533 -6.9596553 -6.6900992 -6.448589  -6.2079473
0:  -6.3319383 -6.068914 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.809103    0.5297532   0.22139311 -0.12650728 -0.46378708 -0.82743883
0:  -1.1887393  -1.592071   -2.0209365  -2.45653    -2.8839622  -3.3330607
0:  -3.7452064  -4.06974    -4.3804545  -4.594956   -4.7667766  -4.894855
0:  -5.4268947  -5.5633836 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.2720103   1.2068286   1.1774178   1.14257     1.1251264   1.0791168
0:   1.0429978   0.96108484  0.8649807   0.7839241   0.6814165   0.5768509
0:   0.46940994  0.36501694  0.2554369   0.20470333  0.17991352  0.18218184
0:  -0.161407   -0.11739016]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [34.779064 34.85573  34.853527 34.74517  34.56759  34.370403 34.181114
0:  33.90877  33.70042  33.463184 33.204784 32.899105 32.629787 32.38145
0:  32.162315 32.00054  31.890707 31.764917 31.506413 31.49877 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.36368  22.617516 22.823643 22.868086 22.828125 22.685898 22.493189
0:  22.21649  21.901567 21.5248   21.060799 20.52586  19.928122 19.276144
0:  18.567392 17.895023 17.252867 16.674002 15.535072 15.193939]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.4944315 13.421809  13.330751  13.193047  13.024817  12.83362
0:  12.690815  12.556188  12.4557    12.365038  12.226631  12.061234
0:  11.821317  11.475157  11.023471  10.452203   9.797641   9.1617
0:   8.8136425  8.54994  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.79077  22.840767 22.980598 23.144268 23.277937 23.391958 23.522022
0:  23.564285 23.65599  23.74064  23.724937 23.653841 23.569283 23.442127
0:  23.313446 23.173338 23.030325 22.88835  21.844963 21.723923]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.6225824 6.5723977 6.595543  6.620937  6.6916537 6.732891  6.7732735
0:  6.765513  6.790219  6.823494  6.876747  6.8611803 6.816626  6.783867
0:  6.706393  6.6598754 6.644096  6.6503086 6.44166   6.355179 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-19.198788 -19.279778 -19.383633 -19.466038 -19.634617 -19.900269
0:  -20.193493 -20.56662  -20.974293 -21.351612 -21.743671 -22.126766
0:  -22.451733 -22.740028 -22.904442 -23.100159 -23.245197 -23.413433
0:  -23.792294 -23.855507]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.59078264 0.47601223 0.5223017  0.71715736 1.0950694  1.640614
0:  2.2750542  2.8741     3.3380594  3.572986   3.6228693  3.4357862
0:  3.1569722  2.894901   2.6378255  2.546364   2.5747943  2.6569245
0:  2.6140213  2.885416  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.58175   9.646164  9.703836  9.736037  9.759107  9.771591  9.774949
0:   9.748933  9.767788  9.814124  9.870707  9.896098  9.92833   9.938477
0:   9.915783  9.90766   9.924837  9.980759  9.902061 10.021471]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.368097 20.496372 20.617748 20.698544 20.746342 20.80603  20.900412
0:  20.957756 21.044409 21.169174 21.261845 21.305464 21.322659 21.26117
0:  21.16035  21.031303 20.931656 20.870417 20.609081 20.574738]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.719273 26.566399 26.443634 26.339901 26.24915  26.174389 26.183174
0:  26.110075 26.091177 26.070559 25.948593 25.797285 25.611395 25.35132
0:  25.09433  24.795197 24.502821 24.225664 23.308653 23.228186]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.6538663  7.602262   7.570738   7.573788   7.6127505  7.690605
0:   7.8508787  8.078652   8.451854   8.967792   9.652178  10.42024
0:  11.255619  12.016396  12.624674  13.036084  13.256733  13.35712
0:  12.16338   12.267927 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.182092  8.974979  8.7779665 8.555609  8.285841  7.9338655 7.542621
0:  7.0788703 6.6290617 6.217376  5.83542   5.4988637 5.216978  4.9862537
0:  4.788563  4.6248546 4.4857273 4.375276  4.1478753 3.9168708]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.0120373 5.8565526 5.6916685 5.4710984 5.245319  4.9918323 4.75681
0:  4.4997177 4.2570624 4.0370474 3.7994463 3.545958  3.295885  3.0662057
0:  2.8516576 2.6890237 2.5520864 2.403611  2.1509078 1.9189234]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.284678 18.373896 18.574194 18.750603 18.957071 19.197493 19.451773
0:  19.719627 20.004711 20.322851 20.675167 21.013617 21.390566 21.748852
0:  22.062979 22.329533 22.59522  22.82583  22.49258  22.286526]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.71665   3.5900164 3.4172528 3.250282  3.0886397 2.9444087 2.9031084
0:  2.9097326 3.0131814 3.1918814 3.4015296 3.5921566 3.7636948 3.9080033
0:  3.9671245 3.9774687 3.913879  3.8013294 2.981214  2.8324122]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [43.642624 43.96894  44.161144 44.186398 44.107685 43.970882 43.851387
0:  43.65722  43.52458  43.373314 43.19866  42.952087 42.700108 42.40276
0:  42.052444 41.722183 41.421585 41.101116 40.38966  40.440636]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.9466891 -1.3099284 -1.6785145 -2.0519247 -2.4056292 -2.776331
0:  -3.1514177 -3.5887365 -4.043586  -4.4933357 -4.8507156 -5.1261606
0:  -5.2521763 -5.19524   -5.062765  -4.822158  -4.536747  -4.2684107
0:  -4.1790714 -4.185749 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.85194   20.260609  19.263912  17.846834  16.15438   14.306599
0:  12.539096  11.007678   9.787492   8.639959   7.465706   6.264164
0:   5.108209   4.3930693  4.2723093  4.8391294  5.9363556  7.128524
0:   8.22727    8.945246 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.9324512   7.937997    8.201518    8.676207    9.345738   10.088865
0:  10.720232   11.1020565  11.154537   10.707504    9.776126    8.393522
0:   6.771818    5.148148    3.7057095   2.6406393   1.9953418   1.6900554
0:   0.1473732   0.48557806]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.407047 29.539406 29.672651 29.791576 29.878092 29.952    30.01493
0:  29.966442 29.916643 29.8041   29.632526 29.401112 29.206318 29.055716
0:  28.998653 29.020767 29.11789  29.24843  29.341331 29.563961]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.680046  14.872399  15.0880375 15.289787  15.445171  15.570261
0:  15.752205  15.899107  16.06929   16.26382   16.397528  16.533783
0:  16.695566  16.838577  16.994606  17.111805  17.211687  17.296272
0:  17.137999  17.448326 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.811486 12.673076 12.665068 12.684965 12.739389 12.795614 12.815294
0:  12.787706 12.798878 12.790563 12.782571 12.758658 12.722627 12.620338
0:  12.460009 12.243809 11.991987 11.72088  10.52903  10.325591]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.357279 13.510126 13.733696 13.965664 14.209894 14.448369 14.700814
0:  14.951539 15.256945 15.610333 15.995154 16.387253 16.82292  17.24695
0:  17.707504 18.14547  18.57214  18.971867 19.040928 19.305964]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.144366  9.053294  9.00371   8.997062  9.072978  9.243652  9.546003
0:   9.872369 10.29886  10.808708 11.38286  12.047666 12.829773 13.655663
0:  14.497512 15.255869 15.871276 16.269056 15.309498 15.692033]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.974215  9.00458   9.020199  9.069732  9.127784  9.130641  9.128945
0:  9.028816  8.941843  8.865999  8.8219185 8.8322735 8.877784  8.918121
0:  8.912202  8.891478  8.896999  8.964561  8.754665  8.894547 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.2322464  2.6122     3.1521716  3.7964416  4.503498   5.227111
0:   5.975144   6.642669   7.277647   7.860194   8.391087   8.889954
0:   9.376423   9.845291  10.328272  10.787062  11.268568  11.682726
0:  12.010115  12.5805235]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.217361  12.105351  12.055174  11.996563  11.951824  11.928011
0:  11.882625  11.848145  11.877159  11.9170265 12.030633  12.154959
0:  12.310619  12.516262  12.683023  12.851883  13.055471  13.278074
0:  14.488515  14.774939 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.707178   9.991067  10.260574  10.3720455 10.389927  10.386698
0:  10.426474  10.528738  10.714449  10.985315  11.281433  11.469645
0:  11.6199875 11.70432   11.745241  11.842764  11.9662285 12.036652
0:  11.6388035 11.703402 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.100574 33.349957 33.53508  33.656918 33.721306 33.822376 33.977802
0:  33.938583 33.95928  33.844296 33.571404 33.126446 32.646935 32.187263
0:  31.806435 31.545668 31.36927  31.214876 31.347958 31.070143]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.1339798  0.40524292 0.698503   1.0153728  1.3529887  1.660449
0:  1.960629   2.201202   2.4483662  2.6756687  2.9333413  3.1914225
0:  3.4838736  3.7946815  4.093631   4.381958   4.6577835  4.9373527
0:  4.95992    5.177315  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-14.02608  -13.891828 -13.724614 -13.514689 -13.264762 -13.058801
0:  -12.841889 -12.692376 -12.560624 -12.409982 -12.22359  -12.05354
0:  -11.856204 -11.635446 -11.404332 -11.121381 -10.771771 -10.405995
0:  -10.682584 -10.590959]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.750511 30.040836 30.284779 30.465122 30.636497 30.822662 31.094162
0:  31.252163 31.451859 31.59896  31.672329 31.688354 31.689915 31.699932
0:  31.746002 31.846024 32.01236  32.166622 32.07467  32.296658]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.0108871  -0.98429155 -0.8890319  -0.7957897  -0.75841427 -0.8146782
0:  -0.9153414  -1.1337504  -1.3364968  -1.562367   -1.8091216  -2.1030145
0:  -2.4077277  -2.6529117  -2.9018064  -3.055819   -3.1734586  -3.1963134
0:  -4.1040683  -4.306062  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [30.86645  30.597853 30.40017  30.304028 30.26574  30.222534 30.23983
0:  30.212492 30.277842 30.309275 30.31454  30.31089  30.300116 30.349728
0:  30.380735 30.433271 30.43678  30.254642 30.92369  30.916374]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.118904   9.264786   9.475893   9.686301   9.85762    9.9635935
0:  10.03669   10.055393  10.063063  10.071259  10.07771   10.056809
0:  10.020493   9.977378   9.874477   9.759479   9.663882   9.565234
0:   9.179408   9.141449 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.55228   3.0003812 3.526832  4.0864673 4.5895224 4.9963136 5.26302
0:  5.4711356 5.60985   5.8022933 5.9655523 6.1496754 6.4039106 6.6384535
0:  6.874111  7.092166  7.3397346 7.683849  8.079659  8.5096655]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.32956   -5.304626  -5.2867913 -5.2678103 -5.261064  -5.296187
0:  -5.319781  -5.3901877 -5.444052  -5.491462  -5.5259643 -5.569755
0:  -5.5988784 -5.6139445 -5.64379   -5.651809  -5.6586576 -5.635473
0:  -5.974097  -5.939243 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.139132  13.106741  13.083096  13.0228405 12.943795  12.857
0:  12.781372  12.683081  12.61199   12.555817  12.483063  12.384276
0:  12.282513  12.171072  12.068898  11.993693  11.960413  11.962326
0:  12.050932  12.097589 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.5658927   3.469871    3.3534658   3.1753771   2.9372838   2.6163568
0:   2.2328153   1.7925315   1.3597779   0.95547485  0.5910711   0.21214247
0:  -0.1565671  -0.51233435 -0.9047079  -1.2852359  -1.6506009  -1.9409928
0:  -2.4061847  -2.325437  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -8.41234    -8.419909   -8.426809   -8.439165   -8.48308    -8.609541
0:   -8.7659645  -9.019356   -9.291988   -9.558533   -9.811199  -10.0624485
0:  -10.286417  -10.44548   -10.604582  -10.709917  -10.7923565 -10.841309
0:  -11.627529  -11.734945 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.6995726 -7.6459475 -7.5639772 -7.455106  -7.33029   -7.261834
0:  -7.164711  -7.1317444 -7.1174984 -7.0874376 -7.0405684 -6.9953337
0:  -6.9322405 -6.8241673 -6.7302036 -6.590822  -6.4606256 -6.2917566
0:  -6.544858  -6.4710913]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.8456621  1.7994542  1.7686753  1.8328204  1.9266057  2.0069227
0:  2.079994   2.0554101  2.0180304  1.9486251  1.8486137  1.7355175
0:  1.659123   1.5737195  1.4931693  1.4329257  1.4087052  1.4766378
0:  0.427948   0.48875046]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.457935  16.155703  15.843472  15.487166  15.11293   14.7195
0:  14.317463  13.922134  13.586941  13.348872  13.21834   13.070454
0:  12.863287  12.603054  12.17885   11.728622  11.300182  10.914169
0:  10.0075245  9.463734 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.254025  10.293638  10.333284  10.35349   10.372936  10.383589
0:  10.384768  10.366644  10.363329  10.370521  10.413097  10.4511385
0:  10.507548  10.599155  10.698429  10.822008  10.972364  11.108436
0:  11.042183  11.110523 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.7829394  -4.548761   -4.283524   -3.9934783  -3.660276   -3.3615022
0:  -3.0632358  -2.8339896  -2.5979056  -2.3310657  -2.0219207  -1.7303948
0:  -1.4391918  -1.1558995  -0.94219065 -0.72918034 -0.49064398 -0.27152967
0:  -0.39466047 -0.26713896]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.557529 14.685526 14.812168 14.897252 14.941982 14.92955  14.923949
0:  14.851934 14.79587  14.71994  14.652086 14.585848 14.580186 14.603098
0:  14.668545 14.739862 14.824712 14.861812 14.513735 14.424845]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.059044   5.2914796  5.5536833  5.8787184  6.2322073  6.6123285
0:   7.0338087  7.413887   7.820604   8.223101   8.614123   9.025883
0:   9.461557   9.881457  10.3159485 10.7111025 11.112614  11.518601
0:  11.46386   11.87439  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [28.02231  28.673893 29.115221 29.266266 29.178238 28.865355 28.378258
0:  27.607632 26.835531 25.969357 25.163496 24.44294  23.931725 23.695765
0:  23.693516 23.918833 24.29446  24.728146 24.470217 24.682972]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.9867482 4.058178  4.1017036 4.165498  4.2457814 4.3086963 4.3952417
0:  4.432616  4.484747  4.5171328 4.5615506 4.5998545 4.6591444 4.721371
0:  4.779769  4.8434715 4.8699446 4.9046535 4.4348364 4.461318 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-17.352242  -17.312157  -17.282988  -17.10448   -16.714478  -16.101994
0:  -15.207111  -14.044489  -12.67972   -11.146818   -9.653839   -8.403704
0:   -7.401299   -6.692866   -6.3433995  -6.190369   -6.154942   -6.249006
0:   -6.4452043  -5.8474364]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.478278  -9.552396  -9.591738  -9.581398  -9.526533  -9.482627
0:  -9.399066  -9.354942  -9.314454  -9.279411  -9.233769  -9.2239685
0:  -9.190802  -9.131381  -9.085375  -9.020451  -8.96485   -8.877349
0:  -9.32189   -9.272294 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.585911  -8.638847  -8.595222  -8.460863  -8.283361  -8.167301
0:  -8.028267  -7.957866  -7.8729386 -7.7874255 -7.702517  -7.6699014
0:  -7.617336  -7.5474668 -7.4888234 -7.385197  -7.3121085 -7.2100377
0:  -7.3618655 -7.345677 ]
0: validation loss for strategy=forecast at epoch 4 : nan
0: validation loss for velocity_u : 0.03497138246893883
0: validation loss for velocity_v : 0.06577525287866592
0: validation loss for specific_humidity : 0.024576298892498016
0: validation loss for velocity_z : 0.47811293601989746
0: validation loss for temperature : 0.06829984486103058
0: validation loss for total_precip : nan
0: 5 : 10:06:28 :: batch_size = 96, lr = 1.857198821839498e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 5, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.9289, 0.9217, 0.9176, 0.9149, 0.9131, 0.9132, 0.9145, 0.9140, 0.9073, 0.8935, 0.8751, 0.8565, 0.8390, 0.8211,
0:         0.8002, 0.7754, 0.7485, 0.7223, 0.8877, 0.8838, 0.8820, 0.8785, 0.8733, 0.8692, 0.8676], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-2.1296, -2.1639, -2.2081, -2.2594, -2.3151, -2.3745, -2.4370, -2.5019, -2.5690, -2.6389, -2.7131, -2.7922,
0:         -2.8747, -2.9591, -3.0434, -3.1247, -3.2000, -3.2677, -2.1219, -2.1484, -2.1843, -2.2281, -2.2800, -2.3397,
0:         -2.4058], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.3861, -0.3935, -0.4008, -0.4054, -0.4085, -0.4110, -0.4110, -0.4136, -0.4148, -0.4189, -0.4255, -0.4346,
0:         -0.4448, -0.4549, -0.4634, -0.4687, -0.4729, -0.4743, -0.3565, -0.3643, -0.3715, -0.3783, -0.3861, -0.3904,
0:         -0.3936], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.9896, -0.9093, -0.6487, -0.2913,  0.0342,  0.2574,  0.4179,  0.5785,  0.7368,  0.8215,  0.7797,  0.6422,
0:          0.4916,  0.3860,  0.3333,  0.3190,  0.3465,  0.4355, -1.2864, -1.1886, -0.9379, -0.5981, -0.2682,  0.0078,
0:          0.2453], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([1.0856, 1.0775, 1.0658, 1.0487, 1.0251, 0.9955, 0.9598, 0.9182, 0.8698, 0.8161, 0.7592, 0.7000, 0.6354, 0.5601,
0:         0.4721, 0.3774, 0.2876, 0.2141, 0.1625, 0.1311, 0.1138, 0.1051, 0.1005, 0.0971, 0.0927], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 5, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2441,     nan,     nan,     nan,     nan, -0.2441,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2429,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2285,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2441,     nan,     nan,     nan,     nan, -0.2441,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2441,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2429,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2429,     nan,     nan,     nan,
0:         -0.2381,     nan, -0.2273,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2357,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2441,     nan,
0:             nan,     nan,     nan,     nan, -0.2273,     nan, -0.2441,     nan,     nan,     nan,     nan, -0.2441,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2357,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2417,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2357,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2369,     nan,     nan])
0: [DEBUG] Epoch 5, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([1.0216, 1.0151, 1.0105, 0.9966, 0.9780, 0.9526, 0.9291, 0.9001, 0.8742, 0.8489, 0.8220, 0.7936, 0.7712, 0.7535,
0:         0.7425, 0.7361, 0.7341, 0.7359, 1.0299, 1.0293, 1.0250, 1.0148, 0.9956, 0.9720, 0.9463], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.1536, -0.1801, -0.2055, -0.2288, -0.2523, -0.2724, -0.2940, -0.3147, -0.3359, -0.3574, -0.3831, -0.4137,
0:         -0.4498, -0.4886, -0.5284, -0.5645, -0.5950, -0.6226, -0.1591, -0.1868, -0.2139, -0.2385, -0.2616, -0.2836,
0:         -0.3051], device='cuda:1', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.4208, -0.4213, -0.4258, -0.4272, -0.4314, -0.4340, -0.4398, -0.4438, -0.4488, -0.4534, -0.4579, -0.4606,
0:         -0.4650, -0.4714, -0.4779, -0.4843, -0.4899, -0.4904, -0.4009, -0.4045, -0.4087, -0.4136, -0.4205, -0.4272,
0:         -0.4322], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([ 0.1143,  0.1092,  0.0636,  0.0970,  0.1251,  0.1022,  0.0376, -0.0942, -0.2035, -0.3005, -0.3909, -0.4114,
0:         -0.4027, -0.4131, -0.4159, -0.4052, -0.3538, -0.2507,  0.0621,  0.0722,  0.0461,  0.1034,  0.1519,  0.1403,
0:          0.0626], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([1.5601, 1.5566, 1.5511, 1.5424, 1.5328, 1.5198, 1.5065, 1.4920, 1.4798, 1.4734, 1.4763, 1.4872, 1.5041, 1.5207,
0:         1.5354, 1.5455, 1.5545, 1.5599, 1.5626, 1.5614, 1.5534, 1.5406, 1.5260, 1.5125, 1.5036], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.05098649114370346; velocity_v: 0.09000593423843384; specific_humidity: 0.02786046452820301; velocity_z: 0.39461591839790344; temperature: 0.07843194901943207; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.08445285260677338; velocity_v: 0.1416744738817215; specific_humidity: 0.05130348727107048; velocity_z: 0.6204668283462524; temperature: 0.12032100558280945; total_precip: nan; 
0: epoch: 5 [1/5 (20%)]	Loss: nan : nan :: 0.16646 (2.60 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.04930910840630531; velocity_v: 0.07795844227075577; specific_humidity: 0.040159374475479126; velocity_z: 0.5077248811721802; temperature: 0.10454417765140533; total_precip: nan; 
0: epoch: 5 [2/5 (40%)]	Loss: nan : nan :: 0.13629 (16.14 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05664099007844925; velocity_v: 0.09173795580863953; specific_humidity: 0.03871187940239906; velocity_z: 0.5485875010490417; temperature: 0.08349794149398804; total_precip: nan; 
0: epoch: 5 [3/5 (60%)]	Loss: nan : nan :: 0.14169 (16.21 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06360030174255371; velocity_v: 0.1079610288143158; specific_humidity: 0.04590563476085663; velocity_z: 0.49619126319885254; temperature: 0.1173098087310791; total_precip: nan; 
0: epoch: 5 [4/5 (80%)]	Loss: nan : nan :: 0.14703 (16.07 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [2.5749207e-05 6.0081482e-05 5.3405762e-05 6.2942505e-05 5.7220459e-05
0:  3.0994415e-05 7.6293945e-06 1.9073486e-06 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 3.5762787e-04 5.5599213e-04 5.8078766e-04 2.8467178e-04
0:  7.1048737e-05 2.9993057e-04 2.9611588e-04 3.4999847e-04 1.0013580e-05
0:  5.6266785e-05 6.3896179e-05 2.1266937e-04 2.0647049e-04 1.4305115e-06
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  3.3378601e-06 9.0599060e-06 2.2411346e-05 4.9114227e-05 1.1587143e-04
0:  1.4925003e-04 1.1730194e-04 1.1777878e-04 3.3855438e-05 3.3378601e-06
0:  1.4305115e-06 9.5367432e-07 1.9073486e-06 2.3365021e-05 3.2901764e-05
0:  8.2492828e-05 1.1777878e-04 6.5374374e-04 5.3977966e-04 2.5749207e-04
0:  3.0183792e-04 5.1355362e-04 6.9665909e-04 6.7996979e-04 6.8855286e-04
0:  6.4373016e-04 4.5681000e-04 3.7288666e-04 3.2377243e-04 2.5129318e-04
0:  1.2111664e-04 5.2928925e-05 3.7670135e-05 3.9577484e-05 3.0708313e-04
0:  6.2847137e-04 9.7751629e-04 1.3489723e-03 1.8401146e-03 1.2001991e-03
0:  2.1171570e-04 5.1164627e-04 4.0054321e-05 1.9073486e-06 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.5367432e-07
0:  1.6689301e-05 7.6293945e-05 1.1730194e-04 2.1266937e-04 9.9611282e-04
0:  9.8419201e-04 1.7738342e-04 3.8623810e-05 4.1007996e-05 2.3841858e-05
0:  3.2424927e-05 4.9114227e-05 5.1498413e-05 3.4809113e-05 1.3351440e-05
0:  1.9073486e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  9.5367432e-07 9.5367432e-07 2.3841858e-06 3.8146973e-06 4.7683716e-06
0:  5.2452087e-06 4.7683716e-06 2.4127960e-04 3.6811829e-04 1.6307831e-04
0:  2.2602081e-04 5.4025650e-04 5.0926208e-04 9.5367432e-07 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 4.7683716e-07 7.6293945e-06 1.9073486e-05
0:  3.7193298e-05 8.2015991e-05 1.8119812e-04 2.6273727e-04 1.3875961e-04
0:  2.6702881e-05 1.4305115e-06 4.7683716e-07 0.0000000e+00 4.7683716e-07
0:  4.7683716e-06 2.6702881e-05 1.8501282e-04 1.8548965e-04 1.4495850e-04
0:  6.1607361e-04 6.4611435e-04 3.2520294e-04 1.1920929e-04 1.0204315e-04
0:  1.0013580e-04 1.3065338e-04 1.6880035e-04 2.6702881e-04 2.5558472e-04
0:  1.9454956e-04 1.1634827e-04 6.4849854e-05 9.1075897e-05 1.3399124e-04
0:  2.0122528e-04 1.8024445e-04 2.3555756e-04 4.8303604e-04 8.7499619e-04
0:  9.4461453e-04 2.0189285e-03 3.5638812e-03 1.1110306e-04 2.8848648e-04]
0: Target values (first 200):
0: [5.96046448e-05 1.01566315e-04 1.43051147e-06 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 2.86102295e-06 2.86102295e-06
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.76837158e-07
0:  4.52995300e-05 4.95910608e-05 1.43051147e-05 9.34600830e-05
0:  3.26633453e-04 1.58309937e-04 9.91821289e-05 9.34600830e-05
0:  1.09195709e-04 9.01222229e-05 5.34057617e-05 4.52995300e-05
0:  5.43594360e-05 8.05854797e-05 7.82012939e-05 1.22070312e-04
0:  7.91549683e-05 7.05718994e-05 2.90870667e-05 3.33786011e-06
0:  1.23977661e-05 3.24249268e-05 4.72068787e-05 1.03473663e-04
0:  1.03473663e-04 1.03950500e-04 1.19209290e-04 1.26361847e-04
0:  1.15871429e-04 8.29696655e-05 6.19888306e-05 5.19752502e-05
0:  2.95639038e-05 3.48091125e-05 3.91006470e-05 1.02519989e-04
0:  2.13146210e-04 2.68459320e-04 2.98976898e-04 3.75747681e-04
0:  2.87532806e-04 2.32696533e-04 5.91278076e-05 1.17778778e-04
0:  1.56402588e-04 2.22682953e-04 2.38895416e-04 1.66416168e-04
0:  6.38961792e-05 1.09672546e-05 1.43051147e-06 9.53674316e-07
0:  1.04904175e-05 9.05990601e-06 1.03950500e-04 4.36306000e-04
0:  1.22165680e-03 2.10666656e-03 2.64167786e-03 3.82423401e-04
0:  2.48432159e-04 6.72340393e-05 8.58306885e-06 0.00000000e+00
0:  0.00000000e+00 5.19752502e-05 2.27928162e-04 2.55107880e-04
0:  6.15119934e-05 5.00678980e-05 1.23500824e-04 8.39233398e-05
0:  7.26699829e-04 7.11441040e-04 2.71797180e-05 4.29153442e-06
0:  2.38418579e-05 1.04904175e-05 2.67028809e-05 6.67572021e-06
0:  4.76837158e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 1.28746033e-05 1.28746033e-05
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.43051147e-06
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 4.76837158e-07 1.90734863e-06
0:  1.86443329e-04 1.87397003e-04 8.10623169e-06 6.38961792e-05
0:  2.52723694e-04 2.46047974e-04 2.68459320e-04 1.56402588e-04
0:  1.57833099e-04 1.95503235e-04 1.81198120e-04 1.50680542e-04
0:  1.42097473e-04 7.77244568e-05 4.43458557e-05 3.43322754e-05
0:  1.18732452e-04 9.72747803e-05 3.67164612e-05 7.15255737e-06
0:  1.14440918e-05 3.48091125e-05 7.77244568e-05 6.29425049e-05
0:  9.39369202e-05 1.81198120e-04 2.06470490e-04 2.36034393e-04
0:  2.03132629e-04 1.13010406e-04 7.77244568e-05 8.77380371e-05
0:  9.63211060e-05 1.50203705e-04 5.72204590e-05 1.85489655e-04
0:  3.25679779e-04 3.44753265e-04 3.22818756e-04 3.35693359e-04
0:  2.80380249e-04 4.05311584e-05 3.86238098e-05 7.39097595e-05
0:  8.24928284e-05 1.48773193e-04 2.01702118e-04 1.59263611e-04
0:  6.53266907e-05 3.24249268e-05 3.33786011e-06 2.38418579e-06
0:  6.67572021e-06 2.71797180e-05 4.38690186e-05 2.61783600e-04
0:  1.31893158e-03 3.23915482e-03 4.10413742e-03 2.88963318e-04]
0: Prediction values (first 20):
0: [0.45054436 0.37778854 0.38742447 0.43049002 0.4668994  0.5302448
0:  0.5816078  0.6256833  0.70515347 0.79472256 0.9519253  1.1145754
0:  1.3188992  1.5500417  1.7593737  1.8957572  1.9463973  1.922329
0:  1.7591434  1.4832234 ]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -0.962, max = 1.880, mean = 0.296
0:          sample (first 20): tensor([-0.5132, -0.5195, -0.5186, -0.5149, -0.5118, -0.5064, -0.5020, -0.4982, -0.4914, -0.4838, -0.4703, -0.4564,
0:         -0.4389, -0.4191, -0.4012, -0.3895, -0.3852, -0.3872, -0.4900, -0.4971])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.278499  -4.778154  -5.170048  -5.3555646 -5.3330483 -5.2067695
0:  -5.0475373 -4.978951  -5.0154376 -5.1642814 -5.3390584 -5.562225
0:  -5.7450643 -5.872132  -6.0560737 -6.2316556 -6.444346  -6.670363
0:  -7.2679667 -7.4003606]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.7402906 6.931291  7.2460275 7.57481   7.914366  8.192613  8.437424
0:  8.571741  8.67645   8.774761  8.839272  8.913925  9.007823  9.107782
0:  9.175634  9.208393  9.192718  9.164895  9.459215  9.284936 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.9369717 -4.9497633 -4.9509077 -4.9248857 -4.835002  -4.7300415
0:  -4.5781307 -4.461375  -4.3383274 -4.213847  -4.0593185 -3.9437418
0:  -3.7838717 -3.5941381 -3.416254  -3.233121  -3.0613298 -2.8817415
0:  -2.7670965 -2.5949268]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.1939397 4.0881143 4.0750656 4.1093388 4.113301  4.12521   4.109597
0:  4.0428057 3.990651  3.9099188 3.836723  3.712805  3.6465335 3.6086357
0:  3.5804968 3.5791788 3.6361806 3.745733  3.9092305 3.8211687]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-12.209903  -12.18616   -12.030461  -11.735707  -11.246398  -10.665896
0:  -10.041438   -9.498375   -9.036554   -8.7127905  -8.436897   -8.307343
0:   -8.224604   -8.137547   -8.159813   -8.1501465  -8.116204   -8.044983
0:   -7.4256773  -6.9520483]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.540592   8.737109   9.002386   9.347775   9.709227  10.078987
0:  10.4302845 10.738447  11.010035  11.300765  11.60927   11.909942
0:  12.224567  12.491898  12.706969  12.859009  13.031137  13.290433
0:  13.039461  13.278481 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.2045016 -5.198191  -5.268727  -5.425157  -5.608066  -5.8071856
0:  -5.9418025 -6.0676312 -6.1356845 -6.1554036 -6.135301  -6.1312785
0:  -6.133839  -6.1333737 -6.222996  -6.278457  -6.3121076 -6.285298
0:  -6.8971972 -6.9675975]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [34.06915  33.916836 33.83513  33.810097 33.827732 33.795094 33.72447
0:  33.502728 33.24852  32.945488 32.577423 32.259186 31.952065 31.699924
0:  31.448391 31.209507 30.954212 30.609211 30.46175  30.307072]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.74964285 0.90955305 1.0442467  1.1432743  1.2479253  1.314836
0:  1.3885937  1.4105244  1.4549813  1.5219264  1.6020079  1.6640153
0:  1.7134047  1.7899237  1.8303905  1.94483    2.114743   2.3476307
0:  2.5000536  2.7638292 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.2131052  -1.1152735  -0.973083   -0.7674856  -0.54250574 -0.37326145
0:  -0.23450804 -0.19467258 -0.18472242 -0.21589422 -0.25760508 -0.32501984
0:  -0.38518238 -0.42949247 -0.48968983 -0.51543045 -0.51144314 -0.4553957
0:  -0.4999051  -0.3527031 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-25.605545 -25.518013 -25.219952 -24.795046 -24.30805  -23.891077
0:  -23.417395 -23.04625  -22.68793  -22.297525 -21.912378 -21.511084
0:  -21.028177 -20.538767 -20.048721 -19.536888 -19.134317 -18.800037
0:  -19.275051 -19.095455]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.189316 26.446177 26.78606  27.171999 27.545706 27.922546 28.273394
0:  28.48291  28.65069  28.683268 28.582048 28.350456 28.04262  27.65366
0:  27.17735  26.672379 26.194077 25.8254   24.735237 24.65683 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.5668855  -1.687139   -1.5103593  -1.0604687  -0.42607117  0.298779
0:   1.0618725   1.7087915   2.3020983   2.790539    3.197213    3.4648209
0:   3.675551    3.8998773   4.0675583   4.270547    4.5197606   4.803557
0:   5.3756046   5.9238243 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.8053827 -4.6677704 -4.548517  -4.433055  -4.312153  -4.230113
0:  -4.1382437 -4.0984735 -4.0593443 -4.005372  -3.9248238 -3.8462772
0:  -3.737752  -3.6006184 -3.4871845 -3.3553457 -3.2603502 -3.1493654
0:  -3.346675  -3.1883993]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.3822045 4.5098433 4.6141396 4.6928625 4.7223434 4.7157345 4.6971884
0:  4.6345835 4.563491  4.4518323 4.2759376 4.029322  3.765845  3.5048954
0:  3.2805865 3.0805488 2.9090579 2.7677026 2.6774838 2.7732081]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.292435  4.1374435 3.924665  3.6574562 3.3382082 3.0378273 2.8594527
0:  2.7149591 2.6392207 2.6348252 2.6648312 2.769907  2.9544377 3.099953
0:  3.2325873 3.252242  3.107477  2.9595017 2.7590356 2.79211  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.970297  10.808283  10.5939865 10.318171   9.994091   9.634756
0:   9.26898    8.849783   8.411678   7.941973   7.3814707  6.79467
0:   6.21587    5.6737847  5.1611037  4.683691   4.1926775  3.6964035
0:   3.369534   3.0880847]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.049488  4.0896416 4.1344757 4.1614895 4.149448  4.065325  3.9324613
0:  3.744677  3.5491111 3.3791862 3.2561288 3.1592538 3.094311  3.0924675
0:  3.0968049 3.1703627 3.2867854 3.4370863 3.7282295 3.690246 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.8975773 -2.754675  -2.6097708 -2.4653692 -2.3251057 -2.1981726
0:  -2.0435581 -1.9294305 -1.8026638 -1.7048044 -1.6472793 -1.6971202
0:  -1.8062835 -1.9673057 -2.205638  -2.3960514 -2.5509453 -2.6308327
0:  -3.3980408 -3.5045033]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.3313355 -2.364452  -2.4584737 -2.5992742 -2.7647014 -3.0071893
0:  -3.2473617 -3.5226426 -3.7478147 -3.8969216 -3.949058  -3.942902
0:  -3.8877883 -3.7682424 -3.657022  -3.4952064 -3.3096414 -3.1035438
0:  -3.0285316 -2.914353 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.891263  9.91765   9.870893  9.49152   8.823733  7.807667  6.5485234
0:  5.2077312 3.975629  3.0305662 2.470718  2.128034  2.037202  2.20719
0:  2.4755554 2.9318974 3.4729626 4.080963  4.3648467 4.461333 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.503054 26.534557 26.568943 26.574337 26.570454 26.524282 26.464762
0:  26.354906 26.319729 26.299973 26.290886 26.284033 26.289902 26.342407
0:  26.32625  26.318596 26.290028 26.231556 26.02995  25.945944]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.538372 15.333778 15.188536 14.94746  14.706295 14.332643 13.890707
0:  13.353806 12.775689 12.229528 11.69267  11.176733 10.708958 10.406334
0:  10.187838 10.174564 10.302524 10.547075 10.957144 10.731934]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.6425285 5.666594  5.6783295 5.658816  5.6247325 5.588792  5.5734577
0:  5.5473022 5.53829   5.5281153 5.4977083 5.4015937 5.2802086 5.137684
0:  4.9695096 4.8468285 4.77226   4.7703753 4.6201096 4.6439486]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.736579   -8.782277   -8.726492   -8.527337   -8.129335   -7.5814466
0:  -6.800349   -5.934989   -4.969492   -3.9969635  -3.0461092  -2.2120085
0:  -1.4491463  -0.82776785 -0.3814373  -0.08774376  0.10855532  0.22549152
0:  -0.23702288 -0.28831387]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.1697965 -4.172726  -4.176212  -4.192312  -4.2307515 -4.318663
0:  -4.4188952 -4.5758376 -4.737082  -4.9034495 -5.0494123 -5.2004743
0:  -5.333347  -5.4517426 -5.6283994 -5.813931  -6.0243487 -6.2092423
0:  -7.235411  -7.4992337]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.5888734  0.8777423  1.4161949  2.0108995  2.685132   3.342836
0:   3.9636912  4.447074   4.926796   5.3131533  5.688292   6.0622106
0:   6.5402055  7.0377374  7.5967956  8.129391   8.737931   9.390231
0:  11.667767  12.0465355]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -9.238114   -9.299354   -9.346447   -9.3848915  -9.388865   -9.418064
0:   -9.533572   -9.790704  -10.113395  -10.43521   -10.588202  -10.577596
0:  -10.381896  -10.021383   -9.674323   -9.305486   -8.955343   -8.631586
0:   -8.592229   -8.294992 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.8698373 -5.8315234 -5.810018  -5.7710433 -5.75872   -5.798572
0:  -5.8287396 -5.913651  -5.993913  -6.0604806 -6.11914   -6.1875443
0:  -6.2454467 -6.2826552 -6.3186374 -6.316914  -6.344908  -6.3700814
0:  -6.841932  -6.894398 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.486999  7.6531796 7.805768  7.8633184 7.9176226 7.959245  7.98631
0:  8.007217  8.083517  8.188549  8.301748  8.358277  8.390766  8.391981
0:  8.355414  8.3857975 8.535284  8.758403  8.685959  8.8756275]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.407941  12.11468   11.78292   11.389084  10.916126  10.392357
0:   9.890707   9.383209   8.930248   8.519748   8.131961   7.7468743
0:   7.383917   7.0091577  6.6257896  6.2175894  5.7860017  5.408746
0:   5.222155   4.9498625]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [40.976746 40.088276 38.299374 35.702248 32.572735 29.34328  26.490486
0:  24.366089 23.00111  22.300678 21.832975 21.420506 20.998951 20.470032
0:  20.04809  19.697407 19.477242 19.31437  18.196476 18.415789]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.117887  -3.99515   -3.877667  -3.7674422 -3.6279693 -3.4991336
0:  -3.3222518 -3.1800618 -3.0166736 -2.8398767 -2.6527247 -2.4733958
0:  -2.3176951 -2.151424  -2.0616736 -1.9954743 -1.9767642 -1.9771562
0:  -2.7445493 -2.8946214]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.075812  14.152521  14.254078  14.3445215 14.4005575 14.423199
0:  14.497126  14.478905  14.581404  14.71546   14.862787  14.947054
0:  15.032476  15.084803  15.065855  15.070509  15.072968  15.052626
0:  14.589724  14.702883 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-14.902166  -14.963856  -14.8390255 -14.600676  -14.335384  -14.190079
0:  -14.069521  -14.093464  -14.107319  -14.067871  -14.027004  -14.025866
0:  -13.995834  -13.949656  -13.974947  -13.916658  -13.903423  -13.879452
0:  -14.063522  -13.9027405]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.512756 23.70253  23.980038 24.283714 24.554058 24.781368 25.011341
0:  25.234238 25.571636 26.00315  26.47329  26.88879  27.256481 27.64101
0:  28.00256  28.388996 28.686306 28.831001 28.096073 27.949001]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.3417425  8.538395   8.765558   8.960523   9.148957   9.301763
0:   9.458388   9.594959   9.760128   9.950398  10.147652  10.313076
0:  10.457081  10.58725   10.683424  10.797495  10.929263  11.035045
0:  11.172671  11.393318 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.6414456 7.7273097 7.7537975 7.682122  7.5327806 7.349166  7.2038774
0:  7.0407815 6.937608  6.8318443 6.7277374 6.5751505 6.443811  6.3384314
0:  6.2195907 6.112091  6.0053663 5.924317  5.4966764 5.4879627]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.5756655 -6.3127966 -5.925152  -5.4254265 -4.853527  -4.3159304
0:  -3.774476  -3.314127  -2.8826075 -2.5489883 -2.2604237 -2.064826
0:  -1.8475561 -1.659977  -1.5317369 -1.3719463 -1.2083278 -0.9414425
0:  -1.1667929 -1.4670811]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.257526 18.165913 18.09277  17.892826 17.675152 17.421667 17.198452
0:  17.004436 16.807232 16.595612 16.320194 15.892392 15.334548 14.683102
0:  13.838854 12.940449 11.954131 11.002366  8.924319  8.071224]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.2932596 2.4025273 2.6525269 2.9537468 3.2723823 3.5450947 3.745944
0:  3.8741038 3.9904442 4.131562  4.3547444 4.5943894 4.850124  5.0698833
0:  5.171376  5.1712956 5.0706797 4.930099  4.5597777 4.563733 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.829182   9.015953   9.251184   9.472728   9.707705   9.935942
0:  10.140738  10.324397  10.511887  10.721662  10.963717  11.173784
0:  11.37986   11.588339  11.770991  11.971242  12.157493  12.3116665
0:  12.444485  12.472338 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.349027  -4.341722  -4.383695  -4.4531655 -4.53352   -4.582804
0:  -4.5528054 -4.4561896 -4.262591  -4.025375  -3.7783122 -3.5747828
0:  -3.421289  -3.3185792 -3.3224626 -3.3578887 -3.413776  -3.4705424
0:  -3.754682  -3.8505712]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.6442895  0.6041584  0.69825315 0.85359526 1.0756588  1.300312
0:  1.564784   1.8104458  2.0852838  2.3436098  2.5428476  2.7207656
0:  2.8917584  3.0309677  3.204163   3.3577704  3.517532   3.741899
0:  4.2275286  4.4979944 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.718253  4.8054276 4.867034  4.915468  4.9712625 4.986823  4.9867907
0:  4.9514565 4.908992  4.881566  4.860515  4.8390226 4.841982  4.835806
0:  4.8142476 4.8047223 4.8094807 4.852806  4.5481286 4.6793604]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.625505   -3.725803   -3.6970162  -3.4488683  -3.043589   -2.5177283
0:  -1.9174418  -1.3343773  -0.7540307  -0.20477104  0.29070282  0.623436
0:   0.83595467  0.93610764  0.91275024  0.8961921   0.9110031   0.9749856
0:   1.0705566   1.2434325 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.4928665 3.4290879 3.380474  3.312056  3.2743979 3.2154176 3.1377459
0:  3.0192823 2.9081933 2.824225  2.7832525 2.7340333 2.6924334 2.6789849
0:  2.6314492 2.6354964 2.7106438 2.8288605 3.0634577 3.0389204]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.57826   8.684384  8.800815  8.963793  9.137862  9.32257   9.527563
0:   9.659069  9.823999  9.977167 10.118247 10.278048 10.483562 10.710188
0:  10.990038 11.287734 11.627108 11.986074 12.501321 12.951151]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.1571262 3.3331053 3.550483  3.85502   4.167821  4.515526  4.913792
0:  5.256698  5.632841  5.9896693 6.3102946 6.660248  7.0453134 7.4395757
0:  7.845538  8.231034  8.616621  9.068206  8.974993  9.174365 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.693449  8.846883  9.010293  9.186724  9.338972  9.478008  9.600753
0:   9.660466  9.71012   9.770082  9.81705   9.876326  9.973295 10.023882
0:  10.093222 10.111071 10.144417 10.192584 10.06749  10.231476]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [34.02332  33.84551  33.823044 33.869297 33.949795 34.03872  34.128593
0:  34.097687 34.161263 34.208572 34.14059  33.97935  33.790653 33.5897
0:  33.481018 33.41354  33.37114  33.28168  33.173737 33.11675 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.8362145 -6.2909446 -6.709951  -7.0407805 -7.2671466 -7.474052
0:  -7.6296067 -7.792544  -7.9187465 -8.032234  -8.085413  -8.04875
0:  -7.94171   -7.7485633 -7.539003  -7.3518405 -7.212704  -7.1077867
0:  -8.838758  -8.958029 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.124207   -3.0518165  -2.9491782  -2.805222   -2.5946536  -2.3942304
0:  -2.1411405  -1.9494624  -1.7517867  -1.5714955  -1.3841524  -1.2323742
0:  -1.1030283  -0.9405403  -0.83192205 -0.7067995  -0.5860295  -0.46206665
0:  -0.9892912  -0.96123886]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.874462 27.834084 27.780521 27.68837  27.599094 27.534672 27.524014
0:  27.462063 27.469257 27.454582 27.391567 27.32172  27.264797 27.238785
0:  27.27259  27.32587  27.374744 27.330143 26.675816 26.681328]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.2991023  -1.2367744  -1.1727762  -1.0575113  -0.93468094 -0.820765
0:  -0.68325615 -0.59138584 -0.4786582  -0.38080359 -0.26829958 -0.1468792
0:   0.02956963  0.24998331  0.49612522  0.7621746   1.0079875   1.2514257
0:   1.153255    1.3852997 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.150078 10.392219 10.709198 11.057132 11.461158 11.846354 12.199212
0:  12.472014 12.687991 12.843813 12.966146 13.04102  13.144095 13.266774
0:  13.399624 13.551705 13.752453 13.992767 13.895508 14.213172]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.286071  6.2068443 6.207185  6.2196326 6.228673  6.1755214 6.021229
0:  5.7662845 5.4372997 5.0976944 4.7468266 4.4124746 4.0967283 3.803829
0:  3.5194092 3.294388  3.124268  2.999433  2.7500284 2.7150254]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [37.60577  37.91496  38.32296  38.810425 39.383766 40.104385 40.893524
0:  41.66147  42.440643 43.1243   43.674427 44.031464 44.36222  44.53787
0:  44.706566 44.791077 44.8683   44.810104 41.083218 41.387295]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [35.937183 35.895737 35.875904 35.786613 35.71793  35.654827 35.572247
0:  35.438377 35.308838 35.15105  34.967167 34.711617 34.41448  34.101166
0:  33.72882  33.385654 33.12687  32.969875 32.509125 32.29619 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.917138  6.9819956 7.1207047 7.3259754 7.5246563 7.6669426 7.8066335
0:  7.8464055 7.894212  7.89774   7.8813653 7.8706255 7.9130993 7.9632215
0:  8.042149  8.136708  8.229967  8.35466   7.9253807 8.007174 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.3940296 2.5041862 2.6334524 2.7592268 2.9053571 3.052533  3.2249067
0:  3.3999    3.6034212 3.8182607 4.039501  4.238545  4.4213552 4.6017857
0:  4.755431  4.9181595 5.0885286 5.281769  4.7567863 4.8246794]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.3015056 -4.0394588 -3.7778468 -3.4892402 -3.2080855 -2.9621081
0:  -2.6975656 -2.5074754 -2.3463607 -2.2231994 -2.1455731 -2.0898376
0:  -2.008185  -1.959269  -1.906528  -1.8724971 -1.8169751 -1.6989512
0:  -1.950233  -1.688396 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.4887614 -1.7561793 -2.0478034 -2.3705697 -2.677198  -2.9661021
0:  -3.2047458 -3.3886085 -3.5109706 -3.5453925 -3.5014968 -3.4598794
0:  -3.439218  -3.4394174 -3.5541053 -3.7107635 -3.8810534 -4.0587516
0:  -4.662087  -4.872929 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.212605 16.284315 16.294722 16.25584  16.20853  16.145716 16.100069
0:  15.987162 15.855484 15.706135 15.505674 15.306154 15.093653 14.889235
0:  14.669136 14.46805  14.285631 14.126301 13.308545 13.343887]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.467154 25.501078 25.498676 25.482677 25.500755 25.559399 25.68639
0:  25.741034 25.820955 25.807837 25.697474 25.628164 25.559778 25.4576
0:  25.306633 24.928143 24.391296 23.783995 22.247019 21.96026 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [42.81742  43.132187 43.396053 43.49836  43.4948   43.101482 42.091415
0:  40.416958 38.31125  36.353413 34.940754 34.37247  34.708225 35.93229
0:  37.707478 39.87654  42.248318 44.38592  47.893764 48.207096]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.5281553  -0.7313757  -0.90090036 -1.0406952  -1.175314   -1.3339314
0:  -1.4421759  -1.5614076  -1.6112757  -1.6026578  -1.4902792  -1.3640285
0:  -1.2001648  -1.0274386  -0.9409313  -0.88765764 -0.8983307  -0.9152007
0:  -1.9548516  -2.2950764 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.165254  -4.1951365 -4.264932  -4.4003463 -4.5517116 -4.770828
0:  -5.0051417 -5.355334  -5.729366  -6.109411  -6.4236474 -6.6742015
0:  -6.8026357 -6.7588716 -6.6403356 -6.3939195 -6.0876307 -5.7517323
0:  -5.3437    -5.0741944]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.710303  8.660165  8.628665  8.586615  8.579494  8.582113  8.556947
0:  8.518095  8.468656  8.407547  8.372297  8.326133  8.273619  8.215537
0:  8.140626  8.046735  7.9877462 7.9723835 7.5989327 7.8183527]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [43.022064 43.651127 44.16582  44.598347 44.931877 45.160812 45.276337
0:  45.21384  45.039318 44.711998 44.15881  43.377632 42.470158 41.50987
0:  40.506866 39.60437  38.802467 38.0238   37.481415 36.556995]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.8506608  -0.753572   -0.6385603  -0.5485649  -0.45290995 -0.3990221
0:  -0.35571814 -0.37253952 -0.3911214  -0.39484167 -0.3576336  -0.3029356
0:  -0.21210623 -0.07566929  0.02979469  0.153512    0.241117    0.32243395
0:   0.08007288  0.17255735]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.6971383   0.523942    0.32744122  0.09245014 -0.16257954 -0.4476652
0:  -0.7303233  -1.0440326  -1.368751   -1.6794257  -1.9631     -2.2498822
0:  -2.5012965  -2.7031045  -2.9072604  -3.0510793  -3.1626515  -3.2089314
0:  -3.365604   -3.3721309 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.390852  4.1415343 3.8695037 3.617578  3.4350524 3.3005767 3.2257862
0:  3.1467333 3.106519  3.088747  3.1041212 3.1121578 3.118642  3.1163218
0:  3.034911  2.9051805 2.7511568 2.5858192 1.8859    1.766006 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.294722  14.640509  15.007545  15.3336525 15.629089  15.883701
0:  16.122652  16.289732  16.478012  16.652504  16.76403   16.85446
0:  16.925724  16.96775   17.03149   17.146006  17.335655  17.548824
0:  18.817806  19.382544 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.832498 12.178095 12.583323 12.981226 13.373142 13.686058 13.972719
0:  14.232702 14.55406  14.95186  15.447971 15.994711 16.620745 17.235598
0:  17.832256 18.418346 19.1158   19.922905 21.081247 21.739906]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.8770442  -1.2010789  -1.4651651  -1.6559367  -1.7193041  -1.6940813
0:  -1.6171288  -1.5558329  -1.4914932  -1.4352236  -1.3496428  -1.2612863
0:  -1.158926   -1.0087805  -0.89601946 -0.76950264 -0.63796425 -0.4942069
0:  -0.8972511  -0.86062765]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.824238  8.870444  9.000475  9.171694  9.365673  9.537738  9.650516
0:  9.717204  9.776843  9.811226  9.838266  9.810517  9.7425165 9.610081
0:  9.408754  9.166453  8.875755  8.589977  8.343538  8.180563 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.961224  -8.146658  -8.294443  -8.38592   -8.492386  -8.641926
0:  -8.778458  -8.965506  -9.136236  -9.291752  -9.43923   -9.587761
0:  -9.687611  -9.769766  -9.8292675 -9.845076  -9.8328285 -9.731735
0:  -9.8134575 -9.889242 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.562286  4.658721  4.8138466 4.9905095 5.214499  5.446677  5.670212
0:  5.8658247 6.0557704 6.23856   6.4650736 6.7021847 7.009471  7.373271
0:  7.7750077 8.195814  8.606667  8.931954  8.957251  9.05571  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.338402 24.658295 24.895245 25.091034 25.230669 25.321125 25.389158
0:  25.39513  25.325283 25.276403 25.201399 25.081062 24.95712  24.770557
0:  24.504776 24.211636 23.899462 23.608553 23.153444 23.003891]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.4489784  2.41567    2.4142342  2.4093676  2.4202414  2.374848
0:  2.2921066  2.113531   1.8888764  1.6374922  1.39575    1.1593485
0:  0.9833369  0.87736654 0.8074775  0.8136859  0.85153484 0.89394474
0:  0.47661495 0.39321423]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.012621 11.373091 11.745632 12.17502  12.657698 13.204345 13.828983
0:  14.385729 14.99586  15.593977 16.19124  16.77716  17.48102  18.169785
0:  18.912968 19.601135 20.228298 20.702877 20.605276 20.92493 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.456032  -10.370674  -10.304199  -10.246559  -10.167341  -10.101309
0:   -9.994812   -9.932266   -9.880293   -9.833815   -9.80649    -9.843977
0:   -9.9146805  -9.985874  -10.120171  -10.185747  -10.207756  -10.145645
0:  -11.287888  -11.255768 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.53644  19.462046 19.384102 19.217415 18.943438 18.550526 18.09958
0:  17.586622 17.152225 16.77149  16.500895 16.253687 16.03195  15.818836
0:  15.564257 15.265743 14.888084 14.427801 12.923014 12.390287]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.86377  21.548615 21.370243 21.32455  21.286953 21.231838 21.187801
0:  21.053007 20.969185 20.897423 20.75837  20.620163 20.478119 20.205177
0:  19.813248 19.288788 18.686485 18.08611  16.947107 16.754684]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.20688  12.357826 12.424671 12.487932 12.535807 12.57305  12.643427
0:  12.698939 12.7458   12.796968 12.811516 12.833445 12.834466 12.830852
0:  12.824278 12.827628 12.837476 12.871458 12.626419 12.75322 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.9860113 3.0792491 3.1434178 3.1610796 3.0990975 2.9308891 2.6891823
0:  2.3877707 2.1228657 1.9312725 1.8217163 1.7645612 1.8097625 1.9514132
0:  2.1550183 2.4433403 2.793211  3.125121  3.4393575 3.7284956]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.887823 25.61413  25.31557  24.988804 24.665054 24.376541 24.176952
0:  24.009892 24.040998 24.170067 24.363176 24.570333 24.79685  25.051655
0:  25.308685 25.609585 25.90049  26.07508  27.1196   27.326305]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.245915  10.177516  10.133012  10.064214  10.0248165  9.965055
0:   9.910608   9.8058405  9.732934   9.6748905  9.631757   9.543808
0:   9.446589   9.342087   9.219826   9.126118   9.062065   9.01423
0:   9.087994   8.977792 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.783586   8.823475   8.918485   9.0823965  9.279309   9.459594
0:   9.655909   9.803026   9.962713  10.110745  10.2498455 10.367028
0:  10.476946  10.555044  10.613968  10.670402  10.7278385 10.786351
0:  10.397567  10.292646 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.479515  -2.76822   -3.0539217 -3.2826033 -3.4057379 -3.4651089
0:  -3.423068  -3.3600597 -3.2908297 -3.2079191 -3.142889  -3.1307878
0:  -3.1960993 -3.30231   -3.5399008 -3.7979994 -4.0554657 -4.2651196
0:  -4.5403843 -4.7275677]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.414952   -7.143892   -6.810555   -6.3488545  -5.8301425  -5.3305125
0:  -4.732307   -4.2301908  -3.725266   -3.2619252  -2.8097186  -2.3676162
0:  -1.8931513  -1.4208522  -0.9849291  -0.58251905 -0.2151804   0.11978769
0:   0.10602903  0.27868128]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -7.7695127  -7.6032615  -7.3870435  -7.1358886  -6.955833   -6.922837
0:   -6.9572167  -7.154431   -7.4639115  -7.8753247  -8.41135    -8.999903
0:   -9.578049  -10.10924   -10.535397  -10.850794  -11.122303  -11.29789
0:  -10.699038  -10.489368 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.214041 11.522533 11.88982  12.309685 12.739229 13.170876 13.601282
0:  13.966956 14.314264 14.625394 14.910303 15.186367 15.48469  15.777301
0:  16.108707 16.431416 16.760178 17.082966 17.84493  18.32742 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.2077465  8.430031   8.801798   9.274295   9.726193  10.120943
0:  10.473448  10.617126  10.680678  10.61409   10.4197855 10.188191
0:   9.993718   9.839233   9.704551   9.637941   9.520029   9.486772
0:   8.457089   8.554466 ]
0: validation loss for strategy=forecast at epoch 5 : nan
0: validation loss for velocity_u : 0.037716399878263474
0: validation loss for velocity_v : 0.0622047483921051
0: validation loss for specific_humidity : 0.026137037202715874
0: validation loss for velocity_z : 0.48708102107048035
0: validation loss for temperature : 0.07248018682003021
0: validation loss for total_precip : nan
0: 6 : 10:10:30 :: batch_size = 96, lr = 1.8119012895995104e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 6, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.6452, 0.6418, 0.6492, 0.6740, 0.7069, 0.7369, 0.7610, 0.7800, 0.7986, 0.8190, 0.8419, 0.8694, 0.8991, 0.9282,
0:         0.9567, 0.9830, 1.0102, 1.0416, 0.5476, 0.5788, 0.6228, 0.6748, 0.7262, 0.7712, 0.8066], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.0489,  0.0305,  0.0292,  0.0475,  0.0708,  0.0755,  0.0483, -0.0116, -0.1032, -0.2211, -0.3587, -0.5151,
0:         -0.6907, -0.8811, -1.0767, -1.2588, -1.4081, -1.5126,  0.1042,  0.1137,  0.1341,  0.1530,  0.1600,  0.1473,
0:          0.1088], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.0363,  0.1318,  0.1502,  0.1301,  0.0869,  0.0128, -0.0432, -0.0808, -0.1208, -0.1590, -0.1958, -0.2293,
0:         -0.2632, -0.2884, -0.3144, -0.3388, -0.3644, -0.3905, -0.0106,  0.0229,  0.0257,  0.0170, -0.0010, -0.0188,
0:         -0.0376], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.2643,  0.1989,  0.1312,  0.2189,  0.4762,  0.6592,  0.7180,  0.7668,  0.7535,  0.6559,  0.5616,  0.4884,
0:          0.4163,  0.3409,  0.2067, -0.0452, -0.3735, -0.6930,  0.1778,  0.2255,  0.2776,  0.3908,  0.5638,  0.7269,
0:          0.8012], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0.5805, -0.5966, -0.6087, -0.6105, -0.6021, -0.5923, -0.5899, -0.5977, -0.6104, -0.6265, -0.6459, -0.6632,
0:         -0.6732, -0.6718, -0.6497, -0.5990, -0.5171, -0.4190, -0.3192, -0.2237, -0.1403, -0.0706, -0.0121,  0.0343,
0:          0.0724], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 6, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan, -0.2417,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2417,     nan,     nan,     nan,     nan,     nan, -0.2417,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2406,     nan,     nan,     nan,     nan,     nan, -0.2417,     nan, -0.2417,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2417,     nan,     nan,     nan,     nan, -0.2417,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2417,     nan,     nan,     nan, -0.2417,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2417,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2417,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2417,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2417,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2417,
0:             nan,     nan,     nan,     nan, -0.2417,     nan, -0.2417, -0.2417, -0.2417,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2417,     nan,     nan,
0:         -0.2417,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 6, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([1.2823, 1.2747, 1.2600, 1.2337, 1.2023, 1.1723, 1.1417, 1.1162, 1.1003, 1.0925, 1.0902, 1.0879, 1.0908, 1.0945,
0:         1.0983, 1.1027, 1.1107, 1.1222, 1.2433, 1.2330, 1.2123, 1.1841, 1.1550, 1.1253, 1.1009], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.5053, 0.5084, 0.5100, 0.5119, 0.5093, 0.5100, 0.5085, 0.5118, 0.5223, 0.5409, 0.5686, 0.6009, 0.6351, 0.6651,
0:         0.6901, 0.7086, 0.7205, 0.7294, 0.4885, 0.4959, 0.5043, 0.5122, 0.5174, 0.5222, 0.5241], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.4317, -0.4338, -0.4418, -0.4534, -0.4680, -0.4830, -0.4942, -0.5041, -0.5129, -0.5227, -0.5317, -0.5447,
0:         -0.5536, -0.5653, -0.5764, -0.5828, -0.5903, -0.5931, -0.4547, -0.4598, -0.4689, -0.4800, -0.4898, -0.5006,
0:         -0.5083], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.4735, 0.3541, 0.2458, 0.1681, 0.2842, 0.4986, 0.5802, 0.6193, 0.5916, 0.5210, 0.5350, 0.5253, 0.4812, 0.4721,
0:         0.4721, 0.5190, 0.6606, 0.7790, 0.2543, 0.1004, 0.0468, 0.0174, 0.1458, 0.3487, 0.3763], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([0.5403, 0.5236, 0.4958, 0.4591, 0.4182, 0.3778, 0.3405, 0.3076, 0.2810, 0.2585, 0.2394, 0.2241, 0.2123, 0.2021,
0:         0.1948, 0.1892, 0.1862, 0.1862, 0.1884, 0.1916, 0.1943, 0.1936, 0.1901, 0.1853, 0.1783], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.051383890211582184; velocity_v: 0.08516794443130493; specific_humidity: 0.03641781955957413; velocity_z: 0.5252431631088257; temperature: 0.0886196419596672; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.058126602321863174; velocity_v: 0.10381714999675751; specific_humidity: 0.044581346213817596; velocity_z: 0.585909903049469; temperature: 0.12208016961812973; total_precip: nan; 
0: epoch: 6 [1/5 (20%)]	Loss: nan : nan :: 0.14454 (2.49 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06804916262626648; velocity_v: 0.11291545629501343; specific_humidity: 0.04017879068851471; velocity_z: 0.4045328199863434; temperature: 0.08848653733730316; total_precip: nan; 
0: epoch: 6 [2/5 (40%)]	Loss: nan : nan :: 0.15845 (16.11 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06265392899513245; velocity_v: 0.10571020841598511; specific_humidity: 0.03499991446733475; velocity_z: 0.5083054304122925; temperature: 0.08290605992078781; total_precip: nan; 
0: epoch: 6 [3/5 (60%)]	Loss: nan : nan :: 0.14732 (16.18 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05478447303175926; velocity_v: 0.09690314531326294; specific_humidity: 0.04093363881111145; velocity_z: 0.5108270049095154; temperature: 0.10434059053659439; total_precip: nan; 
0: epoch: 6 [4/5 (80%)]	Loss: nan : nan :: 0.14280 (16.21 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [6.10351562e-05 8.05854797e-05 1.28746033e-05 1.43051147e-06
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  3.33786011e-06 1.81198120e-05 4.10079956e-05 4.38690149e-05
0:  5.00679016e-05 2.19345093e-05 1.71661377e-05 1.76429749e-05
0:  8.10623169e-06 1.43051147e-06 6.67572021e-06 1.90734863e-06
0:  3.33786011e-06 2.09808350e-05 2.90870667e-05 9.05990601e-06
0:  1.47819519e-05 8.10623169e-06 2.81333923e-05 2.05039978e-05
0:  1.33514404e-05 1.71661377e-05 1.85966492e-05 2.95639038e-05
0:  7.34329224e-05 9.20295715e-05 1.32083893e-04 1.99317932e-04
0:  2.82764435e-04 2.94208527e-04 2.55107880e-04 1.41143799e-04
0:  7.82012939e-05 4.95910645e-05 2.33650208e-05 2.09808350e-05
0:  3.52859497e-05 8.01086426e-05 7.58171082e-05 6.34193420e-05
0:  5.81741333e-05 5.00679016e-05 4.00543213e-05 2.95639038e-05
0:  1.09672546e-05 2.00271606e-05 7.20024109e-05 1.71661377e-04
0:  7.57217407e-04 1.18398666e-03 9.98020172e-04 7.44342804e-04
0:  5.20229340e-04 3.62873077e-04 1.01089478e-04 6.91413879e-05
0:  6.19888306e-05 2.18868256e-04 1.38711929e-03 2.98023224e-03
0:  3.27348709e-03 1.73997879e-03 9.53197421e-04 4.66823578e-04
0:  2.26974487e-04 1.70707703e-04 1.67369843e-04 1.07288361e-04
0:  1.02519989e-04 6.10351562e-05 4.05311584e-05 2.00271606e-05
0:  3.43322754e-05 5.19752502e-05 2.57492065e-05 3.81469727e-05
0:  1.62124634e-05 1.14440918e-05 1.66893005e-05 7.62939453e-06
0:  1.52587891e-05 8.10623169e-06 1.00135803e-05 1.04904175e-05
0:  1.23977661e-05 1.66893005e-05 5.24520874e-06 5.72204590e-06
0:  2.38418579e-06 1.90734863e-06 1.43051147e-06 1.90734863e-06
0:  4.76837158e-07 4.76837158e-07 4.76837158e-07 0.00000000e+00
0:  7.86781311e-05 7.48634338e-05 9.53674316e-07 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.43051147e-06
0:  1.66893005e-05 4.38690149e-05 6.05583191e-05 2.52723694e-05
0:  1.47819519e-05 3.81469727e-06 1.43051147e-06 1.90734863e-06
0:  3.81469727e-06 1.57356262e-05 1.00135803e-05 9.53674316e-06
0:  2.09808350e-05 2.62260437e-05 2.05039978e-05 1.85966492e-05
0:  5.67436218e-05 5.14984131e-05 2.62260437e-05 1.04904175e-05
0:  5.24520874e-06 2.38418579e-06 9.53674316e-07 1.90734863e-06
0:  5.24520874e-06 2.62260437e-05 7.72476196e-05 1.69754028e-04
0:  3.06129456e-04 4.34875488e-04 1.85966492e-04 7.15255737e-05
0:  3.71932983e-05 2.57492065e-05 1.52587891e-05 2.09808350e-05
0:  4.33921814e-05 4.48226892e-05 3.71932983e-05 4.00543213e-05
0:  3.95774841e-05 3.81469727e-06 2.86102295e-06 5.24520874e-06
0:  1.33514404e-05 1.85966492e-05 2.28881836e-05 4.72068787e-05
0:  1.32083893e-04 8.18729401e-04 1.26218796e-03 8.88824463e-04
0:  2.95162201e-04 5.91278076e-05 1.62124634e-05 3.81469727e-05
0:  4.81605566e-05 2.03132629e-04 1.34325027e-03 2.95591354e-03
0:  3.43847275e-03 1.86777115e-03 1.30844116e-03 8.35895538e-04
0:  5.64098358e-04 4.64439392e-04 4.24861908e-04 3.69548798e-04
0:  2.98023224e-04 2.30312347e-04 1.57356262e-04 8.91685486e-05
0:  5.43594360e-05 7.58171082e-05 6.29425049e-05 2.09808350e-05
0:  9.05990601e-06 6.67572021e-06 8.10623169e-06 1.66893005e-05]
0: Target values (first 200):
0: [4.76837158e-07 4.76837158e-07 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 4.76837158e-07 1.43051147e-06
0:  3.81469727e-06 1.14440918e-05 2.24113464e-05 4.86373901e-05
0:  8.05854797e-05 7.77244568e-05 7.86781311e-05 1.02519989e-04
0:  3.98635864e-04 1.07526779e-03 1.10435486e-03 8.73565674e-04
0:  5.35011350e-04 3.16143036e-04 2.62260437e-04 1.06334686e-04
0:  7.86781311e-05 6.81877136e-05 6.58035278e-05 1.41143799e-04
0:  1.64508820e-04 8.63075256e-05 6.00814819e-05 6.62803650e-05
0:  2.81333923e-05 1.00135803e-05 1.90734863e-06 9.53674316e-07
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.23977661e-05
0:  3.67164612e-05 1.87873840e-04 1.52587891e-04 1.00135803e-04
0:  7.67707825e-05 4.29153479e-05 1.61647797e-04 1.53064728e-04
0:  1.05381012e-04 8.01086426e-05 8.05854797e-05 1.10149384e-04
0:  5.72204590e-05 5.05447388e-05 1.23500824e-04 1.59263611e-04
0:  1.41143799e-04 9.63211060e-05 5.05447388e-05 5.91278076e-05
0:  1.18255615e-04 1.45435333e-04 1.90734863e-04 2.40802765e-04
0:  3.13282013e-04 4.25815582e-04 7.76290894e-04 8.26358795e-04
0:  8.49246979e-04 7.82489777e-04 6.77585602e-04 6.06536865e-04
0:  3.00884247e-04 3.11851501e-04 2.23636627e-04 1.12533569e-04
0:  1.07288361e-04 1.01566315e-04 8.24928284e-05 6.86645508e-05
0:  9.39369202e-05 1.32083893e-04 1.67369843e-04 1.74045563e-04
0:  2.23636627e-04 2.36988068e-04 2.19821930e-04 1.14917755e-04
0:  3.38554382e-05 9.05990601e-06 9.05990601e-06 7.15255737e-06
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  1.62124634e-05 2.86102295e-06 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  4.76837158e-07 1.90734863e-06 4.76837158e-06 9.05990601e-06
0:  2.00271606e-05 4.72068787e-05 5.00679016e-05 6.29425049e-05
0:  1.03473663e-04 1.52111053e-04 2.11238861e-04 2.05039978e-04
0:  1.73568726e-04 1.87397003e-04 1.66893005e-04 5.53131104e-05
0:  1.19209290e-04 4.67300379e-05 4.43458557e-05 1.20639801e-04
0:  1.48296356e-04 7.82012939e-05 3.38554382e-05 2.57492065e-05
0:  5.38825989e-05 3.05175781e-05 5.72204590e-06 2.38418579e-06
0:  9.53674316e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 7.62939453e-06 4.48226892e-05
0:  2.65121460e-04 1.75952911e-04 1.10149384e-04 1.07765198e-04
0:  1.02043152e-04 2.76565552e-05 3.81469727e-06 1.90734863e-06
0:  1.09672546e-05 2.33650208e-05 5.24520874e-05 9.29832458e-05
0:  6.29425049e-05 4.38690149e-05 1.12056732e-04 1.26838684e-04
0:  1.03950500e-04 8.58306885e-05 6.10351562e-05 5.62667847e-05
0:  4.14848328e-05 2.81333923e-05 3.33786011e-05 6.24656677e-05
0:  1.15394592e-04 2.26497650e-04 4.28199768e-04 7.85827637e-04
0:  1.00040436e-03 9.41753387e-04 6.89506531e-04 5.47885895e-04
0:  6.40392303e-04 6.35623932e-04 4.65393066e-04 2.52246857e-04
0:  1.15871429e-04 8.44001770e-05 1.25408173e-04 1.14917755e-04
0:  1.70707703e-04 2.41756439e-04 2.96115875e-04 3.38554382e-04]
0: Prediction values (first 20):
0: [6.3107147 6.398201  6.507151  6.658533  6.8034215 6.953955  7.1278152
0:  7.2669983 7.43057   7.5626607 7.6465044 7.6787105 7.703184  7.6848445
0:  7.6456747 7.5353465 7.3863745 7.236251  6.3294263 6.1120834]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -1.650, max = 3.417, mean = 0.751
0:          sample (first 20): tensor([-0.0470, -0.0395, -0.0302, -0.0172, -0.0047,  0.0082,  0.0231,  0.0351,  0.0491,  0.0605,  0.0677,  0.0704,
0:          0.0726,  0.0710,  0.0676,  0.0581,  0.0453,  0.0325,  0.0417,  0.0494])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.10151196 -0.1326561  -0.12057924 -0.10331917 -0.09037828 -0.10173225
0:  -0.1116209  -0.16287088 -0.18798447 -0.22110319 -0.26147652 -0.28032923
0:  -0.278378   -0.26742172 -0.26197195 -0.2751441  -0.2985978  -0.34165812
0:  -0.40978575 -0.47080517]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.1104174 6.1482916 6.225659  6.2940893 6.351308  6.369549  6.384346
0:  6.3648815 6.3625126 6.377547  6.3943024 6.376461  6.348475  6.3178496
0:  6.263998  6.2489486 6.2694325 6.347513  6.033701  6.0322614]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.631658   9.050922   9.559305  10.040491  10.435054  10.679201
0:  10.705706  10.5034485 10.109644   9.571542   8.9639015  8.34829
0:   7.7723026  7.2441263  6.753947   6.2965508  5.8953094  5.5506115
0:   4.6925445  4.3257093]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.8194003 -6.7388387 -6.6168294 -6.449266  -6.2048583 -5.891557
0:  -5.5039525 -5.1929975 -4.959724  -4.8856006 -5.0116773 -5.345329
0:  -5.7705493 -6.1405797 -6.407082  -6.4259553 -6.229119  -5.8976636
0:  -4.7590528 -4.741388 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.574869  10.49556   10.347561  10.126244   9.867084   9.548742
0:   9.200483   8.824579   8.483721   8.196901   7.9515524  7.760029
0:   7.62947    7.5424976  7.477954   7.4908414  7.5698767  7.7235575
0:   8.034476   8.327932 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.864384 22.114754 22.326763 22.458427 22.553112 22.630554 22.704582
0:  22.73024  22.785912 22.863861 22.942616 23.017925 23.105843 23.186039
0:  23.279713 23.374252 23.522621 23.687176 23.84518  24.049934]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-15.783961 -15.914231 -15.995957 -16.0051   -15.936902 -15.861316
0:  -15.748157 -15.694987 -15.615413 -15.513734 -15.359227 -15.18646
0:  -15.004558 -14.767377 -14.566098 -14.347613 -14.123708 -13.936858
0:  -13.910975 -13.883212]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.296446  13.31879   13.386652  13.4357815 13.515571  13.588465
0:  13.710167  13.763909  13.860271  13.978349  14.074518  14.12736
0:  14.146357  14.1422615 14.0902195 14.069644  14.131556  14.260586
0:  13.884984  13.8059225]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.3052263 -3.5053205 -3.4940863 -2.8073635 -1.1105843  1.3479328
0:   3.8761177  5.6029243  6.054463   5.250839   3.8797672  2.6159577
0:   1.9904914  2.0938187  2.544239   3.0284438  3.24284    3.198835
0:   2.439546   1.8321805]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.957748  5.1223245 5.3394666 5.569294  5.8101807 5.9873977 6.0825143
0:  6.0402937 5.9861374 5.9224606 5.947249  6.0262556 6.1601005 6.3353095
0:  6.44126   6.5476303 6.6287045 6.74598   5.988061  6.384838 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.050508 19.198782 19.39251  19.587872 19.791039 19.981443 20.142761
0:  20.232681 20.313057 20.367281 20.438198 20.496178 20.588041 20.704157
0:  20.803654 20.887787 20.975065 21.059317 20.835663 20.876162]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.326923  8.544938  8.8425045 9.142517  9.44312   9.662806  9.809774
0:  9.839505  9.8102455 9.708265  9.552476  9.315793  9.031681  8.735779
0:  8.417336  8.184485  8.000416  7.902822  8.09056   8.025389 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-20.856335 -21.129375 -21.471455 -21.834637 -22.255116 -22.743252
0:  -23.258926 -23.85939  -24.42377  -25.016163 -25.618439 -26.20842
0:  -26.727467 -27.148048 -27.440697 -27.636639 -27.742718 -27.751339
0:  -29.31886  -29.79279 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.264526 10.295294 10.374035 10.448875 10.534443 10.593855 10.663996
0:  10.719842 10.774765 10.830705 10.852228 10.801841 10.702223 10.588652
0:  10.458414 10.365721 10.316248 10.311365  9.9858    9.925818]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.164651  8.277494  8.349517  8.335265  8.264758  8.146438  8.013744
0:  7.860621  7.7248206 7.652019  7.623956  7.6640077 7.788621  7.9954166
0:  8.254102  8.534689  8.803891  9.025903  9.199997  9.229359 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.1242776 -5.2029386 -5.251311  -5.2545047 -5.246835  -5.276936
0:  -5.2712817 -5.3050923 -5.298263  -5.266751  -5.226272  -5.2214246
0:  -5.2029185 -5.2054296 -5.1858754 -5.118791  -5.0571523 -4.969541
0:  -5.313091  -5.3291745]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.650528    7.1208186   6.5780005   6.045538    5.5205817   4.9624486
0:   4.3771996   3.6952872   3.007206    2.3049102   1.6072607   0.90477324
0:   0.28481293 -0.23732376 -0.6761794  -1.0117788  -1.2745137  -1.459796
0:  -1.8191624  -1.8913488 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.7115083 3.7832885 3.8547235 3.9449368 4.0625544 4.1429553 4.248396
0:  4.2937965 4.3501015 4.419196  4.500823  4.539203  4.5852904 4.614292
0:  4.586358  4.5756817 4.567934  4.5843296 4.0988803 4.1697655]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 6.0465684  6.2000213  6.3351226  6.5259624  6.8101344  7.1785393
0:   7.6809225  8.150227   8.672516   9.133753   9.569833   9.930254
0:  10.258507  10.542136  10.762223  10.976879  11.170471  11.35606
0:  10.666361  10.848866 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.1483555 14.099908  13.970139  13.789375  13.653782  13.570585
0:  13.488745  13.323261  13.074881  12.742353  12.358996  11.944731
0:  11.575808  11.300001  11.1149025 11.022962  11.117308  11.330715
0:  11.805832  12.119139 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.873005 24.603123 25.261253 25.885624 26.471329 27.09512  27.792076
0:  28.4189   29.116264 29.809414 30.494125 31.168747 31.872238 32.581886
0:  33.293053 33.93408  34.48492  34.894012 35.61627  35.952766]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.977096  -5.821175  -5.6160474 -5.414825  -5.209391  -5.012573
0:  -4.8202386 -4.6613812 -4.4587846 -4.2703767 -4.0617805 -3.8742862
0:  -3.7137418 -3.5558906 -3.45499   -3.393495  -3.3735728 -3.3331552
0:  -3.3455825 -3.1795926]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.3592865 3.3687108 3.3881738 3.4391735 3.4779592 3.4940236 3.5273921
0:  3.5106866 3.5248504 3.5545707 3.5857408 3.634338  3.7144608 3.7524922
0:  3.7902997 3.790621  3.7667606 3.749075  3.677573  3.6748178]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.0267377 -3.9612212 -3.9456687 -3.993094  -4.118304  -4.3250623
0:  -4.567678  -4.8883166 -5.2107015 -5.5292172 -5.8104386 -6.0599704
0:  -6.2442813 -6.3494287 -6.4190135 -6.427119  -6.388448  -6.271977
0:  -6.5559535 -6.5004544]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.922874  6.7966413 6.712591  6.6122417 6.53672   6.4558616 6.410877
0:  6.3722744 6.404271  6.4969172 6.6251655 6.8032026 7.016122  7.2318482
0:  7.4643683 7.6706557 7.832192  7.952934  8.822353  8.804451 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.001521  5.483877  4.967161  4.6523886 4.557748  4.635382  4.754774
0:  4.811653  4.784459  4.7094975 4.6246595 4.531124  4.458688  4.3901715
0:  4.2746143 4.1590004 4.0717697 4.0502715 3.5632668 3.6038241]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.7973423   0.45474005  0.13264465 -0.22160387 -0.58019257 -0.9524684
0:  -1.2702117  -1.5601621  -1.7659173  -1.9116311  -1.9837155  -2.0449338
0:  -2.0272403  -1.9766421  -1.9037623  -1.7846313  -1.6684289  -1.5188088
0:  -1.9221549  -1.919868  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.034509   -9.976024   -9.934888   -9.804931   -9.621825   -9.4969015
0:   -9.192756   -8.996036   -8.808663   -8.645515   -8.53753    -8.484438
0:   -8.433742   -8.408301   -8.357953   -8.286938   -8.248326   -8.163812
0:   -8.929242   -8.845656 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.077251 9.032702 9.123043 9.24366  9.354927 9.437607 9.49313  9.484559
0:  9.502899 9.516474 9.557756 9.573298 9.626596 9.698851 9.735936 9.771042
0:  9.777138 9.774866 9.80678  9.801275]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.22572947 0.27732515 0.35112715 0.4678831  0.64592314 0.79357815
0:  0.96509933 1.0131159  1.0525055  1.0866385  1.1348848  1.1396465
0:  1.1691356  1.1942496  1.1692562  1.1797051  1.204762   1.2384973
0:  1.056994   1.077034  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.492581  -7.358395  -7.222673  -7.07459   -6.9177155 -6.794147
0:  -6.664204  -6.602737  -6.5124135 -6.383185  -6.19795   -5.9757133
0:  -5.7167125 -5.4039016 -5.1040998 -4.7443624 -4.343635  -3.9203439
0:  -3.508841  -3.1408277]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.34171  33.46723  33.496902 33.47105  33.386044 33.279514 33.134995
0:  32.881653 32.66461  32.44792  32.24459  32.050793 31.912859 31.785208
0:  31.681875 31.59774  31.57961  31.614492 31.706907 31.821627]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.3627224 4.537238  4.690445  4.812919  4.9517336 5.0357246 5.136441
0:  5.186615  5.2603016 5.3622565 5.4855103 5.5973434 5.7030573 5.813114
0:  5.870521  5.9575477 6.0783067 6.243262  5.9591155 6.104042 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.972775   -2.059792   -2.0800242  -2.088921   -2.057053   -2.0374055
0:  -1.9750056  -1.9256759  -1.8466268  -1.7617068  -1.6615014  -1.5916476
0:  -1.5074592  -1.3482537  -1.1412091  -0.7885804  -0.34283876  0.17810106
0:   0.18125057  0.51065016]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.5643163 -4.5160193 -4.456843  -4.386213  -4.271236  -4.1502137
0:  -3.9752345 -3.8017201 -3.6070933 -3.3990579 -3.1864657 -3.0106654
0:  -2.8623204 -2.6953607 -2.5489955 -2.3348994 -2.0894475 -1.8244557
0:  -1.8706117 -1.7158151]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.1491485 -4.44369   -4.691851  -4.837625  -4.9524055 -5.062823
0:  -5.120027  -5.1974597 -5.261829  -5.283508  -5.2776217 -5.254867
0:  -5.179791  -5.0664725 -4.955731  -4.8169103 -4.7253566 -4.6590686
0:  -4.7390046 -4.733231 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.467127  13.603355  13.73184   13.783682  13.810333  13.807344
0:  13.809073  13.795717  13.793615  13.785873  13.741578  13.6175995
0:  13.420961  13.18466   12.910551  12.673418  12.476957  12.2835045
0:  11.686955  11.591164 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [42.914    43.097343 43.2569   43.291794 43.295094 43.279743 43.252304
0:  43.21317  43.25718  43.33721  43.334747 43.327477 43.342228 43.346794
0:  43.334854 43.18264  42.951366 42.589725 43.467422 43.561768]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.260825  -7.5190716 -7.7335873 -7.881361  -7.968254  -8.005276
0:  -7.964983  -7.924958  -7.7335434 -7.446373  -7.002327  -6.479762
0:  -5.877757  -5.2163258 -4.5922594 -3.9810677 -3.3801441 -2.7731352
0:  -1.7908764 -1.657177 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.7394209  -0.5802326  -0.3740101  -0.15650177  0.03167486  0.14808178
0:   0.16923189  0.05328989 -0.15957117 -0.3982644  -0.5788045  -0.6828904
0:  -0.6659827  -0.5169177  -0.33496714 -0.09366655  0.15414381  0.38100815
0:   0.30133915  0.15640926]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.11232  21.221792 21.21554  21.13773  20.986582 20.81006  20.639702
0:  20.426554 20.240068 20.083466 19.91999  19.793736 19.720045 19.678877
0:  19.695599 19.693985 19.720884 19.766632 19.906578 20.014938]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.9551396 -4.816193  -4.65803   -4.4611497 -4.221747  -3.9835143
0:  -3.7100444 -3.477734  -3.2418923 -3.0101275 -2.7615056 -2.5298057
0:  -2.3129182 -2.1048017 -1.9535365 -1.7886481 -1.6203704 -1.429604
0:  -1.3585811 -1.1799569]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.271803 15.137201 14.947679 14.717273 14.48434  14.269199 14.074389
0:  13.85903  13.677227 13.525505 13.401081 13.336269 13.33235  13.40041
0:  13.521303 13.694916 13.932917 14.22872  14.261903 14.268664]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.352945  9.265675  9.217226  9.23975   9.349561  9.652284 10.184998
0:  10.858216 11.733805 12.708836 13.765686 14.845833 15.919941 16.862873
0:  17.751057 18.485487 19.161554 19.770863 21.83982  22.621557]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.356528  7.293601  7.2095375 7.1243687 7.037177  6.935174  6.845001
0:  6.735665  6.648485  6.5889926 6.53728   6.48887   6.4499288 6.4054565
0:  6.351556  6.328464  6.3442836 6.419488  6.2721753 6.2592   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.476875  -5.386212  -5.2445674 -5.0792813 -4.89356   -4.739756
0:  -4.601375  -4.5738444 -4.6781507 -4.9102626 -5.2488427 -5.6384997
0:  -5.9793468 -6.1701093 -6.224216  -6.095244  -5.8953137 -5.6649985
0:  -5.7474675 -5.593555 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.5968337  1.6668432  1.7253542  1.7335927  1.733844   1.6810529
0:  1.6286826  1.5227442  1.4107647  1.2927084  1.1584172  0.97757006
0:  0.7859731  0.6463642  0.5387645  0.5421195  0.59127426 0.67510176
0:  0.86265326 0.85349894]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.3301196 -3.270369  -3.2149596 -3.1476417 -3.1150918 -3.1312938
0:  -3.1310706 -3.1769366 -3.206019  -3.2243543 -3.2517753 -3.2714877
0:  -3.2689776 -3.258308  -3.2430997 -3.224174  -3.2264237 -3.2163882
0:  -3.4058585 -3.348043 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.1516123  -3.2201166  -3.2682323  -3.27351    -3.2084093  -3.129531
0:  -2.985753   -2.8469925  -2.6457205  -2.4127226  -2.128954   -1.8420057
0:  -1.5368648  -1.1966987  -0.8859911  -0.5644083  -0.24667025  0.05145884
0:   0.0598402   0.1907177 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.183187 18.452377 18.84388  19.282679 19.73154  20.190937 20.64707
0:  21.066908 21.495407 21.889692 22.232729 22.509737 22.742863 22.917963
0:  23.039686 23.128471 23.262041 23.399174 22.912373 22.926105]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -9.882179  -9.982561 -10.076773 -10.145481 -10.208883 -10.313976
0:  -10.411228 -10.575111 -10.702684 -10.767721 -10.74749  -10.6714
0:  -10.544754 -10.365858 -10.204512 -10.030495  -9.844439  -9.663893
0:   -9.993269 -10.061611]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.828632  20.557123  20.292896  19.943272  19.581043  19.232807
0:  18.856182  18.44249   18.057003  17.628712  17.142601  16.644691
0:  16.194422  15.816577  15.522866  15.301549  15.172475  15.0762615
0:  15.177031  15.066896 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-17.424389  -17.419525  -17.226147  -16.865284  -16.473755  -16.156807
0:  -15.915841  -15.777583  -15.562947  -15.3235235 -15.056199  -14.712121
0:  -14.279969  -13.896241  -13.462195  -13.193265  -13.026931  -12.97823
0:  -12.721501  -12.563846 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.357095 13.320095 13.297471 13.246298 13.189433 13.120728 13.073593
0:  12.987596 12.959761 12.914338 12.891602 12.840562 12.778826 12.716507
0:  12.62798  12.569592 12.508895 12.438269 12.194866 12.128351]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.978247  10.022209  10.076283  10.149437  10.220119  10.2492485
0:  10.272621  10.223275  10.138586   9.972912   9.744703   9.45224
0:   9.119528   8.742065   8.324415   7.8692617  7.394305   6.9302278
0:   6.156557   5.9065948]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.8470998 -1.7637029 -1.3987823 -0.8102069 -0.0551405  0.7026868
0:   1.507719   2.27985    3.1280804  4.0308275  4.962395   5.986054
0:   7.0466037  8.086101   9.077351   9.931948  10.664854  11.262814
0:  12.7008705 13.157494 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.019066 10.971249 10.941822 10.913473 10.909486 10.82793  10.717313
0:  10.533406 10.321802 10.119082  9.943607  9.772875  9.617648  9.460131
0:   9.236708  9.028618  8.826427  8.680971  8.257966  8.025402]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.5967364   1.5463562   1.5179877   1.4852834   1.4442887   1.3625841
0:   1.2903333   1.186194    1.0992737   1.0215025   0.94149685  0.8330765
0:   0.7373123   0.65299034  0.5627761   0.5025892   0.44563866  0.41020393
0:   0.08122253 -0.01499939]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.522379  15.499512  15.479164  15.464878  15.42363   15.348871
0:  15.256535  15.06819   14.847418  14.572369  14.2573185 13.990051
0:  13.794425  13.678194  13.62121   13.573736  13.522144  13.435148
0:  12.694286  12.731749 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.06082   7.328001  7.606195  7.7885027 7.941986  8.042862  8.119416
0:  8.176229  8.266911  8.385151  8.5578375 8.657584  8.702898  8.67362
0:  8.520613  8.362269  8.248977  8.211892  8.165695  8.3669815]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [51.482952 51.718895 52.099052 52.525204 53.022713 53.51604  53.99687
0:  54.30647  54.54775  54.605103 54.467064 54.16444  53.695683 53.06804
0:  52.142242 50.993256 49.69205  48.35721  46.582703 46.365253]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.6558895  1.61695    1.5784197  1.5382304  1.4706178  1.3730526
0:  1.3064332  1.2328186  1.1989703  1.1940484  1.2097759  1.1995654
0:  1.167264   1.1066084  0.9857216  0.83500624 0.6845002  0.55465555
0:  0.09153175 0.00706148]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.143488 16.250996 16.4195   16.587536 16.807287 17.051214 17.355
0:  17.59904  17.868858 18.06281  18.16896  18.247515 18.294483 18.286983
0:  18.268673 18.155167 17.974508 17.732151 16.748302 16.60508 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.706076  9.022654  9.420088  9.858232 10.332267 10.802538 11.311071
0:  11.788876 12.267477 12.753683 13.211786 13.646154 14.033848 14.391621
0:  14.665121 14.906072 15.16337  15.463844 15.00738  15.357021]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.60202  18.707205 18.810598 18.86471  18.924322 18.971432 18.950605
0:  18.829355 18.614813 18.297283 17.875454 17.376795 16.85877  16.325365
0:  15.82119  15.379261 15.020376 14.731535 14.144531 14.158577]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.515351  9.708883 10.068344 10.544246 11.124746 11.744408 12.374245
0:  12.919197 13.3465   13.575916 13.604589 13.426195 13.113832 12.66901
0:  12.145709 11.584303 11.025903 10.533071  9.224607  8.666691]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -8.409693  -8.438074  -8.47695   -8.559877  -8.710411  -8.966993
0:   -9.264378  -9.6502   -10.050318 -10.415934 -10.735125 -11.039963
0:  -11.284029 -11.446644 -11.586952 -11.633091 -11.628002 -11.568628
0:  -11.852276 -11.861435]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.832653  -7.813833  -7.791977  -7.7660036 -7.7250967 -7.7009172
0:  -7.6723413 -7.69724   -7.692872  -7.65761   -7.5814934 -7.508912
0:  -7.425558  -7.3155355 -7.265808  -7.197773  -7.115099  -6.9908533
0:  -7.3436947 -7.322563 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.2662916 4.4043217 4.733923  5.1425314 5.541572  5.7684274 5.8369594
0:  5.6465063 5.4068327 5.126922  4.906164  4.7506332 4.648879  4.5829864
0:  4.4963174 4.43931   4.416727  4.4734015 4.990281  4.9613967]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.867985  9.676088  9.544187  9.345796  9.188837  8.973501  8.873107
0:  8.738873  8.708425  8.71138   8.652149  8.54526   8.366179  8.042661
0:  7.6499763 7.181304  6.7260523 6.3661995 6.0360913 5.740265 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [30.443003 30.86912  31.295216 31.677881 31.984423 32.254524 32.549015
0:  32.70982  32.88422  33.014496 33.036896 32.98609  32.943867 32.911606
0:  32.943375 33.048782 33.239525 33.490303 34.491604 34.949467]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [38.744213 40.452717 41.967022 43.071247 43.777813 44.02816  43.852524
0:  43.178898 42.369167 41.30433  40.201492 38.934025 37.670628 36.50245
0:  35.49539  34.79219  34.417175 34.333523 34.38031  33.992065]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.8088465 -6.7406454 -6.537819  -6.19569   -5.752243  -5.240753
0:  -4.675666  -4.0755672 -3.3695116 -2.5235271 -1.5057917 -0.3627143
0:   0.9781203  2.3722558  3.8100765  5.220013   6.5722456  7.763337
0:  10.334541  11.739497 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.607208  4.7685795 4.925349  5.0415215 5.126563  5.173941  5.2136283
0:  5.230001  5.269798  5.3414197 5.4141426 5.4479284 5.4396157 5.410594
0:  5.3414745 5.3022976 5.2992315 5.3367662 5.4379787 5.4711437]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.411434  10.03154    9.672286   9.260177   8.793757   8.253197
0:   7.714821   7.1323643  6.59699    6.0989485  5.630911   5.176654
0:   4.742566   4.353627   3.966974   3.6408823  3.3273513  3.0688057
0:   3.2831683  2.9426742]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.185638  15.921299  15.429012  14.616772  13.553744  12.293806
0:  10.970554   9.730524   8.688907   7.944996   7.494423   7.279192
0:   7.228884   7.3139124  7.4178157  7.5605507  7.730172   7.9287834
0:   8.171598   8.203507 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.27443647 0.3244896  0.4646039  0.6984534  0.91927385 1.1291661
0:  1.358808   1.5266333  1.729805   1.9667192  2.2251348  2.522368
0:  2.8850393  3.2345817  3.623112   3.9721458  4.3161716  4.7161007
0:  4.8591003  5.1475816 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.7904043 -4.5293684 -4.3388777 -4.3026295 -4.4299574 -4.7295866
0:  -5.174671  -5.7456675 -6.3302536 -6.8376665 -7.1876535 -7.335455
0:  -7.2495203 -6.8803625 -6.352641  -5.752451  -5.16325   -4.6357565
0:  -4.156008  -3.464983 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.018052 11.51543  11.934448 12.291511 12.617582 12.934352 13.332684
0:  13.722562 14.188087 14.615427 14.980282 15.228613 15.374365 15.364061
0:  15.243784 15.043837 14.778749 14.503424 13.282435 13.238096]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.838876  -5.883237  -5.9333096 -5.9791965 -6.0241604 -6.106019
0:  -6.1429625 -6.189392  -6.190117  -6.126276  -6.0207806 -5.9043884
0:  -5.7753468 -5.6204443 -5.490985  -5.31213   -5.129898  -4.9195786
0:  -4.883068  -4.7186604]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.5694916 3.4886484 3.4656956 3.4555404 3.5158172 3.6409273 3.8701591
0:  4.1495013 4.487304  4.8300743 5.1591125 5.434827  5.6473823 5.811291
0:  5.8556023 5.825945  5.6914425 5.4543004 4.3260355 3.822563 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.378702   8.6665945  9.014743   9.441378   9.872737  10.302764
0:  10.783157  11.15901   11.596801  12.07276   12.562496  13.099517
0:  13.648899  14.181841  14.695563  15.136766  15.527397  15.86212
0:  16.08907   16.509676 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.2216   18.198908 18.152758 18.06147  17.921743 17.753956 17.61066
0:  17.394068 17.227505 17.06622  16.865273 16.6572   16.504866 16.395489
0:  16.334572 16.294918 16.287428 16.284203 15.982658 16.001202]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.63803  21.401258 21.116228 20.82341  20.529758 20.286995 20.177479
0:  20.02248  19.971586 19.947496 19.839653 19.719522 19.599829 19.43799
0:  19.295927 19.124996 18.92437  18.7012   18.590221 18.32584 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.576931  -6.530423  -6.4635305 -6.384988  -6.291959  -6.249588
0:  -6.2175426 -6.264306  -6.3206253 -6.380022  -6.4195757 -6.4665346
0:  -6.4859514 -6.4491196 -6.4108715 -6.284131  -6.0896454 -5.8700705
0:  -5.678754  -5.41201  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.886371  -7.7203126 -7.572141  -7.452932  -7.3310447 -7.2628007
0:  -7.154405  -7.0918    -7.0071588 -6.909694  -6.7985625 -6.682736
0:  -6.5540204 -6.419662  -6.2842956 -6.139768  -6.003711  -5.8831134
0:  -6.3088183 -6.137343 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.416954 18.417583 18.480234 18.624384 18.879616 19.165808 19.44176
0:  19.645504 19.953459 20.271471 20.75264  21.26731  21.844934 22.416441
0:  22.816515 23.136063 23.381094 23.59549  24.989016 25.260761]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-17.301615 -17.304556 -17.226122 -17.071676 -16.868366 -16.665415
0:  -16.504341 -16.46894  -16.509167 -16.618872 -16.785736 -16.98718
0:  -17.17086  -17.283691 -17.320501 -17.25698  -17.117989 -16.948208
0:  -17.40172  -17.329525]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.169062 17.636486 18.102232 18.510418 18.894428 19.276188 19.687376
0:  20.011114 20.31879  20.54939  20.669506 20.665073 20.605982 20.483871
0:  20.330988 20.172121 20.079678 20.038925 19.006762 19.164413]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.7985282  1.7020504  1.5187206  1.2956109  1.1017942  0.95548344
0:  0.9363351  0.9846587  1.1483126  1.4248538  1.7808695  2.1548357
0:  2.4828644  2.7531397  2.8957813  2.9999058  3.0824287  3.1932101
0:  2.833045   2.8038006 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.4938216  -1.5411596  -1.5498948  -1.5120988  -1.4598866  -1.4147358
0:  -1.3956604  -1.4040804  -1.3964915  -1.3529649  -1.2541714  -1.153657
0:  -1.0304723  -0.888093   -0.7595601  -0.6143069  -0.46237707 -0.2775221
0:  -0.53747797 -0.39722776]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.407569  5.365878  5.370015  5.4040146 5.4070387 5.350197  5.2930193
0:  5.1964455 5.1254654 5.073129  5.004636  4.9282346 4.8567095 4.7922525
0:  4.739169  4.714239  4.6836376 4.6535673 4.2451086 4.1764092]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.06236029  0.07398367  0.2598548   0.44576263  0.6838374   0.9158039
0:   1.1296258   1.2546177   1.3393373   1.4094882   1.5428038   1.705996
0:   1.9349575   2.258088    2.5241313   2.813009    2.992101    3.0645747
0:   3.476579    3.3377504 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.263859 25.004597 25.560265 25.774506 25.842636 25.931755 26.11668
0:  26.387775 26.726883 27.054878 27.420563 27.845787 28.37347  28.99691
0:  29.611137 30.171032 30.64896  31.026665 31.782711 32.609848]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [28.372387 28.676388 29.01226  29.344814 29.685993 30.070759 30.552914
0:  31.00808  31.5666   32.143803 32.712173 33.254246 33.797756 34.306934
0:  34.796246 35.295475 35.826786 36.304115 36.66263  37.20081 ]
0: validation loss for strategy=forecast at epoch 6 : nan
0: validation loss for velocity_u : 0.029654668644070625
0: validation loss for velocity_v : 0.053780946880578995
0: validation loss for specific_humidity : 0.023316994309425354
0: validation loss for velocity_z : 0.4359011948108673
0: validation loss for temperature : 0.0806351974606514
0: validation loss for total_precip : nan
0: 7 : 10:14:31 :: batch_size = 96, lr = 1.7677085752190346e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 7, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.6387, 0.6253, 0.6150, 0.6079, 0.6039, 0.6028, 0.6049, 0.6097, 0.6170, 0.6260, 0.6364, 0.6477, 0.6586, 0.6683,
0:         0.6754, 0.6792, 0.6797, 0.6771, 0.7124, 0.6960, 0.6818, 0.6699, 0.6602, 0.6528, 0.6474], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.4617, 0.4476, 0.4302, 0.4102, 0.3874, 0.3623, 0.3353, 0.3064, 0.2762, 0.2453, 0.2151, 0.1868, 0.1619, 0.1419,
0:         0.1275, 0.1192, 0.1164, 0.1188, 0.4483, 0.4387, 0.4259, 0.4100, 0.3915, 0.3710, 0.3491], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.5554, -0.5577, -0.5612, -0.5648, -0.5711, -0.5791, -0.5902, -0.6042, -0.6166, -0.6323, -0.6480, -0.6548,
0:         -0.6616, -0.6632, -0.6564, -0.6418, -0.6195, -0.6037, -0.5524, -0.5558, -0.5598, -0.5638, -0.5686, -0.5736,
0:         -0.5802], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.2264,  0.1965,  0.1721,  0.1544,  0.1466,  0.1510,  0.1677,  0.1810,  0.1776,  0.1499,  0.1100,  0.0712,
0:          0.0379,  0.0069, -0.0297, -0.0663, -0.0973, -0.1217,  0.3273,  0.3118,  0.2830,  0.2497,  0.2231,  0.2120,
0:          0.2098], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0.6036, -0.5900, -0.5803, -0.5742, -0.5713, -0.5705, -0.5711, -0.5721, -0.5733, -0.5742, -0.5743, -0.5728,
0:         -0.5696, -0.5645, -0.5581, -0.5512, -0.5450, -0.5393, -0.5346, -0.5308, -0.5288, -0.5277, -0.5280, -0.5296,
0:         -0.5324], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 7, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,  0.2196,     nan,     nan,     nan,  0.0399,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.1571,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.1872,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2278,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.1942,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2023,     nan,     nan,     nan,     nan,     nan,     nan, -0.2382,     nan, -0.2382,
0:             nan,     nan,     nan,     nan, -0.2451, -0.2451,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.1038,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2104,     nan,     nan, -0.1293,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2405,     nan, -0.2289,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2127,     nan,
0:             nan,     nan,     nan, -0.2405,     nan, -0.2428,     nan,     nan,     nan,     nan, -0.2243,     nan,
0:             nan,     nan,     nan, -0.2428,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2451,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0748,     nan, -0.1617,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.1999,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2417,     nan,     nan,     nan,
0:         -0.2417,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2451,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 7, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([1.7525, 1.7536, 1.7460, 1.7327, 1.7227, 1.7185, 1.7253, 1.7351, 1.7487, 1.7675, 1.7830, 1.7980, 1.8153, 1.8322,
0:         1.8519, 1.8858, 1.9260, 1.9643, 1.6841, 1.6829, 1.6700, 1.6529, 1.6468, 1.6459, 1.6623], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([1.1860, 1.2418, 1.2873, 1.3279, 1.3597, 1.3932, 1.4289, 1.4656, 1.5062, 1.5558, 1.6059, 1.6680, 1.7303, 1.8099,
0:         1.9029, 2.0091, 2.1266, 2.2388, 1.1682, 1.2215, 1.2751, 1.3275, 1.3749, 1.4238, 1.4667], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.3393, -0.3360, -0.3310, -0.3252, -0.3234, -0.3254, -0.3293, -0.3364, -0.3407, -0.3436, -0.3442, -0.3415,
0:         -0.3309, -0.3138, -0.2881, -0.2618, -0.2389, -0.2275, -0.3605, -0.3596, -0.3534, -0.3471, -0.3430, -0.3457,
0:         -0.3456], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.1515, -0.1384, -0.1315, -0.1355, -0.1204, -0.1027, -0.1117, -0.1179, -0.0897, -0.0771, -0.0709, -0.0417,
0:         -0.0387, -0.0787, -0.0920, -0.0673, -0.0328, -0.0007, -0.1484, -0.1062, -0.0903, -0.0990, -0.0988, -0.0850,
0:         -0.0892], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([0.2386, 0.2224, 0.2120, 0.2078, 0.2072, 0.2052, 0.1991, 0.1893, 0.1797, 0.1732, 0.1710, 0.1725, 0.1750, 0.1728,
0:         0.1701, 0.1672, 0.1673, 0.1696, 0.1728, 0.1745, 0.1757, 0.1771, 0.1775, 0.1737, 0.1565], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.055321164429187775; velocity_v: 0.09077496826648712; specific_humidity: 0.035513393580913544; velocity_z: 0.45804545283317566; temperature: 0.10489673912525177; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06428635865449905; velocity_v: 0.10529772937297821; specific_humidity: 0.04391339421272278; velocity_z: 0.4848601222038269; temperature: 0.13245368003845215; total_precip: nan; 
0: epoch: 7 [1/5 (20%)]	Loss: nan : nan :: 0.15981 (2.80 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.07349702715873718; velocity_v: 0.11804705113172531; specific_humidity: 0.048107825219631195; velocity_z: 0.5153129696846008; temperature: 0.13716702163219452; total_precip: nan; 
0: epoch: 7 [2/5 (40%)]	Loss: nan : nan :: 0.15908 (16.23 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05874047800898552; velocity_v: 0.09315655380487442; specific_humidity: 0.04373301938176155; velocity_z: 0.5166509747505188; temperature: 0.09555423259735107; total_precip: nan; 
0: epoch: 7 [3/5 (60%)]	Loss: nan : nan :: 0.14382 (16.27 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05607355386018753; velocity_v: 0.09382535517215729; specific_humidity: 0.036035411059856415; velocity_z: 0.4937376081943512; temperature: 0.08689051866531372; total_precip: nan; 
0: epoch: 7 [4/5 (80%)]	Loss: nan : nan :: 0.14004 (16.21 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [5.29289246e-05 5.34057617e-05 7.39097595e-05 7.86781311e-05
0:  1.27315521e-04 1.57833099e-04 7.72476196e-05 5.86509705e-05
0:  1.02519989e-04 1.62124634e-04 1.61647797e-04 1.20639801e-04
0:  8.34465027e-05 1.32560730e-04 1.09195709e-04 6.48498535e-05
0:  2.62260437e-05 1.66893005e-05 1.09672546e-05 1.76429749e-05
0:  2.00271606e-05 1.76429749e-05 2.86102295e-05 8.86917114e-05
0:  1.25885010e-04 5.19752502e-05 4.43458557e-05 4.95910645e-05
0:  4.29153479e-05 5.10215796e-05 2.30789185e-04 1.25885010e-04
0:  9.39369202e-05 7.96318054e-05 1.27315521e-04 1.07288361e-04
0:  1.36375427e-04 1.35898590e-04 1.27792358e-04 1.04904175e-04
0:  1.14440918e-04 1.24931335e-04 1.08718872e-04 1.07288361e-04
0:  8.44001770e-05 6.81877136e-05 1.31130219e-04 1.26361847e-04
0:  6.91413879e-05 3.57627869e-05 2.67028809e-05 2.76565552e-05
0:  4.33921778e-05 6.10351562e-05 6.00814819e-05 4.57763635e-05
0:  8.48770142e-05 6.10351562e-05 1.76429749e-05 6.19888306e-06
0:  7.62939453e-06 3.81469727e-06 2.38418579e-06 1.76429749e-05
0:  1.95503235e-05 2.00271606e-05 2.43186951e-05 3.14712524e-05
0:  2.43186951e-05 1.38282776e-05 2.38418579e-05 4.52995337e-05
0:  5.76972961e-05 3.71932983e-05 3.81469727e-05 5.19752502e-05
0:  7.86781311e-05 9.25064087e-05 9.48905945e-05 3.05175781e-05
0:  7.62939453e-06 7.27595761e-12 8.58306885e-06 2.57492065e-05
0:  6.19888306e-05 1.08718872e-04 1.39713287e-04 1.79767609e-04
0:  1.18732452e-04 1.66893005e-05 5.24520874e-06 5.72204590e-06
0:  7.27595761e-12 7.27595761e-12 4.76837158e-07 1.90734863e-06
0:  2.38418579e-06 2.09808350e-05 7.15255737e-06 1.14440918e-05
0:  3.09944153e-05 4.72068787e-05 6.15119934e-05 4.05311584e-05
0:  1.66893005e-05 2.05039978e-05 1.43051147e-05 7.15255737e-06
0:  6.62803650e-05 4.48226929e-05 5.14984094e-05 4.76837158e-05
0:  9.58442688e-05 1.34944916e-04 8.72612000e-05 4.10079956e-05
0:  3.71932983e-05 8.20159912e-05 1.16348267e-04 2.44617462e-04
0:  2.01225281e-04 1.67846680e-04 1.71184540e-04 1.45435333e-04
0:  1.24454498e-04 9.44137573e-05 4.52995337e-05 3.91006470e-05
0:  1.57356262e-05 1.33514404e-05 1.09672546e-05 5.53131104e-05
0:  7.58171082e-05 8.24928284e-05 6.10351562e-05 7.05718994e-05
0:  5.81741333e-05 5.19752502e-05 1.80244446e-04 1.64508820e-04
0:  6.96182251e-05 8.82148743e-05 1.07288361e-04 8.67843628e-05
0:  1.25408173e-04 1.74522400e-04 1.64508820e-04 1.02996826e-04
0:  1.12533569e-04 1.02996826e-04 7.96318054e-05 5.72204590e-05
0:  2.71797180e-05 3.52859497e-05 6.43730164e-05 8.67843628e-05
0:  3.76701355e-05 1.28746033e-05 9.53674316e-06 8.58306885e-06
0:  8.10623169e-06 1.38282776e-05 2.43186951e-05 2.38418579e-05
0:  5.05447388e-05 4.10079956e-05 3.48091125e-05 8.10623169e-06
0:  8.10623169e-06 8.10623169e-06 1.00135803e-05 2.24113464e-05
0:  3.24249268e-05 8.44001770e-05 8.53538513e-05 6.62803650e-05
0:  5.91278076e-05 4.86373865e-05 2.24113464e-05 5.43594360e-05
0:  5.38825989e-05 1.71661377e-05 2.86102295e-06 3.81469727e-06
0:  2.62260437e-05 2.33650208e-05 3.33786011e-06 4.76837158e-07
0:  7.27595761e-12 7.27595761e-12 4.76837158e-06 3.38554382e-05
0:  4.33921778e-05 8.77380371e-05 1.09195709e-04 1.46865845e-04
0:  1.02043152e-04 7.15255737e-05 4.19616699e-05 1.19209290e-05]
0: Target values (first 200):
0: [1.9073486e-04 2.0456314e-04 2.2077560e-04 2.1886826e-04 1.6641617e-04
0:  5.1021580e-05 2.9087067e-05 2.8133392e-05 1.4781952e-05 1.0013580e-05
0:  4.7683716e-06 1.4305115e-06 4.7683716e-07 6.1988831e-06 1.3351440e-05
0:  1.0967255e-05 9.5367432e-06 2.3841858e-06 3.3378601e-06 9.5368159e-07
0:  7.2759576e-12 9.5368159e-07 2.8610229e-06 6.1988831e-06 1.4305115e-05
0:  1.2397766e-04 2.0790100e-04 1.4686584e-04 2.4795532e-05 4.8637386e-05
0:  1.7738342e-04 1.2445450e-04 7.2479248e-05 7.9631805e-05 6.5803528e-05
0:  6.7234039e-05 1.0061264e-04 1.0061264e-04 8.4877014e-05 1.0108948e-04
0:  7.2956085e-05 3.3378601e-05 1.0013580e-05 1.1444092e-05 9.5367432e-06
0:  2.3841858e-06 4.2915344e-06 4.2915344e-06 5.2452087e-06 1.7642975e-05
0:  7.4863434e-05 3.3378601e-05 2.2888184e-05 7.6293945e-06 7.6293945e-06
0:  1.4305115e-06 1.4305115e-06 1.9550323e-05 2.3365021e-05 5.8174133e-05
0:  7.3432922e-05 3.6716461e-05 6.1988831e-06 7.2759576e-12 7.2759576e-12
0:  5.7220459e-06 2.6702881e-05 3.8623810e-05 4.9591064e-05 6.4373016e-05
0:  7.1048737e-05 2.9563904e-05 2.4318695e-05 4.6253204e-05 6.4373016e-05
0:  7.2479248e-05 3.1471252e-05 1.1920929e-05 3.3378601e-06 2.8610229e-06
0:  2.8610229e-06 1.5735626e-05 2.0027161e-05 1.0013580e-05 9.5367432e-06
0:  1.7166138e-05 3.2424927e-05 4.9591064e-05 3.3855438e-05 5.5313110e-05
0:  4.0531158e-05 4.4822693e-05 4.5299534e-05 4.7206879e-05 5.0067902e-05
0:  4.2438507e-05 3.0040741e-05 4.6253204e-05 2.1934509e-05 4.3392178e-05
0:  3.6239624e-05 4.2438507e-05 3.6239624e-05 4.0531158e-05 2.8133392e-05
0:  2.7656555e-05 4.1007996e-05 2.7179718e-05 2.4557114e-04 1.9311905e-04
0:  1.7118454e-04 1.8692017e-04 1.5306473e-04 1.7166138e-05 1.7642975e-05
0:  9.0599060e-06 5.7220459e-06 3.8146973e-06 2.8610229e-06 4.7683716e-07
0:  1.4305115e-06 5.2452087e-06 9.5367432e-06 9.0599060e-06 6.1988831e-06
0:  1.4305115e-06 4.7683716e-07 7.2759576e-12 4.7683716e-07 4.7683716e-07
0:  4.7683716e-07 1.9073486e-06 6.1988831e-06 7.3432922e-05 1.4591217e-04
0:  1.5020370e-04 1.9073486e-05 3.9577484e-05 1.3494492e-04 5.2452087e-05
0:  5.3405762e-05 4.0531158e-05 6.3896179e-05 8.2492828e-05 1.7261505e-04
0:  2.1791458e-04 1.9741058e-04 1.3589859e-04 1.0251999e-04 4.1007996e-05
0:  2.2888184e-05 1.0967255e-05 7.1525574e-06 3.8146973e-06 2.1457672e-05
0:  2.4318695e-05 7.9631805e-05 9.3936920e-05 1.5354156e-04 9.3936920e-05
0:  4.3392178e-05 8.1062317e-06 4.2915344e-06 7.2759576e-12 2.3841858e-06
0:  2.5272369e-05 4.8160557e-05 7.2956085e-05 7.4386597e-05 3.9577484e-05
0:  5.2452087e-06 7.2759576e-12 7.2759576e-12 1.4305115e-06 1.1920929e-05
0:  2.3841858e-05 3.3855438e-05 4.9591064e-05 6.6280365e-05 4.6730042e-05
0:  3.5762787e-05 5.2452087e-05 5.7220459e-05 6.1511993e-05 4.8160557e-05
0:  2.5749207e-05 5.2452087e-06 9.5367432e-06 1.4305115e-05 2.5272369e-05
0:  3.5762787e-05 2.4318695e-05 5.7220459e-06 1.2874603e-05 1.2874603e-05
0:  3.4809113e-05 4.2915348e-05 4.7206879e-05 3.4332275e-05 4.2915348e-05]
0: Prediction values (first 20):
0: [-4.3413057 -4.2077312 -4.1445427 -4.1873665 -4.2580795 -4.3874884
0:  -4.487651  -4.619138  -4.7130404 -4.7845716 -4.837839  -4.929573
0:  -5.0435333 -5.145606  -5.3220434 -5.4557676 -5.5560513 -5.622655
0:  -6.1212645 -6.1846676]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -2.253, max = 0.803, mean = -0.944
0:          sample (first 20): tensor([-0.8722, -0.8609, -0.8555, -0.8591, -0.8651, -0.8761, -0.8846, -0.8957, -0.9037, -0.9097, -0.9142, -0.9220,
0:         -0.9317, -0.9403, -0.9552, -0.9666, -0.9751, -0.9807, -0.8921, -0.8791])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.483353 27.672394 27.82759  27.902653 27.92184  27.912985 27.951603
0:  27.944115 27.990885 28.04352  28.030586 27.978394 27.921835 27.85859
0:  27.804243 27.751568 27.690699 27.570953 27.53021  27.767366]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.2108054 6.205818  6.1659513 6.1084948 6.0149317 5.9016347 5.7421136
0:  5.57211   5.4656696 5.4995966 5.6743417 5.9192033 6.211484  6.4866214
0:  6.7054806 6.914262  7.162827  7.423366  7.2697983 7.6023474]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.440104  -3.3823895 -3.3459992 -3.3193564 -3.267634  -3.2202268
0:  -3.0972314 -2.9984498 -2.8769593 -2.7544084 -2.6358695 -2.560594
0:  -2.5180173 -2.4881406 -2.5192742 -2.5312295 -2.5281081 -2.4935746
0:  -2.599504  -2.6262298]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.9768894 3.023767  3.083376  3.1671052 3.2719173 3.37002   3.4702413
0:  3.5188801 3.5692585 3.6045775 3.6483545 3.733841  3.8828633 4.0806084
0:  4.297242  4.54313   4.8200173 5.1315947 5.571325  5.95347  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.6795335 7.632247  7.63543   7.624073  7.6080875 7.5782313 7.5565443
0:  7.4916134 7.473788  7.4583254 7.443259  7.3922853 7.3412795 7.2887783
0:  7.232083  7.210808  7.2432737 7.327722  7.090056  7.070439 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [36.203484 36.25296  36.277756 36.193718 36.027374 35.809265 35.520256
0:  35.168457 34.82213  34.44163  33.981018 33.45314  32.908726 32.35136
0:  31.771364 31.255972 30.826815 30.452536 30.00162  29.793694]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.1587076 3.2356985 3.3629162 3.5321772 3.6927416 3.8256662 3.931352
0:  3.9835682 4.0304375 4.0325766 4.0305004 4.017457  4.0533743 4.0997553
0:  4.201874  4.3094697 4.4280453 4.5771627 4.803034  4.853879 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -7.696805  -7.991214  -8.229813  -8.448767  -8.690345  -9.094259
0:   -9.528612 -10.056279 -10.541053 -10.941916 -11.253346 -11.4863
0:  -11.640698 -11.644858 -11.611466 -11.479228 -11.333409 -11.194791
0:  -11.290843 -11.506646]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.517567  15.594418  15.66796   15.7196045 15.811506  15.903961
0:  15.985534  15.907792  15.752691  15.514672  15.244093  15.013241
0:  14.877393  14.799929  14.809696  14.826954  14.89971   15.126504
0:  15.065096  15.219276 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.916489 18.895191 18.939041 18.956083 18.97763  19.01598  19.068384
0:  19.116997 19.199604 19.306461 19.430286 19.526672 19.640179 19.737743
0:  19.796978 19.810688 19.809713 19.809027 19.748186 19.769249]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.701091  3.868888  4.15695   4.379509  4.5982366 4.7082224 4.7533226
0:  4.6345735 4.495882  4.3124456 4.1814394 4.082592  4.050129  4.117525
0:  4.109492  4.082483  3.9609637 3.7793736 2.840199  2.6066613]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.293812 26.367363 26.572308 26.671753 26.774097 26.830872 26.882153
0:  26.981739 27.168407 27.454117 27.769394 28.000854 28.15157  28.250504
0:  28.217533 28.19078  28.146717 28.055573 28.68383  28.209312]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.868507 20.062922 20.203892 20.18519  20.129375 20.035393 19.987223
0:  19.974333 20.031887 20.114244 20.166578 20.168276 20.127144 20.05925
0:  19.922857 19.796604 19.699375 19.58544  18.909298 18.983152]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.15199    -6.0158863  -5.645339   -5.0815134  -4.4755707  -3.961133
0:  -3.437724   -3.1213045  -2.812438   -2.55472    -2.3196936  -2.0541372
0:  -1.7900143  -1.4800467  -1.292613   -1.1507196  -1.0550337  -0.95357513
0:  -0.23123789  0.09667635]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.942566 22.411222 22.789124 23.128893 23.40711  23.636118 23.770493
0:  23.785343 23.738085 23.635876 23.522501 23.387123 23.281466 23.147507
0:  23.008598 22.850693 22.735188 22.683943 22.217638 22.49672 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.17888   -4.33058   -4.52113   -4.698179  -4.816091  -4.884085
0:  -4.843617  -4.7580676 -4.587621  -4.3597283 -4.0775685 -3.7787852
0:  -3.490621  -3.191113  -2.9581904 -2.7309031 -2.4979596 -2.2560277
0:  -2.234694  -2.1531835]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.618619  4.555431  4.5144672 4.4839706 4.450583  4.390359  4.3361077
0:  4.249632  4.1866703 4.1310797 4.101415  4.068136  4.055707  4.0552425
0:  4.0595493 4.0787983 4.0848656 4.08881   3.8905473 3.8890004]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -4.053051   -4.1466646  -4.2977877  -4.506879   -4.82185    -5.2399178
0:   -5.6945066  -6.2349806  -6.7826815  -7.323332   -7.840045   -8.345227
0:   -8.7889805  -9.14962    -9.466487   -9.733977  -10.00147   -10.21206
0:  -10.7446165 -10.908973 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.1029425  7.757448   8.354126   8.806298   9.159376   9.518517
0:   9.952551  10.395528  10.813368  11.075126  11.079825  10.794714
0:  10.369978   9.949706   9.700417   9.734385  10.047246  10.524761
0:  11.564049  12.239404 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.915272 12.792667 12.763054 12.787715 12.868715 12.967019 13.087863
0:  13.165995 13.233406 13.283024 13.271129 13.169006 13.078431 12.959713
0:  12.856637 12.75797  12.695415 12.645983 12.403488 12.499531]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [31.802029 32.28236  32.764687 33.25595  33.73457  34.24075  34.78333
0:  35.249615 35.757725 36.271988 36.79929  37.314003 37.832462 38.35794
0:  38.86827  39.33275  39.8302   40.274952 40.619728 41.47846 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.5970955  9.86496   10.1544895 10.446401  10.6824    10.859863
0:  11.0214    11.157995  11.286379  11.423502  11.552657  11.609579
0:  11.613693  11.552271  11.451028  11.347961  11.276091  11.267803
0:  11.445772  11.454252 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.708609   -3.6796021  -3.7274146  -3.7859063  -3.8095899  -3.7985969
0:  -3.7134376  -3.5981603  -3.3912091  -3.0871034  -2.6731505  -2.190722
0:  -1.6609316  -1.1243911  -0.63673735 -0.15618896  0.3470745   0.82640696
0:   1.5996361   2.0458503 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.60015965  0.16552973 -0.16822052 -0.3527999  -0.41252232 -0.41407824
0:  -0.33373356 -0.26700497 -0.17202234 -0.04352188  0.19427681  0.47760963
0:   0.8211932   1.1533971   1.3422756   1.3939195   1.2695718   1.0706301
0:  -0.2945752  -0.45334005]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.48458433 0.49823093 0.6278701  0.8404074  1.1259427  1.4513521
0:  1.8426876  2.2100606  2.585556   2.9096193  3.1985488  3.4164565
0:  3.6408153  3.8906767  4.0622435  4.1729155  4.1182737  3.9051142
0:  2.2034407  1.4685063 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.3231363 -1.5934691 -1.9089684 -2.2907233 -2.7190309 -3.1678367
0:  -3.58911   -3.9222054 -4.0706553 -4.0379415 -3.8610196 -3.6673913
0:  -3.5141835 -3.3927484 -3.307487  -3.1913667 -3.0160174 -2.755857
0:  -1.4463954 -0.7992015]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.824763  -4.7089534 -4.53416   -4.3238873 -4.04505   -3.7373967
0:  -3.41505   -3.115272  -2.8807397 -2.6984096 -2.5583224 -2.5105252
0:  -2.521154  -2.568334  -2.65836   -2.7488303 -2.780044  -2.7578273
0:  -3.3222098 -3.2601247]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.4368858 3.4139695 3.3642356 3.283591  3.2100322 3.1112316 3.0373518
0:  2.940124  2.882853  2.8940907 2.9575486 3.0501845 3.165811  3.339609
0:  3.4665306 3.6128354 3.755103  3.882465  3.716134  3.6497416]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.714427    0.59954643  0.52065134  0.49431562  0.49703884  0.43494081
0:   0.3271389   0.12330389 -0.08586597 -0.2821226  -0.41135454 -0.53044176
0:  -0.64880896 -0.7665415  -0.9457097  -1.0905666  -1.1732559  -1.1851139
0:  -2.0594544  -2.1618886 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-15.096761  -15.021913  -14.915706  -14.78925   -14.666392  -14.599784
0:  -14.5393915 -14.551448  -14.547954  -14.496839  -14.409398  -14.301145
0:  -14.176398  -14.001245  -13.835837  -13.65124   -13.438066  -13.194722
0:  -13.342164  -13.068095 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.071255  8.93105   8.830536  8.716099  8.555377  8.347461  8.108283
0:  7.8198595 7.5016103 7.205919  6.892874  6.565405  6.3046165 6.0814943
0:  5.9344797 5.847796  5.7974024 5.795991  5.120441  5.113773 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.7045183 -1.6947532 -1.6962223 -1.7345786 -1.7856345 -1.8872595
0:  -1.9869103 -2.130454  -2.256691  -2.367362  -2.4596987 -2.5688229
0:  -2.6741219 -2.7368174 -2.8016977 -2.7961464 -2.7340422 -2.6267796
0:  -2.4437962 -2.2076988]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [39.006824 39.11681  39.301933 39.546967 39.805767 40.030437 40.34372
0:  40.52675  40.75696  40.903038 41.003178 40.984135 40.93509  40.870335
0:  40.719498 40.628754 40.522137 40.389175 41.23584  41.089527]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.304771 15.175322 15.1035   15.065292 15.000988 14.915371 14.835996
0:  14.691423 14.597477 14.47642  14.324077 14.12623  13.925808 13.734419
0:  13.543198 13.37752  13.224983 13.083341 13.344091 13.34459 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-17.54292  -17.593723 -17.57238  -17.449589 -17.331053 -17.228762
0:  -17.080202 -16.982819 -16.899952 -16.806484 -16.705032 -16.623009
0:  -16.47161  -16.332592 -16.102448 -15.881615 -15.688967 -15.499529
0:  -15.781887 -15.642603]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.937248  -5.200327  -5.3594894 -5.4807386 -5.5534945 -5.713703
0:  -5.9014664 -6.210062  -6.475685  -6.5853786 -6.4817944 -6.2157135
0:  -5.8459826 -5.413727  -5.0850315 -4.7975016 -4.561496  -4.317545
0:  -3.9709558 -3.8065653]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.9068022   1.5588808   1.1588788   0.68166256  0.13522625 -0.42885542
0:  -0.9836173  -1.4881897  -1.9201145  -2.2159748  -2.4535437  -2.704585
0:  -2.9815407  -3.3044424  -3.6831026  -4.0256205  -4.291026   -4.4250593
0:  -3.9176693  -3.9128675 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.108584  8.970953  8.874784  8.782374  8.567949  8.063215  7.148104
0:  5.875838  4.4160395 3.0161893 1.8786783 1.1493926 0.8718877 0.9951997
0:  1.4464517 2.1298442 2.8888407 3.5402546 3.9525528 3.819804 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.033071  -4.886705  -4.7655225 -4.7111382 -4.726378  -4.821964
0:  -4.959555  -5.1890492 -5.4071326 -5.627745  -5.786452  -5.8861194
0:  -5.9201255 -5.877395  -5.848023  -5.7989535 -5.747477  -5.6442
0:  -5.9130483 -5.7313733]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.607637 20.737635 20.878374 21.068556 21.232754 21.422691 21.681097
0:  21.89955  22.231209 22.654148 23.120964 23.683558 24.331291 24.99684
0:  25.693949 26.346352 26.942677 27.442833 28.202066 28.59081 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.001499 13.285963 13.595829 13.898013 14.182503 14.399319 14.596165
0:  14.695186 14.81622  14.944265 15.085727 15.278642 15.524548 15.805007
0:  16.057152 16.2838   16.55805  16.88934  16.103348 16.353909]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.772806 25.655277 25.491379 25.17338  24.803627 24.36977  23.880283
0:  23.339342 22.796646 22.271112 21.757227 21.21083  20.670044 20.14004
0:  19.581966 19.099499 18.734211 18.47685  17.987406 17.860325]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.2722287 1.3295774 1.4125643 1.5158067 1.6358905 1.7238755 1.8730745
0:  1.9879322 2.1400137 2.3292665 2.5081081 2.6292386 2.6855392 2.7180347
0:  2.6907125 2.6960573 2.7248726 2.797648  1.8356485 1.6829524]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.2720132  1.3154387  2.0799775  3.550921   5.404549   7.118634
0:  8.455009   8.804082   8.351965   7.0993223  5.3036914  3.2806058
0:  1.5519462  0.4755168  0.05876493 0.54855585 1.6692762  3.123384
0:  6.34289    6.718153  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.162517  7.011367  6.862414  6.7085366 6.5519276 6.368027  6.166674
0:  5.939956  5.739829  5.554763  5.387458  5.2484384 5.137869  5.0452642
0:  4.9890223 4.947729  4.9063096 4.8395967 4.954817  5.0820737]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.5209107  -1.5629692  -1.5193758  -1.4592199  -1.4068284  -1.36168
0:  -1.318305   -1.3056908  -1.2566195  -1.2111282  -1.150784   -1.1202865
0:  -1.0641627  -1.0121918  -0.96949387 -0.92113113 -0.89093065 -0.84607553
0:  -0.81619596 -0.7997575 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.432902  -4.562883  -4.625715  -4.690128  -4.746321  -4.862206
0:  -4.9856896 -5.101743  -5.1333737 -4.9913487 -4.702679  -4.3628144
0:  -4.0144267 -3.6562724 -3.4141326 -3.2260213 -3.0921311 -2.9358296
0:  -2.4391465 -2.2297454]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-14.340242 -14.429453 -14.481998 -14.511398 -14.548403 -14.66041
0:  -14.841923 -15.163197 -15.515793 -15.831306 -16.040215 -16.12049
0:  -16.057673 -15.855413 -15.660191 -15.433775 -15.236778 -15.071186
0:  -14.968065 -14.988211]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.247213   -2.8537745  -2.3328433  -1.8476205  -1.4268613  -1.1458473
0:  -0.9157429  -0.73088694 -0.4868827  -0.2683797  -0.14143991 -0.2615013
0:  -0.588593   -1.0434194  -1.5677495  -1.9382777  -2.1403499  -2.2248282
0:  -1.7080855  -1.5191731 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-13.13467   -13.23983   -13.314262  -13.3592415 -13.387377  -13.443426
0:  -13.491663  -13.578239  -13.6465435 -13.695679  -13.697765  -13.679674
0:  -13.638086  -13.562887  -13.478531  -13.399059  -13.340502  -13.249901
0:  -13.69849   -13.800434 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.1072083 1.374855  1.6572008 1.9850125 2.3360684 2.652991  2.9706972
0:  3.199919  3.4214537 3.6023526 3.786569  3.9569707 4.1535454 4.3464622
0:  4.507603  4.664831  4.8214726 5.0128593 5.1183143 5.2556   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.920363  -8.042942  -8.143589  -8.182817  -8.170818  -8.154251
0:  -8.115915  -8.124403  -8.145393  -8.1611    -8.137957  -8.129522
0:  -8.095194  -8.045897  -7.9951043 -7.933909  -7.8814483 -7.7759414
0:  -7.9469724 -8.019699 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.459822 14.280861 13.95983  13.551981 13.091364 12.631498 12.210653
0:  11.821051 11.491718 11.263687 11.096125 11.009536 11.002693 11.018146
0:  11.045559 11.068907 11.08424  11.07423  10.899959 10.726419]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.1686034  -1.2254672  -1.2009006  -1.0742536  -0.85885906 -0.62328005
0:  -0.33292007 -0.08355045  0.17248821  0.3885231   0.5855622   0.71172714
0:   0.8025651   0.9198847   1.0242529   1.182272    1.3742108   1.5866494
0:   1.433208    1.5830383 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.70145   10.656389  10.612474  10.534124  10.4579935 10.382613
0:  10.328822  10.246456  10.21379   10.176447  10.135386  10.081823
0:  10.0426655  9.985115   9.916098   9.864915   9.826677   9.801674
0:   9.6209755  9.562867 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.957012 27.47296  27.964464 28.31438  28.509819 28.52964  28.404737
0:  28.028465 27.588964 27.02665  26.35208  25.53455  24.693073 23.880346
0:  23.15604  22.644085 22.284288 22.084143 23.066187 22.838062]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.5680776 -1.6556315 -1.8080382 -2.031467  -2.3596864 -2.8069263
0:  -3.28645   -3.8295999 -4.309424  -4.729737  -5.082104  -5.3775077
0:  -5.596909  -5.725264  -5.860312  -5.969807  -6.0995193 -6.2549434
0:  -6.9651427 -7.2012687]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.844355 17.080116 17.308376 17.495853 17.678791 17.836065 17.978113
0:  18.061682 18.135164 18.200083 18.251007 18.268078 18.282133 18.257607
0:  18.187931 18.11355  18.07428  18.088348 17.602215 17.555107]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.823677 12.979521 13.201994 13.411673 13.626316 13.808842 13.941244
0:  14.02663  14.093071 14.146623 14.183858 14.157598 14.106187 14.011646
0:  13.869986 13.723056 13.594007 13.479072 12.670525 12.460867]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.2466435 -1.2891841 -1.2782845 -1.2721906 -1.2880301 -1.3609557
0:  -1.4671359 -1.6367536 -1.7927585 -1.9259162 -1.9955707 -2.0571303
0:  -2.0919375 -2.032641  -1.9684501 -1.8503451 -1.738915  -1.603704
0:  -1.4867196 -1.4580169]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.19996691 -0.4126501  -0.819942   -0.81451607 -0.39148903  0.32980108
0:   1.2430811   2.1410022   2.97754     3.6891541   4.358317    4.91096
0:   5.4665203   6.0472755   6.5558896   7.0002265   7.3007994   7.3539186
0:   5.799262    5.7121143 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.6715636 -3.7085528 -3.7502398 -3.7459388 -3.7187743 -3.7370267
0:  -3.784803  -3.9218612 -4.0966315 -4.29586   -4.4694896 -4.6167293
0:  -4.6774592 -4.690868  -4.684111  -4.6273894 -4.557443  -4.4156003
0:  -4.1569934 -3.9942183]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.4751954  -1.3418059  -1.2396388  -1.0941501  -0.88050556 -0.6268177
0:  -0.25056076  0.11054182  0.4898739   0.77655125  0.97847176  1.0655003
0:   1.066483    1.0131602   0.8970218   0.7908611   0.6724634   0.5823307
0:   0.48836327  0.6014347 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.2154183 -3.2325444 -3.222177  -3.235745  -3.3087173 -3.4871926
0:  -3.7467809 -4.108793  -4.456615  -4.774163  -5.0276694 -5.240565
0:  -5.4268975 -5.5655007 -5.725291  -5.8637986 -5.9602504 -5.9834685
0:  -6.547442  -6.682544 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.739962  6.5986032 6.48801   6.3853726 6.320046  6.261585  6.225781
0:  6.1848207 6.1784363 6.213905  6.2989535 6.385832  6.4686737 6.568081
0:  6.655951  6.7865887 6.9691553 7.2107344 7.5236683 7.7642217]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.2484035 6.7935786 6.384066  5.9972024 5.6937037 5.482621  5.3903213
0:  5.4150305 5.580471  5.854267  6.275239  6.7262454 7.222605  7.7327824
0:  8.152263  8.482973  8.649173  8.687811  8.272431  8.053094 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -9.146976   -9.248415   -9.4113655  -9.612648   -9.822426  -10.085426
0:  -10.33713   -10.645952  -10.898523  -11.05768   -11.096212  -11.046782
0:  -10.8821125 -10.607403  -10.3301525 -10.02788    -9.730606   -9.438885
0:   -9.113316   -9.1002865]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.501988   -3.4380984  -3.237412   -2.97504    -2.703713   -2.4560056
0:  -2.1986394  -2.0308347  -1.8660197  -1.7301927  -1.5878186  -1.410469
0:  -1.1953444  -0.9235444  -0.65520096 -0.38484907 -0.1805253  -0.01024961
0:  -0.32579947 -0.17838001]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.946729  8.016921  8.177769  8.467903  8.859279  9.306366  9.780001
0:  10.16927  10.521114 10.742833 10.810662 10.745853 10.593775 10.400796
0:  10.212421 10.051271  9.951187  9.904553  9.94058   9.869331]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-17.059023 -17.101116 -17.188164 -17.234612 -17.277927 -17.345013
0:  -17.329554 -17.418848 -17.535498 -17.664753 -17.821358 -17.990097
0:  -18.103083 -18.190275 -18.20849  -18.199806 -18.172386 -18.034298
0:  -18.488482 -18.527983]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.5657015 -4.416561  -4.2475796 -4.079706  -3.9639091 -3.9400368
0:  -3.9568243 -4.0354977 -4.048424  -3.9813223 -3.811264  -3.630046
0:  -3.4782343 -3.352332  -3.3268747 -3.2853642 -3.1766872 -3.0300465
0:  -3.212265  -2.8427668]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.841989 16.105927 16.380741 16.689198 17.001423 17.303064 17.61464
0:  17.858719 18.121088 18.402084 18.67081  18.932404 19.20533  19.481606
0:  19.784088 20.103676 20.434788 20.77185  20.689075 20.972218]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [35.920685 35.72044  35.48206  35.165295 34.80343  34.357445 33.89923
0:  33.353767 32.87745  32.40411  31.94634  31.51366  31.108692 30.758827
0:  30.35073  29.938019 29.483994 28.929932 28.721329 28.551064]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.6476574   0.58063793  0.53650045  0.5139775   0.478642    0.40625572
0:   0.2960472   0.12140226 -0.08157682 -0.30398512 -0.54562616 -0.7850957
0:  -1.0092893  -1.2046809  -1.4145169  -1.6043086  -1.786037   -1.9169135
0:  -1.8695493  -1.9926019 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.871191 20.111256 20.342255 20.464294 20.467821 20.350391 20.105314
0:  19.675037 19.156256 18.504898 17.74502  16.89119  16.04078  15.227768
0:  14.466442 13.80325  13.252842 12.822657 12.256645 11.910009]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.685827 25.824984 25.986422 26.166107 26.384562 26.636873 26.970566
0:  27.284636 27.673012 28.062265 28.413221 28.767286 29.115477 29.457859
0:  29.762857 30.034534 30.282534 30.381186 30.065393 30.108496]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-15.117457  -15.260119  -15.270844  -15.158158  -15.006433  -14.933097
0:  -14.838645  -14.849174  -14.865256  -14.854634  -14.819638  -14.792176
0:  -14.70852   -14.6204195 -14.503982  -14.3225355 -14.116555  -13.835395
0:  -13.952619  -13.871472 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.0553086   2.6486845   2.2124772   1.7882605   1.4000978   1.0186553
0:   0.6536236   0.2886691  -0.05869007 -0.35907125 -0.63185835 -0.9198642
0:  -1.2120175  -1.5050902  -1.8014703  -2.0423598  -2.2111678  -2.2877336
0:  -2.9213567  -3.0833707 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.069653 10.940666 10.894846 10.894079 10.912956 10.930086 10.971079
0:  10.982223 11.032787 11.05164  11.018317 10.884092 10.7106   10.503662
0:  10.257435 10.03071   9.7901    9.572362  9.558669  9.234049]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.9606223 -2.0295587 -2.1026835 -2.1845431 -2.2523475 -2.3360353
0:  -2.3790765 -2.4312654 -2.4772553 -2.499845  -2.50987   -2.5426126
0:  -2.5814824 -2.6075997 -2.6585383 -2.6698756 -2.6521506 -2.5848699
0:  -2.7068505 -2.688768 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.624878 22.330101 22.271145 22.391615 22.610071 22.804684 22.948381
0:  22.93994  22.945604 22.843828 22.645607 22.431368 22.1818   21.933802
0:  21.699907 21.45939  21.250544 21.024902 21.672602 21.324873]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.1348877 1.3339725 1.5474706 1.7579525 1.9804122 2.188171  2.4275193
0:  2.645561  2.8949313 3.1858442 3.500668  3.7537928 3.94706   4.0484333
0:  3.9892337 3.8758054 3.7467313 3.6406024 3.0905216 3.0393994]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.9195218 -1.8965163 -1.8918843 -1.9621463 -2.1075692 -2.3615155
0:  -2.6356282 -2.9921842 -3.304933  -3.5679774 -3.7532086 -3.888227
0:  -3.9754786 -3.9732919 -3.9783673 -3.9360642 -3.8684916 -3.765862
0:  -4.035809  -4.0402436]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.5001845  4.200773   5.075965   6.0677013  7.0435596  7.9980516
0:   8.897444   9.68398   10.357699  10.969691  11.481337  11.885894
0:  12.266298  12.590872  12.924202  13.257576  13.608456  13.943283
0:  13.944251  14.457823 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.3553119 1.3020344 1.2152405 1.1487865 1.1043997 1.0670209 1.081768
0:  1.0972328 1.1762476 1.3027163 1.4616385 1.5874176 1.6839166 1.7360845
0:  1.6898489 1.6304908 1.5906606 1.5506568 1.1733799 1.3042068]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.551281  7.4742837 7.440169  7.4052396 7.379334  7.3415174 7.3149624
0:  7.3006606 7.3209577 7.396741  7.49929   7.596993  7.6834607 7.743827
0:  7.746312  7.7164984 7.691602  7.645545  6.293451  6.1311197]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.3655767 4.3940277 4.408044  4.4119625 4.42457   4.3973775 4.3907895
0:  4.3439016 4.3141203 4.290955  4.277648  4.2316093 4.1762834 4.1256733
0:  4.0488577 4.010808  3.9952767 4.023918  3.6201744 3.6078768]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.534088  15.239439  15.047794  14.893127  14.812662  14.724582
0:  14.577942  14.297089  13.92227   13.41075   12.809769  12.141418
0:  11.49337   10.887449  10.367231   9.929105   9.537182   9.181929
0:   7.6807637  7.4665585]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [36.412975 36.758358 36.93927  36.889763 36.72345  36.399666 35.94134
0:  35.31157  34.575733 33.726814 32.80658  31.842983 30.919939 30.021397
0:  29.12781  28.325697 27.660849 27.120115 26.587294 26.462963]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.0275893   2.805879    2.5512795   2.3322062   2.0797725   1.827465
0:   1.6015267   1.3560677   1.1547637   0.9854288   0.81867933  0.6720705
0:   0.56430435  0.48079538  0.42668915  0.35469532  0.26592922  0.20648861
0:   0.07111979 -0.13335991]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.159719   7.849465   8.518623   9.181868   9.792428  10.28087
0:  10.771949  11.097531  11.412657  11.7208805 12.070122  12.521553
0:  13.064747  13.695271  14.233961  14.631141  14.851428  14.970882
0:  14.300973  14.661299 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-13.81897   -13.6713295 -13.48513   -13.154829  -12.671543  -12.117628
0:  -11.369263  -10.5980835  -9.761122   -8.866381   -7.901504   -6.9511933
0:   -5.938906   -4.9512925  -4.00423    -3.1441483  -2.3773503  -1.7234468
0:   -1.7324219  -1.2792768]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.2935424 6.28567   6.358011  6.490611  6.6601586 6.8547907 7.0332465
0:  7.1769094 7.345111  7.4961863 7.6795034 7.8397226 8.011843  8.1719885
0:  8.317394  8.445905  8.563691  8.682456  8.786972  9.047556 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.1315441 1.6177392 2.1674469 2.6489463 2.9925601 3.158009  3.225983
0:  3.249632  3.3643236 3.5345936 3.7167144 3.7334943 3.579966  3.3306208
0:  3.0475264 2.989817  3.2283816 3.6697564 4.6634765 5.7483053]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.33183  19.494272 19.633638 19.740503 19.813974 19.841208 19.888142
0:  19.823671 19.776056 19.667177 19.514175 19.32503  19.146698 19.025013
0:  18.91664  18.88906  18.91208  18.995447 18.927704 19.421377]
0: validation loss for strategy=forecast at epoch 7 : nan
0: validation loss for velocity_u : 0.03266477584838867
0: validation loss for velocity_v : 0.060036953538656235
0: validation loss for specific_humidity : 0.02355690859258175
0: validation loss for velocity_z : 0.47549939155578613
0: validation loss for temperature : 0.0713343694806099
0: validation loss for total_precip : nan
0: 8 : 10:18:25 :: batch_size = 96, lr = 1.7245937319210094e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 8, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.7577, -0.7144, -0.6689, -0.6249, -0.5943, -0.5600, -0.5279, -0.4804, -0.4287, -0.3756, -0.3071, -0.2511,
0:         -0.1629, -0.0924, -0.0365,  0.0261, -0.0517, -0.0945, -0.7288, -0.6857, -0.6449, -0.6043, -0.5807, -0.5539,
0:         -0.5238], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.3779, 1.4302, 1.4709, 1.5142, 1.5484, 1.5883, 1.6184, 1.6544, 1.6882, 1.7170, 1.7471, 1.7460, 1.7411, 1.6899,
0:         1.6037, 1.5258, 1.3708, 1.3019, 1.3998, 1.4579, 1.4940, 1.5360, 1.5693, 1.6086, 1.6399], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.5071, -0.5057, -0.5084, -0.5085, -0.5150, -0.5242, -0.5350, -0.5477, -0.5613, -0.5795, -0.5994, -0.6128,
0:         -0.6135, -0.6088, -0.5762, -0.5448, -0.3105, -0.0927, -0.4993, -0.4938, -0.4975, -0.4978, -0.5053, -0.5171,
0:         -0.5317], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.1242,  0.0276, -0.0375, -0.0689, -0.0937, -0.1812, -0.2419, -0.0802,  0.1018,  0.2769,  0.3353,  0.1961,
0:         -0.0308, -0.2015, -0.2441, -0.1431,  0.4117,  0.8295,  0.3443,  0.2096,  0.1669,  0.1961,  0.1691,  0.0928,
0:          0.0074], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([ 0.9741,  0.9271,  0.8861,  0.8487,  0.8155,  0.7972,  0.7849,  0.7904,  0.8081,  0.8286,  0.8514,  0.8234,
0:          0.7588,  0.5716,  0.1862, -0.2557, -0.7154, -0.9830, -1.0308, -1.2075, -1.3679, -1.5521, -1.9477, -2.1237,
0:         -2.1106], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 8, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan, -0.0708,     nan, -0.1640,     nan,     nan,     nan, -0.2095,
0:             nan,     nan,  0.0214,     nan,     nan, -0.1967,     nan,     nan,     nan,     nan,     nan,     nan,
0:          0.0983,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0358,     nan,  0.0913,
0:          0.0622,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1174,     nan,
0:             nan,     nan,     nan, -0.1757,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.1092,     nan, -0.1489, -0.1407, -0.1349,     nan, -0.1932,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  0.0097, -0.0078,
0:             nan,     nan,     nan, -0.1780,     nan,     nan,     nan,     nan,     nan,     nan, -0.0183,     nan,
0:             nan,     nan, -0.1839,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.0789,     nan,  0.0132,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.0789,     nan,     nan,     nan,     nan, -0.1442,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2002, -0.0311,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2025,     nan, -0.0661,  0.0598,     nan,     nan,
0:             nan,     nan, -0.0101,     nan,     nan,     nan,  0.4225,     nan,     nan,     nan,     nan,     nan,
0:         -0.0381,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,  0.0738,     nan,     nan,     nan,     nan, -0.0183,     nan,     nan,  0.0668,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.1291,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 8, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-1.6328, -1.6617, -1.6854, -1.6974, -1.7016, -1.6978, -1.6879, -1.6797, -1.6729, -1.6677, -1.6601, -1.6547,
0:         -1.6487, -1.6381, -1.6271, -1.6177, -1.6085, -1.6005, -1.6231, -1.6568, -1.6899, -1.7054, -1.7113, -1.7071,
0:         -1.6953], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.8327, 0.8450, 0.8522, 0.8567, 0.8644, 0.8807, 0.9045, 0.9384, 0.9812, 1.0314, 1.0822, 1.1350, 1.1807, 1.2200,
0:         1.2492, 1.2754, 1.2969, 1.3125, 0.8047, 0.8203, 0.8288, 0.8396, 0.8514, 0.8695, 0.8918], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([ 2.6890e-01,  2.2498e-01,  1.6867e-01,  1.1621e-01,  5.6980e-02, -2.2994e-03, -6.3454e-02, -1.1407e-01,
0:         -1.6810e-01, -2.1640e-01, -2.6441e-01, -3.1052e-01, -3.5495e-01, -4.0279e-01, -4.4816e-01, -4.9096e-01,
0:         -5.3242e-01, -5.7038e-01,  2.9296e-01,  2.5013e-01,  2.0716e-01,  1.6013e-01,  1.1005e-01,  5.4824e-02,
0:          4.2172e-04], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.9090, 0.8378, 0.6952, 0.5063, 0.3464, 0.2536, 0.2139, 0.2057, 0.2623, 0.3682, 0.4480, 0.5474, 0.5923, 0.5574,
0:         0.5568, 0.5812, 0.6410, 0.6878, 0.8557, 0.8038, 0.6874, 0.5252, 0.3953, 0.2923, 0.2264], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([-0.1998, -0.1874, -0.1591, -0.1205, -0.0731, -0.0241,  0.0264,  0.0693,  0.1041,  0.1317,  0.1536,  0.1702,
0:          0.1800,  0.1812,  0.1685,  0.1409,  0.0931,  0.0190, -0.0911, -0.2456, -0.4438, -0.6699, -0.8977, -1.1037,
0:         -1.2688], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.06363420933485031; velocity_v: 0.09396413713693619; specific_humidity: 0.0446225181221962; velocity_z: 0.4375355541706085; temperature: 0.14005622267723083; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.053374603390693665; velocity_v: 0.08629829436540604; specific_humidity: 0.037433478981256485; velocity_z: 0.4520237445831299; temperature: 0.0875735878944397; total_precip: nan; 
0: epoch: 8 [1/5 (20%)]	Loss: nan : nan :: 0.14171 (2.46 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05319037288427353; velocity_v: 0.09061585366725922; specific_humidity: 0.03315278887748718; velocity_z: 0.4479372203350067; temperature: 0.07542790472507477; total_precip: nan; 
0: epoch: 8 [2/5 (40%)]	Loss: nan : nan :: 0.13980 (16.10 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05132094398140907; velocity_v: 0.09328766167163849; specific_humidity: 0.035776033997535706; velocity_z: 0.4797576665878296; temperature: 0.09810275584459305; total_precip: nan; 
0: epoch: 8 [3/5 (60%)]	Loss: nan : nan :: 0.13633 (16.20 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06671667098999023; velocity_v: 0.09732041507959366; specific_humidity: 0.04009987413883209; velocity_z: 0.5182041525840759; temperature: 0.11496688425540924; total_precip: nan; 
0: epoch: 8 [4/5 (80%)]	Loss: nan : nan :: 0.15822 (16.23 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [2.33173370e-04 2.24113464e-04 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  1.90734863e-06 4.10079956e-05 3.08036804e-04 3.20434541e-04
0:  1.02996826e-04 7.24792480e-05 6.05583191e-05 8.29696655e-05
0:  1.36852264e-04 7.53402710e-05 2.47955322e-05 2.47955322e-05
0:  3.05175781e-05 1.43051147e-05 1.52587891e-05 2.47955322e-05
0:  2.62260437e-05 2.71797180e-05 4.52995300e-05 4.00543213e-05
0:  1.64508820e-04 2.21729279e-04 1.15871429e-04 7.58171082e-05
0:  2.33650208e-05 6.19888306e-06 9.53674316e-06 1.90734863e-05
0:  6.34193420e-05 9.20295715e-05 1.53541565e-04 2.48432159e-04
0:  2.07424164e-04 1.46389008e-04 1.16348267e-04 1.45912170e-04
0:  8.67843628e-05 8.15391541e-05 1.00612640e-04 8.86917114e-05
0:  3.19480896e-05 4.05311584e-05 2.47955322e-05 1.71661377e-05
0:  6.67572021e-06 6.67572021e-06 4.29153442e-06 1.90734863e-06
0:  1.43051147e-06 2.38418579e-06 1.33514404e-05 1.52587891e-04
0:  2.86579132e-04 1.03473663e-04 8.53538513e-05 8.53538513e-05
0:  1.04904175e-04 1.44481659e-04 1.51157379e-04 1.10626221e-04
0:  1.09672546e-04 1.62124634e-04 9.20295715e-05 5.05447388e-05
0:  2.19345093e-05 1.19209290e-05 3.14712524e-05 5.24520874e-05
0:  6.38961792e-05 7.62939453e-05 1.37805939e-04 1.12533569e-04
0:  4.95910645e-05 3.76701355e-05 5.19752502e-05 8.20159912e-05
0:  1.16825104e-04 1.10149384e-04 3.05175781e-05 2.09808350e-05
0:  1.33514404e-05 4.29153442e-06 0.00000000e+00 0.00000000e+00
0:  9.53674316e-07 1.90734863e-06 8.10623169e-06 1.23977661e-05
0:  2.86102295e-06 0.00000000e+00 0.00000000e+00 2.38418579e-06
0:  2.38418579e-06 2.45571136e-04 3.13281984e-04 2.26497650e-04
0:  1.24454498e-04 2.22682953e-04 1.64508820e-04 9.63211060e-05
0:  9.53674316e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  9.53674316e-07 1.81198120e-05 2.79903412e-04 6.31332397e-04
0:  4.27246094e-04 1.02043152e-04 1.11579895e-04 1.10626221e-04
0:  1.54018402e-04 8.77380371e-05 4.91142273e-05 4.86373865e-05
0:  7.53402710e-05 6.05583191e-05 3.86238098e-05 3.71932983e-05
0:  2.47955322e-05 5.19752502e-05 7.67707825e-05 1.44004822e-04
0:  2.66075134e-04 2.37464905e-04 1.32083893e-04 7.10487366e-05
0:  3.33786011e-05 1.19209290e-05 2.00271606e-05 2.52723694e-05
0:  3.52859497e-05 6.43730164e-05 1.03950500e-04 1.96933746e-04
0:  2.07424164e-04 1.63555145e-04 1.20162964e-04 1.69754028e-04
0:  1.12056732e-04 1.06811523e-04 1.24931335e-04 1.08242035e-04
0:  5.24520874e-05 3.71932983e-05 1.90734863e-05 2.52723694e-05
0:  2.38418579e-05 1.71661377e-05 5.24520874e-06 2.86102295e-06
0:  3.33786011e-06 4.29153442e-06 3.81469727e-05 1.95980072e-04
0:  4.57286835e-04 1.76906586e-04 1.21116638e-04 1.14917755e-04
0:  1.33514404e-04 1.02519989e-04 1.08242035e-04 1.32083893e-04
0:  1.56402588e-04 1.73568726e-04 7.15255737e-05 3.52859497e-05
0:  1.85966492e-05 8.58306885e-06 4.24385034e-05 6.38961792e-05
0:  7.86781311e-05 9.87052917e-05 1.43051147e-04 1.47819519e-04
0:  7.58171082e-05 4.91142273e-05 6.34193420e-05 6.15119934e-05
0:  9.53674316e-05 1.05381012e-04 3.05175781e-05 2.05039978e-05
0:  9.53674316e-06 2.38418579e-06 0.00000000e+00 0.00000000e+00]
0: Target values (first 200):
0: [8.48770142e-05 3.81469727e-06 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  9.53674316e-07 3.91006470e-05 1.32560730e-04 1.49726868e-04
0:  1.83105469e-04 2.01225281e-04 1.23023987e-04 1.02996826e-04
0:  5.81741333e-05 1.52587891e-05 1.52587891e-05 2.95639038e-05
0:  2.76565552e-05 2.28881836e-05 1.43051147e-05 9.53674316e-06
0:  6.67572021e-06 4.76837158e-06 1.14440918e-05 7.62939453e-06
0:  4.76837158e-06 9.53674316e-07 9.53674316e-07 1.90734863e-06
0:  1.90734863e-06 2.86102295e-06 4.76837158e-06 6.67572021e-06
0:  6.67572021e-06 2.57492065e-05 3.24249268e-05 2.00271606e-05
0:  7.62939453e-06 2.86102295e-06 9.53674316e-07 0.00000000e+00
0:  0.00000000e+00 9.53674316e-07 1.90734863e-06 1.90734863e-06
0:  3.81469727e-06 2.86102295e-06 5.72204590e-06 4.76837158e-06
0:  9.53674316e-07 0.00000000e+00 0.00000000e+00 9.53674316e-07
0:  2.86102295e-06 1.52587891e-05 3.14712524e-05 9.44137573e-05
0:  1.56402588e-04 1.99317932e-04 1.53541565e-04 1.19209290e-04
0:  1.05857849e-04 1.94549561e-04 2.38418579e-04 1.27792358e-04
0:  1.52587891e-04 1.64985657e-04 2.47955322e-04 2.47955322e-04
0:  2.17437744e-04 1.50680542e-04 1.09672546e-04 4.67300415e-05
0:  4.38690222e-05 1.59263611e-04 1.01089478e-04 1.04904175e-05
0:  1.90734863e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  4.76837158e-06 8.58306885e-06 7.62939453e-06 1.81198120e-05
0:  4.76837158e-06 1.90734863e-06 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 6.67572021e-06 2.38418579e-05 4.67300415e-05
0:  2.47955322e-05 9.53674316e-06 1.90734863e-06 0.00000000e+00
0:  7.62939453e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  9.53674316e-07 3.81469727e-06 9.63211060e-05 1.46865845e-04
0:  1.81198120e-04 1.87873840e-04 1.35421753e-04 1.34468079e-04
0:  5.43594360e-05 1.33514404e-05 8.58306885e-06 2.28881836e-05
0:  9.05990601e-05 8.67843628e-05 1.90734863e-05 6.67572021e-06
0:  4.76837158e-06 4.76837158e-06 5.72204590e-06 2.86102295e-06
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  9.53674316e-07 9.53674316e-07 1.43051147e-05 1.62124634e-05
0:  7.82012939e-05 9.53674316e-05 4.86373865e-05 3.52859497e-05
0:  7.62939453e-06 9.53674316e-07 9.53674316e-07 9.53674316e-07
0:  1.90734863e-06 2.86102295e-06 3.81469727e-06 2.86102295e-06
0:  4.76837158e-06 3.81469727e-06 5.72204590e-06 5.72204590e-06
0:  9.53674316e-07 9.53674316e-07 2.86102295e-06 2.86102295e-06
0:  5.72204590e-06 1.81198120e-05 4.86373865e-05 1.22070312e-04
0:  1.48773193e-04 1.32560730e-04 6.38961792e-05 6.96182251e-05
0:  5.72204590e-05 6.19888306e-05 1.04904175e-04 9.72747803e-05
0:  1.53541565e-04 1.38282776e-04 1.75476074e-04 1.85012817e-04
0:  1.49726868e-04 8.29696655e-05 1.41143799e-04 8.01086426e-05
0:  2.47955322e-05 1.35421753e-04 2.38418579e-05 7.62939453e-06
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  4.76837158e-06 7.62939453e-06 6.67572021e-06 1.14440918e-05
0:  2.86102295e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00]
0: Prediction values (first 20):
0: [-6.576981  -6.61968   -6.669351  -6.722261  -6.7589726 -6.7989297
0:  -6.824964  -6.8920283 -6.9643044 -7.0141625 -7.0226426 -7.0249925
0:  -7.0099387 -6.9672904 -6.953054  -6.9399867 -6.9605136 -6.952392
0:  -7.530318  -7.5555167]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -1.940, max = 1.212, mean = -0.702
0:          sample (first 20): tensor([-1.1252, -1.1288, -1.1330, -1.1374, -1.1405, -1.1439, -1.1461, -1.1518, -1.1579, -1.1621, -1.1629, -1.1631,
0:         -1.1618, -1.1582, -1.1570, -1.1559, -1.1576, -1.1569, -1.1497, -1.1519])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.953213  12.981346  13.054326  13.121299  13.194685  13.242212
0:  13.273396  13.271807  13.271294  13.260904  13.236467  13.177455
0:  13.101059  13.000139  12.8677435 12.72802   12.610054  12.520142
0:  12.191032  12.045532 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.377274  11.384327  11.41357   11.451485  11.435612  11.364517
0:  11.298727  11.155504  11.054163  10.970172  10.873056  10.823127
0:  10.828907  10.878433  11.015261  11.1806755 11.368415  11.575972
0:  11.76604   12.023695 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.614943  14.577921  14.574626  14.657021  14.8611355 15.19907
0:  15.706203  16.29991   17.031963  17.850668  18.799099  19.861351
0:  20.992834  22.17718   23.245817  24.107693  24.798574  25.281942
0:  25.824284  26.445852 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.53907204 -0.5446758  -0.54573107 -0.5628996  -0.59388447 -0.67162657
0:  -0.72511816 -0.8052139  -0.8453002  -0.842731   -0.80386686 -0.77557755
0:  -0.7397442  -0.66204643 -0.6027379  -0.49384975 -0.365036   -0.20914316
0:  -0.04996634  0.10375023]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.906104  -7.64478   -7.2816086 -6.7409506 -6.0916014 -5.4663677
0:  -4.782447  -4.2697544 -3.7711983 -3.3800058 -3.1030989 -2.9681349
0:  -2.8916092 -2.7975426 -2.7399778 -2.6002264 -2.4930897 -2.4041996
0:  -2.8665037 -2.3444662]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.9717755 -6.8372197 -6.6393323 -6.4402575 -6.269176  -6.1965623
0:  -6.1738086 -6.2492824 -6.3599467 -6.4900174 -6.590942  -6.6631904
0:  -6.681394  -6.624355  -6.561133  -6.4708524 -6.3796906 -6.283382
0:  -6.576484  -6.603666 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.377247 20.866081 21.370785 21.78928  22.072855 22.255316 22.341564
0:  22.292135 22.191256 22.018955 21.793594 21.491571 21.176184 20.85813
0:  20.560331 20.325022 20.17844  20.130606 19.881098 19.608658]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.266087 23.691584 24.114714 24.530294 24.974691 25.478785 26.017244
0:  26.51479  26.995718 27.4569   27.88484  28.234968 28.584229 28.840273
0:  29.087973 29.293058 29.56057  29.790766 29.073124 29.153685]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.4033127 2.5844297 2.6923628 2.7644396 2.8971457 3.0742273 3.3765328
0:  3.703518  4.124613  4.5718145 5.0037775 5.383436  5.693419  5.9778404
0:  6.184075  6.3727183 6.5484505 6.6807036 6.3186436 6.1316166]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.22691774 -0.09837008  0.02386475  0.11577463  0.23578358  0.3350587
0:   0.49693346  0.6495042   0.8174181   0.9901829   1.170362    1.2952294
0:   1.4246454   1.506331    1.6106277   1.7359605   1.856935    1.9444976
0:   2.8144934   3.018024  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.32353  33.2355   33.068817 32.796925 32.471485 32.083733 31.678724
0:  31.147905 30.685791 30.273844 29.911146 29.680586 29.611782 29.671358
0:  29.838053 30.02665  30.203974 30.303947 29.673288 29.546612]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.43761  14.230149 14.124231 14.054612 14.053413 14.099704 14.246393
0:  14.337496 14.528856 14.708233 14.863645 15.015712 15.170945 15.337261
0:  15.529974 15.756514 15.977991 16.207504 16.02612  16.074064]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -6.7359996  -7.122579   -7.5096736  -7.868832   -8.179159   -8.492651
0:   -8.810413   -9.171333   -9.525677   -9.849312  -10.125832  -10.400824
0:  -10.631636  -10.801804  -10.938431  -10.973742  -10.889227  -10.69939
0:  -10.833746  -10.618652 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.0595026 5.264366  5.4992223 5.7189145 5.9443035 6.1020365 6.211558
0:  6.2393036 6.206408  6.1341753 6.0506973 5.9213543 5.7906976 5.6714964
0:  5.5339346 5.4334426 5.35479   5.3014774 4.852338  4.8773985]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.591043 21.359577 21.016254 20.5857   20.129923 19.708462 19.342712
0:  18.963081 18.657507 18.396345 18.162823 17.959026 17.7992   17.622803
0:  17.478807 17.33702  17.24016  17.201393 17.216343 17.222847]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.7800994 -7.684624  -7.5375648 -7.308927  -6.968596  -6.5765023
0:  -6.1115355 -5.6645465 -5.202125  -4.696832  -4.112946  -3.5492988
0:  -3.052402  -2.6579652 -2.4981046 -2.4616685 -2.4666276 -2.451922
0:  -2.8351321 -2.8084455]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.69515276 0.9593768  1.2717581  1.6401105  2.0647216  2.512511
0:  2.998048   3.4824955  3.9729743  4.456176   4.918121   5.3315015
0:  5.7079043  6.0073056  6.2345138  6.3911924  6.5055346  6.5998893
0:  5.7740254  5.900271  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.212452 26.961845 26.827057 26.719723 26.640003 26.531418 26.436615
0:  26.22844  26.026966 25.784096 25.393528 24.981339 24.603916 24.268776
0:  23.998726 23.79945  23.627003 23.455112 23.541927 23.457642]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.974856  -4.860824  -4.785234  -4.704641  -4.6506505 -4.647268
0:  -4.6213956 -4.6435533 -4.664842  -4.6355453 -4.5931077 -4.550154
0:  -4.4908404 -4.370053  -4.2189946 -4.0267396 -3.832994  -3.6332974
0:  -4.508826  -4.5841327]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.003714 15.253141 15.526016 15.766407 15.96615  16.126236 16.290836
0:  16.387915 16.476562 16.564337 16.630548 16.68107  16.735493 16.788137
0:  16.85488  16.956913 17.08646  17.297344 17.331097 17.450201]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.74245596 -0.72271776 -0.6828451  -0.7024379  -0.81549644 -1.0934095
0:  -1.4993944  -2.066514   -2.7146444  -3.3660908  -3.9608498  -4.514785
0:  -4.977516   -5.336729   -5.6513643  -5.854748   -5.997815   -6.0866003
0:  -6.496358   -6.616725  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.410958  9.05333   8.73168   8.438837  8.1685    7.9297447 7.7835903
0:  7.6459618 7.6146774 7.634267  7.6671367 7.7398677 7.8443213 7.964724
0:  8.111041  8.239046  8.353299  8.449797  8.497303  8.58671  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.9914665 -3.2743587 -3.5550718 -3.787469  -3.9761152 -4.142996
0:  -4.258816  -4.344509  -4.3749924 -4.352208  -4.306033  -4.296893
0:  -4.3109655 -4.3703165 -4.473691  -4.5691795 -4.644702  -4.6839733
0:  -5.2025967 -5.256607 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.0494599 -1.3707194 -1.716661  -2.073048  -2.3850303 -2.65484
0:  -2.875176  -3.0705924 -3.2276587 -3.4124799 -3.6485476 -3.9718614
0:  -4.3325906 -4.633488  -4.890281  -5.015119  -5.0166535 -4.948055
0:  -4.7676816 -4.9121175]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.543459 25.340866 25.078897 24.760366 24.446249 24.150541 23.88722
0:  23.678892 23.56608  23.560883 23.61434  23.658386 23.67154  23.652056
0:  23.576826 23.484613 23.457294 23.50423  23.36893  23.359001]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.104702 27.105286 27.034351 26.917595 26.796755 26.759438 26.82784
0:  26.95631  27.204073 27.522028 27.840015 28.135017 28.357826 28.477936
0:  28.501797 28.392769 28.22514  28.011753 27.529247 27.62357 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [38.197735 38.26184  38.31655  38.218758 38.055298 37.787884 37.367695
0:  36.808502 36.13912  35.399357 34.596222 33.756523 32.954517 32.213097
0:  31.499912 30.920738 30.511541 30.236383 30.728199 30.248524]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.512406  11.218912  10.978568  10.744731  10.517638  10.247366
0:   9.9484005  9.544363   9.101652   8.545179   7.9250493  7.2426057
0:   6.566724   5.9070024  5.2925105  4.74932    4.261572   3.884185
0:   3.3271213  3.1678476]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.921507  9.963953 10.025954 10.056927 10.049923  9.974512  9.868721
0:   9.725038  9.584223  9.488311  9.444773  9.459734  9.55351   9.719399
0:   9.925813 10.161517 10.395875 10.597803 10.269284 10.075907]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.807346  -8.541372  -8.365486  -8.228966  -8.095732  -7.9916787
0:  -7.7762685 -7.585015  -7.379309  -7.2080026 -7.102773  -7.0222964
0:  -6.8723636 -6.7289996 -6.6432366 -6.650535  -6.7497373 -6.990701
0:  -7.220361  -6.903897 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.5310693 -2.4553533 -2.346681  -2.2217746 -2.129559  -2.1021934
0:  -2.093821  -2.153191  -2.2060199 -2.2692456 -2.3445067 -2.4733796
0:  -2.6577668 -2.9109445 -3.2613635 -3.6496472 -4.0287433 -4.340574
0:  -5.321028  -5.5058312]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.628454 -9.446833 -9.222904 -8.998608 -8.823238 -8.732256 -8.672289
0:  -8.688499 -8.702843 -8.716875 -8.715336 -8.718231 -8.704567 -8.634846
0:  -8.580643 -8.483971 -8.380859 -8.272366 -8.719025 -8.793451]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.6650352  5.590437   5.454813   5.3295426  5.1924934  5.03191
0:   4.9044995  4.7195797  4.6190166  4.606916   4.6874084  4.881934
0:   5.1961145  5.6333933  6.148302   6.719879   7.3700247  8.073337
0:   9.67607   10.631259 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.7925239  -1.4449143  -1.0081983  -0.55580044 -0.13749552  0.16198826
0:   0.3104143   0.20721388 -0.1028595  -0.6279421  -1.2598066  -1.9233742
0:  -2.4567418  -2.7390218  -2.8001695  -2.602304   -2.2621293  -1.8552566
0:  -1.5000525  -1.3975792 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.7386284 -6.63455   -6.4562435 -6.290617  -6.1384573 -6.028947
0:  -5.904252  -5.7978487 -5.6554804 -5.4875994 -5.3185606 -5.2207203
0:  -5.1903753 -5.20782   -5.3176575 -5.4045515 -5.464325  -5.473979
0:  -5.994194  -5.991996 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [45.15814  45.36234  45.297493 44.865658 44.09671  43.147533 42.285027
0:  41.44464  40.891773 40.433434 39.982265 39.426083 38.894405 38.408512
0:  37.924    37.528717 37.12485  36.549267 36.862545 36.123074]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.719727 12.768538 12.833808 12.868805 12.887024 12.885887 12.903341
0:  12.886047 12.913452 12.943388 12.969519 12.968742 12.957079 12.920362
0:  12.865458 12.82887  12.820814 12.843517 12.732044 12.764971]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.23308468 0.23258781 0.36532784 0.62456226 0.90912914 1.1840353
0:  1.4330602  1.5889568  1.7593956  1.9431453  2.1473846  2.3133793
0:  2.57373    2.8376875  3.1158571  3.43894    3.7646363  4.11924
0:  4.4115534  4.758647  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.6146369  0.76998377 1.0607052  1.4388366  1.8787842  2.343214
0:  2.7770414  3.1355858  3.3665903  3.496114   3.562953   3.5619562
0:  3.586914   3.600847   3.6390362  3.7066283  3.7970138  3.9449418
0:  3.7307491  3.771282  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.902159 21.094805 21.379059 21.694162 22.017742 22.368328 22.70391
0:  22.995848 23.325365 23.660341 23.990358 24.289703 24.604282 24.886723
0:  25.164835 25.398224 25.657455 25.963316 26.042171 26.444677]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [36.095562 35.701923 35.107273 34.21552  33.158623 31.948914 30.782154
0:  29.55695  28.497654 27.598553 26.842777 26.311214 25.98774  25.819489
0:  25.779282 25.793129 25.714329 25.541714 23.991238 23.925053]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.5236692 6.1161823 5.8950315 5.794961  5.743099  5.683424  5.6275935
0:  5.5055795 5.424986  5.320757  5.2046895 5.0986185 5.0491896 4.981954
0:  4.9842424 4.955721  4.9367723 4.921275  4.610839  4.1225276]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.550196  9.300976  8.93144   8.470294  8.032415  7.6474185 7.4109006
0:  7.2795753 7.306683  7.4609504 7.6722713 7.8930507 8.086538  8.172149
0:  8.143891  8.057902  7.9039288 7.7077727 6.8420496 6.4170027]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.2035341 3.3548934 3.5019526 3.761492  4.066453  4.3304925 4.587494
0:  4.7395844 4.848339  4.931159  5.0176105 5.1345506 5.278127  5.417666
0:  5.5419335 5.666829  5.770315  5.90764   5.1998286 5.320983 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.571966 15.753145 15.998219 16.27282  16.524427 16.763874 17.056057
0:  17.284199 17.569134 17.855043 18.0715   18.242764 18.41783  18.548765
0:  18.685368 18.794628 18.88888  18.950996 18.576742 18.694674]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [32.39995  32.55448  32.742958 33.01619  33.322464 33.62366  33.972378
0:  34.11656  34.31032  34.406284 34.44712  34.45535  34.458786 34.540302
0:  34.623325 34.759987 34.864597 34.93166  35.051617 34.907898]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.030197  11.069693  11.1172085 11.15522   11.19299   11.219461
0:  11.247636  11.228912  11.24542   11.257033  11.300699  11.339888
0:  11.382151  11.416941  11.434894  11.455253  11.46675   11.478994
0:  11.28537   11.305917 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.893604 34.06441  34.0609   33.88672  33.546207 33.108677 32.668053
0:  32.20487  31.859589 31.70742  31.650425 31.704475 31.815216 31.879282
0:  31.836975 31.69164  31.480927 31.189486 30.495203 30.19328 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.457618  11.520069  11.617874  11.701127  11.782375  11.865995
0:  11.949066  11.989504  12.0560255 12.118651  12.213167  12.280333
0:  12.3547    12.440704  12.486332  12.549812  12.607601  12.676151
0:  12.5549    12.614252 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.7396708 7.7695947 7.845419  7.8598156 7.80896   7.646286  7.4718275
0:  7.219081  6.9636097 6.705749  6.43213   6.116011  5.759159  5.4282093
0:  5.0248885 4.6447077 4.2740936 3.9330428 2.8319635 2.3512092]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.150047  5.2602124 5.361722  5.4623623 5.5786695 5.6752105 5.8334126
0:  5.9717565 6.13326   6.2981486 6.433534  6.5506144 6.6239653 6.7092843
0:  6.770691  6.8577223 6.9242024 6.9797487 7.206579  7.3231525]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.8739567 -6.6807823 -6.4885597 -6.393283  -6.4710417 -6.7370796
0:  -7.1439524 -7.6939993 -8.238315  -8.7219715 -9.064861  -9.273916
0:  -9.291322  -9.109466  -8.830201  -8.422743  -8.012031  -7.6293964
0:  -6.8200045 -6.1677885]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.571901 26.625088 26.6228   26.570557 26.529037 26.540546 26.549515
0:  26.536129 26.550163 26.666893 26.854134 27.07929  27.27894  27.372314
0:  27.312496 27.136326 26.954449 26.82766  25.663534 25.50099 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.677693  12.006077  12.317639  12.612094  12.895695  13.183456
0:  13.499353  13.78193   14.0803585 14.372389  14.659483  14.931412
0:  15.217094  15.502361  15.794542  16.079977  16.37389   16.651127
0:  16.517282  16.829071 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.954503  7.056501  7.1033764 7.110634  7.1316433 7.1308017 7.1007195
0:  7.0156507 6.885077  6.706219  6.4846396 6.2120132 5.914119  5.6289496
0:  5.352199  5.1373186 5.000742  4.9492545 5.0320716 4.8751383]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -9.674355   -9.684269   -9.657295   -9.613981   -9.509867   -9.378933
0:   -9.2239685  -9.194189   -9.246664   -9.380936   -9.583094   -9.794292
0:   -9.957735  -10.009356  -10.052666  -10.024136  -10.046959  -10.114269
0:  -10.782709  -10.769598 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.8240795 12.086697  12.416008  12.729998  13.048664  13.355849
0:  13.667965  13.975381  14.31699   14.689052  15.096668  15.50983
0:  15.931316  16.338093  16.729689  17.10015   17.46072   17.76917
0:  18.075983  18.239569 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.4059896 5.504228  5.6398063 5.7647157 5.875704  5.904473  5.880696
0:  5.7829833 5.6447053 5.5049233 5.3843355 5.248127  5.1436205 5.0860796
0:  5.022376  5.025303  5.0706224 5.174162  5.103904  5.1007895]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.3287501 -2.335691  -2.3467612 -2.384128  -2.452433  -2.6093793
0:  -2.8592105 -3.2385755 -3.6729484 -4.105744  -4.438084  -4.6771445
0:  -4.7668567 -4.710896  -4.6155972 -4.459473  -4.294337  -4.1517673
0:  -4.202995  -4.1281447]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.7752805 -6.798575  -6.8227725 -6.8007636 -6.753652  -6.7613454
0:  -6.7453237 -6.7646804 -6.7472014 -6.6150985 -6.4084897 -6.1308007
0:  -5.821588  -5.5214524 -5.262017  -5.0358834 -4.845676  -4.7062497
0:  -4.9580483 -4.77933  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.460222 19.784695 20.171146 20.559309 20.956787 21.356596 21.759726
0:  22.134842 22.531158 22.931932 23.330656 23.670689 23.993    24.274517
0:  24.511467 24.71613  24.89331  25.042715 24.72021  24.929794]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.879404 17.80641  17.757586 17.674171 17.557621 17.415756 17.272104
0:  17.062195 16.844099 16.614246 16.334892 16.045784 15.833469 15.666964
0:  15.559549 15.480415 15.433174 15.407648 15.214254 15.300545]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.1156058  -0.77156067 -0.41403627 -0.06485462  0.27277613  0.52688646
0:   0.77598476  0.9469199   1.1340547   1.3339696   1.534864    1.7243004
0:   1.9495583   2.1978354   2.434722    2.7013865   2.9612188   3.2055733
0:   2.5293703   2.7168093 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.95569944 -0.8801031  -0.79405737 -0.69980574 -0.61128426 -0.56371737
0:  -0.5380583  -0.5649147  -0.6192241  -0.6840267  -0.7578511  -0.87787914
0:  -1.0281329  -1.2127614  -1.4599252  -1.7047095  -1.8967996  -1.9975629
0:  -2.6932597  -2.570665  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.83091736 0.92434263 1.0348573  1.1398458  1.2368927  1.2687364
0:  1.2648697  1.1942153  1.0958467  0.98658943 0.87339497 0.74741745
0:  0.6284127  0.5369196  0.484612   0.51153374 0.59114695 0.72685385
0:  0.56443834 0.68265295]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.111626  13.830318  13.602653  13.396236  13.163708  12.905111
0:  12.678726  12.4404955 12.292917  12.115744  11.932167  11.733702
0:  11.537468  11.320531  11.048275  10.71312   10.28695    9.858604
0:   8.973457   8.795517 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.572781   -2.4782367  -2.3539948  -2.1736417  -1.9958053  -1.8628478
0:  -1.7102227  -1.6252799  -1.5483689  -1.4989028  -1.4592538  -1.4373212
0:  -1.3728824  -1.2930207  -1.16432    -1.0169392  -0.90672445 -0.7849779
0:  -0.8070359  -0.64168835]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-15.809136 -15.726615 -15.599242 -15.507289 -15.436868 -15.473443
0:  -15.551507 -15.753467 -16.011967 -16.26661  -16.514359 -16.757362
0:  -16.955189 -17.038307 -17.078423 -16.975136 -16.7495   -16.37392
0:  -16.378319 -15.953338]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.658072  1.6946063 1.7341628 1.7497087 1.7814207 1.7838655 1.7894044
0:  1.7596507 1.754169  1.7702565 1.8087454 1.8201442 1.8167396 1.8274279
0:  1.7981    1.822628  1.8717136 1.95223   1.7022877 1.7751555]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 6.764301  7.33812   8.043724  8.774722  9.508404 10.201982 10.890177
0:  11.527266 12.094591 12.578022 12.959209 13.227793 13.479816 13.76815
0:  14.098225 14.50452  14.964001 15.418951 16.126226 16.519234]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.906933 27.467144 26.980858 26.37193  25.627895 24.799793 24.009369
0:  23.139492 22.305214 21.467058 20.511028 19.492481 18.524384 17.635845
0:  16.878788 16.26015  15.733002 15.259506 15.3498   14.90283 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.999364  6.907781  6.9044566 6.932431  6.9871674 6.9988465 6.9314947
0:  6.758274  6.455662  5.966421  5.3587317 4.590394  3.8179917 3.1191936
0:  2.559721  2.2010782 2.024993  1.9740789 1.6835208 1.552104 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.088764 20.307924 20.474646 20.53722  20.508074 20.429186 20.355976
0:  20.234566 20.216    20.225534 20.200897 20.123957 19.984324 19.817087
0:  19.613558 19.524397 19.50104  19.45542  18.03002  18.41931 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [41.30749  41.133636 40.903004 40.576183 40.21368  39.866367 39.521538
0:  39.117184 38.825584 38.581604 38.341583 38.137527 38.001896 37.90494
0:  37.80517  37.670956 37.45717  37.0894   37.624416 37.238976]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.165089 18.653784 19.167624 19.685066 20.132933 20.47791  20.712982
0:  20.786222 20.748323 20.627321 20.412975 20.146109 19.856743 19.537676
0:  19.25217  18.959091 18.70439  18.524874 18.250322 18.143375]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.854948 27.210693 27.504358 27.78413  28.117523 28.479464 28.886858
0:  29.186085 29.44147  29.56345  29.562632 29.446007 29.282415 29.128096
0:  28.971151 28.898602 28.922438 29.062258 28.333124 28.34393 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.406283 15.73207  16.279566 16.984116 17.803156 18.614231 19.443932
0:  20.056278 20.585133 20.933434 21.115536 21.220945 21.282665 21.351204
0:  21.452908 21.531803 21.613918 21.668364 21.367664 21.640871]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -9.6775255  -9.793216   -9.9185095  -9.998443  -10.059493  -10.142102
0:  -10.247537  -10.454806  -10.667119  -10.867543  -10.994493  -11.047854
0:  -11.012301  -10.868657  -10.703919  -10.47067   -10.192445   -9.87503
0:   -9.561211   -9.25888  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.03566551 -0.0897584  -0.15502024 -0.22639179 -0.28877115 -0.3936987
0:  -0.4891715  -0.622942   -0.74175024 -0.8457627  -0.9318843  -1.0400691
0:  -1.1484332  -1.2249246  -1.3252816  -1.377686   -1.4025121  -1.3841901
0:  -1.4758859  -1.4190202 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.875706  3.9030104 3.907809  3.8976116 3.8668454 3.806478  3.7244375
0:  3.5934415 3.4694133 3.34869   3.2433262 3.1606114 3.1362255 3.1351745
0:  3.1506565 3.181704  3.230708  3.3043745 2.9403117 3.0426886]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.324675 25.42093  25.516409 25.60853  25.70567  25.827179 25.984005
0:  26.121817 26.314724 26.559732 26.841795 27.157076 27.530245 27.919062
0:  28.335655 28.734222 29.105883 29.444878 30.221079 30.498392]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.64575   9.582259  9.525353  9.439511  9.330437  9.168144  8.974733
0:  8.70165   8.4395485 8.143343  7.912225  7.7287717 7.7032576 7.79259
0:  7.957104  8.178042  8.37959   8.5687275 8.85136   8.916817 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.804951  -4.6254115 -4.4494967 -4.191484  -3.9770436 -3.811811
0:  -3.6459737 -3.5706086 -3.4898038 -3.3962235 -3.2753205 -3.1573148
0:  -3.009251  -2.8955579 -2.7884564 -2.714745  -2.6533895 -2.5380588
0:  -2.4930139 -2.2696824]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.164425 23.114197 23.10844  23.064728 23.032001 22.991344 23.036327
0:  23.029673 23.047184 22.98662  22.788675 22.502043 22.220263 21.969969
0:  21.771473 21.664434 21.59838  21.52029  22.170053 22.117582]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.551924 15.314195 15.163098 15.044436 14.946025 14.840324 14.78157
0:  14.634681 14.572996 14.512735 14.469473 14.434569 14.451445 14.502365
0:  14.571673 14.629576 14.624884 14.604059 15.258903 15.196017]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.3343916  -3.3080578  -3.1751099  -3.0104046  -2.8322601  -2.7383528
0:  -2.640746   -2.6799374  -2.6785488  -2.5852604  -2.3948221  -2.1300097
0:  -1.8359694  -1.5319791  -1.2363458  -0.9066644  -0.4754305  -0.00764799
0:   0.400146    1.0197043 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.17998934  0.12418938  0.32162523  0.47985935  0.6200652   0.6844163
0:   0.80124235  0.8684039   0.9299798   1.0141106   1.1324477   1.2250857
0:   1.2992392   1.3589692   1.3397889   1.349093    1.3854494   1.4947515
0:   1.3879809   1.6151552 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.172166  8.285629  8.414259  8.5353    8.673418  8.813815  8.978279
0:   9.138792  9.321869  9.534518  9.75813   9.955018 10.140785 10.305128
0:  10.440096 10.584639 10.750587 10.950758 11.061181 11.191781]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.688216 11.545233 11.402801 11.199132 10.961984 10.690031 10.442899
0:  10.27239  10.183414 10.175322 10.168426 10.102977  9.938341  9.692689
0:   9.368114  9.070407  8.792644  8.596126  8.799515  8.81234 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.293478  19.19819   19.04287   18.80355   18.477505  18.04894
0:  17.58492   17.064558  16.55038   16.083021  15.683363  15.363249
0:  15.157524  15.04542   14.953541  14.915941  14.946927  15.0692215
0:  14.309391  14.309719 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.025254  -8.091569  -8.172003  -8.228507  -8.196458  -8.14462
0:  -7.9744406 -7.871792  -7.747899  -7.6541004 -7.558796  -7.4894266
0:  -7.4209194 -7.296321  -7.223076  -7.0585384 -6.8721304 -6.622281
0:  -6.6403437 -6.652149 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.325985   9.632847   9.861715  10.002483  10.075745  10.099283
0:  10.109705  10.073738  10.054508  10.037816  10.044085  10.0716915
0:  10.111063  10.134725  10.133757  10.110346  10.083287  10.070843
0:  10.056263  10.046487 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.129635 -10.377001 -10.642315 -10.881702 -11.084019 -11.278744
0:  -11.442682 -11.620518 -11.770445 -11.874983 -11.94183  -11.997032
0:  -12.043638 -12.077925 -12.140331 -12.179094 -12.175131 -12.104906
0:  -12.505211 -12.520687]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.505857 23.488325 23.489134 23.513231 23.567598 23.654026 23.836872
0:  23.991352 24.270435 24.638533 25.042704 25.506056 25.965822 26.312029
0:  26.489515 26.429125 26.186455 25.86655  23.803137 23.75773 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.121965 18.147644 18.17404  18.150658 18.073627 17.978195 17.926653
0:  17.832787 17.764732 17.70799  17.596838 17.472925 17.396303 17.345566
0:  17.351448 17.383923 17.434391 17.465734 18.179995 18.28192 ]
0: validation loss for strategy=forecast at epoch 8 : nan
0: validation loss for velocity_u : 0.03441395238041878
0: validation loss for velocity_v : 0.06728570908308029
0: validation loss for specific_humidity : 0.023179152980446815
0: validation loss for velocity_z : 0.5259885787963867
0: validation loss for temperature : 0.07387221604585648
0: validation loss for total_precip : nan
0: 9 : 10:22:29 :: batch_size = 96, lr = 1.6825304701668386e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 9, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.0973, 0.0950, 0.0925, 0.0897, 0.0870, 0.0838, 0.0809, 0.0778, 0.0747, 0.0716, 0.0686, 0.0657, 0.0629, 0.0603,
0:         0.0576, 0.0552, 0.0526, 0.0501, 0.0648, 0.0619, 0.0586, 0.0555, 0.0522, 0.0490, 0.0458], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.1109,  0.0751,  0.0387,  0.0014, -0.0363, -0.0745, -0.1125, -0.1504, -0.1877, -0.2241, -0.2597, -0.2935,
0:         -0.3255, -0.3554, -0.3829, -0.4079, -0.4300, -0.4489,  0.1019,  0.0646,  0.0265, -0.0124, -0.0514, -0.0906,
0:         -0.1299], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.5895, -0.5864, -0.5832, -0.5802, -0.5770, -0.5739, -0.5707, -0.5675, -0.5669, -0.5663, -0.5658, -0.5652,
0:         -0.5645, -0.5638, -0.5632, -0.5629, -0.5678, -0.5729, -0.5938, -0.5913, -0.5888, -0.5862, -0.5836, -0.5811,
0:         -0.5786], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.3952, 0.4174, 0.4418, 0.4640, 0.4884, 0.5106, 0.5328, 0.5528, 0.5727, 0.5905, 0.6105, 0.6282, 0.6482, 0.6704,
0:         0.6948, 0.7214, 0.7503, 0.7814, 0.4307, 0.4640, 0.4973, 0.5328, 0.5705, 0.6060, 0.6438], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0.9627, -0.9570, -0.9512, -0.9457, -0.9405, -0.9354, -0.9305, -0.9260, -0.9218, -0.9177, -0.9141, -0.9111,
0:         -0.9084, -0.9061, -0.9041, -0.9029, -0.9020, -0.9015, -0.9015, -0.9020, -0.9027, -0.9041, -0.9057, -0.9074,
0:         -0.9092], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 9, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([-0.2580,     nan, -0.2580,     nan,     nan,     nan,     nan,     nan, -0.2545,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2556, -0.2556,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2568,     nan, -0.2556,     nan,     nan,
0:             nan, -0.2580,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2556, -0.2556,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2556,     nan,     nan,     nan,     nan, -0.2568, -0.2568,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2568,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2486, -0.2475,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2568,     nan,     nan,     nan,     nan,     nan, -0.2580,     nan, -0.2580,     nan,     nan,
0:             nan,     nan,     nan, -0.2568,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2580,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2568,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2568,     nan,     nan,     nan, -0.2568,     nan,     nan,     nan, -0.2580,     nan,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 9, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.0216, -0.0229, -0.0235, -0.0258, -0.0316, -0.0381, -0.0426, -0.0486, -0.0528, -0.0579, -0.0642, -0.0741,
0:         -0.0814, -0.0886, -0.0951, -0.0980, -0.1009, -0.1027,  0.0087,  0.0054,  0.0017, -0.0050, -0.0136, -0.0230,
0:         -0.0278], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.9341, 0.9213, 0.9044, 0.8862, 0.8695, 0.8540, 0.8402, 0.8299, 0.8225, 0.8161, 0.8065, 0.7944, 0.7778, 0.7571,
0:         0.7370, 0.7208, 0.7109, 0.7060, 0.8653, 0.8501, 0.8330, 0.8178, 0.8041, 0.7882, 0.7741], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.4081, -0.4106, -0.4132, -0.4144, -0.4171, -0.4167, -0.4171, -0.4168, -0.4174, -0.4178, -0.4171, -0.4201,
0:         -0.4265, -0.4376, -0.4517, -0.4688, -0.4866, -0.5012, -0.4158, -0.4180, -0.4187, -0.4189, -0.4185, -0.4159,
0:         -0.4148], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.0899, 0.0915, 0.0841, 0.0689, 0.0726, 0.0865, 0.0867, 0.0934, 0.1215, 0.1267, 0.1230, 0.1500, 0.1553, 0.1406,
0:         0.1346, 0.1354, 0.1580, 0.1879, 0.0905, 0.0936, 0.0915, 0.0834, 0.0805, 0.0815, 0.0837], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([-0.1077, -0.1083, -0.1060, -0.1051, -0.1027, -0.1000, -0.0975, -0.0952, -0.0934, -0.0928, -0.0924, -0.0915,
0:         -0.0878, -0.0827, -0.0769, -0.0719, -0.0689, -0.0674, -0.0664, -0.0643, -0.0621, -0.0606, -0.0613, -0.0637,
0:         -0.0668], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.05910833925008774; velocity_v: 0.12179074436426163; specific_humidity: 0.03993534296751022; velocity_z: 0.48069146275520325; temperature: 0.1123700812458992; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.055819395929574966; velocity_v: 0.09564253687858582; specific_humidity: 0.04305223003029823; velocity_z: 0.5206209421157837; temperature: 0.10929980129003525; total_precip: nan; 
0: epoch: 9 [1/5 (20%)]	Loss: nan : nan :: 0.14078 (2.46 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05996796488761902; velocity_v: 0.11350397765636444; specific_humidity: 0.04377765581011772; velocity_z: 0.5399624109268188; temperature: 0.12002548575401306; total_precip: nan; 
0: epoch: 9 [2/5 (40%)]	Loss: nan : nan :: 0.14442 (16.30 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05773850530385971; velocity_v: 0.09998588263988495; specific_humidity: 0.03679799661040306; velocity_z: 0.40972504019737244; temperature: 0.0884074717760086; total_precip: nan; 
0: epoch: 9 [3/5 (60%)]	Loss: nan : nan :: 0.14956 (16.21 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05356115847826004; velocity_v: 0.09765119105577469; specific_humidity: 0.03838396817445755; velocity_z: 0.4956941604614258; temperature: 0.10617949813604355; total_precip: nan; 
0: epoch: 9 [4/5 (80%)]	Loss: nan : nan :: 0.13633 (16.18 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.76837158e-07
0:  3.81469727e-06 1.00135803e-05 3.81469727e-06 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 4.76837158e-07 4.76837158e-07 9.53674316e-07
0:  4.76837158e-07 4.76837158e-07 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 4.76837158e-07 4.76837158e-07
0:  4.76837158e-07 9.53674316e-07 1.90734863e-06 2.38418579e-06
0:  2.38418579e-06 2.38418579e-06 2.38418579e-06 2.38418579e-06
0:  2.86102295e-06 2.86102295e-06 3.33786011e-06 3.33786011e-06
0:  4.76837158e-06 7.15255737e-06 9.53674316e-06 1.19209290e-05
0:  1.38282776e-05 1.57356262e-05 1.28746033e-05 1.14440918e-05
0:  1.04904175e-05 9.53674316e-06 9.53674316e-06 9.05990601e-06
0:  1.00135803e-05 1.19209290e-05 1.66893005e-05 2.00271606e-05
0:  2.62260437e-05 3.62396240e-05 5.53131104e-05 6.91413879e-05
0:  1.00612640e-04 1.45912170e-04 1.96456909e-04 2.34603882e-04
0:  2.93254852e-04 3.59535217e-04 4.04357910e-04 4.49657440e-04
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 9.53674316e-07 1.90734863e-06
0:  9.53674316e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  4.76837158e-07 4.76837158e-07 4.76837158e-07 4.76837158e-07
0:  4.76837158e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  4.76837158e-07 9.53674316e-07 9.53674316e-07 1.43051147e-06
0:  1.43051147e-06 1.43051147e-06 1.90734863e-06 1.90734863e-06
0:  2.86102295e-06 3.33786011e-06 4.76837158e-06 6.19888306e-06
0:  7.62939453e-06 8.58306885e-06 8.58306885e-06 9.05990601e-06
0:  8.58306885e-06 8.58306885e-06 8.10623169e-06 7.15255737e-06]
0: Target values (first 200):
0: [1.90734863e-06 2.86102295e-06 4.76837158e-06 6.19888306e-06
0:  7.62939453e-06 9.05990601e-06 2.19345093e-05 3.43322754e-05
0:  5.62667847e-05 7.58171082e-05 7.72476196e-05 8.24928284e-05
0:  6.48498535e-05 4.76837158e-05 3.33786011e-05 1.66893005e-05
0:  9.05990601e-06 2.86102295e-06 1.90734863e-06 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  9.53674316e-07 2.38418579e-06 1.43051147e-06 9.53674316e-07
0:  8.58306885e-06 9.05990601e-06 1.14440918e-05 1.28746033e-05
0:  2.09808350e-05 2.09808350e-05 5.38825989e-05 6.77108765e-05
0:  4.38690186e-05 1.43051147e-05 3.86238098e-05 5.34057617e-05
0:  6.67572021e-05 8.53538513e-05 1.12533569e-04 1.30176544e-04
0:  1.01089478e-04 5.00678980e-05 6.72340393e-05 9.25064087e-05
0:  9.91821289e-05 1.21593475e-04 1.37805939e-04 1.51157379e-04
0:  1.33037567e-04 1.05857849e-04 7.72476196e-05 5.38825989e-05
0:  5.19752502e-05 4.81605530e-05 6.34193420e-05 7.15255737e-05
0:  7.05718994e-05 6.58035278e-05 8.01086426e-05 1.01089478e-04
0:  9.25064087e-05 7.82012939e-05 7.58171082e-05 6.29425049e-05
0:  4.81605530e-05 3.38554382e-05 3.24249268e-05 2.95639038e-05
0:  2.43186951e-05 2.00271606e-05 1.62124634e-05 1.23977661e-05
0:  1.04904175e-05 8.10623169e-06 6.19888306e-06 4.76837158e-06
0:  5.24520874e-06 5.72204590e-06 5.72204590e-06 5.72204590e-06
0:  5.24520874e-06 4.76837158e-06 4.29153442e-06 3.33786011e-06
0:  3.33786011e-06 3.33786011e-06 2.38418579e-06 1.90734863e-06
0:  1.43051147e-06 9.53674316e-07 4.76837158e-07 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  1.43051147e-06 1.90734863e-06 2.86102295e-06 3.81469727e-06
0:  5.72204590e-06 7.15255737e-06 1.85966492e-05 3.00407410e-05
0:  5.48362732e-05 7.96318054e-05 9.25064087e-05 1.02996826e-04
0:  8.48770142e-05 6.86645508e-05 4.72068787e-05 2.71797180e-05
0:  1.76429749e-05 6.67572021e-06 3.33786011e-06 9.53674316e-07
0:  4.76837158e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  4.76837158e-07 9.53674316e-07 1.43051147e-06 1.43051147e-06
0:  1.81198120e-05 3.09944153e-05 3.43322754e-05 3.48091125e-05
0:  5.34057617e-05 6.53266907e-05 6.00814819e-05 4.76837158e-05
0:  3.09944153e-05 2.05039978e-05 2.05039978e-05 2.33650208e-05
0:  2.86102295e-05 3.09944153e-05 3.57627869e-05 4.10079956e-05
0:  4.14848328e-05 4.29153479e-05 7.29560852e-05 1.09195709e-04
0:  9.44137573e-05 8.24928284e-05 9.34600830e-05 1.02519989e-04
0:  9.67979431e-05 8.91685486e-05 7.62939453e-05 5.96046448e-05
0:  6.05583191e-05 6.10351562e-05 6.00814819e-05 5.91278076e-05
0:  6.34193420e-05 6.77108765e-05 9.77516174e-05 1.26838684e-04
0:  1.25885010e-04 1.20162964e-04 9.87052917e-05 7.20024109e-05
0:  5.62667847e-05 4.10079956e-05 3.33786011e-05 2.90870667e-05
0:  2.24113464e-05 1.57356262e-05 1.28746033e-05 9.53674316e-06
0:  8.10623169e-06 7.15255737e-06 5.72204590e-06 4.76837158e-06
0:  5.24520874e-06 5.72204590e-06 5.72204590e-06 5.72204590e-06
0:  4.76837158e-06 3.81469727e-06 2.86102295e-06 1.90734863e-06
0:  1.43051147e-06 9.53674316e-07 9.53674316e-07 9.53674316e-07]
0: Prediction values (first 20):
0: [28.110044 28.093134 28.035189 27.786858 27.462015 27.003508 26.426376
0:  25.647661 24.723087 23.631891 22.378963 21.002443 19.671915 18.412735
0:  17.348457 16.490503 15.846018 15.396875 16.085281 15.637077]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -3.960, max = 2.691, mean = 0.580
0:          sample (first 20): tensor([1.8546, 1.8532, 1.8482, 1.8269, 1.7991, 1.7599, 1.7105, 1.6438, 1.5647, 1.4712, 1.3640, 1.2461, 1.1322, 1.0245,
0:         0.9333, 0.8599, 0.8047, 0.7663, 1.8262, 1.8367])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.9159226 4.931895  4.915818  4.8625064 4.814835  4.7756395 4.7438006
0:  4.701137  4.6326017 4.5788746 4.5381393 4.515149  4.530791  4.555925
0:  4.608002  4.6939526 4.81919   5.019833  4.675559  4.733073 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.526595  13.293161  13.078393  12.788355  12.4192295 11.996668
0:  11.582748  11.149452  10.732161  10.34831    9.93147    9.510205
0:   9.144527   8.789101   8.476779   8.18168    7.8842177  7.6308823
0:   7.219946   7.0708036]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.920804  11.863773  11.783386  11.661577  11.510897  11.324397
0:  11.146334  10.961172  10.8185005 10.714495  10.651172  10.595167
0:  10.575209  10.596815  10.639931  10.717234  10.7922    10.860924
0:  10.706665  10.565328 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.862633 11.698444 11.609091 11.582304 11.596121 11.654817 11.764504
0:  11.887229 12.052614 12.240452 12.428095 12.58152  12.790607 12.998932
0:  13.227388 13.437222 13.615265 13.774723 13.908358 14.046283]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.666513  14.414117  15.2179    15.931249  16.485657  16.835203
0:  16.955963  16.820812  16.487125  15.95615   15.241624  14.363825
0:  13.407291  12.480779  11.600188  10.855574  10.288729   9.856668
0:   9.3488245  9.103882 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.572734  -7.345805  -7.012435  -6.65493   -6.3333845 -6.121072
0:  -5.997072  -5.9591637 -5.939947  -5.894781  -5.8035927 -5.687479
0:  -5.5354595 -5.3719645 -5.2152023 -5.045313  -4.822981  -4.563283
0:  -4.294672  -4.1458254]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.664428  -5.7500596 -5.7445025 -5.659744  -5.551501  -5.512814
0:  -5.566993  -5.7680173 -6.051498  -6.378572  -6.693357  -7.0105023
0:  -7.2549577 -7.402881  -7.482414  -7.429299  -7.296098  -7.118468
0:  -7.1164794 -6.99781  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.064404  15.05382   14.966364  14.800272  14.584299  14.350923
0:  14.120794  13.852646  13.605049  13.394428  13.210262  13.088428
0:  13.061701  13.109853  13.257498  13.45437   13.706793  13.975525
0:  14.229226  14.5236225]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.254484  12.388109  12.4821005 12.538218  12.562426  12.531153
0:  12.473891  12.351061  12.180476  12.032738  11.893738  11.743362
0:  11.591248  11.4298    11.231651  11.041898  10.857941  10.720344
0:   9.345395   9.128626 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.466424   -0.43985176 -0.43602085 -0.44803667 -0.4655285  -0.52598
0:  -0.6034975  -0.7211156  -0.8531828  -0.9718728  -1.0918965  -1.2244248
0:  -1.3464575  -1.4710298  -1.6004152  -1.6954279  -1.7473202  -1.7434511
0:  -2.0432615  -2.039917  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.600383  -10.753533  -10.848701  -10.838836  -10.723929  -10.555844
0:  -10.290099  -10.023757   -9.755261   -9.473111   -9.211446   -9.017084
0:   -8.860876   -8.7284355  -8.655975   -8.558676   -8.452684   -8.312254
0:   -8.565195   -8.410699 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.593161  -6.5161376 -6.3997474 -6.2632394 -6.106031  -5.9746976
0:  -5.85327   -5.8078275 -5.786287  -5.7672496 -5.709951  -5.624989
0:  -5.4560704 -5.218599  -4.9736238 -4.721622  -4.5162663 -4.2763734
0:  -4.337708  -4.1530013]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.43452   17.001633  17.221272  16.867062  16.178165  15.416308
0:  15.047359  14.996561  15.341536  15.658923  15.709781  15.3710375
0:  14.719494  13.886721  12.879934  11.775074  10.562695   9.429676
0:   9.976213  10.375992 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.5374665   0.5782652   0.58954763  0.5711813   0.51081896  0.3891983
0:   0.2643857   0.09991217 -0.02924633 -0.13726711 -0.22631979 -0.32413673
0:  -0.42021942 -0.51179886 -0.6339345  -0.7516928  -0.85084057 -0.90759706
0:  -1.218039   -1.3320794 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.3871346 4.494878  4.634138  4.7840805 4.9440417 5.08529   5.2219505
0:  5.3111963 5.393954  5.440075  5.45549   5.420679  5.3817797 5.3514442
0:  5.3243146 5.3432627 5.373329  5.4251013 5.1348295 5.2573195]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.426842 17.456182 17.541103 17.588898 17.632353 17.661377 17.699379
0:  17.690891 17.670279 17.638878 17.5519   17.409525 17.217642 17.020687
0:  16.792597 16.595165 16.421755 16.280848 15.750166 15.667505]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.39848042 -0.73420286 -1.1843629  -1.6822238  -2.2169538  -2.8140674
0:  -3.4208198  -4.046619   -4.6317964  -5.145165   -5.6020675  -6.0169473
0:  -6.367456   -6.666057   -6.9634356  -7.2098193  -7.4395995  -7.6609244
0:  -8.419157   -8.608467  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.641761  13.548241  13.4643345 13.339436  13.212988  13.067846
0:  12.923261  12.737129  12.541096  12.338335  12.105087  11.814459
0:  11.504499  11.179707  10.809538  10.459087  10.097521   9.734858
0:   8.787531   8.417374 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.215595  -5.237145  -5.241984  -5.295468  -5.3747525 -5.4672236
0:  -5.5875907 -5.6875424 -5.723308  -5.6992    -5.5849624 -5.4205565
0:  -5.1383405 -4.7987523 -4.3938727 -4.0174136 -3.720818  -3.4967437
0:  -3.888784  -3.7576823]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.169895 25.32457  25.605167 25.880825 26.143387 26.333523 26.463322
0:  26.410522 26.25459  25.9743   25.543999 25.03938  24.507416 23.994179
0:  23.553673 23.195942 22.915756 22.754208 22.58266  22.63955 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.497734  9.205812  9.058881  9.013996  9.027632  9.008237  8.897905
0:  8.704966  8.467942  8.197302  7.934054  7.7114234 7.567547  7.4359927
0:  7.317982  7.1559815 6.938871  6.685506  6.700693  6.4125204]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.25783  26.328417 26.39396  26.369009 26.324526 26.259747 26.206135
0:  26.124187 26.089703 26.065401 26.077854 26.085588 26.097515 26.078993
0:  26.00902  25.936323 25.849495 25.767899 25.732964 25.83256 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 4.7002783  4.988774   5.274869   5.5938654  5.917808   6.241912
0:   6.5931273  6.893858   7.199235   7.4927745  7.7831426  8.106804
0:   8.469763   8.828866   9.200269   9.526821   9.830381  10.120466
0:  10.23589   10.622311 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.9382458 -3.8878708 -3.7928247 -3.6911287 -3.5644865 -3.455205
0:  -3.3531551 -3.276472  -3.184043  -3.065158  -2.893468  -2.727847
0:  -2.5451117 -2.3447914 -2.1911955 -2.0251951 -1.8491764 -1.6669254
0:  -1.9843569 -2.028657 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.55161047 -0.8754544  -1.2076182  -1.5410094  -1.8941236  -2.243669
0:  -2.5103269  -2.7511277  -2.9623017  -3.143396   -3.3360982  -3.5690856
0:  -3.8064046  -4.033591   -4.276588   -4.4732165  -4.653342   -4.778319
0:  -5.048735   -5.3031907 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.629136 13.860243 14.081968 14.254062 14.400054 14.534277 14.707782
0:  14.844868 14.995371 15.158496 15.28407  15.388006 15.49344  15.599881
0:  15.68361  15.76327  15.890429 16.035156 15.821791 16.069841]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.9814322 3.02083   3.0623798 3.1472073 3.2463877 3.3045492 3.4103217
0:  3.4461267 3.476833  3.4828048 3.4693737 3.452951  3.5034041 3.543694
0:  3.5999396 3.737308  3.9082832 4.160989  3.4878054 3.5888114]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.5404477  -0.07358122 -0.6168103  -1.0835133  -1.422946   -1.7125387
0:  -1.96661    -2.216776   -2.4493723  -2.626482   -2.7286663  -2.8109598
0:  -2.8124304  -2.7394733  -2.6225348  -2.480361   -2.352727   -2.2234612
0:  -1.8491106  -1.6702137 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -9.824956  -9.90652  -10.01821  -10.206937 -10.455983 -10.763131
0:  -11.058917 -11.354289 -11.519965 -11.53152  -11.405999 -11.192569
0:  -10.895585 -10.510781 -10.152175  -9.757163  -9.412911  -9.122114
0:   -9.293806  -9.372198]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.9750619  -2.460792   -2.7504344  -2.5995736  -1.9573712  -1.0030146
0:   0.10380363  1.1019206   1.9307284   2.4953995   2.8539004   3.075477
0:   3.2106478   3.3887777   3.5976048   3.9307826   4.3656216   4.859888
0:   4.9240694   4.926364  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.344396    8.935779    8.515233    8.063442    7.5714283   6.990147
0:   6.3508964   5.6055045   4.791068    3.9148674   3.0044127   2.0251727
0:   1.0099378   0.01936579 -0.9505143  -1.8371611  -2.6816998  -3.4003277
0:  -4.508052   -4.7726746 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.136902 16.536018 16.997374 17.466072 17.973068 18.51797  19.142738
0:  19.747864 20.330023 20.878359 21.361006 21.797417 22.20359  22.604443
0:  22.960184 23.275135 23.51418  23.655106 21.763683 21.84347 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.483197   8.674273   8.8924265  9.138031   9.437525   9.753181
0:  10.047087  10.261919  10.44615   10.607115  10.784004  10.95302
0:  11.167057  11.358934  11.536238  11.705582  11.893777  12.110848
0:  11.322277  11.241423 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.59819  17.943684 18.13499  18.211946 18.147509 18.002121 17.816763
0:  17.50182  17.24262  17.017204 16.876888 16.840796 16.929523 17.15012
0:  17.441713 17.85784  18.395454 19.0323   20.578638 21.469496]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.044313  13.905117  13.776094  13.596983  13.378241  13.078518
0:  12.756427  12.326138  11.823794  11.247482  10.527764   9.722057
0:   8.919321   8.114588   7.395375   6.742197   6.171602   5.7277484
0:   4.9293485  4.724322 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.06079292  0.09682131  0.3212309   0.6073556   0.9690447   1.3587365
0:   1.8013439   2.2241209   2.6718001   3.138534    3.6650615   4.190675
0:   4.7757907   5.369689    5.8989177   6.3833437   6.8231177   7.2666745
0:   7.341529    7.9280987 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.9134502 7.8281846 7.835395  7.9655876 8.247697  8.631335  9.068236
0:  9.396649  9.606068  9.630919  9.516933  9.295292  9.081304  8.919486
0:  8.794588  8.723893  8.701449  8.722488  8.616625  8.647464 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.110232  6.1624737 6.219875  6.294565  6.3527975 6.3690195 6.3785686
0:  6.3351984 6.297545  6.2361417 6.1690736 6.0705576 5.9874334 5.8955235
0:  5.7791576 5.692661  5.632677  5.642087  5.225267  5.1042833]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.643543  11.713496  11.937869  12.201479  12.475012  12.664619
0:  12.819258  12.8891735 12.98119   13.071733  13.190381  13.20186
0:  13.136299  13.046398  12.854687  12.717254  12.631597  12.565472
0:  12.100447  11.896241 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.395281  -6.5642443 -6.6035223 -6.5547695 -6.402458  -6.224758
0:  -6.0261974 -5.893799  -5.811493  -5.785329  -5.7538557 -5.775461
0:  -5.813588  -5.7932644 -5.808978  -5.825732  -5.894435  -5.973118
0:  -7.0486    -7.6683645]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-21.24923  -21.29127  -21.239485 -21.225836 -21.413637 -21.880352
0:  -22.56706  -23.462488 -24.390299 -25.285648 -26.063316 -26.7625
0:  -27.31709  -27.64315  -27.763393 -27.691391 -27.543861 -27.374897
0:  -25.113964 -25.129902]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.053361  8.253     8.565403  8.998114  9.581773 10.225523 10.900232
0:  11.45643  11.987784 12.526569 13.101452 13.70105  14.363375 14.97736
0:  15.521181 15.941095 16.274876 16.491753 15.64957  15.261259]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.4415693 -5.5354643 -5.581064  -5.5476274 -5.3518066 -5.0657816
0:  -4.6734276 -4.340811  -4.0937624 -3.987691  -4.016056  -4.2139435
0:  -4.479829  -4.7717667 -5.138835  -5.4583673 -5.7276134 -5.899066
0:  -6.0869093 -6.15168  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [30.029343 29.979746 29.933933 29.670853 29.22223  28.555466 27.744251
0:  26.813585 25.894604 25.010588 24.165972 23.317331 22.517859 21.758373
0:  20.941395 20.2226   19.551535 19.026978 18.10399  17.470469]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [28.23479  28.327248 28.349968 28.252714 28.098726 27.912567 27.696619
0:  27.457645 27.215841 26.964518 26.713648 26.362381 26.01443  25.622301
0:  25.17723  24.772404 24.45112  24.217428 23.224365 22.940025]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -8.302394   -9.155316  -10.216844  -11.3772745 -12.367829  -12.944779
0:  -12.844348  -12.2338915 -11.27505   -10.289805   -9.524966   -9.043885
0:   -8.725676   -8.355608   -7.9037094  -7.3542233  -6.893668   -6.628208
0:   -6.5416718  -6.1599903]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.426131 9.470915 9.530637 9.566812 9.602343 9.61647  9.592129 9.519203
0:  9.426848 9.32376  9.213879 9.060668 8.951798 8.829888 8.731413 8.687816
0:  8.705717 8.760192 8.383876 8.465293]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.9037004 7.684322  7.494861  7.2984147 7.0780897 6.849403  6.6099987
0:  6.364634  6.131673  5.930861  5.7693105 5.6420155 5.586409  5.5835724
0:  5.5915155 5.5882816 5.530645  5.411201  5.661312  5.5412097]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [30.336685 29.681824 29.268942 28.981117 28.829885 28.73729  28.650454
0:  28.460323 28.261086 27.923727 27.413448 26.75664  26.104155 25.503765
0:  25.009075 24.708874 24.52944  24.436045 24.929047 24.8838  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.496829  8.332301  8.184597  8.063186  7.9514523 7.8207655 7.692464
0:  7.530507  7.397284  7.303728  7.220603  7.1395235 7.0522914 6.967415
0:  6.8792925 6.827227  6.809058  6.8205657 6.5358553 6.385535 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.291332 -10.256552 -10.226601 -10.215273 -10.231953 -10.312147
0:  -10.394428 -10.529018 -10.657665 -10.78401  -10.883511 -10.991718
0:  -11.071798 -11.083677 -11.091381 -11.028965 -10.954439 -10.876884
0:  -11.137613 -11.160503]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.351089   -5.031918   -4.7408633  -4.4885144  -4.1918454  -3.911385
0:  -3.584271   -3.286224   -2.9847846  -2.6647515  -2.3270788  -2.009632
0:  -1.7181196  -1.4430327  -1.2517033  -1.045476   -0.83917475 -0.6089978
0:  -0.41631603 -0.14805794]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.6443229 2.7240796 2.8671007 3.083616  3.325466  3.5583434 3.8229742
0:  3.9951952 4.1591797 4.2748337 4.372489  4.481533  4.65867   4.859441
0:  5.0875854 5.275353  5.434018  5.570778  5.5894403 5.7367926]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.9912143 -7.8868594 -7.836345  -7.864757  -7.959577  -8.118242
0:  -8.312559  -8.525562  -8.727665  -8.880535  -8.992655  -9.144682
0:  -9.273994  -9.300795  -9.320396  -9.178862  -8.919163  -8.621799
0:  -8.114141  -7.8574433]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.8098655 -3.8412814 -3.855762  -3.872044  -3.9054713 -4.0044675
0:  -4.130347  -4.322614  -4.4857745 -4.5840354 -4.5879817 -4.5215764
0:  -4.393205  -4.18628   -3.9980235 -3.7898164 -3.5766072 -3.3591743
0:  -3.5529819 -3.6631398]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.3516603 4.299946  4.3139877 4.3899894 4.442824  4.475955  4.5169973
0:  4.4750376 4.4071207 4.29115   4.1301794 3.9516904 3.8108935 3.6682394
0:  3.5385127 3.369819  3.1707704 2.9714177 2.3961759 2.22649  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.051646 11.130634 11.203894 11.234373 11.249188 11.228159 11.201714
0:  11.153288 11.144257 11.145655 11.159651 11.151162 11.137566 11.112686
0:  11.067423 11.04281  11.034332 11.049455 10.673182 10.719353]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.75109   3.1236873 3.5192952 3.9244502 4.305339  4.627822  4.938857
0:  5.1951714 5.4476023 5.6878586 5.9222727 6.1282697 6.3489637 6.562405
0:  6.775723  6.982114  7.1951175 7.401186  7.3421464 7.6392183]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-15.158031 -15.081221 -14.958544 -14.8139   -14.65959  -14.546368
0:  -14.449106 -14.449818 -14.475363 -14.52821  -14.602966 -14.726122
0:  -14.847166 -14.946745 -15.079159 -15.173801 -15.25345  -15.282167
0:  -16.039991 -16.193298]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.1989508  -1.2487259  -1.2243996  -1.151473   -1.033411   -0.9425831
0:  -0.8624964  -0.8466935  -0.8140893  -0.75534916 -0.68460226 -0.6418309
0:  -0.60634375 -0.5836711  -0.58880424 -0.5750966  -0.5297799  -0.4339347
0:  -0.6412306  -0.6378498 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 4.792303   5.121309   5.4616776  5.876834   6.2881794  6.6930575
0:   7.0899167  7.4030075  7.7283945  8.051844   8.396536   8.792296
0:   9.237209   9.651958  10.059756  10.360817  10.663658  10.964661
0:  10.907705  11.339796 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.066732 20.644165 21.258577 21.714838 22.167042 22.50632  22.841902
0:  23.014765 23.276518 23.442766 23.47992  23.364664 23.000408 22.544395
0:  22.018389 21.45826  21.02429  20.630213 18.055944 17.37011 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 6.466218    6.1159496   5.7997546   5.418866    4.8867188   4.2482805
0:   3.5156083   2.6618347   1.8081899   0.8697138  -0.16709566 -1.2435555
0:  -2.2511363  -3.2106833  -4.086864   -4.9444737  -5.777311   -6.4528184
0:  -5.9543443  -5.965449  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.42349195 -0.37042046 -0.29289198 -0.2274375  -0.17193699 -0.14716053
0:  -0.14272308 -0.17087507 -0.24046993 -0.31170177 -0.40146255 -0.53462505
0:  -0.6720104  -0.810554   -0.975451   -1.1095114  -1.211801   -1.2679229
0:  -1.6130176  -1.6259065 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.695706  -3.8459544 -3.9223819 -3.8908267 -3.7624087 -3.6359477
0:  -3.5214782 -3.5073638 -3.4950747 -3.452931  -3.318255  -3.1382518
0:  -2.8475986 -2.5234437 -2.2153487 -1.9548526 -1.7443566 -1.6088929
0:  -2.740394  -2.928145 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.342382 24.245975 24.075068 23.852955 23.530674 23.130018 22.68306
0:  22.117268 21.611298 21.166082 20.770271 20.51226  20.39357  20.36746
0:  20.429012 20.500397 20.606129 20.727215 21.152363 21.228304]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.0070047 7.118388  7.2387843 7.3481493 7.4406557 7.4967685 7.563509
0:  7.604452  7.6633043 7.7390947 7.8135433 7.8779707 7.9511085 8.009834
0:  8.050286  8.099101  8.150542  8.216629  8.300657  8.46759  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.378891  -3.2631598 -3.2026863 -3.2619324 -3.4418507 -3.7480125
0:  -4.1547127 -4.621745  -5.054558  -5.387871  -5.567194  -5.639658
0:  -5.5927677 -5.4321346 -5.2319317 -4.947526  -4.605013  -4.237795
0:  -3.8120794 -3.5915794]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.00799799 -0.08085632 -0.08156824 -0.00785637  0.09514856  0.20374441
0:   0.3357215   0.4339404   0.52126217  0.5940833   0.6708708   0.68179274
0:   0.69130945  0.6758976   0.6161895   0.5807953   0.5384865   0.49244642
0:  -0.33335924 -0.61531115]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.251282  10.349729  10.501547  10.665812  10.82822   10.913542
0:  10.932485  10.7835455 10.547665  10.144281   9.597942   8.890103
0:   8.076348   7.2303567  6.397169   5.6473827  4.981331   4.479033
0:   3.7723336  3.550061 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.6099281 1.6089091 1.6433592 1.7390776 1.8455167 1.9685702 2.1914225
0:  2.4311745 2.7079806 3.0035794 3.2814033 3.4773154 3.6449516 3.7569854
0:  3.7919514 3.8101497 3.7343373 3.6263967 3.2277699 3.2443733]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.5781446 2.4631305 2.402832  2.415533  2.5240831 2.6962204 2.9017572
0:  3.0901775 3.267043  3.3901174 3.5016973 3.5474143 3.5594788 3.5615726
0:  3.5221262 3.46191   3.3801184 3.3134801 2.808857  2.6762433]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.540972 19.981882 20.388025 20.66425  20.928366 21.170702 21.394138
0:  21.592903 21.770222 21.964884 22.188528 22.43096  22.745472 23.027184
0:  23.30285  23.55029  23.765984 23.960957 24.277327 24.892933]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.8345776   5.6533866   5.5117126   5.374849    5.243344    5.0372863
0:   4.776287    4.4279256   4.012145    3.5704525   3.1223955   2.6156611
0:   2.0844479   1.5567493   0.998343    0.4759884  -0.03437471 -0.4729147
0:  -1.3192062  -1.5729656 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-11.602194  -11.637125  -11.633867  -11.645304  -11.690445  -11.814238
0:  -11.968355  -12.210453  -12.455593  -12.7126465 -12.978529  -13.25758
0:  -13.483814  -13.683746  -13.885365  -14.045353  -14.182568  -14.250687
0:  -15.122934  -15.303226 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.206805  6.277054  6.378385  6.5088587 6.606319  6.650911  6.683628
0:  6.61147   6.5137234 6.403964  6.2708235 6.1682234 6.119005  6.078801
0:  6.0936694 6.122958  6.170212  6.268899  6.394681  6.5742683]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.208708 22.528292 22.830666 23.079958 23.284628 23.498152 23.727379
0:  23.932695 24.172026 24.445543 24.711784 24.977905 25.301342 25.62291
0:  25.967545 26.282698 26.581594 26.766678 26.518562 26.59971 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [32.366447 32.37303  32.350494 32.268387 32.245403 32.250595 32.410618
0:  32.500862 32.62129  32.663185 32.561577 32.275097 31.931742 31.641844
0:  31.39009  31.345814 31.328873 31.272902 30.497717 30.237747]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.0643725 -5.030524  -4.9651084 -4.86822   -4.735687  -4.6563725
0:  -4.6277785 -4.698466  -4.7848535 -4.8512464 -4.843188  -4.7966228
0:  -4.711125  -4.562671  -4.450458  -4.3082347 -4.1444964 -3.9620566
0:  -4.3268294 -4.3012033]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.7069297 -2.7219453 -2.8093152 -3.0260682 -3.3078876 -3.6538491
0:  -3.9905477 -4.348005  -4.637424  -4.8634    -5.0760846 -5.338145
0:  -5.6541705 -5.9875474 -6.3947864 -6.7439275 -7.000899  -7.122421
0:  -7.3299527 -7.3401923]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.703796 22.43515  22.200378 21.95557  21.715591 21.480581 21.30504
0:  21.041351 20.780338 20.42841  19.92481  19.321184 18.720572 18.156502
0:  17.666313 17.261786 16.91385  16.603163 16.289751 16.068424]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.7808347 -3.8562942 -3.8724418 -3.8543382 -3.786139  -3.736033
0:  -3.6433377 -3.6049132 -3.5601325 -3.5026002 -3.4248376 -3.368298
0:  -3.345882  -3.2867608 -3.2817101 -3.2058282 -3.0747113 -2.9146018
0:  -2.83149   -2.784037 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.7420344 -1.6975894 -1.6576877 -1.6300244 -1.6467786 -1.7125659
0:  -1.7884326 -1.9354692 -2.1291318 -2.3737273 -2.680429  -3.0513282
0:  -3.441812  -3.854858  -4.315246  -4.77895   -5.220549  -5.5802426
0:  -6.315211  -6.410297 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.842932  13.778543  13.684397  13.532228  13.3806095 13.199215
0:  13.039406  12.874098  12.767668  12.675171  12.58412   12.452936
0:  12.28047   12.091604  11.871159  11.664827  11.499977  11.38213
0:  10.572777  10.430999 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.826819  -5.812118  -5.711596  -5.5638394 -5.3715863 -5.214648
0:  -5.0720897 -5.0194125 -5.018005  -5.036654  -5.0543017 -5.1007733
0:  -5.151296  -5.1852527 -5.2891297 -5.3650556 -5.4543977 -5.5381036
0:  -6.1156764 -6.20577  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.1295123 -3.1200862 -3.0701127 -3.0061612 -2.9360995 -2.8889318
0:  -2.8498254 -2.8856444 -2.9891639 -3.1609988 -3.3787608 -3.6664815
0:  -3.9867492 -4.3223176 -4.7426534 -5.2239203 -5.765782  -6.3416514
0:  -8.292315  -8.892809 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.633564   -0.4898095  -0.34632397 -0.18683767 -0.0380497   0.07134533
0:   0.20554638  0.316144    0.43811655  0.5563793   0.6699233   0.787436
0:   0.9165487   1.029058    1.1142893   1.1810045   1.244339    1.2968669
0:   1.356257    1.486134  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.844345  11.079711  11.3328705 11.552289  11.720985  11.833383
0:  11.888708  11.872135  11.800058  11.66169   11.4757595 11.215476
0:  10.890892  10.514999  10.058193   9.5615225  9.047045   8.552229
0:   7.98455    7.660167 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.169846 14.570377 14.904737 15.115978 15.337038 15.515289 15.7904
0:  15.970089 16.208736 16.368156 16.447363 16.518425 16.544899 16.627832
0:  16.717155 16.757458 16.880392 17.112806 16.945585 17.218918]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-16.586155 -16.45311  -16.314837 -16.115604 -15.872389 -15.672199
0:  -15.469006 -15.385284 -15.320656 -15.240444 -15.150555 -15.052126
0:  -14.93852  -14.792093 -14.638157 -14.44743  -14.198763 -13.896421
0:  -14.389023 -14.228107]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.5723183 3.587104  3.693881  3.8421261 4.037286  4.201118  4.3443136
0:  4.4500957 4.546995  4.6761994 4.81413   4.908295  4.996816  5.0284925
0:  4.9944453 4.998991  5.0643377 5.2071447 4.793834  4.850813 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.8786244 -6.848536  -6.702049  -6.417545  -6.061955  -5.707909
0:  -5.3852944 -5.184097  -5.048904  -4.973659  -4.9209933 -4.904097
0:  -4.8862405 -4.8552184 -4.8347793 -4.7504725 -4.6149125 -4.4229674
0:  -4.5319247 -4.3504167]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.085186  -1.8791299 -1.6902494 -1.5804677 -1.6200023 -1.8620281
0:  -2.2751966 -2.862496  -3.5263524 -4.2198005 -4.902326  -5.55475
0:  -6.0921063 -6.4787736 -6.7510705 -6.89047   -6.972653  -7.0004954
0:  -7.4356713 -7.5449786]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.419178  -8.302179  -8.112024  -7.8792195 -7.590732  -7.3383355
0:  -7.0975003 -6.959123  -6.860186  -6.7700696 -6.673039  -6.594231
0:  -6.5221515 -6.4058614 -6.338265  -6.222998  -6.076303  -5.9292426
0:  -6.4598346 -6.4381166]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [64.499245 65.27505  65.867744 66.29228  66.53456  66.79786  66.946396
0:  67.13063  67.43235  67.5925   67.808975 67.71257  67.582504 67.477234
0:  67.33336  67.21266  67.075325 66.70861  65.90675  66.142136]
0: validation loss for strategy=forecast at epoch 9 : nan
0: validation loss for velocity_u : 0.039480313658714294
0: validation loss for velocity_v : 0.06654336303472519
0: validation loss for specific_humidity : 0.02456170879304409
0: validation loss for velocity_z : 0.5422640442848206
0: validation loss for temperature : 0.07264696806669235
0: validation loss for total_precip : nan
0: 10 : 10:26:47 :: batch_size = 96, lr = 1.6414931416261842e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 10, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.4880, 0.4575, 0.4230, 0.3877, 0.3544, 0.3245, 0.2976, 0.2735, 0.2513, 0.2304, 0.2111, 0.1948, 0.1828, 0.1757,
0:         0.1730, 0.1730, 0.1745, 0.1768, 0.4341, 0.3949, 0.3566, 0.3215, 0.2904, 0.2625, 0.2380], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.5854, 1.5582, 1.5223, 1.4839, 1.4468, 1.4107, 1.3754, 1.3421, 1.3106, 1.2807, 1.2537, 1.2293, 1.2061, 1.1843,
0:         1.1643, 1.1443, 1.1239, 1.1031, 1.5394, 1.4969, 1.4537, 1.4129, 1.3760, 1.3421, 1.3098], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.9176, 0.8957, 0.8778, 0.8560, 0.8292, 0.8002, 0.7658, 0.7360, 0.7061, 0.6822, 0.6658, 0.6561, 0.6558, 0.6621,
0:         0.6725, 0.6882, 0.7041, 0.7167, 0.8681, 0.8471, 0.8282, 0.8075, 0.7806, 0.7505, 0.7166], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.7750, -0.7814, -0.7462, -0.6760, -0.5652, -0.4173, -0.2970, -0.2289, -0.1884, -0.1724, -0.1607, -0.1192,
0:         -0.0819, -0.0628, -0.0426, -0.0596, -0.1267, -0.1916, -0.7707, -0.7771, -0.7281, -0.6504, -0.5408, -0.3981,
0:         -0.2810], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0.2285, 0.2538, 0.2818, 0.3105, 0.3390, 0.3674, 0.3944, 0.4194, 0.4431, 0.4663, 0.4894, 0.5130, 0.5383, 0.5642,
0:         0.5896, 0.6158, 0.6430, 0.6705, 0.6989, 0.7278, 0.7557, 0.7826, 0.8071, 0.8276, 0.8445], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 10, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([-0.1210,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,  0.5027,     nan,     nan,  0.1195,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2390,     nan,
0:             nan,     nan,     nan, -0.2334,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,  0.1105,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0210,  0.1971,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.0389,     nan,     nan,     nan,     nan,     nan,
0:          0.2993,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  0.2207,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0479,     nan,     nan, -0.2008,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0288, -0.0255,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1895,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2154,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2154,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,  0.3454,     nan,     nan,     nan,     nan,     nan,     nan,  0.0622,     nan,
0:             nan,  0.0105, -0.0580,     nan, -0.1749,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 10, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([1.4217, 1.3950, 1.3723, 1.3486, 1.3261, 1.3011, 1.2666, 1.2224, 1.1720, 1.1183, 1.0632, 1.0106, 0.9636, 0.9225,
0:         0.8844, 0.8468, 0.8189, 0.8013, 1.5318, 1.5049, 1.4777, 1.4511, 1.4227, 1.3912, 1.3541], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([1.8156, 1.8753, 1.9225, 1.9562, 1.9793, 1.9923, 1.9984, 1.9938, 1.9829, 1.9640, 1.9348, 1.8963, 1.8465, 1.7965,
0:         1.7495, 1.7240, 1.7155, 1.7258, 1.7825, 1.8428, 1.8904, 1.9265, 1.9519, 1.9634, 1.9635], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.0901, -0.0906, -0.1084, -0.1294, -0.1742, -0.2410, -0.3242, -0.4130, -0.4836, -0.5318, -0.5455, -0.5074,
0:         -0.4461, -0.3486, -0.2363, -0.1265, -0.0207,  0.0647, -0.1258, -0.1499, -0.1680, -0.1936, -0.2422, -0.3060,
0:         -0.3801], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-1.8799, -2.0624, -2.1868, -2.1942, -1.9683, -1.5471, -1.0587, -0.6543, -0.4234, -0.3512, -0.3638, -0.4299,
0:         -0.5503, -0.6650, -0.7258, -0.7113, -0.6583, -0.6739, -1.9238, -2.0981, -2.1726, -2.0840, -1.7709, -1.3084,
0:         -0.8367], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([-1.2542, -1.2124, -1.1687, -1.1207, -1.0573, -0.9752, -0.8768, -0.7678, -0.6590, -0.5600, -0.4784, -0.4176,
0:         -0.3756, -0.3481, -0.3302, -0.3175, -0.3088, -0.3014, -0.2927, -0.2772, -0.2544, -0.2251, -0.1919, -0.1557,
0:         -0.1159], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.05994768813252449; velocity_v: 0.09781327098608017; specific_humidity: 0.037397533655166626; velocity_z: 0.5412459969520569; temperature: 0.09140214323997498; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06257110834121704; velocity_v: 0.09901011735200882; specific_humidity: 0.035739652812480927; velocity_z: 0.5185489654541016; temperature: 0.0954345166683197; total_precip: nan; 
0: epoch: 10 [1/5 (20%)]	Loss: nan : nan :: 0.14340 (2.71 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.051097407937049866; velocity_v: 0.08690790086984634; specific_humidity: 0.03627397119998932; velocity_z: 0.48617860674858093; temperature: 0.09252191334962845; total_precip: nan; 
0: epoch: 10 [2/5 (40%)]	Loss: nan : nan :: 0.13568 (16.29 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05079473555088043; velocity_v: 0.09319499135017395; specific_humidity: 0.03139422461390495; velocity_z: 0.4365195631980896; temperature: 0.08841506391763687; total_precip: nan; 
0: epoch: 10 [3/5 (60%)]	Loss: nan : nan :: 0.13743 (16.30 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05362044274806976; velocity_v: 0.0875258669257164; specific_humidity: 0.03908265009522438; velocity_z: 0.45708411931991577; temperature: 0.08825872838497162; total_precip: nan; 
0: epoch: 10 [4/5 (80%)]	Loss: nan : nan :: 0.14102 (16.38 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 4.76837158e-06 7.62939453e-06 2.00271606e-05
0:  7.15255737e-05 1.12533569e-04 1.00135803e-04 5.34057617e-05
0:  1.19209290e-04 8.10623169e-05 3.05175781e-05 4.57763672e-05
0:  5.14984131e-05 2.67028809e-05 5.24520874e-05 4.29153479e-05
0:  4.38690222e-05 2.28881836e-05 2.76565552e-05 2.76565552e-05
0:  0.00000000e+00 9.53674316e-07 3.81469727e-06 1.33514404e-05
0:  8.58306885e-05 1.43051147e-04 2.56538391e-04 3.96728516e-04
0:  5.20706177e-04 6.54220581e-04 7.99179077e-04 9.16481018e-04
0:  1.02233887e-03 1.11103058e-03 1.15871429e-03 1.21498108e-03
0:  1.31225586e-03 1.34181976e-03 1.27124786e-03 1.25885010e-03
0:  1.21593475e-03 1.01184845e-03 8.77380371e-04 9.30786133e-04
0:  9.30786133e-04 8.85963440e-04 7.03811646e-04 6.29425049e-04
0:  5.34057617e-04 5.12123108e-04 4.63485718e-04 4.39643860e-04
0:  4.65393066e-04 4.32014465e-04 3.84330750e-04 3.48091125e-04
0:  2.90870667e-04 2.69889832e-04 1.11579895e-04 3.24249268e-05
0:  1.33514404e-05 7.62939453e-06 9.53674316e-07 9.53674316e-07
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 1.14440918e-05 3.81469727e-05 9.34600830e-05
0:  1.48773193e-04 2.10762024e-04 1.42097473e-04 8.01086426e-05
0:  3.62396240e-05 2.00271606e-05 3.24249268e-05 3.52859497e-05
0:  4.38690222e-05 1.07765198e-04 1.41143799e-04 1.51634216e-04
0:  1.06811523e-04 6.00814819e-05 1.23977661e-04 6.67572021e-05
0:  0.00000000e+00 2.86102295e-06 3.14712524e-05 6.86645508e-05
0:  1.54495239e-04 2.71797180e-04 4.24385071e-04 5.72204532e-04
0:  7.27653503e-04 8.84056091e-04 1.03759754e-03 1.16252899e-03
0:  1.39141083e-03 1.43909454e-03 1.48296356e-03 1.33514404e-03
0:  1.63650513e-03 1.74713135e-03 1.25122070e-03 1.15776062e-03
0:  1.05476379e-03 8.82148743e-04 8.52584839e-04 9.19342041e-04
0:  9.24110413e-04 8.89778137e-04 7.97271729e-04 7.83920288e-04]
0: Target values (first 200):
0: [4.29153442e-06 0.00000000e+00 0.00000000e+00 9.53674316e-07
0:  2.38418579e-06 2.38418579e-06 2.38418579e-06 1.43051147e-06
0:  1.43051147e-06 9.53674316e-07 9.53674316e-06 1.14440918e-05
0:  1.62124634e-05 8.58306885e-06 9.53674316e-07 4.76837158e-07
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 4.76837158e-07 2.38418579e-06 1.04904175e-05
0:  1.90734863e-05 3.00407410e-05 4.48226929e-05 6.19888306e-05
0:  7.43865967e-05 6.10351562e-05 6.43730164e-05 7.82012939e-05
0:  1.09672546e-04 1.59263611e-04 2.36034393e-04 4.67300415e-04
0:  6.98566437e-04 9.95635986e-04 1.20496750e-03 1.55448914e-03
0:  2.25925446e-03 2.29930878e-03 2.05039978e-03 1.28936768e-03
0:  5.86986484e-04 4.13417816e-04 2.10762024e-04 1.23977661e-04
0:  1.18732452e-04 1.02043152e-04 7.43865967e-05 5.67436218e-05
0:  3.86238098e-05 2.09808350e-05 1.04904175e-05 6.19888306e-06
0:  9.53674316e-07 0.00000000e+00 1.04904175e-05 1.14440918e-05
0:  5.10215759e-05 9.53674316e-05 1.58786774e-04 1.22070312e-04
0:  3.71932983e-05 1.90734863e-05 2.86102295e-06 1.90734863e-06
0:  1.33514404e-05 7.15255737e-06 4.76837158e-06 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 4.76837158e-07 1.43051147e-06 4.76837158e-06
0:  1.00135803e-05 1.66893005e-05 2.28881836e-05 3.86238098e-05
0:  6.10351562e-05 9.53674316e-05 9.67979431e-05 1.07288361e-04
0:  1.57833099e-04 2.46524811e-04 3.48567963e-04 6.22272491e-04
0:  8.49246979e-04 1.21545792e-03 1.33562088e-03 1.41286850e-03
0:  1.64127350e-03 1.63030624e-03 5.83648682e-04 3.44276428e-04
0:  1.35898590e-04 8.20159912e-05 5.05447388e-05 4.91142273e-05
0:  4.76837158e-05 4.38690222e-05 2.62260437e-05 9.53674316e-06]
0: Prediction values (first 20):
0: [3.4359531 3.4336965 3.5557358 3.8095393 4.05313   4.2644176 4.464443
0:  4.5797243 4.7043543 4.792283  4.852625  4.880561  4.898745  4.8966575
0:  4.9042015 4.9079504 4.901012  4.878093  4.880466  4.877421 ]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -2.029, max = 2.585, mean = 0.495
0:          sample (first 20): tensor([-0.2780, -0.2782, -0.2679, -0.2464, -0.2258, -0.2079, -0.1910, -0.1813, -0.1707, -0.1633, -0.1582, -0.1558,
0:         -0.1543, -0.1545, -0.1538, -0.1535, -0.1541, -0.1560, -0.2338, -0.2351])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.436201 23.31254  23.190067 22.979124 22.721464 22.401703 22.013494
0:  21.529081 21.001223 20.442038 19.84352  19.218674 18.62023  18.060312
0:  17.523848 17.075869 16.7258   16.455074 15.972811 15.555828]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.744394 19.81922  19.873652 19.849964 19.78483  19.689451 19.646585
0:  19.580608 19.596558 19.656702 19.680984 19.674461 19.649479 19.62501
0:  19.617952 19.634733 19.66876  19.721642 19.44372  19.487478]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.00036  23.365627 22.904623 22.504353 22.226585 21.981049 21.91582
0:  21.738195 21.669727 21.599833 21.49341  21.447626 21.466833 21.545704
0:  21.68628  21.86625  21.976284 21.93834  21.730183 21.48774 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.362405  4.3147182 4.281916  4.2696857 4.3336115 4.4503026 4.6191483
0:  4.8201733 5.066563  5.333358  5.6081977 5.84006   6.0521097 6.241949
0:  6.3920937 6.5466347 6.6868424 6.8465433 7.456045  7.628095 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.244394 25.357449 25.52797  25.736807 25.98321  26.28122  26.63116
0:  26.943483 27.305656 27.658388 27.951044 28.180908 28.400928 28.555326
0:  28.724321 28.851713 28.987402 29.086376 29.018957 29.286781]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.054304 21.079973 21.135618 21.171259 21.181866 21.169647 21.129116
0:  21.057617 21.00005  20.96611  20.934376 20.896452 20.899551 20.891914
0:  20.880177 20.839048 20.790583 20.740522 20.167522 20.072233]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.5258422   0.39222574  0.32607508  0.26447964  0.25422144  0.28514004
0:   0.3399725   0.31536198  0.1707673  -0.13097715 -0.57846975 -1.2118702
0:  -1.8994689  -2.5773215  -3.2818122  -3.9084277  -4.4723372  -4.939753
0:  -6.3870883  -6.9865193 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.6672764  2.4563594  2.2691345  2.0959244  1.9447398  1.7711802
0:  1.5849223  1.3626971  1.1410832  0.95920753 0.843699   0.7353592
0:  0.6428056  0.5782156  0.45684242 0.38900614 0.38884306 0.4568715
0:  0.3954234  0.6778102 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.9139268 3.9545949 4.00136   4.048458  4.1626873 4.2649903 4.3803473
0:  4.461023  4.525155  4.6006374 4.6820726 4.6740866 4.612995  4.494828
0:  4.2960873 4.1427946 4.0300527 3.9596539 3.4352944 3.318369 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.708348  6.706609  6.66104   6.5265574 6.3011336 6.0258136 5.7470202
0:  5.544051  5.4388185 5.387627  5.3686633 5.243812  5.0458503 4.8332796
0:  4.6427507 4.5881724 4.6392646 4.6967545 4.65471   4.5457973]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.747288 20.804153 20.835938 20.794628 20.716324 20.657162 20.66102
0:  20.630705 20.67868  20.740406 20.773563 20.749378 20.719984 20.665085
0:  20.602537 20.566998 20.593319 20.636509 20.55045  20.628769]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.6938567  -5.7755055  -5.644832   -5.3006806  -4.781383   -4.243547
0:  -3.6915498  -3.272162   -2.9501796  -2.6740537  -2.4107938  -2.1923394
0:  -1.9763894  -1.7224345  -1.5444026  -1.3179832  -1.113153   -0.93797255
0:  -0.9175544  -1.1371169 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.9195666 -4.0476823 -4.107057  -4.121882  -4.1069207 -4.1174083
0:  -4.1379075 -4.2038226 -4.2657056 -4.31574   -4.321525  -4.3171144
0:  -4.297665  -4.2507424 -4.2449546 -4.2337537 -4.206899  -4.1293263
0:  -4.0115438 -3.9870152]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.5016327 4.033131  3.645687  3.429545  3.3960264 3.460482  3.563434
0:  3.6285954 3.6855795 3.7358081 3.8602898 4.012023  4.2335215 4.5148544
0:  4.7651024 4.9993243 5.192557  5.3530874 5.1836343 4.822038 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.322445  13.524893  13.737059  13.904907  14.004637  14.012753
0:  13.913334  13.678018  13.379334  13.0190115 12.615438  12.216551
0:  11.902971  11.724846  11.666643  11.708622  11.829645  11.99386
0:  12.316292  12.735256 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -3.609118   -3.8731313  -4.1795135  -4.5941195  -5.1641774  -5.91645
0:   -6.7303777  -7.6094747  -8.429741   -9.181528   -9.825668  -10.424307
0:  -10.953627  -11.390644  -11.8027115 -12.178995  -12.536886  -12.822039
0:  -13.182322  -13.544371 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.080965   -0.9860859  -0.8834028  -0.7466893  -0.59848356 -0.4441762
0:  -0.28799772 -0.17824697 -0.07444239  0.0048337   0.08168602  0.14637375
0:   0.23402643  0.36061144  0.4912181   0.64617205  0.8301163   1.0688539
0:   1.1012936   1.1023126 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.8740416 7.4807982 6.9480915 6.3005714 5.5630345 4.793537  4.107068
0:  3.4909382 2.9740458 2.5703487 2.248734  2.0461173 1.9863496 2.0531702
0:  2.2309494 2.4581218 2.645574  2.8661404 3.4447324 3.7445948]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.354633 15.701308 16.067947 16.498415 16.940853 17.30708  17.730072
0:  17.962444 18.250488 18.476604 18.561985 18.563398 18.529243 18.501682
0:  18.555292 18.730099 18.989525 19.288895 20.530767 21.242619]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.235086 15.338034 15.466005 15.711695 16.092228 16.563206 17.081476
0:  17.493109 17.788359 17.91647  17.836632 17.621407 17.301582 16.934572
0:  16.586252 16.286015 16.121136 16.10408  16.12606  16.182062]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.5391312  1.3699946  1.1943836  1.0337648  0.9547396  0.94146585
0:  1.0754919  1.2819185  1.5867682  1.9302654  2.2871277  2.5883617
0:  2.807587   2.9691813  3.0060425  2.9930458  2.9482982  2.8829622
0:  2.3761673  2.210188  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.603318  5.514002  5.4189944 5.412314  5.446185  5.5092797 5.621786
0:  5.7027035 5.7868814 5.8557596 5.922427  5.9980006 6.1196404 6.2240696
0:  6.301105  6.329503  6.313649  6.3017836 5.3469715 5.253249 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.3738832 6.62146   6.9574914 7.2713184 7.464044  7.5347614 7.5155907
0:  7.402592  7.312326  7.234498  7.184514  7.148357  7.1356    7.1049895
0:  7.016107  6.8503084 6.5957985 6.328076  5.9458113 5.425962 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.034481  6.1125765 6.197937  6.2594867 6.3007226 6.3193855 6.3327017
0:  6.3304586 6.3504233 6.3860397 6.4459987 6.5027757 6.571935  6.644819
0:  6.705252  6.7828054 6.882513  6.9942536 6.9794145 7.055475 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.751995 15.811632 15.883659 15.989105 16.081545 16.158993 16.257498
0:  16.2554   16.282307 16.283989 16.270815 16.278008 16.340988 16.412424
0:  16.487993 16.551327 16.611454 16.718649 16.606173 16.652397]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [28.959663 28.280777 27.58132  26.862932 26.24939  25.679096 25.263632
0:  24.794945 24.421556 23.996542 23.421602 22.777601 22.085281 21.380676
0:  20.721075 20.11616  19.58814  19.147552 18.196932 17.606142]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.3785925 -8.212205  -7.989753  -7.7076836 -7.457595  -7.300705
0:  -7.14581   -7.0537834 -6.974802  -6.851775  -6.747612  -6.6517773
0:  -6.537346  -6.3989677 -6.2446623 -6.0432434 -5.8462973 -5.6423006
0:  -5.5490236 -5.2726183]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.259703  -10.588411  -11.045286  -11.578953  -12.078388  -12.53669
0:  -12.844608  -13.036697  -13.071514  -12.9480095 -12.712282  -12.453972
0:  -12.212135  -11.92104   -11.680237  -11.410969  -11.098679  -10.781746
0:  -10.678608  -10.5303135]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.8214307 -4.1318364 -4.4907136 -4.8885484 -5.268356  -5.652447
0:  -5.9930587 -6.3203664 -6.6004214 -6.796208  -6.9133296 -7.0206723
0:  -7.128592  -7.2205195 -7.3895392 -7.5348496 -7.6358037 -7.687308
0:  -8.442419  -8.522871 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.5901146  -0.516314   -0.3399005  -0.15253782 -0.01575327 -0.08824778
0:  -0.24229431 -0.4023757  -0.3318262   0.13865948  0.96763897  1.9567213
0:   2.899045    3.622992    4.01997     4.2186933   4.3766913   4.5523314
0:   4.506045    4.3429666 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.9020934 -3.9408937 -4.0066886 -4.12662   -4.2643666 -4.3983026
0:  -4.4588513 -4.441817  -4.329243  -4.13042   -3.9105601 -3.7531466
0:  -3.7109694 -3.7808938 -4.031154  -4.3723416 -4.751908  -5.0975223
0:  -5.5674167 -5.7635427]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.82911  18.174778 18.513378 18.933872 19.336765 19.754402 20.231365
0:  20.584778 21.021397 21.447613 21.878464 22.370934 22.9502   23.54771
0:  24.193623 24.78915  25.345394 25.851078 26.396507 26.86364 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.535097 24.485292 24.374285 24.207205 24.034893 23.861105 23.67943
0:  23.444397 23.292488 23.178349 23.140306 23.154076 23.232533 23.39758
0:  23.612156 23.890007 24.207525 24.531456 24.594454 24.926508]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.156046  -6.2016773 -6.2192116 -6.209403  -6.1746902 -6.1486826
0:  -6.128318  -6.1458797 -6.162402  -6.1660976 -6.120414  -6.0733967
0:  -5.9824076 -5.863841  -5.7489243 -5.644821  -5.5709314 -5.466153
0:  -5.7685537 -5.8090105]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.366991 19.399591 19.427574 19.46458  19.54333  19.71455  20.018042
0:  20.339571 20.82331  21.40684  22.083427 22.867422 23.726622 24.602037
0:  25.47777  26.23885  26.908491 27.40723  27.30331  27.625267]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.339612  4.6956654 5.0161586 5.3430524 5.6563406 5.9476657 6.195363
0:  6.3470473 6.4245324 6.4058948 6.2840176 6.0572424 5.778446  5.5108404
0:  5.3181477 5.2418265 5.3469286 5.5969834 5.914185  6.211022 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.3054609  -1.3626709  -1.3577414  -1.2814913  -1.1279097  -0.9897728
0:  -0.8654709  -0.7635102  -0.702816   -0.6023712  -0.4880085  -0.44366932
0:  -0.41392517 -0.422287   -0.5198097  -0.6417675  -0.8130975  -1.0405245
0:  -2.3500576  -2.5356388 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.500183  -6.4042234 -6.248893  -6.059168  -5.847246  -5.6635685
0:  -5.48254   -5.34921   -5.213955  -5.0705957 -4.908781  -4.7861156
0:  -4.670208  -4.531933  -4.42605   -4.30291   -4.206936  -4.0868673
0:  -4.456031  -4.3790855]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.90828   6.2447443 6.5671053 6.8834343 7.1856146 7.474429  7.7716007
0:  7.9755726 8.149668  8.250903  8.268719  8.258987  8.265459  8.255731
0:  8.269089  8.301734  8.356455  8.446314  8.3906765 8.77062  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.63172  22.819735 23.015953 23.196161 23.35397  23.453285 23.50808
0:  23.455196 23.389206 23.290064 23.13157  22.977776 22.829765 22.68525
0:  22.56175  22.412006 22.289392 22.199404 22.124256 22.194435]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.4783764  -1.4460583  -1.3481894  -1.1613264  -0.8709502  -0.54128504
0:  -0.17404318  0.13396597  0.40032482  0.61477613  0.78728294  0.87626314
0:   0.9109125   0.9234929   0.88895464  0.9102359   0.9613657   1.0320559
0:   0.67075825  0.58540916]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.0042543  -3.1200533  -3.1419048  -3.0932856  -3.0074005  -2.9924107
0:  -3.0481844  -3.1567955  -3.1344004  -2.8989162  -2.4112806  -1.7937412
0:  -1.1717119  -0.60624456 -0.2773323  -0.07985592  0.05718517  0.14885092
0:   0.38435316  0.3514657 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.2649417 -5.307297  -5.294518  -5.226564  -5.135162  -5.077788
0:  -5.0207953 -5.0068936 -5.015734  -5.011863  -4.988545  -4.97127
0:  -4.9166512 -4.847017  -4.8033957 -4.7090297 -4.589289  -4.421538
0:  -4.3784995 -4.414578 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.46853495 -0.4110713  -0.29207754 -0.12762499  0.07899618  0.31511545
0:   0.610538    0.8963456   1.1849236   1.4779534   1.7457519   1.9986353
0:   2.2702093   2.5308213   2.821165    3.140231    3.4634123   3.8043175
0:   3.912344    4.1426115 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.950106 19.710608 20.460968 21.15302  21.800522 22.413372 23.00467
0:  23.477507 23.934578 24.317776 24.633888 24.844585 24.98439  25.04506
0:  25.067104 25.075205 25.11614  25.13608  24.204416 24.100294]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.288154  -6.3356843 -6.3865867 -6.43028   -6.457421  -6.481196
0:  -6.435329  -6.361012  -6.209971  -6.002092  -5.747728  -5.5142083
0:  -5.3298793 -5.1697116 -5.1176677 -5.092589  -5.074596  -5.0311017
0:  -5.6598945 -5.719361 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.817643  8.745306  8.69557   8.573779  8.404074  8.114631  7.788203
0:  7.4506807 7.1422973 7.024632  7.0580387 7.24609   7.53222   7.8902144
0:  8.225485  8.549839  8.788668  8.968489  9.255414  9.758571 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.603823  -9.661291  -9.720556  -9.748938  -9.740799  -9.7290745
0:  -9.664448  -9.6423645 -9.565636  -9.465424  -9.291634  -9.086645
0:  -8.811035  -8.469683  -8.13994   -7.775971  -7.415833  -7.049296
0:  -6.8217406 -6.6951776]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.25573  21.804707 21.263971 20.61403  19.919245 19.210897 18.599646
0:  18.005222 17.500288 17.05568  16.56758  16.074226 15.590786 15.094788
0:  14.620094 14.144278 13.662378 13.222103 12.622152 11.973761]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.499945 14.782379 15.152317 15.678768 16.231815 16.762234 17.397547
0:  17.92096  18.528938 19.167294 19.757593 20.36146  21.004442 21.648432
0:  22.294529 22.906322 23.45152  23.897354 23.590677 23.809774]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.12253   -3.8298235 -3.611476  -3.4670868 -3.326168  -3.2353792
0:  -3.1650705 -3.1524668 -3.1733913 -3.1998243 -3.244913  -3.3307276
0:  -3.4106283 -3.4685478 -3.5219994 -3.5113325 -3.442194  -3.357294
0:  -3.8567762 -3.652485 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.42936516  0.27028322  0.15880299  0.10049772  0.05186796 -0.03319836
0:  -0.11531973 -0.26044846 -0.40702343 -0.5651736  -0.7257743  -0.90329885
0:  -1.0698614  -1.2149649  -1.365057   -1.4889331  -1.5948691  -1.6759658
0:  -2.019011   -2.051536  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.633698   9.771973   8.754169   7.8073854  7.153862   6.6983995
0:   6.4853745  6.334899   6.2033234  6.155485   6.138335   6.113661
0:   6.140381   6.148692   5.952389   5.8045506  5.738569   5.7713223
0:   6.8543944  6.965554 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.525316 21.54645  21.545698 21.488232 21.401604 21.30601  21.242561
0:  21.14832  21.113098 21.0879   21.039396 20.959946 20.881487 20.810062
0:  20.744806 20.700882 20.677523 20.650719 20.349207 20.249365]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.839514 21.01158  20.756693 19.821762 18.504698 17.013592 15.705839
0:  14.866224 14.561586 14.743214 15.237617 15.813931 16.304482 16.585873
0:  16.466389 15.999414 15.295439 14.492171 13.234341 12.852379]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.57970905  1.0123019   1.3309612   1.559917    1.7725835   1.9730067
0:   1.9747472   1.7486067   1.3495007   0.7284236   0.07038069 -0.65296507
0:  -1.2191873  -1.556232   -1.6115766  -1.239613   -0.42140055  0.70735836
0:  -1.965281   -1.3361106 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.55252    5.3048625  5.0206013  4.671936   4.331135   3.9414868
0:  3.5733955  3.1817353  2.8433013  2.5680113  2.3705907  2.1891217
0:  2.0239506  1.9172888  1.7629023  1.6409092  1.5290847  1.4205418
0:  0.74000597 0.5073347 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.9252324 -1.019156  -1.1116996 -1.2291403 -1.3714814 -1.5814118
0:  -1.8297582 -2.168445  -2.533586  -2.8991055 -3.2292552 -3.53332
0:  -3.7636876 -3.8787246 -3.9582906 -3.9544196 -3.9272199 -3.897015
0:  -4.0962234 -4.1675324]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-14.031664  -13.803141  -13.337446  -12.673111  -11.9066105 -11.157173
0:  -10.47019    -9.958769   -9.60511    -9.382473   -9.2318325  -9.173473
0:   -9.118761   -9.065767   -9.0420685  -9.014105   -9.007231   -8.962931
0:   -9.348043   -9.244638 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.214889  -7.259338  -7.2926154 -7.3178496 -7.305589  -7.3043494
0:  -7.271832  -7.2585626 -7.225446  -7.1503177 -7.0320973 -6.9174304
0:  -6.804072  -6.673427  -6.597652  -6.5089726 -6.4181476 -6.320415
0:  -6.5076165 -6.4676633]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [31.9859   32.33088  32.685074 33.02885  33.344883 33.616905 33.9401
0:  34.03616  34.165756 34.198906 34.126324 33.96835  33.80697  33.68528
0:  33.651276 33.700268 33.788273 33.855473 34.83009  35.126945]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-11.174529  -10.762803  -10.298299   -9.751412   -9.139873   -8.517837
0:   -7.8075695  -7.1794415  -6.611005   -6.128439   -5.726802   -5.4477806
0:   -5.2654104  -5.1585875  -5.1553116  -5.1454697  -5.143862   -5.1019373
0:   -6.999714   -7.3429213]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [28.002949 28.333286 28.622654 28.941164 29.233885 29.496044 29.830143
0:  30.04762  30.297403 30.519073 30.654512 30.817406 30.982443 31.1567
0:  31.324722 31.432962 31.49749  31.480091 31.522308 31.62453 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.070093 18.322916 18.615479 18.879084 19.140911 19.375128 19.590967
0:  19.744453 19.862722 19.894941 19.861135 19.740423 19.590532 19.436565
0:  19.26866  19.139277 19.042484 18.967962 19.565907 19.741686]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.311002  7.200358  7.1531086 7.1080923 7.049755  6.9736342 6.911166
0:  6.822086  6.7627397 6.753394  6.753174  6.7397943 6.7538853 6.8006873
0:  6.844065  6.9390955 7.051985  7.1780963 7.374088  7.427982 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.810241  6.590604  6.3699355 6.170333  6.009055  5.847119  5.710879
0:  5.559853  5.4106116 5.2552795 5.0821795 4.831572  4.5372763 4.196124
0:  3.756039  3.3002622 2.887343  2.5523093 2.2742386 2.1148953]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.094433 24.153347 24.412228 24.822567 25.19474  25.40366  25.60645
0:  25.68724  25.78841  25.940338 26.02972  26.177353 26.424011 26.77253
0:  27.272232 27.78204  28.293438 28.742588 28.840332 28.970417]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.66557264 0.6479974  0.67235804 0.73302364 0.78272104 0.8060045
0:  0.8348422  0.8077731  0.78850746 0.76587486 0.75911283 0.7506652
0:  0.77048016 0.82027864 0.85965776 0.9205775  1.0019364  1.1420898
0:  0.8793869  0.77205324]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.3897276 -1.3746576 -1.3817463 -1.5012074 -1.7442684 -2.099306
0:  -2.4782772 -2.7852983 -2.949091  -2.9170923 -2.755621  -2.6162367
0:  -2.5542107 -2.6139822 -2.8016968 -2.9911509 -3.1220016 -3.1704216
0:  -3.070445  -2.8054686]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.3334727 -2.3113484 -2.2963777 -2.3075109 -2.3239741 -2.372476
0:  -2.4052825 -2.4806256 -2.5318007 -2.5612035 -2.5803285 -2.6277509
0:  -2.663526  -2.690765  -2.7488933 -2.7631059 -2.7748418 -2.7737803
0:  -3.0148787 -3.014442 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.1141634 4.219829  4.3302007 4.4249587 4.502166  4.5244303 4.5899725
0:  4.613388  4.6685724 4.7126236 4.748822  4.7476187 4.7616787 4.776053
0:  4.7929983 4.8643236 4.9571133 5.085427  4.524299  4.6015863]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.15123081  0.27169895  0.39496326  0.64042044  0.9722948   1.3067122
0:   1.7126851   2.0239973   2.4999113   3.0769186   3.8263292   4.8715563
0:   6.198319    7.8474326   9.621403   11.3914795  13.041828   14.538895
0:  17.031733   18.070799  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.369692 20.329712 20.342615 20.328484 20.288504 20.194925 20.079517
0:  19.838987 19.564537 19.245451 18.840427 18.464869 18.150742 17.822342
0:  17.507526 17.084814 16.596739 16.099293 14.058035 13.700517]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.2134311   1.9580269   1.7146864   1.4968219   1.3408518   1.2382278
0:   1.1976881   1.1493897   1.1115279   1.025487    0.9258256   0.7511616
0:   0.5545211   0.3909011   0.1987381   0.07625008 -0.0304985  -0.14274502
0:  -0.20103693 -0.12279987]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.045202  -6.9294705 -6.791249  -6.687904  -6.627665  -6.6416106
0:  -6.6878304 -6.790093  -6.8642764 -6.8720107 -6.756207  -6.575953
0:  -6.307938  -5.9184117 -5.525868  -5.0948253 -4.7274404 -4.491918
0:  -4.4875245 -4.623729 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.427386  13.404904  13.409405  13.418659  13.4110985 13.390295
0:  13.371464  13.350628  13.36109   13.375463  13.39489   13.366504
0:  13.360581  13.348189  13.336753  13.338209  13.340235  13.378113
0:  13.693881  13.768007 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.2510114 -2.7757373 -3.338717  -3.8681397 -4.3026557 -4.6945205
0:  -5.087091  -5.507602  -5.9488206 -6.3974013 -6.8152947 -7.204763
0:  -7.5579276 -7.834596  -8.084084  -8.228886  -8.26552   -8.198639
0:  -8.496456  -8.712524 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.476706  14.480942  14.570347  14.6553955 14.739872  14.805725
0:  14.851273  14.838062  14.842234  14.855892  14.873915  14.882166
0:  14.910561  14.956409  15.03113   15.13398   15.278513  15.458746
0:  16.087255  16.214304 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.236065  -9.108409  -8.980428  -8.778939  -8.578945  -8.433063
0:  -8.2665825 -8.19802   -8.1607895 -8.132862  -8.09296   -8.03321
0:  -7.916171  -7.753249  -7.610606  -7.4770555 -7.368512  -7.227604
0:  -7.58825   -7.4710684]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [35.433315 34.563843 32.729534 29.778545 26.243793 22.853779 20.170593
0:  18.549904 17.956982 18.115036 18.667225 19.307468 20.05429  20.929585
0:  21.887062 22.889324 23.77016  24.357334 25.676865 26.165104]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.249142 27.337273 27.381596 27.392803 27.433712 27.51764  27.65445
0:  27.745506 27.879784 28.008312 28.04779  28.05988  28.037243 27.893127
0:  27.661469 27.315289 26.885624 26.394798 24.596382 24.157234]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.149538   -3.1957989  -3.0809422  -2.793254   -2.3834543  -1.9637833
0:  -1.5210838  -1.1486864  -0.8394203  -0.59015703 -0.3679862  -0.19644594
0:   0.02938557  0.25997543  0.4996271   0.7615099   1.0383205   1.2979879
0:   0.8083987   0.8436899 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.340057  -4.414907  -4.4536576 -4.4892764 -4.483725  -4.5088296
0:  -4.52904   -4.5917554 -4.6158566 -4.5984826 -4.477774  -4.3208766
0:  -4.1192384 -3.8666215 -3.6603541 -3.410421  -3.151258  -2.8963847
0:  -2.3111625 -2.3383594]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.00131   12.924408  12.831445  12.646039  12.386738  12.026773
0:  11.564604  11.028821  10.512635  10.060698   9.694498   9.400132
0:   9.190134   9.0506115  8.960624   8.969769   9.085943   9.259756
0:   9.50251    9.191704 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.2368975e-01 -4.3780327e-01 -3.0109739e-01 -1.7118406e-01
0:  -4.9242020e-02  9.3221664e-04 -5.7566643e-02 -2.8260851e-01
0:  -6.3099813e-01 -1.0834255e+00 -1.5517793e+00 -2.0198102e+00
0:  -2.3954377e+00 -2.6185031e+00 -2.7552714e+00 -2.7810264e+00
0:  -2.7619624e+00 -2.7508302e+00 -3.8567185e+00 -4.2387395e+00]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.3069916 -1.8031731 -2.2967029 -2.7249093 -3.046142  -3.3023362
0:  -3.4535556 -3.5546393 -3.5521188 -3.4748387 -3.2859378 -3.071673
0:  -2.8033452 -2.4893374 -2.2525887 -2.0152202 -1.842587  -1.7585177
0:  -1.2908039 -1.3739438]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.1534247 2.4988973 2.8687415 3.1372051 3.3639414 3.3726654 3.3399162
0:  3.1572044 3.0645747 2.9416838 2.7820914 2.5876954 2.300702  2.0420785
0:  1.8003545 1.6197839 1.5752878 1.5912986 1.7452164 1.7999439]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.831451 21.059622 21.380463 21.778511 22.205961 22.620197 23.08548
0:  23.455185 23.844278 24.2471   24.637167 25.076792 25.538025 26.074705
0:  26.618282 27.169323 27.735197 28.268803 28.628475 29.149714]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.94178534 -0.65674543 -0.31896448  0.0424819   0.47142696  0.9396548
0:   1.4990225   2.0811782   2.7239828   3.4367237   4.22823     5.0409675
0:   5.9259496   6.8147783   7.6936016   8.556533    9.389528   10.136662
0:  11.666027   12.647968  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.371987   6.135676   7.088837   8.007639   8.804398   9.432032
0:   9.880781  10.209305  10.491381  10.767967  11.079439  11.377426
0:  11.671585  11.937827  12.185331  12.429027  12.694473  12.9831085
0:  12.827728  13.040835 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.556681 10.829151 11.174181 11.459042 11.733425 12.08906  12.457805
0:  12.909097 13.614487 14.390038 15.22402  15.921305 16.564102 17.114998
0:  17.608284 18.061165 18.54101  18.928051 20.18141  20.25174 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.787159  -8.643196  -8.512253  -8.393257  -8.298864  -8.284941
0:  -8.263491  -8.328579  -8.381205  -8.41905   -8.422804  -8.400574
0:  -8.354666  -8.240534  -8.126759  -7.9438434 -7.7097306 -7.411857
0:  -7.424604  -7.0564   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.0054   13.062086 13.074375 12.916018 12.820256 12.847584 13.052713
0:  13.315489 13.649361 13.99837  14.484467 15.073444 15.861725 16.706564
0:  17.349623 17.6977   17.66202  17.430622 17.20315  16.640823]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.317493  14.4311695 14.466911  14.483433  14.454021  14.379627
0:  14.298882  14.129585  13.936953  13.698675  13.40253   13.065358
0:  12.74268   12.398301  12.034456  11.654303  11.290873  11.00194
0:  10.477228  10.159918 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.921105  -4.7732253 -4.50719   -4.171943  -3.8036847 -3.462009
0:  -3.1282458 -2.8729138 -2.6579356 -2.500832  -2.4076428 -2.4344993
0:  -2.5372872 -2.676869  -2.8909316 -3.0709643 -3.2146392 -3.31066
0:  -3.5768695 -3.4105887]
0: validation loss for strategy=forecast at epoch 10 : nan
0: validation loss for velocity_u : 0.0354112945497036
0: validation loss for velocity_v : 0.064341701567173
0: validation loss for specific_humidity : 0.029097868129611015
0: validation loss for velocity_z : 0.5839282274246216
0: validation loss for temperature : 0.06633580476045609
0: validation loss for total_precip : nan
0: 11 : 10:30:45 :: batch_size = 96, lr = 1.601456723537741e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 11, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.0309, -1.0545, -1.0702, -1.0795, -1.0839, -1.0842, -1.0812, -1.0747, -1.0652, -1.0533, -1.0404, -1.0268,
0:         -1.0124, -0.9966, -0.9791, -0.9607, -0.9430, -0.9269, -0.8779, -0.9284, -0.9704, -1.0047, -1.0324, -1.0542,
0:         -1.0699], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2463, -0.2438, -0.2452, -0.2481, -0.2499, -0.2502, -0.2483, -0.2450, -0.2401, -0.2331, -0.2247, -0.2161,
0:         -0.2087, -0.2034, -0.1995, -0.1958, -0.1909, -0.1843, -0.3594, -0.3348, -0.3176, -0.3047, -0.2932, -0.2813,
0:         -0.2692], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6855, -0.6823, -0.6790, -0.6740, -0.6690, -0.6630, -0.6567, -0.6502, -0.6439, -0.6376, -0.6309, -0.6237,
0:         -0.6165, -0.6076, -0.5988, -0.5910, -0.5835, -0.5761, -0.6902, -0.6893, -0.6879, -0.6857, -0.6849, -0.6836,
0:         -0.6820], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.6016, 0.6417, 0.6753, 0.7295, 0.8108, 0.8954, 0.9485, 0.9550, 0.9279, 0.8975, 0.8769, 0.8596, 0.8282, 0.7805,
0:         0.7328, 0.6992, 0.6764, 0.6472, 0.4282, 0.4716, 0.5139, 0.5854, 0.7003, 0.8390, 0.9506], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([1.3634, 1.3718, 1.3764, 1.3768, 1.3736, 1.3659, 1.3535, 1.3368, 1.3170, 1.2946, 1.2704, 1.2437, 1.2144, 1.1814,
0:         1.1457, 1.1084, 1.0705, 1.0328, 0.9951, 0.9568, 0.9177, 0.8782, 0.8382, 0.7980, 0.7576], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 11, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2241,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2241,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2220, -0.2220,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2198, -0.2198,     nan,
0:             nan,     nan, -0.2198,     nan,     nan,     nan,     nan, -0.2177,     nan,     nan,     nan, -0.2155,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2155,     nan,     nan, -0.2047,     nan,     nan,
0:         -0.2198,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2263,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2241,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2198, -0.2177,     nan,     nan,     nan,     nan, -0.2198,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2198, -0.2177,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2177,
0:         -0.2155,     nan,     nan,     nan,     nan,     nan, -0.2263,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2241,     nan,     nan,     nan,
0:             nan,     nan, -0.2263,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2047,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2112,     nan,     nan])
0: [DEBUG] Epoch 11, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.2236, 0.2221, 0.2272, 0.2295, 0.2364, 0.2425, 0.2467, 0.2491, 0.2513, 0.2557, 0.2624, 0.2688, 0.2772, 0.2887,
0:         0.2948, 0.2993, 0.3019, 0.3020, 0.1532, 0.1522, 0.1545, 0.1598, 0.1668, 0.1750, 0.1836], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.5647, -0.5640, -0.5584, -0.5476, -0.5354, -0.5198, -0.5080, -0.4971, -0.4848, -0.4687, -0.4543, -0.4389,
0:         -0.4275, -0.4191, -0.4145, -0.4063, -0.3959, -0.3804, -0.5315, -0.5281, -0.5197, -0.5062, -0.4887, -0.4738,
0:         -0.4584], device='cuda:1', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.6335, -0.6367, -0.6401, -0.6392, -0.6393, -0.6375, -0.6355, -0.6328, -0.6316, -0.6305, -0.6291, -0.6295,
0:         -0.6314, -0.6333, -0.6374, -0.6394, -0.6395, -0.6370, -0.6155, -0.6169, -0.6162, -0.6139, -0.6102, -0.6069,
0:         -0.6029], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.1271, -0.1119, -0.1031, -0.0997, -0.0861, -0.0941, -0.1097, -0.1231, -0.1292, -0.1369, -0.1536, -0.1505,
0:         -0.1370, -0.1484, -0.1736, -0.1970, -0.2007, -0.1981, -0.1032, -0.1090, -0.1055, -0.0925, -0.0664, -0.0595,
0:         -0.0751], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([0.4190, 0.4111, 0.4069, 0.4008, 0.3961, 0.3915, 0.3878, 0.3810, 0.3734, 0.3658, 0.3585, 0.3544, 0.3533, 0.3503,
0:         0.3465, 0.3405, 0.3331, 0.3271, 0.3246, 0.3227, 0.3222, 0.3218, 0.3221, 0.3211, 0.3188], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.07548396289348602; velocity_v: 0.10829761624336243; specific_humidity: 0.035605672746896744; velocity_z: 0.5408990383148193; temperature: 0.12123209238052368; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05976623669266701; velocity_v: 0.10164774954319; specific_humidity: 0.044570017606019974; velocity_z: 0.49958449602127075; temperature: 0.10410451889038086; total_precip: nan; 
0: epoch: 11 [1/5 (20%)]	Loss: nan : nan :: 0.14831 (2.55 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.07742621004581451; velocity_v: 0.11190244555473328; specific_humidity: 0.04243539646267891; velocity_z: 0.5099485516548157; temperature: 0.10923963785171509; total_precip: nan; 
0: epoch: 11 [2/5 (40%)]	Loss: nan : nan :: 0.16233 (16.20 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05490829423069954; velocity_v: 0.09835883229970932; specific_humidity: 0.04037627577781677; velocity_z: 0.6173516511917114; temperature: 0.1125449389219284; total_precip: nan; 
0: epoch: 11 [3/5 (60%)]	Loss: nan : nan :: 0.13885 (16.24 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05515129491686821; velocity_v: 0.10128116607666016; specific_humidity: 0.041877634823322296; velocity_z: 0.46263718605041504; temperature: 0.09451968967914581; total_precip: nan; 
0: epoch: 11 [4/5 (80%)]	Loss: nan : nan :: 0.13669 (16.22 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [2.11715698e-04 2.35557556e-04 2.48908997e-04 2.84671783e-04
0:  3.20434570e-04 3.68595123e-04 4.27722931e-04 5.09738922e-04
0:  5.65528870e-04 6.22749329e-04 7.05242157e-04 7.68184662e-04
0:  8.13484192e-04 8.49246979e-04 9.00745392e-04 9.56535339e-04
0:  1.00564968e-03 1.06000912e-03 1.11341476e-03 1.14583969e-03
0:  1.19256973e-03 1.23310089e-03 1.24025345e-03 1.23023987e-03
0:  1.25503540e-03 1.25885010e-03 1.24025345e-03 1.23262405e-03
0:  1.23453140e-03 1.24073029e-03 1.22547150e-03 1.19781494e-03
0:  1.20019913e-03 1.19638443e-03 1.15489960e-03 1.09481812e-03
0:  1.06906891e-03 1.00564968e-03 9.18388367e-04 8.19683075e-04
0:  7.32421875e-04 6.35147095e-04 5.37872314e-04 4.61101532e-04
0:  3.57151031e-04 2.64644623e-04 2.09331512e-04 1.76906586e-04
0:  1.09195709e-04 6.72340393e-05 4.86373901e-05 4.14848328e-05
0:  1.95503235e-05 9.53674316e-06 6.67572021e-06 6.19888306e-06
0:  2.38418579e-06 9.53674316e-07 9.53674316e-07 1.43051147e-06
0:  1.43051147e-06 2.38418579e-06 2.86102295e-06 3.33786011e-06
0:  3.81469727e-06 2.86102295e-06 2.38418579e-06 2.86102295e-06
0:  3.33786011e-06 4.29153442e-06 6.19888306e-06 7.15255737e-06
0:  8.10623169e-06 1.09672546e-05 1.38282776e-05 1.47819519e-05
0:  1.62124634e-05 1.71661377e-05 1.62124634e-05 1.57356262e-05
0:  1.71661377e-05 1.76429749e-05 1.81198120e-05 1.81198120e-05
0:  1.57356262e-05 1.76429749e-05 2.14576721e-05 3.00407410e-05
0:  3.71932983e-05 4.76837158e-05 5.91278076e-05 6.86645508e-05
0:  7.96318054e-05 8.15391541e-05 8.86917114e-05 1.08242035e-04
0:  1.41620636e-04 1.34468079e-04 1.17778778e-04 1.06811523e-04
0:  9.58442688e-05 1.13487244e-04 1.29699707e-04 1.44958496e-04
0:  1.42574310e-04 1.35898590e-04 1.24931335e-04 1.42097473e-04
0:  2.85625458e-04 2.95162201e-04 3.17573547e-04 3.60965729e-04
0:  4.05311584e-04 4.72545624e-04 5.38349152e-04 6.27994537e-04
0:  7.12394714e-04 7.92503357e-04 8.75473022e-04 9.36031342e-04
0:  1.00040436e-03 1.04904186e-03 1.10244751e-03 1.15871429e-03
0:  1.18827820e-03 1.23882294e-03 1.26934052e-03 1.29842758e-03
0:  1.31320953e-03 1.31559372e-03 1.30748749e-03 1.29222870e-03
0:  1.27506256e-03 1.25455856e-03 1.23119354e-03 1.21736526e-03
0:  1.19781494e-03 1.17444992e-03 1.14583969e-03 1.10769272e-03
0:  1.06525421e-03 1.01137161e-03 9.56535339e-04 8.85486603e-04
0:  8.13961029e-04 7.21454620e-04 6.32286072e-04 5.38349152e-04
0:  4.43458557e-04 3.66210938e-04 2.75611877e-04 2.25543976e-04
0:  1.54972076e-04 1.25408173e-04 7.53402710e-05 4.76837158e-05
0:  3.33786011e-05 1.81198120e-05 1.09672546e-05 5.72204590e-06
0:  3.33786011e-06 1.43051147e-06 4.76837158e-07 4.76837158e-07
0:  9.53674316e-07 9.53674316e-07 1.43051147e-06 1.90734863e-06
0:  2.38418579e-06 2.86102295e-06 3.33786011e-06 3.33786011e-06
0:  3.81469727e-06 3.33786011e-06 3.33786011e-06 4.29153442e-06
0:  5.24520874e-06 6.67572021e-06 8.58306885e-06 9.53674316e-06
0:  1.04904175e-05 1.19209290e-05 1.47819519e-05 1.47819519e-05
0:  1.57356262e-05 1.57356262e-05 1.47819519e-05 1.38282776e-05
0:  1.23977661e-05 1.28746033e-05 1.38282776e-05 1.43051147e-05
0:  1.62124634e-05 2.00271606e-05 2.47955322e-05 3.33786011e-05
0:  4.33921814e-05 5.48362732e-05 6.58035278e-05 7.58171082e-05]
0: Target values (first 200):
0: [4.48226929e-05 4.24385107e-05 3.62396240e-05 3.71932983e-05
0:  3.81469727e-05 3.81469727e-05 3.67164612e-05 3.62396240e-05
0:  3.33786011e-05 3.24249268e-05 3.14712524e-05 2.86102295e-05
0:  2.71797180e-05 2.81333923e-05 3.05175781e-05 3.43322754e-05
0:  3.71932983e-05 4.05311584e-05 4.57763635e-05 4.76837158e-05
0:  4.86373901e-05 4.19616663e-05 3.48091125e-05 3.24249268e-05
0:  2.95639038e-05 2.76565552e-05 2.52723694e-05 1.95503235e-05
0:  1.57356262e-05 1.28746033e-05 1.33514404e-05 3.09944153e-05
0:  3.14712524e-05 5.29289246e-05 1.17778778e-04 1.69277191e-04
0:  1.77860260e-04 1.83105469e-04 1.47819519e-04 1.50680542e-04
0:  2.26497650e-04 1.61170959e-04 1.28746033e-04 8.39233398e-05
0:  1.10149384e-04 7.39097595e-05 6.62803650e-05 5.96046448e-05
0:  4.14848328e-05 4.14848328e-05 3.76701355e-05 3.81469727e-05
0:  3.62396240e-05 2.81333923e-05 3.09944153e-05 2.86102295e-05
0:  3.29017639e-05 2.81333923e-05 2.67028809e-05 1.95503235e-05
0:  1.57356262e-05 1.57356262e-05 1.52587891e-05 1.09672546e-05
0:  8.58306885e-06 8.10623169e-06 7.62939453e-06 8.10623169e-06
0:  1.00135803e-05 4.76837158e-06 6.67572021e-06 5.72204590e-06
0:  4.29153442e-06 3.81469727e-06 9.53674316e-07 9.53674316e-07
0:  9.53674316e-07 6.19888306e-06 7.62939453e-06 2.52723694e-05
0:  9.15527344e-05 1.94549561e-04 2.95639038e-04 3.01837921e-04
0:  2.44617462e-04 2.30789185e-04 1.79767609e-04 1.76429749e-04
0:  1.24931335e-04 1.17301941e-04 7.62939453e-05 6.91413879e-05
0:  6.48498535e-05 6.19888306e-05 1.05857849e-04 1.19686127e-04
0:  1.00612640e-04 1.12533569e-04 7.53402710e-05 4.86373901e-05
0:  2.47955322e-05 3.38554382e-05 3.29017639e-05 5.72204590e-05
0:  1.54495239e-04 1.16348267e-04 1.50680542e-04 1.54018402e-04
0:  4.86373901e-05 4.29153479e-05 3.67164612e-05 3.52859497e-05
0:  3.48091125e-05 3.29017639e-05 3.14712524e-05 3.09944153e-05
0:  3.09944153e-05 3.14712524e-05 3.05175781e-05 3.00407410e-05
0:  2.71797180e-05 3.19480896e-05 3.48091125e-05 3.86238098e-05
0:  3.95774841e-05 4.43458557e-05 4.95910608e-05 5.19752502e-05
0:  5.34057617e-05 4.76837158e-05 4.24385107e-05 4.00543213e-05
0:  3.71932983e-05 3.43322754e-05 3.00407410e-05 2.38418579e-05
0:  2.33650208e-05 2.67028809e-05 4.33921814e-05 7.29560852e-05
0:  9.87052917e-05 1.56402588e-04 2.09808350e-04 2.43663788e-04
0:  2.85625458e-04 2.59399414e-04 2.13146210e-04 1.73091888e-04
0:  1.64985657e-04 1.46389008e-04 1.20162964e-04 9.34600830e-05
0:  4.10079956e-05 3.62396240e-05 3.29017639e-05 2.76565552e-05
0:  2.62260437e-05 2.19345093e-05 2.05039978e-05 2.09808350e-05
0:  2.14576721e-05 2.57492065e-05 2.86102295e-05 2.62260437e-05
0:  2.57492065e-05 2.57492065e-05 2.76565552e-05 2.33650208e-05
0:  1.85966492e-05 1.81198120e-05 2.00271606e-05 1.90734863e-05
0:  1.28746033e-05 9.05990601e-06 7.15255737e-06 5.24520874e-06
0:  5.24520874e-06 5.72204590e-06 8.58306885e-06 9.53674316e-06
0:  8.10623169e-06 4.76837158e-06 1.43051147e-06 9.53674316e-07
0:  9.53674316e-07 1.43051147e-06 2.38418579e-06 1.33514404e-05
0:  1.90734863e-05 1.15394592e-04 1.70230865e-04 1.85966492e-04
0:  2.38418579e-04 2.00748444e-04 1.62601471e-04 1.61647797e-04
0:  1.45435333e-04 1.01566315e-04 6.29425049e-05 4.95910608e-05]
0: Prediction values (first 20):
0: [13.647196 13.621397 13.59486  13.527178 13.464979 13.416614 13.332285
0:  13.256046 13.201565 13.214942 13.292126 13.371216 13.505381 13.646854
0:  13.775213 13.910948 14.092095 14.27139  14.410719 14.620176]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -4.590, max = 2.736, mean = -1.008
0:          sample (first 20): tensor([0.6165, 0.6143, 0.6120, 0.6062, 0.6009, 0.5967, 0.5895, 0.5830, 0.5783, 0.5795, 0.5861, 0.5929, 0.6043, 0.6165,
0:         0.6274, 0.6391, 0.6546, 0.6699, 0.5839, 0.5794])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.3243752 3.3733552 3.4231954 3.5195885 3.6852791 3.8798385 4.1622214
0:  4.4577293 4.8163958 5.2148323 5.6477385 6.1080227 6.5793424 7.049141
0:  7.475077  7.8728046 8.241931  8.580226  8.925112  9.061823 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.7023907  0.78642607 0.979043   1.243691   1.6102986  1.8977952
0:  2.1477823  2.2600307  2.3354564  2.3567028  2.3567452  2.298005
0:  2.240427   2.2391424  2.2649312  2.4668164  2.767333   3.0811372
0:  3.1641831  3.2484946 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.920874 16.156775 16.456293 16.771807 17.01692  17.196777 17.412254
0:  17.50638  17.673342 17.83745  17.905912 17.89837  17.884897 17.880224
0:  17.877058 17.886984 17.813238 17.709364 15.041439 15.075008]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.6237097 -6.8252373 -7.0025167 -7.158163  -7.283353  -7.412183
0:  -7.508602  -7.6189594 -7.722513  -7.80087   -7.842902  -7.8979626
0:  -7.935793  -7.9501314 -7.9960184 -8.007759  -8.019603  -7.99249
0:  -8.455572  -8.494039 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.813171  -2.8360543 -2.8470511 -2.8715768 -2.8731704 -2.902863
0:  -2.9032617 -2.9229875 -2.9196362 -2.9171443 -2.9074912 -2.933782
0:  -2.9896474 -3.0418983 -3.1327262 -3.1579642 -3.1331286 -3.042871
0:  -3.0359693 -2.9467978]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -8.77025    -8.981119   -9.203136   -9.389673   -9.591429   -9.819729
0:  -10.054127  -10.334497  -10.589163  -10.801447  -10.949852  -11.000322
0:  -10.934366  -10.754568  -10.47307   -10.130964   -9.817129   -9.493938
0:   -8.262068   -7.7811446]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-13.969368  -13.783115  -13.238045  -12.297113  -11.069231   -9.738964
0:   -8.328632   -7.0849223  -6.0549855  -5.294145   -4.7458196  -4.357528
0:   -4.018143   -3.714703   -3.4082122  -3.1394248  -2.969051   -2.8568168
0:   -3.108211   -2.9965615]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.9134583 -4.7426705 -4.523641  -4.313395  -4.1791997 -4.121206
0:  -4.0587296 -4.041492  -4.0103498 -4.004329  -4.0703244 -4.273333
0:  -4.5804114 -4.9555764 -5.393213  -5.7621484 -6.0597787 -6.2352586
0:  -6.1298575 -6.04913  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.748824   8.6208725  8.677896   8.874572   9.208496   9.649895
0:  10.259506  10.938677  11.777607  12.67811   13.578999  14.482617
0:  15.387374  16.182758  16.877405  17.335194  17.623245  17.699898
0:  16.60757   16.640602 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.3728437 -7.317025  -7.2207413 -7.11992   -6.994486  -6.8897457
0:  -6.799865  -6.774435  -6.7533045 -6.7423363 -6.7155313 -6.6997023
0:  -6.6686707 -6.592045  -6.54222   -6.456723  -6.3349314 -6.1846886
0:  -6.1878567 -6.0391045]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.98243475 -0.92053175 -0.932817   -0.98240995 -1.0802646  -1.2169394
0:  -1.3169732  -1.4166512  -1.5136628  -1.600678   -1.7027936  -1.8049989
0:  -1.8897815  -1.9289002  -1.9491572  -1.9226451  -1.9077363  -1.8896565
0:  -2.208261   -2.1051278 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.933033 23.817593 23.747757 23.614319 23.434814 23.166397 22.88026
0:  22.532234 22.20449  21.87479  21.46274  20.997662 20.550556 20.14249
0:  19.761864 19.37791  18.952152 18.478033 17.332706 16.873337]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.545958 20.758554 21.007738 21.141783 21.150713 21.024807 20.854315
0:  20.650646 20.57271  20.629717 20.794996 21.040146 21.337242 21.617495
0:  21.842747 21.950935 21.950083 21.806314 21.539526 21.484015]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.456388  15.445597  15.456003  15.506142  15.556896  15.60577
0:  15.6856365 15.735735  15.807253  15.884039  15.931124  15.969383
0:  16.042646  16.11116   16.207394  16.308214  16.408688  16.503027
0:  16.401855  16.283625 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.747347  -4.6040277 -4.4478607 -4.2666674 -4.0528    -3.8509922
0:  -3.6233711 -3.4698849 -3.330967  -3.208644  -3.1016865 -3.027359
0:  -2.9621582 -2.8709087 -2.8032131 -2.6800966 -2.5293884 -2.3683643
0:  -2.4731684 -2.2714882]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.7453527 6.8522115 6.963274  7.083628  7.1853647 7.2722235 7.370107
0:  7.4394293 7.5239086 7.5945225 7.645867  7.693477  7.7371044 7.792056
0:  7.846583  7.8940153 7.940756  7.984105  7.913247  7.9607706]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [31.122578 31.16735  31.236649 31.28634  31.307081 31.31143  31.299831
0:  31.219273 31.148338 31.063404 30.947842 30.78807  30.631824 30.456942
0:  30.277245 30.076042 29.871561 29.667446 28.76127  28.472584]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [28.761005 28.849762 29.018272 29.143032 29.186123 29.124771 29.007225
0:  28.802814 28.677929 28.551731 28.470196 28.40456  28.356758 28.382874
0:  28.369007 28.41637  28.458782 28.449001 28.11935  28.10271 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.1765313  -2.0564952  -1.9350858  -1.8051476  -1.6418538  -1.5124388
0:  -1.3532896  -1.2471123  -1.1200037  -0.9977484  -0.84743786 -0.65378284
0:  -0.40871954 -0.10869884  0.19225216  0.51708364  0.8497267   1.214746
0:   1.891089    2.1381185 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.900536 19.30149  19.656677 20.185333 20.62346  21.040138 21.558205
0:  21.907396 22.352837 22.811747 23.029514 23.14072  23.122822 23.038666
0:  23.163528 23.419449 23.562408 23.357826 21.495844 21.814352]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.206488  -8.134907  -8.073721  -8.021784  -7.940308  -7.8868375
0:  -7.7742553 -7.698109  -7.6094193 -7.4945426 -7.345735  -7.222676
0:  -7.0957236 -6.9611554 -6.898995  -6.8389096 -6.7925    -6.7493663
0:  -6.9019303 -6.882939 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.223125 18.221586 18.235617 18.204933 18.13497  18.038462 17.884323
0:  17.667612 17.44276  17.22705  17.016388 16.790403 16.598806 16.405375
0:  16.218187 16.038929 15.937508 15.903622 15.58024  15.616983]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.026287  14.145529  14.282963  14.398876  14.519472  14.624407
0:  14.6922245 14.716936  14.775669  14.852474  14.943161  15.008829
0:  15.070076  15.070118  15.034788  15.003443  15.018684  15.07798
0:  14.946043  15.09828  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.977623 33.59426  33.189487 32.851517 32.601147 32.432217 32.486954
0:  32.585682 32.831097 32.990845 32.99607  32.93903  32.824352 32.63522
0:  32.430756 32.11149  31.646782 31.023575 29.645863 29.325611]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.07569933 0.21179247 0.34910774 0.50238085 0.6580944  0.76513624
0:  0.9052062  1.0112991  1.1593499  1.3426223  1.5625467  1.7812057
0:  2.0029287  2.2496943  2.4708195  2.71771    2.950172   3.1644378
0:  3.5928364  3.816274  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.8427968 3.2347982 3.4520648 3.6804123 3.8203847 3.9614148 4.2352734
0:  4.5447173 4.8804293 5.211766  5.4416375 5.693639  5.936681  6.245432
0:  6.5532007 6.8110824 6.9792457 7.1191363 6.9013276 7.3573494]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -8.895      -9.068773   -9.184616   -9.275061   -9.393011   -9.6192665
0:   -9.97028   -10.497473  -11.151411  -11.862377  -12.567083  -13.239677
0:  -13.759148  -14.129709  -14.343618  -14.432596  -14.443056  -14.401617
0:  -14.740313  -14.776287 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.761451  -9.7562065 -9.58479   -9.355058  -9.138364  -8.988939
0:  -8.84282   -8.824149  -8.769027  -8.738016  -8.710855  -8.741143
0:  -8.680811  -8.598627  -8.495858  -8.332774  -8.184053  -8.067692
0:  -8.119613  -7.9768143]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -8.750292   -8.850796   -8.905378   -8.940838   -8.952719   -9.039951
0:   -9.138176   -9.309099   -9.472733   -9.63637    -9.8127365 -10.024298
0:  -10.210592  -10.345617  -10.479727  -10.527256  -10.529383  -10.49062
0:  -10.863188  -10.783634 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.37704   9.287604  9.20944   9.093649  8.939898  8.71834   8.485577
0:  8.216699  7.9696016 7.742183  7.531173  7.304678  7.0822587 6.861767
0:  6.60792   6.3714895 6.1278133 5.906039  5.355363  5.2214704]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.1031547 -5.4815    -5.8170066 -6.00112   -6.0320287 -5.9935975
0:  -5.894178  -5.835071  -5.781489  -5.6743436 -5.5396323 -5.4412503
0:  -5.3267674 -5.181542  -5.11367   -5.0191197 -4.939526  -4.8882403
0:  -4.264688  -4.1586595]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.1492033 -4.0772114 -4.0005198 -3.9238558 -3.8447714 -3.812024
0:  -3.8178873 -3.9168425 -4.0703306 -4.2866154 -4.537986  -4.8509893
0:  -5.1966095 -5.518984  -5.88632   -6.1990957 -6.440881  -6.6300898
0:  -7.2815666 -7.3673277]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.625208    8.407948    8.142972    7.6771016   7.089553    6.3650484
0:   5.630301    4.992026    4.50279     4.1194267   3.8204815   3.5380483
0:   3.2214952   2.84145     2.3210382   1.6450996   0.8156557  -0.05800438
0:  -2.3004127  -3.0935864 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.384514 18.255404 18.541836 19.073801 19.599953 19.947458 20.176386
0:  20.393734 20.819468 21.411438 21.985079 22.300419 22.261002 21.94088
0:  21.521524 21.243374 21.15751  21.165726 20.55192  20.849386]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.314499 24.364698 24.3829   24.31785  24.213074 24.104067 23.989397
0:  23.85715  23.748152 23.65746  23.539309 23.390167 23.231064 23.063898
0:  22.892935 22.746891 22.642012 22.552362 22.147455 22.143574]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.139072  8.401744  8.678345  8.921619  9.171183  9.386733  9.566447
0:   9.698982  9.795109  9.875886  9.96043  10.016537 10.063067 10.110685
0:  10.133336 10.210728 10.388451 10.629112 10.646193 10.693945]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.6401296  -2.2264762  -2.7713408  -3.2185855  -3.4684663  -3.4859624
0:  -3.1926646  -2.6516013  -1.9007583  -1.0085559  -0.02554512  0.9227171
0:   1.8575559   2.6761036   3.2695277   3.7018237   3.895399    3.9040399
0:   1.5614142   1.3814459 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.385105 13.399744 13.427761 13.428942 13.439892 13.441531 13.406305
0:  13.337657 13.237421 13.11817  12.986768 12.791968 12.550953 12.295604
0:  12.030982 11.820758 11.691853 11.623725 11.012627 10.968686]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.110351  3.1277797 3.0359871 2.8512592 2.6749911 2.546949  2.5306454
0:  2.5436988 2.6071587 2.6275692 2.555584  2.299067  1.91891   1.491446
0:  1.037365  0.7401557 0.6267586 0.6661649 1.2983713 1.3430204]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.2565355 1.3001709 1.3940539 1.5097556 1.6702557 1.8622494 2.099023
0:  2.392355  2.725265  3.0728922 3.4223475 3.6710753 3.8066385 3.8202055
0:  3.646644  3.3688858 3.0509882 2.7094605 1.7885668 1.5195532]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.35073  16.587786 16.85183  17.105343 17.42197  17.812284 18.21737
0:  18.51866  18.653946 18.574734 18.294044 17.85973  17.417812 17.022038
0:  16.679173 16.379051 16.116573 15.878252 15.184252 15.054014]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.119593  8.940633  8.859398  8.863988  8.826815  8.704249  8.580715
0:  8.350618  8.182497  8.030273  7.8447065 7.7183347 7.6751957 7.640062
0:  7.661966  7.623002  7.516289  7.339575  6.9789295 6.713283 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.144894 25.939474 25.636618 25.104868 24.44727  23.629501 22.749735
0:  21.77057  20.855637 19.923283 19.028954 18.154854 17.377298 16.709726
0:  16.075052 15.540775 15.012154 14.440439 13.430849 13.082675]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.105233  4.2801933 4.5086746 4.790722  5.116183  5.426545  5.7314816
0:  5.9667244 6.190035  6.401273  6.6393394 6.908943  7.2281675 7.5656586
0:  7.9117117 8.263877  8.62387   8.973285  9.547512  9.840295 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.38614273 -0.09776115  0.33798504  0.8076439   1.2475739   1.5445695
0:   1.6951838   1.6652555   1.5729017   1.4767852   1.4157386   1.3951688
0:   1.4129744   1.4774089   1.5428896   1.6861124   1.8804364   2.1249373
0:   1.5782471   1.5696359 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.559942  7.3771753 7.251026  7.114527  6.963583  6.70213   6.4070964
0:  6.0257015 5.675274  5.3766184 5.1346397 4.9366713 4.8303823 4.777569
0:  4.679308  4.62      4.570504  4.5208726 4.627036  4.671648 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -6.375858   -6.7355304  -7.0260653  -7.2049956  -7.3274846  -7.512235
0:   -7.6797996  -7.986487   -8.297157   -8.613144   -8.964153   -9.339916
0:   -9.690184  -10.009785  -10.248709  -10.354656  -10.341366  -10.227264
0:   -9.456882   -9.383196 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [36.43438  36.171364 35.83198  35.443905 35.051304 34.663296 34.347027
0:  33.980038 33.692333 33.41771  33.118988 32.84492  32.639427 32.50628
0:  32.397778 32.27793  32.125637 31.803654 31.814173 31.490717]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.366442 23.363647 23.41634  23.4555   23.476358 23.449326 23.38962
0:  23.161287 22.83164  22.387516 21.788738 21.12766  20.504635 19.946774
0:  19.518902 19.187117 18.988104 18.880533 19.389381 19.236261]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.5855136  -7.3843102  -6.9105344  -6.144029   -5.1467443  -4.145291
0:  -3.189755   -2.39438    -1.7348437  -1.1418672  -0.59952116 -0.22013903
0:   0.14226723  0.39697552  0.5029659   0.49413347  0.4411626   0.39575958
0:  -0.80047894 -0.88474655]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [38.94607  38.736885 38.311966 37.671432 36.859303 35.968597 35.053795
0:  34.097847 33.255447 32.47044  31.735615 31.085629 30.510763 30.077534
0:  29.68678  29.370325 29.104488 28.813898 28.907417 28.711565]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.6393027 -5.533426  -5.332971  -5.072366  -4.7479625 -4.429353
0:  -4.114342  -3.8857036 -3.7383018 -3.6930938 -3.7325902 -3.8974004
0:  -4.1069474 -4.2832522 -4.439614  -4.453504  -4.3259206 -4.103065
0:  -3.9454646 -3.6250682]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.456024 22.549284 22.612255 22.633354 22.650467 22.662483 22.757723
0:  22.815117 22.935244 23.099663 23.281849 23.516026 23.82893  24.190441
0:  24.58171  24.959263 25.302536 25.579777 25.98008  26.353996]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.474928  10.498676  10.538446  10.544522  10.5334015 10.520449
0:  10.518517  10.498516  10.535297  10.605937  10.669606  10.706337
0:  10.728619  10.727083  10.716614  10.734976  10.78476   10.847967
0:  10.621286  10.658083 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-12.23123    -11.657669   -11.044563   -10.409964    -9.773304
0:   -9.158953    -8.4844475   -7.815827    -7.142155    -6.449246
0:   -5.7665296   -5.042191    -4.2749496   -3.5212827   -2.7577376
0:   -2.0471683   -1.4355612   -0.97874165   0.6732664    1.5518947 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.02245617  0.14270115  0.3544073   0.592329    0.8218708   1.0038276
0:   1.1396742   1.2305431   1.2625766   1.2570982   1.2247591   1.1576366
0:   1.1328721   1.194665    1.3025141   1.4820085   1.6788177   1.864244
0:   1.74084     1.730443  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.0527334  1.706439   2.471509   3.116321   3.6013017  3.9225354
0:  4.204836   4.4306884  4.575732   4.552352   4.27437    3.679828
0:  2.9050229  2.1689425  1.5563507  1.2541361  1.1819887  1.2336035
0:  0.90291786 0.9115753 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.655947  14.580019  14.4731865 14.265665  14.00474   13.660639
0:  13.303177  12.867008  12.437194  12.009863  11.596809  11.146568
0:  10.67422   10.22111    9.717502   9.275326   8.903486   8.597717
0:   7.620594   7.294536 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.284804 10.253896 10.225365 10.19983  10.18416  10.156584 10.157843
0:  10.122897 10.122534 10.094202 10.02697   9.931374  9.828504  9.725013
0:   9.635091  9.584846  9.570163  9.587286  9.530679  9.44792 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.7521577 5.743345  5.775439  5.8252306 5.9004416 5.986964  6.090937
0:  6.18845   6.3085856 6.442471  6.5830336 6.692556  6.7941003 6.8650556
0:  6.889305  6.885655  6.8532996 6.8078446 5.9965897 5.7390885]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.6303244  5.6435084  5.6621356  5.6577926  5.664787   5.7709103
0:   6.0673656  6.5035715  7.0830173  7.677156   8.249779   8.734287
0:   9.183163   9.636518  10.055839  10.434588  10.691756  10.861508
0:  11.488726  11.441748 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.36405325  0.29227638  0.19132519  0.0787282  -0.03974676 -0.20443249
0:  -0.3888569  -0.63834715 -0.9003415  -1.1728945  -1.4766531  -1.8419709
0:  -2.1959028  -2.528389   -2.8244286  -3.0054913  -3.0775013  -3.0477467
0:  -3.6383276  -3.3647594 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.3129444 -4.236038  -4.134449  -4.0467873 -3.9573517 -3.893444
0:  -3.8240461 -3.802946  -3.8009377 -3.8367023 -3.9034882 -4.0631046
0:  -4.282565  -4.5610313 -4.9243813 -5.261467  -5.551218  -5.7337084
0:  -5.69831   -5.727559 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.134382  9.096899  9.128385  9.1912365 9.252928  9.316839  9.351851
0:  9.3537035 9.359804  9.342528  9.333633  9.308669  9.315029  9.315426
0:  9.315862  9.295761  9.242926  9.205188  9.229565  9.249207 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.88033533 -0.7382798  -0.53282356 -0.29455137 -0.01034355  0.2320075
0:   0.43915987  0.5338907   0.59502935  0.6202688   0.64587116  0.61101675
0:   0.543663    0.4869728   0.36011696  0.2868786   0.26446056  0.2975645
0:  -0.00230074  0.05191231]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.5952697  0.5513468  0.54799557 0.5822711  0.64187145 0.7136717
0:  0.8095994  0.86598873 0.95562553 1.0450692  1.1695113  1.3151937
0:  1.529304   1.7524543  2.0129542  2.2706678  2.5038404  2.7555518
0:  3.0085132  3.215406  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.0162587  -4.7628036  -4.3935666  -3.9836907  -3.5229545  -3.0676885
0:  -2.6186042  -2.256372   -1.9614816  -1.7210422  -1.5248756  -1.3893757
0:  -1.2929177  -1.1705937  -1.0711412  -0.8917351  -0.6664653  -0.40696
0:   0.22760487  0.49509335]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.714846 10.001336 10.326772 10.664074 11.012854 11.308515 11.584471
0:  11.797653 12.047955 12.343922 12.701534 13.060294 13.434898 13.713481
0:  13.988855 14.248886 14.532489 14.818144 14.193302 14.2271  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.9834852 -4.0526905 -4.158367  -4.2870436 -4.476083  -4.7345514
0:  -4.9991064 -5.3168726 -5.6237335 -5.916848  -6.2388706 -6.5818806
0:  -6.9398937 -7.29313   -7.663512  -8.025337  -8.412471  -8.769945
0:  -9.626121  -9.955777 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.9308405   3.7922282   3.606454    3.3243356   2.9918401   2.595786
0:   2.2069988   1.8011804   1.4398208   1.1183524   0.85741186  0.6184044
0:   0.43044758  0.31863594  0.2162137   0.16397095  0.11000824  0.05161524
0:  -0.3702197  -0.5402999 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.7806492   1.5993996   1.3438544   1.0095577   0.63722134  0.24478292
0:  -0.09373617 -0.43016672 -0.701797   -0.91957664 -1.0983582  -1.2829542
0:  -1.4554071  -1.6213055  -1.8333035  -2.0157375  -2.1733456  -2.284195
0:  -2.7781906  -2.8343868 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.607961  5.7436576 5.887921  6.0393434 6.132321  6.1812034 6.247912
0:  6.240775  6.268792  6.2934775 6.2888083 6.2886367 6.3217306 6.3844557
0:  6.473845  6.5302677 6.563495  6.5761833 6.468196  6.5494213]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.42651415  0.40431118  0.39127493  0.36041212  0.3240304   0.26199245
0:   0.22143412  0.16429329  0.12760353  0.08529472  0.03662348 -0.06658125
0:  -0.20531511 -0.3672681  -0.56687975 -0.73569536 -0.87358    -0.9496503
0:  -1.2378163  -1.1637912 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.746649  12.020235  12.2430935 12.295015  12.178546  11.86518
0:  11.469854  11.036133  10.763658  10.674998  10.727276  10.830858
0:  10.983007  11.183319  11.43627   11.8167515 12.256847  12.750153
0:  14.6026945 14.804357 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.289542  7.3097043 7.3484726 7.3429117 7.3305264 7.282584  7.2579055
0:  7.214495  7.2050734 7.266695  7.387958  7.531737  7.679673  7.83844
0:  7.9310746 8.01703   8.101134  8.220647  8.139567  8.397144 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.477589 25.751495 25.964695 26.157902 26.328915 26.515503 26.732822
0:  26.821991 26.943115 27.05162  27.094936 27.17778  27.365456 27.6162
0:  28.023087 28.507656 29.095676 29.737343 32.46425  33.75678 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.101835  4.9426055 4.820789  4.724125  4.641409  4.567021  4.5105495
0:  4.4645276 4.469039  4.517335  4.592366  4.6587744 4.7719746 4.8973618
0:  5.0544167 5.244374  5.4613156 5.6892323 5.5883894 5.763982 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.6276717 -2.3567061 -1.997601  -1.466434  -0.848505  -0.2389698
0:   0.4873252  1.1657143  1.8519354  2.5762029  3.3156374  4.0852284
0:   4.891326   5.72349    6.5377755  7.3487945  8.053455   8.615731
0:   9.048082   9.105658 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.438174 9.46768  9.482532 9.518117 9.53184  9.528006 9.543824 9.52095
0:  9.506739 9.515471 9.519275 9.528086 9.57621  9.625429 9.672819 9.701071
0:  9.7148   9.729984 9.553405 9.586883]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.194893 22.95605  22.69664  22.454243 22.202114 21.961597 21.787842
0:  21.509064 21.264889 21.003216 20.672983 20.334862 20.141472 20.017372
0:  20.031841 20.10005  20.165611 20.177185 21.368568 21.466843]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.709984 21.741594 21.75125  21.749353 21.71266  21.618    21.48888
0:  21.220087 20.961918 20.65881  20.33431  20.067984 19.838057 19.620457
0:  19.427416 19.216059 19.059378 18.988523 19.215612 19.141483]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [40.989124 41.26518  41.483395 41.62475  41.709263 41.789734 41.885384
0:  41.947617 42.074406 42.199318 42.332314 42.379555 42.42968  42.418663
0:  42.358467 42.295216 42.262665 42.23415  41.186543 41.139175]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [43.345013 43.27921  43.05583  42.624035 41.981968 41.15966  40.187344
0:  38.996387 37.821087 36.624218 35.51394  34.40077  33.36336  32.383434
0:  31.363052 30.470154 29.6982   29.09938  27.998697 27.763573]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.156704 21.073738 20.980814 20.822758 20.670124 20.521652 20.39989
0:  20.31024  20.262314 20.264565 20.275507 20.251474 20.182947 20.068733
0:  19.888836 19.694347 19.51593  19.361805 18.642277 18.459822]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.274878 15.230303 15.158188 14.896786 14.555529 14.126278 13.610711
0:  13.070884 12.540396 12.066939 11.610939 11.112256 10.599549 10.127624
0:   9.683746  9.380125  9.212665  9.117057  8.682858  8.508625]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.7243805  0.7711148  0.8557701  0.98782635 1.2087102  1.4744067
0:  1.8445368  2.2265563  2.6320672  2.9703784  3.1592152  3.1457024
0:  2.9589205  2.6633706  2.2837129  1.922277   1.6254115  1.3650517
0:  0.8886237  1.09793   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.698874 16.477848 16.244936 15.970378 15.629782 15.217952 14.776357
0:  14.242829 13.729305 13.215326 12.668486 12.11812  11.634388 11.182301
0:  10.801402 10.460104 10.133923  9.855241  9.768218  9.458586]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.634007  13.233107  12.891083  12.582363  12.367719  12.192707
0:  12.09419   12.032282  12.07247   12.1768465 12.32835   12.483738
0:  12.633391  12.699618  12.716024  12.670283  12.578676  12.4492855
0:  13.147041  13.065218 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.869259 29.889683 29.89996  29.83733  29.794521 29.735027 29.687466
0:  29.551666 29.378578 29.113537 28.662441 28.065392 27.384834 26.689732
0:  26.033028 25.41438  24.842163 24.292889 23.44059  23.368778]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.005215 27.246597 27.403791 27.518614 27.593542 27.695414 27.87169
0:  28.017414 28.233574 28.438406 28.628958 28.797812 28.968004 29.114565
0:  29.170345 29.140657 29.070345 29.02737  29.09995  29.418852]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.665966  6.558174  6.432468  6.2622333 6.0750856 5.8558464 5.6448565
0:  5.4361186 5.264353  5.125143  5.006097  4.868086  4.7396793 4.6215076
0:  4.488543  4.3957934 4.315961  4.2662745 3.9532914 3.8690789]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [40.886936 41.155376 41.369    41.487984 41.507126 41.43239  41.458637
0:  41.31233  41.30199  41.18584  40.94819  40.60427  40.22303  39.932392
0:  39.654274 39.484478 39.23288  38.86381  38.595604 38.426426]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.477036 33.513466 33.55402  33.558224 33.571747 33.65746  33.74432
0:  33.90195  34.163082 34.462543 34.779255 35.064648 35.410522 35.73599
0:  35.990543 36.184544 36.338432 36.389915 35.661243 35.738247]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.4885893 -5.400586  -5.337784  -5.3381186 -5.348075  -5.3986635
0:  -5.403001  -5.4505854 -5.494158  -5.538454  -5.5850353 -5.6497345
0:  -5.6971407 -5.741212  -5.7980022 -5.8078594 -5.7816563 -5.7322893
0:  -6.130108  -6.025522 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.909687 19.961073 20.32738  20.758743 20.936348 20.565674 19.630022
0:  18.352913 17.096193 16.116182 15.468124 15.075682 14.86949  14.768639
0:  14.845665 15.133755 15.574291 16.082237 16.184324 16.757866]
0: validation loss for strategy=forecast at epoch 11 : nan
0: validation loss for velocity_u : 0.03919689357280731
0: validation loss for velocity_v : 0.06820371001958847
0: validation loss for specific_humidity : 0.023773713037371635
0: validation loss for velocity_z : 0.5492625832557678
0: validation loss for temperature : 0.07426684349775314
0: validation loss for total_precip : nan
0: 12 : 10:34:47 :: batch_size = 96, lr = 1.5623968034514547e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 12, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.2513, -1.2187, -1.1814, -1.1398, -1.0957, -1.0565, -1.0221, -0.9952, -0.9725, -0.9546, -0.9418, -0.9353,
0:         -0.9329, -0.9300, -0.9287, -0.9255, -0.9204, -0.9150, -1.2187, -1.1819, -1.1435, -1.1022, -1.0618, -1.0275,
0:         -0.9978], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.5404, -0.5186, -0.5023, -0.4842, -0.4765, -0.4715, -0.4696, -0.4691, -0.4694, -0.4717, -0.4744, -0.4814,
0:         -0.4901, -0.5009, -0.5131, -0.5258, -0.5393, -0.5506, -0.4342, -0.4262, -0.4209, -0.4137, -0.4154, -0.4165,
0:         -0.4201], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.3531, -0.3664, -0.3783, -0.3871, -0.3937, -0.3981, -0.4023, -0.4044, -0.4067, -0.4060, -0.4060, -0.4044,
0:         -0.4048, -0.4096, -0.4158, -0.4250, -0.4360, -0.4510, -0.3800, -0.3935, -0.4067, -0.4173, -0.4266, -0.4348,
0:         -0.4421], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.6340, 0.4966, 0.4501, 0.3813, 0.3481, 0.2993, 0.2550, 0.2328, 0.2882, 0.3148, 0.3503, 0.4922, 0.5498, 0.6540,
0:         0.7693, 0.8247, 0.8579, 0.8047, 0.6274, 0.5653, 0.5254, 0.4257, 0.3924, 0.2661, 0.1907], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0.6315, -0.6494, -0.6743, -0.6594, -0.6540, -0.6330, -0.6145, -0.6078, -0.6034, -0.6180, -0.6112, -0.6203,
0:         -0.6306, -0.6456, -0.6820, -0.7087, -0.7422, -0.7603, -0.7692, -0.7671, -0.7452, -0.7396, -0.7424, -0.7819,
0:         -0.8550], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 12, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1838,
0:             nan,     nan,  0.0149, -0.0655,     nan, -0.1793,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2284,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2239,     nan,
0:             nan,     nan, -0.2284,     nan,     nan,     nan,     nan,     nan,     nan, -0.1503,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0454,     nan,
0:         -0.1771,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2306,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2463,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2463,     nan,     nan,     nan,     nan,     nan, -0.2440,     nan,
0:             nan, -0.2440,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2306,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0744,     nan,     nan,     nan,     nan,
0:          0.1041,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.0833,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2463,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,  0.1577,  0.1298,     nan,     nan, -0.2407,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 12, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-1.0738, -1.0780, -1.0784, -1.0785, -1.0722, -1.0655, -1.0515, -1.0380, -1.0185, -0.9958, -0.9668, -0.9375,
0:         -0.9097, -0.8786, -0.8537, -0.8267, -0.8002, -0.7723, -1.0299, -1.0363, -1.0402, -1.0422, -1.0413, -1.0365,
0:         -1.0220], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-2.3952e-02, -4.1944e-02, -6.7057e-02, -9.1276e-02, -1.1353e-01, -1.2784e-01, -1.3170e-01, -1.2767e-01,
0:         -1.1335e-01, -9.4691e-02, -7.2960e-02, -5.0246e-02, -2.8074e-02, -1.3639e-04,  3.4669e-02,  7.4068e-02,
0:          1.1546e-01,  1.5611e-01, -1.1111e-03, -1.9139e-02, -4.3672e-02, -6.7216e-02, -8.5375e-02, -9.9359e-02,
0:         -1.0585e-01], device='cuda:1', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.4339, -0.4189, -0.4160, -0.3955, -0.4013, -0.4071, -0.4450, -0.4768, -0.5142, -0.5394, -0.5560, -0.5526,
0:         -0.5425, -0.5236, -0.4906, -0.4481, -0.3739, -0.2501, -0.4514, -0.4354, -0.4060, -0.3838, -0.3818, -0.4018,
0:         -0.4232], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.1342, 0.1397, 0.1285, 0.1245, 0.1503, 0.2080, 0.2596, 0.2960, 0.3223, 0.3433, 0.3763, 0.3801, 0.3382, 0.2954,
0:         0.2702, 0.2589, 0.2711, 0.2740, 0.1607, 0.1570, 0.1462, 0.1641, 0.1834, 0.2144, 0.2406], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([ 0.1482,  0.1335,  0.1206,  0.1094,  0.1047,  0.1114,  0.1299,  0.1657,  0.2302,  0.3225,  0.4275,  0.5184,
0:          0.5560,  0.4976,  0.3345,  0.0800, -0.2203, -0.5155, -0.7565, -0.9267, -1.0274, -1.0783, -1.1036, -1.1124,
0:         -1.1202], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.05914202332496643; velocity_v: 0.09512558579444885; specific_humidity: 0.03784358128905296; velocity_z: 0.6306954026222229; temperature: 0.09469097852706909; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.0674978643655777; velocity_v: 0.09943205863237381; specific_humidity: 0.044912099838256836; velocity_z: 0.4589502215385437; temperature: 0.10951640456914902; total_precip: nan; 
0: epoch: 12 [1/5 (20%)]	Loss: nan : nan :: 0.15654 (2.26 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05149947851896286; velocity_v: 0.087227463722229; specific_humidity: 0.03853890672326088; velocity_z: 0.523709774017334; temperature: 0.0877474769949913; total_precip: nan; 
0: epoch: 12 [2/5 (40%)]	Loss: nan : nan :: 0.13971 (16.01 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05420920252799988; velocity_v: 0.0863812118768692; specific_humidity: 0.03841368481516838; velocity_z: 0.4292231500148773; temperature: 0.0847407877445221; total_precip: nan; 
0: epoch: 12 [3/5 (60%)]	Loss: nan : nan :: 0.14479 (16.20 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06949005275964737; velocity_v: 0.11256373673677444; specific_humidity: 0.03387269377708435; velocity_z: 0.5539034008979797; temperature: 0.11466727405786514; total_precip: nan; 
0: epoch: 12 [4/5 (80%)]	Loss: nan : nan :: 0.16257 (16.27 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [1.1444092e-05 1.1444092e-05 1.1444092e-05 1.1444092e-05 1.1444092e-05
0:  1.1444092e-05 1.1444092e-05 1.1444092e-05 1.1444092e-05 1.1444092e-05
0:  1.1444092e-05 1.1444092e-05 1.1444092e-05 1.2397766e-05 1.2397766e-05
0:  1.2397766e-05 1.2397766e-05 1.2397766e-05 1.2397766e-05 1.2397766e-05
0:  1.2397766e-05 1.2397766e-05 1.2397766e-05 1.2397766e-05 1.2397766e-05
0:  1.2397766e-05 1.2397766e-05 1.2397766e-05 1.2397766e-05 1.2397766e-05
0:  1.2397766e-05 1.2397766e-05 1.2397766e-05 1.3351440e-05 1.3351440e-05
0:  1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05
0:  1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05
0:  1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05
0:  1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05
0:  1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05
0:  1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05
0:  1.3351440e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05
0:  1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05
0:  1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05
0:  1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05
0:  1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05
0:  1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05
0:  1.4305115e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05
0:  1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05
0:  1.3351440e-05 1.3351440e-05 1.3351440e-05 1.2397766e-05 1.2397766e-05
0:  1.2397766e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05 1.3351440e-05
0:  1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05 1.4305115e-05
0:  1.4305115e-05 1.4305115e-05 1.4305115e-05 1.5258789e-05 1.5258789e-05
0:  1.5258789e-05 1.5258789e-05 1.5258789e-05 1.5258789e-05 1.5258789e-05
0:  1.5258789e-05 1.5258789e-05 1.5258789e-05 1.5258789e-05 1.5258789e-05
0:  1.5258789e-05 1.5258789e-05 1.5258789e-05 1.5258789e-05 1.5258789e-05
0:  1.5258789e-05 1.5258789e-05 1.5258789e-05 1.5258789e-05 1.5258789e-05
0:  1.5258789e-05 1.5258789e-05 1.5258789e-05 1.6212463e-05 1.6212463e-05
0:  1.6212463e-05 1.6212463e-05 1.6212463e-05 1.6212463e-05 1.6212463e-05
0:  1.6212463e-05 1.6212463e-05 1.6212463e-05 1.6212463e-05 1.6212463e-05
0:  1.6212463e-05 1.6212463e-05 1.6212463e-05 1.6212463e-05 1.6212463e-05
0:  1.7166138e-05 1.7166138e-05 1.7166138e-05 1.8119812e-05 1.8119812e-05
0:  1.8119812e-05 1.8119812e-05 1.9073486e-05 1.9073486e-05 1.9073486e-05
0:  1.9073486e-05 1.9073486e-05 1.9073486e-05 1.9073486e-05 1.9073486e-05
0:  1.9073486e-05 2.0027161e-05 2.0027161e-05 2.0027161e-05 2.0027161e-05
0:  2.0027161e-05 2.0027161e-05 2.0027161e-05 2.0027161e-05 2.0027161e-05
0:  2.0027161e-05 2.0027161e-05 1.9073486e-05 1.9073486e-05 1.9073486e-05
0:  1.9073486e-05 1.9073486e-05 1.9073486e-05 1.9073486e-05 1.9073486e-05]
0: Target values (first 200):
0: [0.00076151 0.00075912 0.00075626 0.00075388 0.00075102 0.00074863
0:  0.00074482 0.00074005 0.00073481 0.00072956 0.00072432 0.00071907
0:  0.00071383 0.00070858 0.00070286 0.00069761 0.00069189 0.00068617
0:  0.00068045 0.00067472 0.000669   0.0006628  0.00065613 0.00064993
0:  0.00064325 0.00063705 0.00063038 0.0006237  0.00061703 0.00061035
0:  0.00060368 0.00059652 0.00058985 0.00058174 0.00057364 0.00056505
0:  0.00055695 0.00054836 0.00053978 0.00053167 0.00052309 0.00051451
0:  0.00050592 0.00049686 0.00048828 0.00048113 0.00047588 0.00047064
0:  0.00046492 0.00045967 0.00045443 0.0004487  0.00044346 0.00043774
0:  0.00043201 0.00042677 0.00042105 0.00041533 0.0004096  0.00040197
0:  0.00039291 0.00038433 0.00037575 0.00036669 0.0003581  0.00034904
0:  0.00034046 0.0003314  0.00032234 0.00031328 0.00030422 0.00029612
0:  0.0002923  0.00028801 0.00028372 0.0002799  0.00027561 0.00027132
0:  0.00026703 0.00026274 0.00025845 0.00025415 0.00024986 0.00024557
0:  0.0002408  0.00023603 0.00022984 0.00022364 0.00021744 0.00021172
0:  0.00020552 0.00019932 0.00019264 0.00018644 0.00018024 0.00017405
0:  0.00016785 0.00016165 0.00015879 0.00015688 0.0001545  0.00015211
0:  0.0001502  0.00014782 0.00014544 0.00014305 0.00014067 0.00013828
0:  0.0010767  0.00107861 0.00108004 0.00108147 0.0010829  0.00108433
0:  0.00108576 0.00108719 0.00108862 0.00108671 0.00108004 0.00107288
0:  0.00106621 0.00105953 0.00105238 0.0010457  0.00103855 0.0010314
0:  0.00102425 0.00101709 0.00100994 0.00100279 0.00099564 0.00098944
0:  0.00098753 0.0009861  0.00098419 0.00098276 0.00098085 0.00097895
0:  0.00097704 0.00097513 0.00097322 0.00096655 0.00095987 0.0009532
0:  0.00094652 0.00093985 0.00093317 0.00092649 0.00091934 0.00091267
0:  0.00090313 0.00089312 0.0008831  0.00087309 0.00086308 0.00085258
0:  0.00084257 0.00083208 0.00082159 0.00081158 0.00080109 0.0007906
0:  0.00077963 0.00076914 0.00075769 0.00074625 0.00073433 0.00072241
0:  0.00071096 0.00069904 0.00068712 0.00067472 0.0006628  0.00065184
0:  0.00064135 0.00063133 0.00062132 0.00061083 0.00060034 0.00058985
0:  0.00057983 0.00056934 0.00055838 0.00054789 0.0005374  0.00052643
0:  0.00051594 0.00050497 0.00049257 0.00048018 0.00046778 0.00045538
0:  0.00044298 0.00043058 0.00041771 0.00040531 0.00039339 0.00038624
0:  0.00037909 0.00037241]
0: Prediction values (first 20):
0: [18.872244 19.078573 19.285105 19.39658  19.471258 19.51127  19.556503
0:  19.532156 19.607405 19.698534 19.754225 19.76077  19.741138 19.612211
0:  19.394033 19.114527 18.886637 18.716616 17.933014 18.11263 ]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -0.736, max = 2.317, mean = 0.782
0:          sample (first 20): tensor([1.1249, 1.1425, 1.1600, 1.1695, 1.1759, 1.1793, 1.1831, 1.1811, 1.1875, 1.1952, 1.2000, 1.2005, 1.1989, 1.1879,
0:         1.1693, 1.1455, 1.1261, 1.1116, 1.2404, 1.2613])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.939762 28.05495  28.039856 27.782658 27.368752 26.82346  26.267895
0:  25.719002 25.291782 24.959488 24.625996 24.239326 23.846535 23.476269
0:  23.152245 22.993416 23.027996 23.138737 23.433895 23.27018 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.901684 25.130157 25.430603 25.779095 26.1374   26.50714  26.951752
0:  27.28377  27.716825 28.138353 28.520424 28.877121 29.196941 29.486837
0:  29.73304  29.947899 30.089884 30.19599  29.30199  29.444016]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [36.42118  36.788147 37.056908 37.337692 37.585373 37.80433  38.072258
0:  38.23267  38.395824 38.549347 38.665455 38.76858  38.899296 39.054756
0:  39.214806 39.36131  39.50568  39.67872  39.519455 39.743053]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.790072  -6.009335  -6.3034015 -6.6291738 -6.955293  -7.295775
0:  -7.5932546 -7.907471  -8.169416  -8.3538685 -8.458254  -8.487322
0:  -8.448652  -8.324564  -8.193375  -8.014999  -7.8173623 -7.6119714
0:  -8.059612  -8.204126 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.338358 8.439963 8.508189 8.522425 8.499016 8.467464 8.453401 8.433441
0:  8.417082 8.416487 8.414057 8.407614 8.394126 8.372165 8.319715 8.252764
0:  8.210804 8.196192 8.059256 8.028271]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.218956 9.176853 9.14732  9.139509 9.134811 9.122139 9.110588 9.057205
0:  9.009302 8.933252 8.834862 8.699746 8.574919 8.44411  8.336343 8.264502
0:  8.264722 8.339062 8.860503 8.88945 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.4983821  -1.3611684  -1.1978192  -1.0372958  -0.8836217  -0.76252747
0:  -0.68674564 -0.68712425 -0.71464443 -0.7717023  -0.84812593 -0.98927927
0:  -1.1397681  -1.2676835  -1.4013991  -1.434093   -1.3748918  -1.2763257
0:  -1.5186973  -2.0406766 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.12447    7.3111897  7.569454   7.8845286  8.221025   8.512767
0:   8.763063   8.90552    9.017176   9.107379   9.205693   9.298968
0:   9.399361   9.493497   9.570885   9.64325    9.766243   9.915119
0:  10.007223   9.907888 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.921783 10.872019 10.837143 10.77668  10.708136 10.616363 10.541283
0:  10.407711 10.291966 10.166208 10.032464  9.867836  9.699432  9.533078
0:   9.339095  9.175665  9.07617   9.027982  8.460361  8.328287]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.1329517 2.4001937 2.7391126 3.069398  3.3786626 3.59268   3.7281435
0:  3.7539124 3.7049587 3.6032677 3.4572263 3.252064  3.0152209 2.7939575
0:  2.542319  2.3449268 2.2178059 2.1481566 2.2385683 2.1523123]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.58621  14.778681 14.997448 15.208229 15.480986 15.817564 16.170996
0:  16.432665 16.628162 16.632488 16.449406 16.03308  15.525171 14.947096
0:  14.379134 13.905319 13.599842 13.385389 12.433222 12.3281  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.018494 28.642273 28.405434 28.21752  28.07166  27.924715 27.859287
0:  27.738682 27.694574 27.69497  27.62276  27.581972 27.569258 27.55202
0:  27.587563 27.602968 27.599983 27.544533 27.573732 27.633541]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.963337 30.331768 30.679668 31.038498 31.379848 31.722076 32.10768
0:  32.38278  32.68419  32.928284 33.059177 33.141487 33.19723  33.22129
0:  33.24639  33.206684 33.15966  33.021473 32.83242  32.834515]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.107431  -3.9699311 -3.7950082 -3.6274695 -3.4932399 -3.4606395
0:  -3.5444102 -3.8035436 -4.170956  -4.641598  -5.150437  -5.6767907
0:  -6.1687894 -6.526874  -6.7953963 -6.8974395 -6.8774247 -6.795468
0:  -6.863416  -6.660133 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.348434  10.594828  10.722692  10.741711  10.689491  10.516981
0:  10.298013  10.037891   9.769499   9.588039   9.492927   9.4676895
0:   9.53272    9.564136   9.577459   9.590313   9.599026   9.577359
0:   9.3042345  9.517651 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.917732 12.872846 12.928895 13.000092 13.148815 13.316889 13.435167
0:  13.477707 13.481976 13.354181 13.157448 12.820853 12.457903 12.05173
0:  11.667505 11.329041 11.067782 10.831037 10.401377 10.272459]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.535655  7.130283  6.647848  6.055449  5.4009213 4.72976   4.178709
0:  3.8275495 3.743159  3.8798385 4.1943517 4.5084105 4.791898  5.1047544
0:  5.4348154 5.8399696 6.3426466 6.8789816 7.3823433 7.9297376]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.1070948  -0.75849724 -0.44462347 -0.18577194 -0.10551977 -0.20122719
0:  -0.42601442 -0.7663603  -1.2050714  -1.6471014  -2.1367931  -2.6461964
0:  -3.1061592  -3.540701   -3.9428806  -4.296417   -4.670534   -5.0234785
0:  -4.67043    -4.4407005 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.6927867 -6.804937  -6.9164367 -7.0185857 -7.1037984 -7.2112136
0:  -7.3064218 -7.4268117 -7.535457  -7.6091447 -7.6561217 -7.6874747
0:  -7.6834416 -7.6897817 -7.6981244 -7.6935763 -7.6738505 -7.614495
0:  -7.9401717 -7.8925214]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.9834003 5.1763954 5.336877  5.493621  5.6691923 5.837137  6.0427675
0:  6.198383  6.365266  6.5062776 6.6612377 6.810224  6.965357  7.1212893
0:  7.2282815 7.319444  7.410319  7.520479  7.3473125 7.5736   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.30817   7.013562  6.7733693 6.59806   6.4886026 6.450866  6.5566883
0:  6.6612206 6.8225403 6.940986  6.978293  6.9025855 6.743365  6.5231953
0:  6.2815638 6.0352936 5.832731  5.7010384 4.9599657 4.7228336]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.675108   8.800896   7.9152737  7.1504683  6.6470766  6.4433913
0:   6.5329566  6.8529634  7.3182826  7.890079   8.485169   9.020305
0:   9.479433   9.829863  10.088782  10.363288  10.759977  11.265867
0:  12.463598  12.93865  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.092033 19.585733 20.159859 20.750803 21.33242  21.86792  22.370045
0:  22.764908 23.100372 23.366842 23.546999 23.637419 23.721941 23.848284
0:  24.044664 24.329988 24.753355 25.25488  26.143589 26.61774 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.621696 27.26812  26.93752  26.688004 26.462467 26.23101  26.041222
0:  25.713833 25.460045 25.184662 24.850967 24.536346 24.261852 23.9814
0:  23.72548  23.434795 23.137878 22.833    23.093697 22.922718]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [34.998257 35.15403  35.2216   35.21801  35.169964 35.111942 35.069485
0:  34.95675  34.921974 34.878166 34.850193 34.802788 34.797394 34.805977
0:  34.80426  34.83134  34.822124 34.80709  35.37875  35.52438 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [36.092964 36.134697 36.22301  36.21471  36.232693 36.23986  36.344063
0:  36.394882 36.532692 36.690636 36.735973 36.794994 36.87718  36.994186
0:  37.16999  37.33392  37.43014  37.322124 35.865864 36.31361 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.0779285 4.934311  4.761751  4.606803  4.4811087 4.39595   4.387724
0:  4.380074  4.428719  4.502594  4.5653462 4.5737023 4.5235066 4.4132605
0:  4.2362514 4.0496473 3.9004047 3.8095782 3.2834322 2.902227 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.0216155  2.9349031  2.788424   2.5658536  2.2792945  1.9359794
0:  1.6068358  1.2722459  1.0333271  0.88754416 0.8350129  0.8214607
0:  0.81146955 0.7923336  0.6768756  0.52392006 0.3549776  0.22103739
0:  0.1855998  0.34385586]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [40.288998 40.402298 40.441235 40.43122  40.3417   40.153202 39.998535
0:  39.757397 39.58319  39.38123  39.076115 38.767895 38.49333  38.2067
0:  37.916622 37.610428 37.26412  36.84594  36.542816 36.613354]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.342896 19.239698 19.131956 19.010506 18.806448 18.52961  18.294735
0:  17.960648 17.666393 17.386374 17.005774 16.634752 16.283081 15.935441
0:  15.682164 15.439734 15.223321 15.034233 15.127942 14.874135]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.806768  -9.734997  -9.642353  -9.522083  -9.401485  -9.2967415
0:  -9.185343  -9.115646  -9.067343  -9.023239  -8.977819  -8.937077
0:  -8.875183  -8.787626  -8.718723  -8.634338  -8.563482  -8.4611225
0:  -8.605381  -8.518932 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.505451 17.304558 17.105005 16.889807 16.698534 16.542542 16.407806
0:  16.237082 16.007116 15.673376 15.217524 14.672653 14.112194 13.600683
0:  13.144588 12.798271 12.531841 12.328953 12.19853  12.034931]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.405697 20.461916 20.497322 20.431553 20.31973  20.147963 19.949068
0:  19.649687 19.320923 18.938635 18.501282 18.02197  17.530073 17.014086
0:  16.493761 16.015032 15.570961 15.158342 13.695499 13.547073]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -5.8086557  -5.8129225  -5.695649   -5.4896755  -5.2442665  -5.0529966
0:   -4.943181   -4.9979267  -5.1478777  -5.3815374  -5.654583   -6.0150185
0:   -6.4267187  -6.8721447  -7.4137707  -7.943553   -8.41404    -8.788891
0:  -10.160911  -10.509271 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.04734  20.459026 20.900187 21.35781  21.836744 22.330973 22.856855
0:  23.334593 23.819305 24.30884  24.760725 25.179804 25.570265 25.91252
0:  26.196823 26.442968 26.710022 26.96837  27.36061  27.599014]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.322751  6.2461314 6.25412   6.256378  6.251018  6.205792  6.152627
0:  6.0550385 5.9765964 5.922338  5.8828955 5.8213325 5.770832  5.7175055
0:  5.6028886 5.528922  5.4506044 5.393536  5.2803955 5.2523594]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.7756276 4.1735277 4.5749855 4.8728495 5.1105113 5.292921  5.465007
0:  5.6254826 5.803842  6.001656  6.2116194 6.382905  6.51039   6.5748525
0:  6.4839873 6.306228  6.0294576 5.723117  4.361615  4.1888103]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.0502152 -3.9559703 -3.8668036 -3.8107524 -3.7887845 -3.8221908
0:  -3.864945  -3.9666963 -4.0709243 -4.1760907 -4.259767  -4.343001
0:  -4.3838525 -4.369125  -4.3370805 -4.242295  -4.121037  -3.9873147
0:  -4.0671744 -3.9780984]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.3616967 -3.5131564 -3.6901088 -3.8887658 -4.1129813 -4.3196235
0:  -4.432303  -4.5155787 -4.5875106 -4.6557364 -4.8029475 -4.9997354
0:  -5.2353683 -5.544787  -5.9101796 -6.3348584 -6.8062835 -7.1758466
0:  -7.472812  -7.4210124]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.7709155 -6.6651645 -6.5709844 -6.4920735 -6.4308705 -6.419602
0:  -6.3583236 -6.3660817 -6.354632  -6.352531  -6.354529  -6.402269
0:  -6.430221  -6.4457784 -6.466104  -6.453192  -6.4379764 -6.3897147
0:  -6.930184  -6.8439946]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.377583 16.499739 16.535698 16.43164  16.304077 16.163107 16.064444
0:  15.949135 15.8461   15.751837 15.684256 15.635883 15.675917 15.784922
0:  15.924238 16.04369  16.14922  16.26747  16.445715 16.617197]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.6122737 -1.6512961 -1.815166  -2.0197816 -2.25415   -2.4828887
0:  -2.7451444 -3.1373649 -3.5859199 -4.004249  -4.3196826 -4.4367976
0:  -4.3292613 -4.062677  -3.7489467 -3.4360929 -3.1936917 -2.9485202
0:  -3.0659661 -3.3481507]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.8415318  7.7677064  7.684903   7.5046864  7.2459345  6.89728
0:   6.572121   6.295146   6.2144146  6.227119   6.347351   6.5415735
0:   6.8564315  7.4164023  8.191508   9.108967  10.017847  10.70904
0:  10.918227  11.128347 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.103388  4.0695825 4.053188  4.029064  4.000952  3.9330256 3.8590267
0:  3.744672  3.6304486 3.5027647 3.3940122 3.2527282 3.1283896 3.0650566
0:  3.0473547 3.1095486 3.2188058 3.3691275 3.2867262 3.3277535]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.57158804 -0.441494   -0.34228182 -0.22665071 -0.05580807  0.15577173
0:   0.46097565  0.78231907  1.1595039   1.5481358   1.9124746   2.2115674
0:   2.4854531   2.7512774   3.032364    3.4200935   3.941052    4.4983063
0:   5.4746923   6.1351724 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.2162995 7.009152  6.7573223 6.433319  6.124853  5.8778906 5.768706
0:  5.765038  5.8812637 6.0936084 6.364655  6.599584  6.846667  7.1372404
0:  7.4429493 7.822441  8.225684  8.61445   8.9931555 9.367867 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.691599  8.622238  8.272866  7.481949  6.392699  5.209116  4.180743
0:  3.4467556 3.0589752 2.9054575 2.834075  2.7215762 2.5960608 2.4771981
0:  2.4115539 2.3616996 2.2807598 2.1660757 2.082962  2.2781534]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.7676296  1.087853   1.5869756  2.2684617  3.145557   4.083044
0:   5.181366   6.2952766  7.489146   8.749195  10.067837  11.386625
0:  12.732573  14.146846  15.463989  16.718258  17.889301  18.877151
0:  20.450867  21.318619 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.2366   23.844421 23.513363 23.216393 22.913078 22.608929 22.42224
0:  22.18683  22.07852  22.009163 21.84123  21.618572 21.391502 21.151672
0:  20.947264 20.787037 20.656149 20.498585 19.637293 19.263247]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.549443 10.52301  10.507905 10.47843  10.441374 10.406826 10.345165
0:  10.244172 10.115513  9.99566   9.853348  9.688113  9.521981  9.347485
0:   9.193381  9.074399  9.037265  9.084092  9.206844  9.268419]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.6456172 2.666596  2.6896577 2.7267838 2.7855546 2.816351  2.849533
0:  2.8496873 2.8639648 2.8918042 2.9359374 2.9838207 3.0384874 3.0988119
0:  3.1326418 3.1908598 3.2673128 3.3849032 3.0641541 3.0882783]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.387839  9.405051  9.38849   9.328211  9.273694  9.176879  9.072605
0:  8.925915  8.794695  8.669392  8.566145  8.438452  8.319272  8.239642
0:  8.149441  8.114579  8.102729  8.087135  7.853478  7.7317038]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.0291777  -1.2087827  -1.2632785  -1.126708   -0.7500186  -0.25566673
0:   0.27960777  0.6904521   0.95205927  1.0451393   1.0188913   0.8649702
0:   0.6547046   0.4165039   0.09499741 -0.22037697 -0.55495405 -0.8400421
0:  -2.0773268  -2.0970707 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.328331 20.326668 20.357904 20.35191  20.329388 20.264685 20.153116
0:  19.991957 19.833178 19.671    19.517122 19.328562 19.136133 18.918943
0:  18.661077 18.417038 18.24197  18.144423 17.50735  17.378622]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-11.820789  -11.568361  -11.146982  -10.569353   -9.831749   -9.131777
0:   -8.460291   -8.028271   -7.837745   -7.912802   -8.131668   -8.499683
0:   -8.788359   -8.918728   -8.934088   -8.816841   -8.620722   -8.420378
0:   -7.759485   -7.5777392]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.058503  7.81515   7.421963  6.856906  6.202939  5.5604625 5.0189657
0:  4.586001  4.2910414 4.1403427 4.089473  4.080005  4.1375647 4.1747737
0:  4.207535  4.2658324 4.352339  4.499416  4.3135114 4.420867 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.77805  26.927711 27.095016 27.227257 27.364029 27.505589 27.663513
0:  27.808159 27.991314 28.175617 28.393677 28.604866 28.818188 29.014507
0:  29.200222 29.360096 29.48122  29.574097 29.206486 29.380096]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.714937  11.9387865 12.201294  12.479539  12.697699  12.786933
0:  12.742598  12.529619  12.211544  11.849249  11.526122  11.254094
0:  11.116341  11.100958  11.188896  11.324787  11.441447  11.564516
0:  11.579651  11.473698 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.147116 18.157248 18.150246 18.038862 17.868095 17.620533 17.307478
0:  16.939571 16.560732 16.2209   15.941362 15.766926 15.746208 15.837769
0:  16.0148   16.205433 16.357492 16.436127 16.603067 16.298977]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.477566   9.525274   9.61441    9.766729   9.930519  10.091789
0:  10.210568  10.178371  10.039156   9.799488   9.449098   9.070707
0:   8.697458   8.327629   8.041512   7.882183   7.932825   8.257351
0:   7.1622996  7.353217 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.8699665 10.959405  11.058275  11.091806  11.094458  11.035638
0:  11.006985  10.884671  10.80466   10.687216  10.537176  10.410318
0:  10.27783   10.180258  10.041412   9.904715   9.783015   9.697992
0:   9.460307   9.3706   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.798365 19.780684 20.637915 21.095474 21.220861 21.279608 21.463972
0:  21.83134  22.335892 22.66846  22.615604 22.035269 21.193653 20.267023
0:  19.508389 18.985859 18.639986 18.327915 17.429373 17.449696]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.4671776 3.6005533 3.7543297 3.933257  4.1367946 4.302252  4.4582543
0:  4.5729904 4.6760845 4.8138304 4.94956   5.0609837 5.1747212 5.2637815
0:  5.3327026 5.4240017 5.5512805 5.702734  5.482689  5.616643 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.097246  11.8858185 11.730107  11.597918  11.461663  11.26113
0:  10.982896  10.619045  10.23201    9.864543   9.574384   9.352237
0:   9.225946   9.206451   9.223533   9.302525   9.426509   9.550266
0:   9.619998   9.450273 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.23749733  0.04529142 -0.16802788 -0.4207282  -0.71649885 -1.0529351
0:  -1.3774409  -1.7195706  -2.0102525  -2.2479463  -2.4168534  -2.586328
0:  -2.7259068  -2.7863545  -2.8445077  -2.872087   -2.9435134  -3.005508
0:  -3.1986756  -3.5360284 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.679307  -9.653396  -9.625535  -9.634404  -9.606742  -9.547507
0:  -9.37518   -9.1329775 -8.742871  -8.263407  -7.7564335 -7.3217087
0:  -7.0220003 -6.830264  -6.8954334 -7.042097  -7.2529306 -7.459283
0:  -8.109643  -8.273538 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [37.187656 37.01453  36.673866 36.20438  35.708714 35.222736 34.906696
0:  34.555588 34.3266   34.066498 33.7511   33.469074 33.383865 33.672
0:  34.267483 35.125908 35.943695 36.491043 37.34044  37.44982 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.0273685  -1.5371823  -0.67847633  0.75173616  2.5556684   4.5115128
0:   6.511749    8.310246    9.88658    11.195909   12.235985   13.059483
0:  13.6809845  14.053431   14.238642   14.179725   13.960017   13.771952
0:  12.097971   12.553853  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.382111  6.2628484 6.1892285 6.165311  6.121385  6.082631  6.056544
0:  5.9891663 5.9926634 6.0715322 6.1878734 6.3763084 6.6485424 6.969156
0:  7.347016  7.747453  8.144231  8.606188  7.84453   8.130346 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.985367 21.205477 21.439926 21.583935 21.599907 21.42752  21.118002
0:  20.679218 20.373404 20.182095 20.16108  20.319775 20.56976  20.905397
0:  21.196873 21.48423  21.71994  21.862982 23.612286 23.108362]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.68273306 -0.41739035 -0.0502243   0.37750196  0.82889557  1.2463741
0:   1.6310434   1.8981156   2.0630403   2.1141958   2.0913277   1.9850516
0:   1.8208447   1.6762681   1.5005693   1.3819151   1.338841    1.3750329
0:   1.5061927   1.5339336 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.427129  10.74423   11.088565  11.335463  11.460856  11.472497
0:  11.471584  11.384928  11.277126  11.095713  10.779011  10.3884325
0:   9.973176   9.565515   9.221226   8.916592   8.615749   8.373106
0:   7.880276   7.672143 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [37.458916 37.722366 37.839626 37.73801  37.50536  37.23393  36.8978
0:  36.395927 35.84943  35.123917 34.278244 33.294125 32.340786 31.430954
0:  30.558643 29.83055  29.235838 28.75986  28.118122 28.092669]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.29922     4.8919687   4.470865    4.057745    3.6453488   3.2239692
0:   2.8022711   2.3457537   1.887907    1.4065833   0.91101503  0.36072016
0:  -0.22745657 -0.85197115 -1.55196    -2.2538857  -2.9348464  -3.5437856
0:  -4.7808137  -5.1355157 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [44.10318  44.05931  44.096546 44.14647  44.233612 44.266254 44.26481
0:  44.117973 43.974228 43.65685  43.06248  42.225563 41.17843  40.008934
0:  38.735565 37.532486 36.44462  35.47036  34.635994 34.008797]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.928794   8.336809   8.795785   9.2911625  9.748778  10.192597
0:  10.635252  11.008785  11.38555   11.786219  12.174599  12.537031
0:  12.921406  13.268627  13.615971  13.941043  14.293522  14.669802
0:  14.846163  15.298001 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [28.178673 28.65615  29.109001 29.511383 29.85025  30.079403 30.282116
0:  30.290375 30.264473 30.181652 30.017792 29.84716  29.687992 29.487274
0:  29.27058  29.07061  28.879642 28.708298 28.665543 28.886215]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.4356155 4.4355936 4.4469523 4.4781303 4.537797  4.6094193 4.6911793
0:  4.7408843 4.794323  4.8227105 4.832794  4.7965946 4.785272  4.758499
0:  4.7165904 4.7059197 4.7644415 4.888154  4.504079  4.521963 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.9453835 7.954619  7.9875603 8.003407  8.026582  8.001565  7.9626517
0:  7.894116  7.841261  7.834991  7.8204303 7.762634  7.6916933 7.6433425
0:  7.5762897 7.561235  7.5692997 7.6029253 6.770584  6.6409287]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.2701826 4.3304563 4.4053116 4.524169  4.626191  4.721013  4.8322
0:  4.8969755 4.984235  5.078679  5.1568327 5.2511    5.3602347 5.4678555
0:  5.6049695 5.7373714 5.860867  5.9897733 6.129675  6.280075 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-13.460165 -13.467272 -13.490612 -13.483627 -13.51409  -13.581369
0:  -13.586275 -13.632273 -13.700771 -13.781069 -13.847139 -13.932163
0:  -13.938894 -13.899422 -13.861349 -13.81624  -13.78125  -13.749073
0:  -14.476713 -14.544563]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.448048  12.428993  12.407072  12.387775  12.332148  12.248447
0:  12.177989  12.067095  11.971207  11.871164  11.740681  11.5932865
0:  11.462271  11.352461  11.268278  11.20616   11.156608  11.096487
0:  10.909187  10.839486 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.800102 23.224634 23.738054 24.218298 24.60789  24.839653 24.838322
0:  24.533218 24.049837 23.31995  22.485508 21.55319  20.621733 19.789097
0:  18.99327  18.349415 17.861973 17.569355 17.056133 17.353853]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.956237  5.072747  5.2099495 5.375049  5.4948974 5.5847697 5.682295
0:  5.7275233 5.8039856 5.8727517 5.9344897 5.997768  6.0846105 6.1749787
0:  6.275338  6.348835  6.405727  6.456775  6.1347837 6.1888323]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.153667 20.220089 20.261824 20.254541 20.214956 20.15013  20.079456
0:  19.969444 19.86383  19.710632 19.488607 19.180916 18.850666 18.490234
0:  18.120344 17.749302 17.416246 17.114153 15.691872 15.017071]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.2310739 1.3166237 1.724194  2.2264204 2.7759326 3.2585852 3.6614141
0:  3.9941633 4.4695196 5.072689  5.8402157 6.6441655 7.4932933 8.176201
0:  8.6769495 8.9892025 9.080593  9.105918  9.030351  9.0254545]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.8941746 4.950643  5.0232286 5.1155176 5.2032094 5.2645273 5.3323116
0:  5.368321  5.425016  5.495396  5.5614386 5.624468  5.7026205 5.7834516
0:  5.873679  5.9829144 6.11459   6.2816114 6.124958  6.249263 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.033125  12.057378  12.099065  12.145086  12.156759  12.116305
0:  12.04232   11.866543  11.706233  11.561256  11.423984  11.315206
0:  11.271747  11.285673  11.375187  11.553461  11.820204  12.1155205
0:  12.745987  13.039537 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-15.083846  -15.298921  -15.407712  -15.328429  -15.139213  -14.917106
0:  -14.621297  -14.379964  -14.121491  -13.800506  -13.4065695 -13.031379
0:  -12.601682  -12.212867  -11.897267  -11.631814  -11.411689  -11.178094
0:  -11.113902  -11.105281 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.1516023  -1.9882407  -1.883079   -1.8396411  -1.799294   -1.8032088
0:  -1.7896733  -1.8149924  -1.8048635  -1.7423034  -1.6471038  -1.5463128
0:  -1.4600224  -1.3607516  -1.3182998  -1.2256117  -1.1108656  -0.93318224
0:  -0.7818327  -0.6774974 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.812512  -4.1443753 -4.522927  -4.9601674 -5.417255  -5.880958
0:  -6.3456836 -6.8468785 -7.298366  -7.714289  -8.06506   -8.369728
0:  -8.609169  -8.716896  -8.780565  -8.72044   -8.630535  -8.551952
0:  -9.050941  -9.048862 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.952892 30.188133 30.442448 30.756016 31.026798 31.264168 31.493282
0:  31.621815 31.770077 31.926243 32.111115 32.358307 32.69087  33.07734
0:  33.495964 33.866554 34.16312  34.37206  34.599144 34.956978]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.190432 12.303738 12.426247 12.483418 12.552247 12.612837 12.684648
0:  12.743641 12.841793 12.952511 13.077595 13.14875  13.17823  13.176703
0:  13.106552 13.057287 13.038916 13.024351 12.481133 12.470229]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.248339  -9.139797  -8.964388  -8.734785  -8.464109  -8.240175
0:  -8.053719  -7.983558  -7.9889684 -8.042997  -8.126589  -8.271166
0:  -8.41461   -8.521967  -8.640657  -8.682085  -8.65583   -8.574417
0:  -9.243273  -9.25881  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.22828054 0.7573118  1.3384023  1.9717503  2.6191268  3.2905107
0:  4.004204   4.6849365  5.336319   5.938412   6.4793105  6.9594536
0:  7.447415   7.901171   8.321165   8.666735   8.897542   9.037199
0:  8.527676   8.713887  ]
0: validation loss for strategy=forecast at epoch 12 : nan
0: validation loss for velocity_u : 0.036857280880212784
0: validation loss for velocity_v : 0.06792197376489639
0: validation loss for specific_humidity : 0.023096159100532532
0: validation loss for velocity_z : 0.47422733902931213
0: validation loss for temperature : 0.06940975040197372
0: validation loss for total_precip : nan
0: 13 : 10:38:51 :: batch_size = 96, lr = 1.5242895643428828e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 13, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([2.2949, 2.2646, 2.2427, 2.2315, 2.2364, 2.2600, 2.2984, 2.3493, 2.4084, 2.4666, 2.5190, 2.5619, 2.5896, 2.6059,
0:         2.6192, 2.6307, 2.6445, 2.6691, 2.4861, 2.4408, 2.3935, 2.3468, 2.3101, 2.2922, 2.2961], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.8469, -0.8869, -0.9345, -0.9867, -1.0391, -1.0901, -1.1373, -1.1772, -1.2083, -1.2285, -1.2351, -1.2309,
0:         -1.2214, -1.2119, -1.2073, -1.2117, -1.2287, -1.2609, -0.8437, -0.8738, -0.9151, -0.9637, -1.0127, -1.0587,
0:         -1.1010], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6719, -0.6752, -0.6817, -0.6861, -0.6936, -0.6996, -0.7072, -0.7107, -0.7134, -0.7156, -0.7176, -0.7195,
0:         -0.7209, -0.7236, -0.7259, -0.7290, -0.7326, -0.7364, -0.6718, -0.6743, -0.6767, -0.6811, -0.6852, -0.6919,
0:         -0.6996], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.5261, 0.4956, 0.5167, 0.5977, 0.6650, 0.7229, 0.7818, 0.7934, 0.8102, 0.8744, 0.9207, 0.9565, 1.0154, 1.0606,
0:         1.1132, 1.1890, 1.2353, 1.2468, 0.9344, 0.8933, 0.8765, 0.9049, 0.9039, 0.9123, 0.9775], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0.3660, -0.3348, -0.2992, -0.2562, -0.2056, -0.1491, -0.0895, -0.0302,  0.0246,  0.0719,  0.1107,  0.1415,
0:          0.1657,  0.1863,  0.2075,  0.2339,  0.2701,  0.3171,  0.3759,  0.4450,  0.5227,  0.6102,  0.7091,  0.8146,
0:          0.9205], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 13, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,  0.2575,     nan,  0.1737,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:          0.2803,     nan,     nan,     nan,     nan, -0.1449,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2329,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2362,     nan,     nan,     nan,     nan,     nan, -0.2112,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2155,     nan,     nan,     nan,     nan,     nan,
0:          0.2238,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.1916,     nan,     nan,     nan, -0.2340,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0709,  0.0237,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0220,
0:          0.0302,     nan,     nan,     nan,     nan, -0.1666,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0927,     nan,
0:         -0.0089,     nan,     nan,     nan,     nan, -0.1862,     nan,     nan,     nan,     nan,     nan,  0.2738,
0:             nan,     nan,     nan,     nan,     nan, -0.2231,     nan,  0.0944,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 13, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.9033, 0.9574, 1.0098, 1.0619, 1.1074, 1.1480, 1.1881, 1.2174, 1.2513, 1.2875, 1.3224, 1.3631, 1.4077, 1.4514,
0:         1.4937, 1.5235, 1.5503, 1.5717, 0.8814, 0.9431, 1.0023, 1.0604, 1.1140, 1.1683, 1.2151], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.0874, -0.2799, -0.4962, -0.7309, -0.9559, -1.1452, -1.2875, -1.3783, -1.4229, -1.4454, -1.4512, -1.4458,
0:         -1.4300, -1.3880, -1.3251, -1.2513, -1.1763, -1.1044,  0.0497, -0.1110, -0.3176, -0.5564, -0.8045, -1.0288,
0:         -1.2055], device='cuda:1', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.7974, -0.7917, -0.7708, -0.7333, -0.6794, -0.6097, -0.5303, -0.4458, -0.3692, -0.3020, -0.2519, -0.2224,
0:         -0.2096, -0.2081, -0.2117, -0.2152, -0.2159, -0.2171, -0.7939, -0.7960, -0.7851, -0.7593, -0.7192, -0.6633,
0:         -0.5911], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([ 0.0683, -0.0052, -0.1073, -0.2532, -0.3632, -0.4416, -0.5578, -0.6985, -0.8486, -1.0438, -1.2630, -1.4684,
0:         -1.6935, -1.9209, -2.0908, -2.1530, -2.0469, -1.7877,  0.1321,  0.1023,  0.0625, -0.0379, -0.1298, -0.2324,
0:         -0.3944], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([-1.1563, -1.1559, -1.1434, -1.1208, -1.0920, -1.0606, -1.0258, -0.9860, -0.9440, -0.9009, -0.8604, -0.8248,
0:         -0.7945, -0.7657, -0.7399, -0.7144, -0.6919, -0.6722, -0.6562, -0.6404, -0.6268, -0.6152, -0.6097, -0.6146,
0:         -0.6297], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.05740032717585564; velocity_v: 0.09137685596942902; specific_humidity: 0.041175976395606995; velocity_z: 0.5978478789329529; temperature: 0.09587040543556213; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.04576602205634117; velocity_v: 0.07410027086734772; specific_humidity: 0.03594707325100899; velocity_z: 0.4290667772293091; temperature: 0.08121013641357422; total_precip: nan; 
0: epoch: 13 [1/5 (20%)]	Loss: nan : nan :: 0.13276 (2.95 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06398395448923111; velocity_v: 0.10333593189716339; specific_humidity: 0.037260062992572784; velocity_z: 0.5063416957855225; temperature: 0.09590230137109756; total_precip: nan; 
0: epoch: 13 [2/5 (40%)]	Loss: nan : nan :: 0.15025 (15.99 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06010152027010918; velocity_v: 0.10281477123498917; specific_humidity: 0.0394606776535511; velocity_z: 0.5150657892227173; temperature: 0.08876124769449234; total_precip: nan; 
0: epoch: 13 [3/5 (60%)]	Loss: nan : nan :: 0.14734 (15.97 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.0707976222038269; velocity_v: 0.11399247497320175; specific_humidity: 0.04520503804087639; velocity_z: 0.4741966724395752; temperature: 0.10063966363668442; total_precip: nan; 
0: epoch: 13 [4/5 (80%)]	Loss: nan : nan :: 0.16125 (16.28 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [4.76837158e-07 4.76837158e-07 4.76837158e-07 4.76837158e-07
0:  4.76837158e-07 4.76837158e-07 4.76837158e-07 4.76837158e-07
0:  4.76837158e-07 4.76837158e-07 4.76837158e-07 4.76837158e-07
0:  4.76837158e-07 4.76837158e-07 4.76837158e-07 4.76837158e-07
0:  4.76837158e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 9.53674316e-07 3.33786011e-06 3.33786011e-06
0:  3.33786011e-06 3.81469727e-06 5.24520874e-06 5.72204590e-06
0:  6.19888306e-06 9.53674316e-06 1.19209290e-05 1.28746033e-05
0:  1.38282776e-05 1.14440918e-05 8.58306885e-06 6.19888306e-06
0:  4.29153442e-06 2.86102295e-06 1.90734863e-06 2.86102295e-06
0:  3.33786011e-06 3.33786011e-06 4.29153442e-06 3.81469727e-06
0:  3.33786011e-06 3.33786011e-06 2.38418579e-06 1.90734863e-06
0:  1.43051147e-06 1.43051147e-06 1.43051147e-06 9.53674316e-07
0:  1.43051147e-06 1.90734863e-06 2.38418579e-06 3.33786011e-06
0:  2.86102295e-06 2.38418579e-06 1.90734863e-06 1.43051147e-06
0:  4.76837158e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  2.38418579e-06 6.19888306e-06 8.10623169e-06 9.53674316e-06
0:  1.04904175e-05 1.00135803e-05 8.10623169e-06 5.72204590e-06
0:  3.81469727e-06 2.38418579e-06 1.90734863e-06 3.81469727e-06
0:  3.33786011e-06 3.33786011e-06 4.29153442e-06 4.76837158e-06
0:  4.76837158e-06 4.29153442e-06 3.33786011e-06 2.86102295e-06
0:  1.90734863e-06 1.43051147e-06 4.76837158e-07 4.76837158e-07
0:  9.53674316e-07 1.43051147e-06 1.90734863e-06 3.81469727e-06]
0: Target values (first 200):
0: [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 1.90734863e-06 1.90734863e-06
0:  1.90734863e-06 2.86102295e-06 5.72204590e-06 7.62939453e-06
0:  9.53674316e-06 1.33514404e-05 1.23977661e-05 1.04904175e-05
0:  8.58306885e-06 7.62939453e-06 8.58306885e-06 1.04904175e-05
0:  1.04904175e-05 9.53674316e-06 8.58306885e-06 7.62939453e-06
0:  7.62939453e-06 8.58306885e-06 7.62939453e-06 6.67572021e-06
0:  6.67572021e-06 5.72204590e-06 5.72204590e-06 5.72204590e-06
0:  4.76837158e-06 4.76837158e-06 3.81469727e-06 2.86102295e-06
0:  2.86102295e-06 1.90734863e-06 9.53674316e-07 9.53674316e-07
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 9.53674316e-07 9.53674316e-07 9.53674316e-07
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  1.90734863e-06 6.67572021e-06 5.72204590e-06 3.81469727e-06
0:  2.86102295e-06 2.86102295e-06 4.76837158e-06 5.72204590e-06
0:  5.72204590e-06 5.72204590e-06 5.72204590e-06 8.58306885e-06
0:  9.53674316e-06 9.53674316e-06 8.58306885e-06 7.62939453e-06
0:  6.67572021e-06 8.58306885e-06 8.58306885e-06 7.62939453e-06
0:  6.67572021e-06 4.76837158e-06 3.81469727e-06 2.86102295e-06
0:  2.86102295e-06 1.90734863e-06 9.53674316e-07 1.90734863e-06]
0: Prediction values (first 20):
0: [27.834732 28.049541 28.31491  28.508728 28.702374 28.888515 29.036945
0:  29.135746 29.289736 29.45199  29.607058 29.674074 29.756205 29.808317
0:  29.802052 29.811567 29.933882 30.1113   29.749306 29.895874]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -2.203, max = 2.698, mean = -0.232
0:          sample (first 20): tensor([1.7875, 1.8064, 1.8298, 1.8468, 1.8639, 1.8803, 1.8934, 1.9021, 1.9156, 1.9299, 1.9436, 1.9495, 1.9567, 1.9613,
0:         1.9607, 1.9616, 1.9724, 1.9880, 1.8181, 1.8416])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.553097    5.127232    4.6406193   4.1292973   3.5907235   3.052909
0:   2.4885175   1.9115272   1.3358054   0.7552929   0.17777252 -0.41132116
0:  -0.9737816  -1.4852395  -1.9476771  -2.3282318  -2.5817776  -2.6971588
0:  -3.1029253  -3.299508  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.46096   17.29683   16.204952  15.26632   14.6291275 14.114761
0:  13.614361  12.928009  12.005159  10.922473   9.830403   8.853054
0:   8.054824   7.506765   7.077842   6.721256   6.4049144  6.174052
0:   6.0889854  6.638069 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.2614799 -2.2330527 -2.218677  -2.2411523 -2.263719  -2.3063407
0:  -2.322394  -2.3574195 -2.3617702 -2.3124232 -2.2192492 -2.1086354
0:  -1.9779944 -1.850266  -1.8202968 -1.853065  -1.9754434 -2.1645179
0:  -3.1364617 -3.39963  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.370518  -8.446398  -8.510223  -8.582329  -8.639227  -8.709774
0:  -8.744335  -8.8098345 -8.853261  -8.873863  -8.863246  -8.867111
0:  -8.850309  -8.78475   -8.7624445 -8.720867  -8.665418  -8.599793
0:  -9.249833  -9.351802 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.6897936 5.881977  6.159552  6.4005895 6.5944643 6.7278657 6.813445
0:  6.8835773 6.970645  7.063738  7.2059145 7.3150473 7.404604  7.521384
0:  7.582279  7.6412168 7.6697564 7.6449285 7.6341724 7.3438773]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.465017  14.262818  14.096958  13.910963  13.704817  13.465651
0:  13.247943  12.996846  12.784     12.60635   12.436398  12.26894
0:  12.141203  12.012297  11.901911  11.798003  11.7221365 11.672577
0:  11.665714  11.598581 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.2257643 4.4512725 4.6915483 5.032576  5.4262676 5.8128777 6.23667
0:  6.588489  6.910809  7.1105056 7.218506  7.2496405 7.2658796 7.219946
0:  7.1092234 6.913862  6.6405067 6.3290086 5.0628448 4.897792 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.078585  12.432188  12.772833  13.080412  13.339184  13.555111
0:  13.752342  13.884667  14.001512  14.079184  14.090893  14.021968
0:  13.903768  13.713245  13.489389  13.270145  13.081922  12.94397
0:  13.142094  13.1650715]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.503988 21.588957 21.641802 21.69094  21.685999 21.640205 21.677765
0:  21.612602 21.6175   21.626831 21.538548 21.459538 21.426441 21.431713
0:  21.550814 21.689426 21.869093 22.013355 23.01191  22.936386]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.789347 10.929247 11.086304 11.252789 11.40571  11.545905 11.701136
0:  11.824583 11.962814 12.108569 12.237869 12.363554 12.490307 12.606731
0:  12.736964 12.864412 13.016041 13.197519 13.132874 13.238068]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.68729115 0.7125325  0.7886014  0.8574939  0.9524393  1.07271
0:  1.1811833  1.2873621  1.3624959  1.4224396  1.4952149  1.5334978
0:  1.6221232  1.7373748  1.8666773  2.0211735  2.2026677  2.4381452
0:  2.5942454  2.697328  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.4868226  1.3206806  1.1430349  1.0164299  0.9333377  0.8954983
0:  0.87938356 0.850688   0.84592295 0.8124628  0.7904072  0.74200773
0:  0.7153506  0.7132783  0.71208715 0.73217964 0.76569414 0.8192158
0:  0.77813864 0.53311396]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.1214905  1.4570422  1.9360609  2.4963043  3.1146464  3.7144659
0:   4.3073173  4.8616076  5.4761686  6.1600146  6.972016   7.879487
0:   8.829566   9.77728   10.647134  11.384607  11.977067  12.413988
0:  13.481687  13.843186 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.487448  4.9685097 5.4674034 5.846069  6.157544  6.3765287 6.5706024
0:  6.742429  6.9293494 7.148896  7.3965764 7.601474  7.778923  7.9521937
0:  8.04837   8.125902  8.214519  8.283028  8.010286  8.048211 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.377074 11.665592 11.929363 12.117233 12.30406  12.470652 12.646317
0:  12.799461 12.950548 13.088888 13.230002 13.323368 13.397917 13.439384
0:  13.434356 13.417803 13.408968 13.423833 13.11121  13.204956]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.068203  -8.905304  -8.703702  -8.39624   -7.9724627 -7.527006
0:  -6.9978704 -6.5249767 -6.057642  -5.6353016 -5.2474136 -4.9813404
0:  -4.754814  -4.555526  -4.4897127 -4.3554897 -4.1732435 -3.933651
0:  -3.9509134 -3.7800932]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.187948 11.19743  11.211409 11.231724 11.245762 11.250591 11.264662
0:  11.248095 11.272337 11.284023 11.311983 11.333542 11.352702 11.379599
0:  11.430977 11.496777 11.563408 11.626503 11.674627 11.774604]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.043567  6.173576  6.2492275 6.327704  6.404437  6.4694443 6.5708165
0:  6.659332  6.843092  7.0878696 7.391075  7.7069817 8.008953  8.261553
0:  8.430119  8.55893   8.677584  8.795267  8.708639  8.732238 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -9.474693  -9.391155  -9.213776  -8.940767  -8.684076  -8.522865
0:   -8.417286  -8.498909  -8.687256  -8.925795  -9.181597  -9.470541
0:   -9.704905  -9.923143 -10.253435 -10.568171 -10.901751 -11.21657
0:  -12.536049 -12.864672]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.6876054 -3.7483506 -3.799748  -3.8246884 -3.8327832 -3.8353887
0:  -3.8187041 -3.8304067 -3.8077006 -3.7676196 -3.7054496 -3.657783
0:  -3.5962472 -3.5411305 -3.5086207 -3.4626985 -3.4122071 -3.3363357
0:  -3.2094827 -2.9351554]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.535362  12.669484  12.7980995 12.812446  12.764834  12.646314
0:  12.422615  12.092979  11.651886  11.067969  10.375254   9.571771
0:   8.695865   7.8196335  6.9409056  6.131217   5.4047117  4.7937784
0:   3.8145998  3.6120307]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.417434  5.546569  5.6587186 5.6977053 5.721241  5.72228   5.75091
0:  5.750542  5.7578564 5.756339  5.7526617 5.696552  5.6045704 5.4934545
0:  5.285757  5.0430827 4.776735  4.5190306 3.809632  3.6255195]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.066144    1.1446028   1.2351203   1.3192883   1.3513255   1.3054509
0:   1.2188082   1.0721712   0.91865444  0.78659105  0.6631236   0.5440078
0:   0.43340397  0.3454256   0.2378149   0.1684103   0.13075542  0.12505102
0:  -0.3890338  -0.43683863]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.640064  -8.417082  -8.186817  -7.9751515 -7.7691665 -7.6153426
0:  -7.4618974 -7.3491445 -7.2210174 -7.072105  -6.8981147 -6.7302575
0:  -6.5488515 -6.3419757 -6.175979  -6.0041842 -5.8422217 -5.6902213
0:  -5.6675906 -5.4162374]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.805529 20.722479 20.583862 20.373909 20.12257  19.847345 19.570234
0:  19.259214 18.993935 18.766573 18.56604  18.377485 18.196428 18.02712
0:  17.865622 17.731936 17.61974  17.53984  17.442165 17.353941]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 6.704216   7.0365043  7.3670177  7.682476   7.998908   8.263772
0:   8.516176   8.708967   8.918704   9.150844   9.386389   9.585501
0:   9.785835   9.965728  10.110408  10.270043  10.431391  10.547809
0:  10.455114  10.734501 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.361395  -8.234863  -8.031424  -7.7721505 -7.4609    -7.1264424
0:  -6.7632747 -6.466149  -6.2126603 -6.041596  -5.9110026 -5.85016
0:  -5.7874055 -5.7176385 -5.690479  -5.648359  -5.6240897 -5.6250024
0:  -6.119161  -6.538693 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.608678  10.421523  10.299286  10.208135  10.145636  10.101957
0:  10.063689   9.97675    9.861941   9.672392   9.378214   9.052478
0:   8.712654   8.336446   7.9340696  7.4565077  6.9091806  6.3812275
0:   4.4132423  3.6629171]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.40871096 -0.52805376 -0.6197953  -0.66594744 -0.7153387  -0.8089919
0:  -0.9029684  -1.0206618  -1.1363859  -1.2329164  -1.3340826  -1.4712257
0:  -1.6089272  -1.7289329  -1.8304834  -1.8662801  -1.8831296  -1.8851008
0:  -2.0111814  -2.1006112 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.42742  13.258049 14.279747 15.407579 16.60376  17.834738 19.137568
0:  20.342884 21.536871 22.685692 23.77192  24.843082 25.906034 26.953733
0:  27.972815 28.930445 29.902382 30.759645 30.430246 31.398787]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.363443 23.38378  23.41278  23.379992 23.317476 23.221739 23.13359
0:  22.987125 22.870514 22.751259 22.59646  22.397743 22.215452 22.03603
0:  21.844553 21.704853 21.601076 21.484406 21.259026 21.16779 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-11.915983   -11.404968   -10.665676    -9.748886    -8.669178
0:   -7.5792365   -6.449146    -5.2877955   -4.1627192   -3.051764
0:   -2.009358    -1.1445575   -0.33570623   0.26908398   0.802413
0:    1.2212911    1.5272255    1.7497296    0.7638192    1.142559  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.139668 24.965935 24.766457 24.541729 24.35389  24.189686 24.099457
0:  23.88242  23.753279 23.621416 23.476967 23.319775 23.189112 23.078724
0:  22.928156 22.79534  22.688131 22.558142 22.740952 22.719889]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [34.304718 34.374428 34.305916 34.09634  33.842266 33.600677 33.379425
0:  33.07592  32.883827 32.751446 32.675697 32.647053 32.747795 32.936867
0:  33.124863 33.4069   33.730804 34.04332  32.990322 32.996883]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.124447   -9.804207   -9.509201   -9.347942   -9.330452   -9.439516
0:   -9.613977   -9.822296   -9.9610405 -10.034609  -10.060907  -10.091703
0:  -10.130587  -10.111828  -10.088224   -9.937452   -9.690468   -9.387629
0:   -8.8813     -8.560574 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.564398  12.758658  12.907719  12.9788685 13.055939  13.075886
0:  13.11307   13.095508  13.11795   13.154234  13.231738  13.281685
0:  13.292616  13.282953  13.213514  13.154888  13.090591  13.056526
0:  12.283527  12.491243 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.9021933 3.0589676 3.2839773 3.5437    3.8365405 4.136322  4.4280224
0:  4.681612  4.907671  5.105625  5.3192625 5.5031915 5.670556  5.825969
0:  5.971944  6.115638  6.2458305 6.378552  6.285117  6.41253  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.1176677 2.891779  2.6201382 2.2872615 1.9325175 1.6467757 1.4401402
0:  1.375215  1.4715824 1.679399  2.0135713 2.3498693 2.6979976 3.0443568
0:  3.3131533 3.5112274 3.60155   3.602667  3.1109538 2.879837 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.194838 12.37429  12.553393 12.676414 12.778912 12.859422 12.938543
0:  12.999821 13.088488 13.185059 13.286226 13.34527  13.405284 13.439348
0:  13.435329 13.436808 13.472577 13.570011 13.286372 13.500999]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.142494 26.548248 26.001846 25.481468 24.98755  24.476103 24.013681
0:  23.49178  23.07499  22.809458 22.598742 22.599873 22.804403 23.149775
0:  23.602715 24.072536 24.531092 24.92872  26.0409   26.50243 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.22595167  0.24800682  0.27178955  0.24440575  0.2081933   0.15114737
0:   0.11009836  0.02154827 -0.06080961 -0.16896677 -0.29705667 -0.45528936
0:  -0.59643793 -0.653461   -0.6932092  -0.66614914 -0.6227088  -0.5726466
0:  -0.63598776 -0.61974525]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.970516 18.833698 18.758574 18.68945  18.585758 18.429218 18.277987
0:  18.038492 17.80812  17.546886 17.17953  16.737082 16.24785  15.716362
0:  15.182508 14.644794 14.125283 13.629389 12.476124 11.714468]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.884478 21.923225 21.873058 21.71091  21.524048 21.377838 21.307394
0:  21.234901 21.194475 21.215096 21.284294 21.411222 21.602652 21.784231
0:  21.935226 22.117163 22.32109  22.507551 22.398268 22.518084]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.347574  12.492804  12.61702   12.686731  12.728928  12.723985
0:  12.726469  12.686928  12.699068  12.746115  12.875997  13.085091
0:  13.388227  13.75959   14.154724  14.540664  14.877303  15.118557
0:  15.476566  15.6273365]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.450831 12.50626  12.585481 12.677834 12.720046 12.723261 12.718657
0:  12.638717 12.585488 12.550335 12.481512 12.427824 12.434296 12.457781
0:  12.557623 12.687537 12.88538  13.124706 13.114103 13.470551]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.6638694 7.7012606 7.751982  7.798362  7.843918  7.8822975 7.9260087
0:  7.937097  7.9364896 7.9445376 7.940269  7.936556  7.945527  7.9486523
0:  7.9355907 7.944791  7.9588137 8.00079   8.003332  8.027541 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.796068  7.8729115 7.9419465 7.9767513 7.9847593 7.972224  7.997214
0:  8.000643  8.067529  8.194237  8.370377  8.609062  8.926422  9.248916
0:  9.542226  9.720966  9.794236  9.775569  8.502143  8.281457 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.741351  4.549093  4.4205823 4.4672785 4.7287073 5.195617  5.8011746
0:  6.4643197 7.202592  7.909458  8.454847  8.671377  8.52132   8.062101
0:  7.4119177 6.835667  6.562722  6.5937533 7.2836676 6.8831964]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.878635  14.022926  14.202021  14.369542  14.481806  14.5362625
0:  14.546558  14.496424  14.448771  14.394714  14.318217  14.201511
0:  14.083136  13.933526  13.769924  13.6040535 13.478834  13.393274
0:  13.20911   13.389467 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-22.999187 -23.084446 -23.118034 -23.062584 -22.964851 -22.886505
0:  -22.781849 -22.706703 -22.604588 -22.452972 -22.279217 -22.115826
0:  -21.914196 -21.677456 -21.436584 -21.213367 -21.044022 -20.825676
0:  -20.734234 -20.53334 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.7094965  7.874178   8.086179   8.300798   8.520364   8.757935
0:   9.030066   9.293054   9.57831    9.851885  10.0889435 10.235117
0:  10.334688  10.407852  10.463446  10.555165  10.6873865 10.851925
0:  11.373178  11.839634 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.8762164 -5.9256835 -5.9310412 -5.8874097 -5.8048453 -5.7476106
0:  -5.645023  -5.596315  -5.5126824 -5.4403663 -5.41204   -5.4398923
0:  -5.570205  -5.657992  -5.8129106 -5.881717  -5.929548  -5.9485545
0:  -6.5358186 -6.7505536]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.9605045 -6.9151077 -6.847414  -6.731103  -6.588667  -6.481698
0:  -6.3742743 -6.3476963 -6.312416  -6.234873  -6.0986166 -5.9389486
0:  -5.778965  -5.612941  -5.550495  -5.5126057 -5.5078535 -5.4777803
0:  -5.666545  -5.6890717]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.0391698  -3.001861   -2.9353757  -2.7969375  -2.5693698  -2.3671956
0:  -2.128224   -1.9424825  -1.7581935  -1.5506921  -1.3218751  -1.1272588
0:  -0.94519854 -0.79040813 -0.6636181  -0.52347803 -0.35688877 -0.18847752
0:  -0.82517767 -0.8492093 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.425972  14.286784  14.182289  14.089479  13.961885  13.762749
0:  13.554195  13.237776  12.976741  12.754099  12.559355  12.453336
0:  12.535438  12.728069  13.097723  13.560217  14.103514  14.714611
0:  15.300219  15.8494835]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.835422    1.4857135   1.1592469   0.8833704   0.65350866  0.45199347
0:   0.29346895  0.17055559  0.11271334  0.07452297  0.0577445  -0.0279789
0:  -0.16438437 -0.31015444 -0.5324421  -0.8028841  -1.0884662  -1.3583312
0:  -2.3201518  -2.5965867 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.7587147e-02 -1.2017393e-01 -1.7647600e-01 -2.1958637e-01
0:  -2.4179268e-01 -2.7296019e-01 -2.3901463e-01 -1.8962812e-01
0:  -1.1612654e-01 -3.0641079e-02  5.8221817e-03 -2.2206306e-03
0:  -6.7557335e-02 -2.1589041e-01 -4.6618986e-01 -7.6762056e-01
0:  -1.1189313e+00 -1.4752278e+00 -2.3139138e+00 -2.4392953e+00]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.98851  30.262192 30.494839 30.708523 30.90783  31.11959  31.395847
0:  31.548012 31.755825 31.94165  32.12655  32.292633 32.526287 32.809772
0:  33.082348 33.391094 33.70426  34.006397 34.825893 35.501648]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.47724   14.588127  14.702176  14.789315  14.832001  14.873706
0:  14.968653  15.0212145 15.125628  15.197713  15.197959  15.119409
0:  15.007306  14.906349  14.82299   14.771712  14.776165  14.7912655
0:  14.517239  14.555281 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.4122281 -1.2810559 -1.1736197 -1.0967698 -1.0478787 -1.0501399
0:  -1.0530171 -1.0923076 -1.1354604 -1.1805377 -1.2340703 -1.3214822
0:  -1.4055696 -1.4968362 -1.6238666 -1.7401481 -1.8832765 -2.008306
0:  -3.0577493 -3.2337337]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.53556824  0.5619116   0.5388341   0.4676094   0.34699392  0.13498688
0:  -0.14190388 -0.5521388  -1.0091567  -1.5453558  -2.1411963  -2.7740898
0:  -3.415203   -3.983695   -4.514311   -4.962146   -5.322876   -5.607709
0:  -6.827921   -7.1158533 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.518215 17.643354 17.77273  17.92488  18.050684 18.17445  18.35976
0:  18.46991  18.651653 18.87408  19.077686 19.30748  19.591328 19.864319
0:  20.17303  20.45203  20.703508 20.915571 20.847343 21.106861]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.876726  5.817074  5.749823  5.662486  5.5740266 5.447077  5.3560033
0:  5.241113  5.1730065 5.128172  5.081895  5.011652  4.9262958 4.841686
0:  4.7435074 4.6985416 4.657054  4.6109467 4.5000467 4.420399 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [32.967945 32.939762 32.825813 32.660618 32.475254 32.306995 32.11267
0:  31.796768 31.465294 31.106934 30.719076 30.340992 30.033386 29.725101
0:  29.46509  29.197744 28.969429 28.786253 28.71915  28.637865]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.683767  17.404703  16.983738  16.320723  15.560513  14.744459
0:  13.9673815 13.316743  12.86956   12.661163  12.63553   12.6643505
0:  12.703083  12.763056  12.776829  12.891478  13.127175  13.418865
0:  14.698832  15.049028 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.8025675 -5.826483  -5.862735  -5.902673  -5.9267597 -6.0040464
0:  -6.0647383 -6.210911  -6.365034  -6.527796  -6.688799  -6.866274
0:  -7.037798  -7.133625  -7.2344913 -7.2720804 -7.273098  -7.2504425
0:  -7.846921  -7.9335318]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.183455   -2.0208592  -1.7522092  -1.4109025  -1.0610566  -0.72421503
0:  -0.36965132 -0.05109406  0.29580736  0.66273546  1.0571451   1.4273734
0:   1.7982664   2.1468964   2.4613118   2.7579598   3.0778666   3.4484403
0:   4.009137    4.404454  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.653728 22.677265 22.70966  22.733677 22.704315 22.68459  22.679573
0:  22.64386  22.651108 22.671455 22.667446 22.629692 22.61208  22.580952
0:  22.56398  22.54972  22.549946 22.555656 22.531372 22.510704]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.3593779  2.3247876  2.4478126  2.6794949  3.057658   3.52559
0:   4.0451536  4.579006   5.138725   5.690194   6.2285137  6.712155
0:   7.172307   7.6707916  8.192173   8.767021   9.389929  10.018728
0:  10.839074  11.101885 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.8972225 12.701282  12.374618  11.915142  11.354551  10.70294
0:   9.987697   9.219228   8.413189   7.639039   6.899733   6.242655
0:   5.726604   5.2949595  4.9922333  4.7914896  4.665998   4.5934668
0:   4.7172737  4.687232 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.546335 15.616971 15.642238 15.607321 15.503081 15.318625 15.092238
0:  14.772394 14.488336 14.206314 13.934776 13.659359 13.427473 13.234665
0:  13.034238 12.889711 12.792929 12.764086 12.736736 12.75284 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.001854 17.375969 17.685192 17.934446 18.0626   18.054562 17.94117
0:  17.70445  17.433132 17.123016 16.798946 16.446321 16.114115 15.76561
0:  15.390045 15.03599  14.738026 14.503439 13.704714 13.186026]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.580803 23.262714 23.924229 24.290707 24.372665 24.156181 23.755356
0:  23.185135 22.54324  21.870073 21.178947 20.546997 20.017632 19.588299
0:  19.22328  18.87201  18.450058 17.958076 17.27708  17.283676]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.244812    1.533916    0.962615    0.5129204   0.06366968 -0.3981037
0:  -0.82294035 -1.2909222  -1.6616406  -1.9630265  -2.3036036  -2.61933
0:  -2.7811399  -2.900763   -2.8551955  -2.7252154  -2.5475516  -2.262032
0:  -2.2118154  -2.2115006 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.1392365 4.175012  4.2202296 4.27013   4.317556  4.3470263 4.383339
0:  4.38214   4.4014773 4.449239  4.498907  4.546051  4.6140223 4.672883
0:  4.725396  4.7941117 4.851215  4.916024  5.178337  5.259628 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.5300055 -4.6623745 -4.765538  -4.8522787 -4.9946775 -5.2278748
0:  -5.4982405 -5.8513346 -6.2000694 -6.5524387 -6.8750696 -7.2053185
0:  -7.4977436 -7.7539654 -8.008139  -8.219025  -8.41504   -8.548812
0:  -9.731178  -9.97171  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.292778  3.868947  3.4186566 2.9772651 2.5490656 2.1688552 1.8935006
0:  1.6612101 1.532723  1.452157  1.4036827 1.3267975 1.2704377 1.2759905
0:  1.3648009 1.6086936 1.9403448 2.3224459 3.1140242 3.4804223]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.558834 25.473694 25.300938 24.932426 24.426426 23.749626 22.892445
0:  21.918438 20.945889 20.088856 19.461452 19.07927  18.992125 19.121347
0:  19.390656 19.693472 19.97742  20.187042 19.634897 20.073385]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [30.27068  30.387934 30.758211 31.07566  31.453194 31.740465 31.69424
0:  31.248129 30.389475 29.143988 27.546227 25.802082 24.121935 22.595453
0:  21.538496 20.879848 20.637608 20.716679 23.52756  23.766264]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.432847   -1.1561728  -0.8599348  -0.6256957  -0.4742384  -0.40442848
0:  -0.35129547 -0.30801916 -0.16195965  0.10053682  0.45514584  0.8331814
0:   1.2024522   1.5505114   1.7726445   1.9229083   1.9776735   1.9527731
0:   1.6194763   1.5984468 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.351804   8.372501   8.427965   8.513121   8.57903    8.612008
0:   8.6284685  8.583892   8.549623   8.527458   8.51686    8.516956
0:   8.56412    8.635831   8.755594   8.896079   9.049514   9.220762
0:   9.654194  10.023384 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.215207 9.192519 9.18599  9.120314 9.060393 8.985086 8.881401 8.767693
0:  8.684931 8.645617 8.649499 8.6464   8.668005 8.696847 8.694766 8.71351
0:  8.781977 8.868537 8.722778 8.721844]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.0343766 5.2779512 5.5513296 5.8585577 6.134307  6.350506  6.5389194
0:  6.6615067 6.76213   6.8428717 6.9139347 6.9768014 7.0502415 7.107867
0:  7.14792   7.169209  7.149147  7.1018925 6.7317624 6.6797338]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.334224  5.3592806 5.3190775 5.1957655 5.0866184 4.9635167 4.8326807
0:  4.7228966 4.6527467 4.660867  4.744014  4.8640804 5.023438  5.209141
0:  5.342886  5.4983974 5.647464  5.7784986 5.950886  6.175173 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.348738 18.382887 18.419464 18.40606  18.309862 18.129417 17.952658
0:  17.683113 17.490961 17.318357 17.162573 17.016373 16.942095 16.87545
0:  16.838617 16.843176 16.853783 16.905382 17.379948 17.586016]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.10571  18.012653 17.971653 17.930227 17.860565 17.756216 17.638277
0:  17.468313 17.342995 17.242382 17.166645 17.082247 17.048409 17.048023
0:  17.0965   17.170397 17.247864 17.348104 17.241322 17.312403]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.7136259 -1.727562  -1.740799  -1.776763  -1.8310585 -1.9335909
0:  -2.0241146 -2.1721315 -2.295597  -2.381463  -2.4302864 -2.4621983
0:  -2.450019  -2.3742256 -2.3177252 -2.2056065 -2.0721931 -1.9304056
0:  -1.5544682 -1.5301428]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.2273955  -2.0455012  -1.8386655  -1.667769   -1.5328641  -1.4670339
0:  -1.413836   -1.4146504  -1.3883376  -1.3135314  -1.1992536  -1.0853543
0:  -0.9462838  -0.7733035  -0.62847424 -0.42899656 -0.22212219  0.00548792
0:  -0.03490591  0.13978434]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.7680173  -0.90689373 -1.00003    -1.0090284  -0.93935204 -0.83739424
0:  -0.6444597  -0.43673706 -0.18993187  0.07388449  0.31706905  0.507802
0:   0.65454006  0.74563074  0.74925375  0.7179575   0.6501322   0.5770173
0:   0.13920498  0.09415483]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.969067 33.78216  33.672543 33.529808 33.43615  33.48054  33.58698
0:  33.830597 34.299908 34.976665 35.74594  36.593716 37.52495  38.37559
0:  39.143867 39.70085  40.085022 40.08758  38.208527 37.947956]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.203335  10.030548   9.857434   9.672415   9.440267   9.168881
0:   8.932961   8.651797   8.434494   8.23817    8.064591   7.9673305
0:   7.967365   8.05099    8.186047   8.312141   8.385084   8.403969
0:   7.769008   7.5708847]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.996168 10.750547 10.526338 10.335506 10.168369  9.998701  9.891392
0:   9.745935  9.64019   9.559061  9.46122   9.389564  9.347918  9.314213
0:   9.310143  9.280526  9.199478  9.10597   9.273118  9.098196]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.42581  14.479801 14.528104 14.527985 14.493453 14.441571 14.429236
0:  14.374707 14.389153 14.39974  14.401076 14.36023  14.321509 14.269869
0:  14.20344  14.178362 14.172187 14.156935 13.93428  13.970885]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.192713 23.506636 23.88819  24.280828 24.643938 24.959793 25.24518
0:  25.448153 25.677374 25.90289  26.119701 26.381313 26.696274 27.086521
0:  27.458933 27.79894  28.037352 28.150433 27.532618 27.55554 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.268267 23.329306 23.481625 23.629358 23.709196 23.631596 23.273249
0:  22.711254 22.000826 21.333261 20.76053  20.32578  20.05727  19.961306
0:  20.028023 20.280083 20.817108 21.376293 21.165556 21.154215]
0: validation loss for strategy=forecast at epoch 13 : nan
0: validation loss for velocity_u : 0.03452427312731743
0: validation loss for velocity_v : 0.06085595861077309
0: validation loss for specific_humidity : 0.02339853160083294
0: validation loss for velocity_z : 0.4572501480579376
0: validation loss for temperature : 0.07231785356998444
0: validation loss for total_precip : nan
0: 14 : 10:42:43 :: batch_size = 96, lr = 1.4871117700906175e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 14, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6456, -0.6450, -0.6450, -0.6458, -0.6472, -0.6493, -0.6518, -0.6550, -0.6585, -0.6625, -0.6669, -0.6717,
0:         -0.6768, -0.6822, -0.6876, -0.6932, -0.6989, -0.7045, -0.3420, -0.3396, -0.3380, -0.3375, -0.3378, -0.3391,
0:         -0.3410], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2083, 0.2091, 0.2102, 0.2116, 0.2135, 0.2159, 0.2192, 0.2231, 0.2283, 0.2344, 0.2416, 0.2503, 0.2601, 0.2710,
0:         0.2832, 0.2963, 0.3103, 0.3251, 0.1958, 0.1929, 0.1904, 0.1890, 0.1882, 0.1884, 0.1894], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6900, -0.6903, -0.6905, -0.6907, -0.6909, -0.6911, -0.6913, -0.6915, -0.6917, -0.6919, -0.6920, -0.6920,
0:         -0.6920, -0.6920, -0.6921, -0.6922, -0.6922, -0.6921, -0.6918, -0.6920, -0.6922, -0.6924, -0.6925, -0.6927,
0:         -0.6928], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2648, 0.2525, 0.2413, 0.2323, 0.2234, 0.2144, 0.2066, 0.1998, 0.1942, 0.1886, 0.1830, 0.1741, 0.1629, 0.1483,
0:         0.1315, 0.1147, 0.1001, 0.0856, 0.3511, 0.3578, 0.3623, 0.3611, 0.3522, 0.3376, 0.3197], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0.9262, -0.9412, -0.9563, -0.9720, -0.9881, -1.0046, -1.0222, -1.0400, -1.0588, -1.0776, -1.0972, -1.1167,
0:         -1.1367, -1.1564, -1.1762, -1.1953, -1.2145, -1.2329, -1.2506, -1.2678, -1.2842, -1.2998, -1.3148, -1.3287,
0:         -1.3416], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 14, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan, -0.2436,     nan,     nan,     nan,     nan, -0.2436,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2436, -0.2436,     nan,     nan,     nan,     nan,     nan,     nan, -0.2436,     nan,
0:             nan,     nan, -0.2436, -0.2436,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2436,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2436,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2436,     nan,     nan, -0.2436,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2436,
0:             nan,     nan,     nan,     nan, -0.2436,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2436,     nan,     nan,     nan,     nan,     nan, -0.2436,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2436,     nan,     nan,     nan,     nan,     nan,     nan, -0.2436,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2436,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2436,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2436,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 14, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.6793, -0.6830, -0.6776, -0.6690, -0.6527, -0.6373, -0.6180, -0.6034, -0.5860, -0.5656, -0.5454, -0.5216,
0:         -0.4989, -0.4732, -0.4473, -0.4173, -0.3811, -0.3501, -0.6651, -0.6605, -0.6572, -0.6494, -0.6368, -0.6236,
0:         -0.6088], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([1.8515, 1.8252, 1.7985, 1.7766, 1.7571, 1.7502, 1.7317, 1.7207, 1.7135, 1.7028, 1.6879, 1.6747, 1.6560, 1.6451,
0:         1.6403, 1.6401, 1.6406, 1.6387, 1.8629, 1.8249, 1.7919, 1.7799, 1.7773, 1.7808, 1.7772], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.7053, -0.7027, -0.7014, -0.6998, -0.7008, -0.7011, -0.7024, -0.7027, -0.7035, -0.7020, -0.6998, -0.6979,
0:         -0.6959, -0.6950, -0.6969, -0.7004, -0.7065, -0.7145, -0.7036, -0.7028, -0.7021, -0.6990, -0.6984, -0.6981,
0:         -0.6976], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([ 0.0489,  0.0562,  0.0225, -0.0066, -0.0209, -0.0323, -0.0256, -0.0373, -0.0660, -0.0906, -0.1134, -0.1161,
0:         -0.1186, -0.1398, -0.1471, -0.1448, -0.1337, -0.1130,  0.0032, -0.0148, -0.0451, -0.0484, -0.0361, -0.0391,
0:         -0.0452], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([-0.9351, -0.9469, -0.9562, -0.9619, -0.9663, -0.9707, -0.9769, -0.9830, -0.9868, -0.9862, -0.9833, -0.9769,
0:         -0.9704, -0.9656, -0.9605, -0.9540, -0.9465, -0.9355, -0.9227, -0.9088, -0.8945, -0.8798, -0.8655, -0.8530,
0:         -0.8403], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.059540919959545135; velocity_v: 0.0937613695859909; specific_humidity: 0.03459601849317551; velocity_z: 0.5837212800979614; temperature: 0.09924590587615967; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.0675957053899765; velocity_v: 0.10862787067890167; specific_humidity: 0.04738184064626694; velocity_z: 0.43067389726638794; temperature: 0.14060650765895844; total_precip: nan; 
0: epoch: 14 [1/5 (20%)]	Loss: nan : nan :: 0.15944 (2.68 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05188319459557533; velocity_v: 0.09237919002771378; specific_humidity: 0.04796842858195305; velocity_z: 0.5265689492225647; temperature: 0.1155058890581131; total_precip: nan; 
0: epoch: 14 [2/5 (40%)]	Loss: nan : nan :: 0.13897 (16.21 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.08556744456291199; velocity_v: 0.14210331439971924; specific_humidity: 0.05095101520419121; velocity_z: 0.6163548827171326; temperature: 0.10755188018083572; total_precip: nan; 
0: epoch: 14 [3/5 (60%)]	Loss: nan : nan :: 0.16756 (16.20 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.07620370388031006; velocity_v: 0.13112221658229828; specific_humidity: 0.04843641445040703; velocity_z: 0.5462846755981445; temperature: 0.13248565793037415; total_precip: nan; 
0: epoch: 14 [4/5 (80%)]	Loss: nan : nan :: 0.15929 (16.21 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0.]
0: Target values (first 200):
0: [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  4.7683716e-06 4.7683716e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]
0: Prediction values (first 20):
0: [-3.1931310e+00 -2.8468537e+00 -2.4165597e+00 -1.8943782e+00
0:  -1.2892938e+00 -6.6731834e-01 -3.1485558e-03  6.4306784e-01
0:   1.3165269e+00  1.9755287e+00  2.6635523e+00  3.3439503e+00
0:   4.0691414e+00  4.8232923e+00  5.5847673e+00  6.3314934e+00
0:   7.0402021e+00  7.6851773e+00  8.1981058e+00  8.7264175e+00]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -1.651, max = 0.969, mean = -0.552
0:          sample (first 20): tensor([-0.7885, -0.7616, -0.7282, -0.6877, -0.6407, -0.5924, -0.5408, -0.4907, -0.4384, -0.3872, -0.3338, -0.2810,
0:         -0.2246, -0.1661, -0.1070, -0.0490,  0.0060,  0.0561, -0.7074, -0.6734])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.56588  11.590495 11.622534 11.62195  11.628033 11.612714 11.605164
0:  11.583927 11.569854 11.589899 11.602526 11.587458 11.549321 11.504435
0:  11.451746 11.443661 11.511076 11.617399 11.602961 11.442623]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.220486 19.156239 19.126125 18.99752  18.901447 18.831745 18.828661
0:  18.871029 19.002277 19.171265 19.346098 19.471266 19.567654 19.678673
0:  19.735981 19.816326 19.850536 19.74348  19.66671  19.497364]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.70322  11.647707 11.79781  12.086548 12.545769 13.245682 14.208799
0:  15.307398 16.65651  18.043482 19.413548 20.675497 21.821209 22.735569
0:  23.419409 23.796047 23.91983  23.85766  22.656134 22.788822]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-12.970966  -13.271593  -13.550062  -13.764719  -13.831415  -13.766232
0:  -13.54921   -13.224169  -12.756922  -12.174944  -11.496536  -10.846041
0:  -10.228321   -9.690115   -9.306463   -9.017279   -8.818813   -8.710171
0:   -9.626291   -9.5288925]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.8143191 3.7956486 3.7419915 3.6858554 3.6413417 3.5839727 3.519367
0:  3.4277792 3.3417258 3.2744813 3.2202642 3.1693728 3.1334534 3.1264281
0:  3.12513   3.1685712 3.252766  3.379456  3.1659336 3.3191228]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.022634   -3.9393315  -3.8123775  -3.5853486  -3.285438   -2.9448724
0:  -2.5037875  -2.1260858  -1.7434044  -1.3814459  -1.0675254  -0.7404647
0:  -0.3179307   0.10143042  0.5615082   1.0152478   1.3791265   1.676825
0:   1.7682765   2.136989  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [30.800144 30.821638 30.829145 30.786139 30.714155 30.656166 30.650244
0:  30.61447  30.66205  30.73373  30.73513  30.719456 30.679878 30.648775
0:  30.633297 30.616102 30.588331 30.538202 30.981834 31.016289]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.7021627 -3.783474  -3.966527  -4.2728825 -4.540612  -4.690937
0:  -4.6274357 -4.4095097 -4.0736084 -3.7363167 -3.451087  -3.3136454
0:  -3.2970037 -3.2832947 -3.3208027 -3.2765064 -3.145937  -2.9781513
0:  -3.3192635 -3.298195 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.14195  33.368217 33.567474 33.60831  33.613056 33.54474  33.46714
0:  33.28374  33.104958 32.844025 32.537743 32.150566 31.808956 31.475697
0:  31.047329 30.663631 30.203644 29.690746 28.806602 28.086403]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.5955167  0.56244755 0.61659336 0.69098186 0.8292155  0.9587178
0:  1.1067429  1.197289   1.2924137  1.4341812  1.5638604  1.6879072
0:  1.7674038  1.8158419  1.8157771  1.8428421  1.9300148  2.0712698
0:  1.3852439  1.4844513 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.30846405 -0.48432016 -0.50535583 -0.40842724 -0.2450242  -0.11181259
0:  -0.02242661 -0.07262325 -0.1529336  -0.29714966 -0.438447   -0.5858555
0:  -0.70013523 -0.76359224 -0.8282027  -0.820559   -0.7888522  -0.70008373
0:  -0.7375083  -0.7873635 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.0037513  -0.8915005  -0.7985835  -0.7580881  -0.7016716  -0.6351452
0:  -0.5326052  -0.42901707 -0.27979755 -0.11914301  0.10784531  0.32897234
0:   0.58980274  0.8744998   1.0883245   1.2604547   1.3447618   1.3529749
0:   1.044611    0.8897557 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.483295  4.4094524 4.489208  4.6530848 4.863306  5.067344  5.308047
0:  5.5252247 5.811107  6.109965  6.425781  6.739728  7.085263  7.4129286
0:  7.748132  8.085352  8.405187  8.731407  9.397051  9.993075 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.1286201  -1.0855808  -1.012886   -0.9473772  -0.85260534 -0.76438427
0:  -0.6844692  -0.6550746  -0.6647401  -0.70270824 -0.75402975 -0.8670716
0:  -0.98236465 -1.0776434  -1.1915941  -1.2496333  -1.2599044  -1.2286468
0:  -1.4596434  -1.5174847 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.67388  12.900507 13.108325 13.27075  13.426461 13.57547  13.670021
0:  13.755375 13.812662 13.905233 14.02897  14.13463  14.244669 14.323023
0:  14.39607  14.474199 14.633358 14.830246 14.093725 14.183449]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.228722 20.822603 21.623672 22.430979 23.212809 23.917906 24.502378
0:  24.98578  25.497496 25.984211 26.527002 26.914755 27.117596 26.849073
0:  26.097898 24.886835 23.346815 21.73477  20.555958 20.083153]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.298943 22.089596 21.656973 20.961771 20.13174  19.240646 18.38964
0:  17.687424 17.215172 17.011171 17.070686 17.333477 17.732756 18.187778
0:  18.64337  19.080189 19.471123 19.775307 21.63147  21.959936]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.871786 19.117142 19.37211  19.561405 19.677197 19.710972 19.711935
0:  19.621698 19.533966 19.450138 19.365896 19.2779   19.18775  19.11163
0:  19.003267 18.908043 18.814066 18.740189 18.35222  18.204275]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.304149  -4.2148433 -4.0874324 -3.9581037 -3.8372293 -3.7426982
0:  -3.6459928 -3.5820575 -3.532188  -3.4725518 -3.4255147 -3.37493
0:  -3.2864919 -3.2012515 -3.1050172 -3.0170827 -2.947371  -2.8514228
0:  -2.6069274 -2.5720763]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [54.880047 54.75829  54.56184  54.36198  54.08394  53.891068 53.709312
0:  53.47537  53.42388  53.30533  53.112144 52.81764  52.543633 52.314175
0:  52.105247 51.845955 51.600613 51.166454 51.599915 51.537296]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.9956522 1.2046514 1.46805   1.7397728 1.9717546 2.142455  2.2966251
0:  2.3731709 2.4679723 2.58001   2.7064571 2.855282  3.0556068 3.2657223
0:  3.5181801 3.777866  4.063389  4.432185  4.62218   4.8308363]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.231422   5.3556337  5.5189185  5.714529   5.9657435  6.238731
0:   6.532409   6.826085   7.1429     7.4784536  7.8796535  8.3076
0:   8.794566   9.297203   9.781737  10.2408085 10.664261  11.036994
0:  11.254877  11.3161955]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.2463956 -2.4018493 -2.522637  -2.5517612 -2.5467973 -2.5771394
0:  -2.5703063 -2.6650043 -2.7655416 -2.8982434 -3.0339751 -3.1940799
0:  -3.2990527 -3.371014  -3.4199805 -3.4456286 -3.4829507 -3.5051951
0:  -3.9825892 -4.050816 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.2201586 1.3877902 1.5705562 1.7809691 1.9688354 2.1260448 2.2894745
0:  2.4235902 2.5793068 2.7276173 2.8487704 2.9681118 3.1013184 3.250195
0:  3.4361312 3.6188872 3.7830317 3.9380662 3.9627807 4.1403694]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.833853  14.785145  14.705431  14.546512  14.349988  14.110587
0:  13.9446945 13.738364  13.582224  13.43988   13.2422695 13.061655
0:  12.958904  12.933094  13.014118  13.175883  13.376608  13.578648
0:  13.345986  13.485755 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.768496   -1.318584   -0.9848027  -0.7082205  -0.49772167 -0.33095217
0:  -0.12860775  0.02645731  0.19261074  0.33485317  0.4398322   0.5747433
0:   0.7406273   0.9057803   1.0794363   1.2491813   1.3873782   1.5029984
0:   1.950922    2.6391525 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-15.276806 -15.178894 -15.015436 -14.786875 -14.524952 -14.284929
0:  -14.01136  -13.790365 -13.571844 -13.334234 -13.066544 -12.80258
0:  -12.511267 -12.207407 -11.931007 -11.659498 -11.419537 -11.166744
0:  -11.134743 -10.902426]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.789221  12.889164  13.0139065 13.138859  13.307869  13.509338
0:  13.782927  14.010646  14.241885  14.449676  14.612012  14.725337
0:  14.796216  14.804329  14.72749   14.582923  14.385274  14.215947
0:  13.802168  13.821785 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.855097  7.6306567 7.459658  7.2656884 7.0475407 6.71976   6.1785603
0:  5.5524807 5.0247087 4.6742716 4.573204  4.5428076 4.5337152 4.3696957
0:  4.093794  3.8413649 3.8151498 4.107027  6.024106  7.0114384]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.2444577 5.3096857 5.350425  5.306807  5.1497693 4.8678274 4.501992
0:  4.076565  3.685738  3.3630266 3.186171  3.1228075 3.1670284 3.2506146
0:  3.2859635 3.241334  3.0927625 2.886176  2.256455  2.272975 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.1456547 -3.14956   -3.1617174 -3.1002817 -3.036193  -3.0305758
0:  -2.9845943 -3.021307  -3.0826702 -3.1393576 -3.2508068 -3.3680592
0:  -3.4616537 -3.5556793 -3.6310902 -3.6521683 -3.6726131 -3.6376104
0:  -3.9950628 -4.0921106]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.1953773 -3.3152742 -3.4536324 -3.5767174 -3.6913643 -3.8072414
0:  -3.8778229 -3.9482355 -3.9663754 -3.9464512 -3.886716  -3.842658
0:  -3.7962713 -3.767066  -3.7947445 -3.8304148 -3.8838825 -3.8975868
0:  -4.4077463 -4.3741436]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.3995824 7.4276223 7.5076146 7.589239  7.677106  7.7243958 7.7748585
0:  7.7459893 7.7399344 7.7518234 7.7865458 7.804047  7.877594  7.932811
0:  7.970191  8.026772  8.0389805 7.995312  8.360346  8.500047 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.229354  8.30138   8.4008    8.487638  8.599127  8.656786  8.665306
0:  8.691874  8.683498  8.713395  8.734047  8.6546    8.546932  8.3707285
0:  8.102638  7.8289523 7.5543127 7.2895336 6.9338503 6.7808967]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.1817884 4.168059  4.2401032 4.359844  4.490308  4.58852   4.638015
0:  4.6196594 4.5990047 4.5673485 4.546036  4.4962583 4.4420877 4.373327
0:  4.2631793 4.1400733 3.9927697 3.86705   3.1722164 2.988276 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.777048  11.904387  12.0231    12.171237  12.443165  12.75324
0:  13.171734  13.615677  14.111987  14.6223345 15.076757  15.413287
0:  15.617038  15.660675  15.558003  15.413487  15.286043  15.237436
0:  14.3190775 14.525116 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.131744    2.213262    2.1866946   2.0311227   1.8095727   1.4697824
0:   1.0975099   0.6414809   0.20811653 -0.20851278 -0.5568137  -0.8824458
0:  -1.1638865  -1.3275466  -1.4961472  -1.536696   -1.475388   -1.3370056
0:  -1.4264421  -1.5042682 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.553806 26.534988 26.423292 26.106724 25.658182 25.077335 24.440609
0:  23.691492 22.930466 22.124138 21.24752  20.354958 19.506834 18.707802
0:  17.947683 17.251871 16.602049 15.999405 15.681782 15.401752]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.420494 8.537273 8.673998 8.74874  8.808022 8.840169 8.869766 8.898298
0:  8.962949 9.068213 9.169956 9.218063 9.238489 9.218682 9.157473 9.107172
0:  9.111324 9.154196 8.599912 8.613971]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.567902 23.47874  23.399826 23.336063 23.268944 23.17218  23.099415
0:  22.951202 22.900661 22.86578  22.821838 22.7794   22.73283  22.699665
0:  22.595661 22.497704 22.340618 22.146664 21.72165  21.498117]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.955273 30.168537 30.426037 30.65892  30.879555 31.128918 31.398922
0:  31.651962 31.965733 32.29936  32.58548  32.737427 32.753876 32.631252
0:  32.36026  32.051167 31.803837 31.66769  31.762981 31.977531]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.7066588  -1.5910726  -1.438806   -1.2597528  -1.0526052  -0.88395023
0:  -0.70531416 -0.573884   -0.4417143  -0.30432558 -0.15226841 -0.01989508
0:   0.11158419  0.2553997   0.37862682  0.52272177  0.6684737   0.83056784
0:   0.7506423   0.8245363 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.183567  -9.010387  -8.819506  -8.603075  -8.358038  -8.136253
0:  -7.8724    -7.644213  -7.420181  -7.1920877 -6.9409633 -6.720404
0:  -6.4978623 -6.289477  -6.141439  -5.9913344 -5.8351903 -5.6849694
0:  -6.0112433 -5.8093286]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-18.18047  -18.43421  -18.632158 -18.810759 -19.020027 -19.349474
0:  -19.719473 -20.16122  -20.528364 -20.823235 -21.03103  -21.203455
0:  -21.304468 -21.315046 -21.31467  -21.203932 -21.048347 -20.827377
0:  -20.518225 -20.63525 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.3980947  -3.1802583  -2.933514   -2.7485375  -2.630405   -2.5879636
0:  -2.573152   -2.634519   -2.6643195  -2.6845107  -2.637487   -2.5482926
0:  -2.388554   -2.115477   -1.8563609  -1.5634837  -1.3052964  -1.0604119
0:  -0.64594555 -0.6510606 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-13.702339 -13.760351 -13.716606 -13.662043 -13.576338 -13.508144
0:  -13.457136 -13.459446 -13.476604 -13.509857 -13.532862 -13.569551
0:  -13.541853 -13.41852  -13.269602 -13.054823 -12.872673 -12.706547
0:  -12.719406 -12.688189]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.3076706 -6.956377  -6.4903345 -5.9778624 -5.379676  -4.799206
0:  -4.289055  -4.004428  -3.9497585 -4.1493864 -4.474804  -4.914956
0:  -5.2655573 -5.442233  -5.513008  -5.4339886 -5.3120365 -5.204932
0:  -5.8448353 -6.1312466]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.387135 19.573877 19.774225 19.986029 20.138565 20.25052  20.359037
0:  20.399496 20.43253  20.487125 20.480343 20.490509 20.513733 20.49977
0:  20.495134 20.422102 20.291115 20.15728  20.017368 20.044422]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.627438  14.133049  13.757779  13.480555  13.2929325 13.170662
0:  13.198751  13.267235  13.524921  13.893087  14.288399  14.776648
0:  15.29838   15.875771  16.505653  17.102886  17.672388  18.222506
0:  19.389568  19.54704  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.0757008 -5.0138426 -4.9325914 -4.8786287 -4.853653  -4.9046135
0:  -4.9857216 -5.143324  -5.306432  -5.457698  -5.5741625 -5.6876993
0:  -5.7576103 -5.7629576 -5.753847  -5.6688013 -5.5388308 -5.3670816
0:  -5.505224  -5.32718  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.556515  -3.7312655 -3.2026172 -2.660478  -2.2956042 -2.0140195
0:  -1.8333092 -1.6693215 -1.6654377 -1.6354408 -1.6527047 -1.7294841
0:  -1.740643  -1.7330489 -1.6124187 -1.4943366 -1.4082065 -1.3236399
0:  -2.9823155 -3.1110387]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.763549  7.6038632 7.3478856 7.010083  6.541602  6.0194535 5.5502853
0:  5.152293  4.955344  4.948798  5.074374  5.260726  5.4591827 5.647614
0:  5.8007984 5.943671  6.095824  6.282703  6.1792603 6.4856873]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.077663  -7.969473  -7.890834  -7.8209333 -7.7140274 -7.5822563
0:  -7.377449  -7.1331835 -6.838131  -6.4751034 -6.040056  -5.5969286
0:  -5.1412344 -4.6799526 -4.270481  -3.851534  -3.4265203 -2.986206
0:  -2.7621603 -2.4807215]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.792411  6.1640472 5.383966  4.4965997 3.600732  2.787149  2.1912603
0:  1.8058906 1.7877402 2.0021157 2.4270816 2.9253278 3.491418  4.1122265
0:  4.68122   5.250659  5.799619  6.2752714 6.225818  6.3892674]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-11.283892 -11.412174 -11.434093 -11.332211 -11.252197 -11.246216
0:  -11.244719 -11.363583 -11.42276  -11.441898 -11.450439 -11.494316
0:  -11.522476 -11.590961 -11.7178   -11.827694 -11.931784 -11.940754
0:  -11.652977 -11.775818]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.3639536 4.4734244 4.51807   4.4167747 4.230811  4.00833   3.821048
0:  3.6164172 3.4258742 3.2204785 2.9962413 2.7679048 2.5899162 2.5000129
0:  2.4145598 2.347434  2.2321386 2.0778599 1.6501927 1.4486389]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.151043  5.076595  5.0219197 4.9574404 4.9198627 4.8687286 4.798728
0:  4.6997786 4.5693693 4.415584  4.2321243 3.9516993 3.5953712 3.213023
0:  2.8125496 2.52143   2.3800635 2.384502  2.2468987 2.4931498]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.97589   10.286861  10.770349  11.285898  11.854332  12.368986
0:  12.797327  13.115663  13.344433  13.474644  13.528955  13.51162
0:  13.40902   13.264244  12.999729  12.650837  12.166077  11.61013
0:   9.5873575  9.051175 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.1213303 3.1500633 3.199257  3.304087  3.3531017 3.3692093 3.4171312
0:  3.3885121 3.3963206 3.436409  3.4663537 3.553976  3.703715  3.8692286
0:  4.0936184 4.2674856 4.3991528 4.5282674 4.2697945 4.5029354]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.7822151 1.8367372 1.8475299 1.855444  1.8119769 1.7494564 1.6921253
0:  1.6039448 1.5495205 1.5143299 1.4991221 1.5271688 1.6110487 1.7246094
0:  1.8504691 1.9650979 2.058024  2.149808  2.4674854 2.5164394]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.308447 21.171085 21.259375 21.364305 21.476269 21.519308 21.498476
0:  21.384094 21.275072 21.258333 21.27499  21.3086   21.367243 21.37594
0:  21.272049 21.091484 20.902838 20.712465 21.023176 21.395632]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.39090824  0.45734692  0.47948217  0.4843459   0.52259684  0.51405525
0:   0.5486083   0.5219989   0.5157771   0.5063391   0.50989294  0.47049618
0:   0.41618538  0.38241673  0.31294394  0.2886958   0.26714897  0.26954794
0:  -0.3689742  -0.47403383]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.806499   -0.70790863 -0.66173077 -0.6570349  -0.66653013 -0.67523766
0:  -0.65789557 -0.64378643 -0.6069021  -0.549819   -0.45875216 -0.36003208
0:  -0.22186184 -0.04017162  0.10828638  0.26989985  0.43262577  0.6319256
0:   0.91973066  1.1392045 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.8070359 2.0808601 2.346294  2.6481414 2.9338837 3.1765938 3.4532866
0:  3.6462843 3.8790236 4.110235  4.378093  4.7354755 5.2169676 5.719283
0:  6.277417  6.809749  7.2766914 7.7379932 7.078472  7.528376 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.8894553 -5.9246182 -6.115401  -6.4692073 -6.9273534 -7.441241
0:  -7.8923163 -8.260351  -8.453135  -8.471558  -8.338627  -8.123856
0:  -7.8604426 -7.5587087 -7.3314195 -7.12725   -6.960851  -6.8420205
0:  -7.33505   -7.5164657]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.6612835 12.923481  13.263052  13.645098  14.07436   14.51951
0:  14.995087  15.405367  15.8544655 16.286232  16.745886  17.203613
0:  17.741335  18.331007  18.941143  19.55315   20.11669   20.63678
0:  20.837824  21.44189  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-13.139226  -13.167047  -13.225966  -13.318334  -13.405595  -13.526458
0:  -13.575898  -13.673818  -13.705871  -13.700543  -13.63597   -13.546422
0:  -13.439891  -13.263885  -13.123914  -12.9476385 -12.774135  -12.5793295
0:  -12.857615  -12.6683855]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.613001 14.315804 14.105017 13.928112 13.844756 13.85894  14.012118
0:  14.170696 14.402303 14.600557 14.671713 14.649691 14.509676 14.271047
0:  13.997629 13.686903 13.395924 13.207076 13.434    13.391434]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.4903655   8.079955    8.701362    9.045787    9.035957    8.7109585
0:   8.083402    7.2465425   6.266349    5.172003    4.06565     2.890438
0:   1.7548566   0.76673317 -0.11073971 -0.7436805  -1.1989131  -1.4556336
0:  -1.2768798  -1.3083892 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.381392  9.460935  9.536585  9.614199  9.690748  9.793158  9.924421
0:  10.034916 10.174187 10.269009 10.311791 10.324329 10.366067 10.43784
0:  10.528975 10.611307 10.707844 10.813379 10.525459 10.684402]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.715988 18.999084 19.280273 19.479706 19.617758 19.697481 19.755028
0:  19.784698 19.83606  19.919724 20.006565 20.062723 20.115463 20.16961
0:  20.21982  20.315681 20.45586  20.62526  20.734497 20.917908]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.53265953  0.38686752  0.28333664  0.20038891  0.15482712  0.05357218
0:  -0.10879612 -0.36293602 -0.65989447 -0.94348097 -1.1910477  -1.4230108
0:  -1.6149063  -1.7171602  -1.8011565  -1.7732453  -1.667985   -1.5164227
0:  -1.6128235  -1.8202686 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.2369   25.187885 25.142788 25.094753 25.018614 24.91257  24.859476
0:  24.740808 24.72927  24.744326 24.73682  24.738703 24.751734 24.741587
0:  24.714685 24.66829  24.579054 24.426792 24.324274 24.281044]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.161783 24.574594 24.9103   24.996431 24.91136  24.714725 24.502274
0:  24.329819 24.244802 24.326214 24.45965  24.612612 24.781477 24.906683
0:  25.012663 25.147266 25.329947 25.494368 25.844973 26.046967]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.16655779 -0.04838276  0.12650967  0.32871914  0.58786726  0.8110995
0:   1.0599189   1.2507977   1.4262218   1.5831037   1.7260289   1.8232288
0:   1.9156404   2.04381     2.1468873   2.320547    2.5201864   2.7163353
0:   2.7281184   2.8838296 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.491626  7.5271254 7.5903563 7.6591873 7.7633843 7.8640027 7.969358
0:  8.039107  8.094378  8.131049  8.133042  8.098508  8.047442  7.988869
0:  7.916512  7.8757496 7.87748   7.913293  7.3101845 7.1979523]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.5746145  0.7758169  0.97102356 1.1404476  1.3010325  1.3909631
0:  1.4701862  1.504736   1.5445161  1.6184735  1.6818902  1.7110262
0:  1.7151663  1.7195933  1.7573566  1.8760586  2.1185942  2.3974924
0:  1.8146448  1.85495   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.70940924 0.95722246 1.2936697  1.6878524  2.105196   2.4912453
0:  2.88969    3.2321405  3.5357282  3.8196297  4.0783567  4.3121595
0:  4.5290504  4.7569146  4.9538665  5.154863   5.3290286  5.4951797
0:  5.2392993  5.301783  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.2056823  -0.84013414 -0.4410391  -0.09490728  0.18867302  0.40132713
0:   0.56881285  0.68789005  0.8002367   0.9353852   1.1130533   1.2744136
0:   1.4454637   1.5940247   1.6669216   1.716886    1.7507391   1.7839146
0:   1.4089866   1.2657752 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.91836166 1.0090709  1.1447821  1.3076515  1.4316487  1.5153913
0:  1.6053591  1.6485143  1.7070384  1.7552404  1.7977729  1.8235412
0:  1.8707066  1.9188104  1.9716477  2.0179234  2.046609   2.0984473
0:  1.8315129  1.9067788 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.599495 27.529942 27.52124  27.464401 27.394012 27.26513  27.12532
0:  26.877316 26.685036 26.445366 26.167366 25.872429 25.605396 25.382774
0:  25.195858 25.055252 24.923405 24.776417 25.357513 25.48198 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.988927 10.019091 10.048382 10.020062  9.983196  9.897281  9.820089
0:   9.705783  9.617612  9.548006  9.480631  9.369352  9.244431  9.096123
0:   8.902766  8.767723  8.677589  8.62463   8.188157  8.146729]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.5520797  1.514749   1.495472   1.4734411  1.4442191  1.3836107
0:  1.3364825  1.256166   1.1997185  1.1556559  1.1034007  1.0263152
0:  0.9348116  0.83499384 0.72931385 0.65999126 0.61432695 0.60912657
0:  0.28865385 0.24676847]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.968666 22.936232 22.873205 22.688023 22.452051 22.16977  21.83105
0:  21.406715 20.947943 20.38698  19.743599 19.01128  18.30336  17.691587
0:  17.158665 16.787035 16.572323 16.444    15.613346 15.269897]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.34977   13.615395  13.78698   13.981789  14.09013   14.146733
0:  14.154465  14.021772  13.713755  13.028128  11.883987  10.430774
0:   8.915711   7.8103156  7.282644   7.4820814  8.270128   9.475035
0:  14.094122  15.016081 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.357108  10.265588  10.071625   9.742794   9.3450165  8.863242
0:   8.381972   7.889446   7.4417086  7.053539   6.6947446  6.3298855
0:   5.9545584  5.5994625  5.223257   4.913359   4.665661   4.481516
0:   4.1436014  4.023434 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.956509 23.948372 23.914467 23.836315 23.771347 23.723385 23.64066
0:  23.483929 23.361397 23.215721 23.04506  22.867191 22.768005 22.70155
0:  22.73518  22.878693 23.145042 23.464676 23.83543  24.167042]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.720784   -5.8364134  -5.94547    -6.0001698  -5.9705124  -5.8947144
0:  -5.692293   -5.4789705  -5.173478   -4.785575   -4.324174   -3.8602057
0:  -3.413413   -2.945403   -2.568039   -2.1474733  -1.6937313  -1.2152405
0:  -0.61637783 -0.31381226]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-13.324042  -13.193749  -13.0050535 -12.755439  -12.484977  -12.247027
0:  -11.984473  -11.799539  -11.613393  -11.427171  -11.25278   -11.115111
0:  -10.982068  -10.824954  -10.706908  -10.537538  -10.351523  -10.155816
0:  -10.318139  -10.184043 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.658976 17.485819 17.33319  17.165607 17.018606 16.939615 16.887606
0:  16.836996 16.842033 16.865582 16.902847 16.916937 16.94269  16.959137
0:  16.99376  17.051216 17.16346  17.315388 17.001307 16.954376]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.89046144 0.9543743  1.0331059  1.140368   1.2506766  1.3280258
0:  1.4208965  1.4648585  1.5237408  1.5898223  1.652411   1.7017474
0:  1.7598615  1.8031082  1.8277593  1.8682351  1.8876605  1.9382014
0:  1.9115324  1.9149523 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.374044 26.417421 26.5042   26.46925  26.391954 26.302492 26.205801
0:  26.13158  26.10708  26.082363 25.997137 25.759865 25.4341   25.028563
0:  24.564665 24.132755 23.787516 23.506815 22.559689 22.246498]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.4352565 -5.37079   -5.470617  -5.7483983 -6.121799  -6.5281644
0:  -6.8358073 -7.0314527 -7.056453  -6.9167533 -6.6523604 -6.3224025
0:  -5.975199  -5.6022983 -5.3119006 -5.0649285 -4.877588  -4.7448096
0:  -5.6361556 -5.7340465]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.653035  -10.529019  -10.372924  -10.213231  -10.070018   -9.961036
0:   -9.843265   -9.78123    -9.714641   -9.6391     -9.549579   -9.456754
0:   -9.351737   -9.201734   -9.091589   -8.96825    -8.858386   -8.7368145
0:   -8.9614935  -8.905758 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.937748  5.944675  5.9871926 6.0635967 6.2020264 6.3865657 6.6067905
0:  6.7743025 6.916962  7.0041904 7.047241  7.039293  7.0324106 6.9876695
0:  6.8874145 6.7237644 6.551907  6.4283767 5.582745  5.505235 ]
0: validation loss for strategy=forecast at epoch 14 : nan
0: validation loss for velocity_u : 0.03382011130452156
0: validation loss for velocity_v : 0.06419908255338669
0: validation loss for specific_humidity : 0.02572145313024521
0: validation loss for velocity_z : 0.45925405621528625
0: validation loss for temperature : 0.07243867963552475
0: validation loss for total_precip : nan
0: 15 : 10:46:43 :: batch_size = 96, lr = 1.4508407513079195e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 15, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2946, 0.3104, 0.3270, 0.3445, 0.3627, 0.3815, 0.4009, 0.4207, 0.4409, 0.4612, 0.4813, 0.5018, 0.5225, 0.5433,
0:         0.5647, 0.5865, 0.6089, 0.6316, 0.1645, 0.1779, 0.1919, 0.2066, 0.2222, 0.2384, 0.2553], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1217, -0.1370, -0.1520, -0.1665, -0.1806, -0.1946, -0.2083, -0.2220, -0.2358, -0.2495, -0.2634, -0.2774,
0:         -0.2915, -0.3059, -0.3206, -0.3355, -0.3509, -0.3664, -0.1053, -0.1166, -0.1275, -0.1380, -0.1481, -0.1582,
0:         -0.1681], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6049, -0.6063, -0.6077, -0.6101, -0.6129, -0.6158, -0.6186, -0.6219, -0.6251, -0.6284, -0.6317, -0.6349,
0:         -0.6382, -0.6415, -0.6444, -0.6473, -0.6504, -0.6534, -0.5790, -0.5801, -0.5813, -0.5831, -0.5853, -0.5875,
0:         -0.5901], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.1725,  0.2402,  0.3078,  0.3754,  0.4453,  0.5195,  0.5937,  0.6678,  0.7377,  0.7988,  0.8511,  0.8970,
0:          0.9362,  0.9755,  1.0148,  1.0562,  1.1021,  1.1544, -0.0610, -0.0195,  0.0176,  0.0547,  0.0961,  0.1420,
0:          0.1900], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0.2139, -0.2051, -0.1965, -0.1878, -0.1789, -0.1696, -0.1595, -0.1488, -0.1377, -0.1261, -0.1140, -0.1022,
0:         -0.0901, -0.0782, -0.0663, -0.0544, -0.0423, -0.0304, -0.0188, -0.0071,  0.0041,  0.0146,  0.0247,  0.0347,
0:          0.0441], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 15, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan, -0.0647,     nan,     nan,     nan, -0.1243,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0456,     nan,     nan,
0:         -0.0051,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0432,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1840,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1339,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.0456, -0.0480,     nan,     nan,     nan,     nan,
0:             nan,     nan,  0.0259,     nan,     nan,     nan,     nan, -0.0707,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1637,
0:             nan,     nan,     nan,     nan, -0.1267,     nan,     nan, -0.1923,     nan,     nan,     nan, -0.1756,
0:             nan,     nan, -0.1589,     nan,     nan, -0.2102,     nan, -0.2054,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2221,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2412,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 15, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.6942, 0.6785, 0.6670, 0.6555, 0.6438, 0.6314, 0.6204, 0.6067, 0.5960, 0.5879, 0.5772, 0.5672, 0.5587, 0.5532,
0:         0.5482, 0.5458, 0.5429, 0.5359, 0.6903, 0.6794, 0.6680, 0.6576, 0.6439, 0.6299, 0.6148], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.9649, 0.9449, 0.9156, 0.8811, 0.8416, 0.8001, 0.7596, 0.7197, 0.6820, 0.6459, 0.6061, 0.5668, 0.5241, 0.4811,
0:         0.4432, 0.4176, 0.4019, 0.3946, 0.9209, 0.8931, 0.8596, 0.8207, 0.7807, 0.7368, 0.6950], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.2735, -0.2748, -0.2803, -0.2832, -0.2881, -0.2934, -0.2986, -0.3045, -0.3086, -0.3117, -0.3115, -0.3073,
0:         -0.3067, -0.3066, -0.3066, -0.3072, -0.3100, -0.3088, -0.2767, -0.2795, -0.2840, -0.2872, -0.2901, -0.2934,
0:         -0.2948], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.2662, -0.2507, -0.2624, -0.2666, -0.2573, -0.2316, -0.2159, -0.2204, -0.1983, -0.1738, -0.1596, -0.1159,
0:         -0.0815, -0.0885, -0.1252, -0.1572, -0.1285, -0.0833, -0.2615, -0.2371, -0.2282, -0.2162, -0.2077, -0.1828,
0:         -0.1701], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([2.1170, 2.1211, 2.1294, 2.1392, 2.1493, 2.1572, 2.1613, 2.1623, 2.1620, 2.1592, 2.1537, 2.1457, 2.1369, 2.1276,
0:         2.1145, 2.1001, 2.0840, 2.0682, 2.0536, 2.0407, 2.0284, 2.0134, 1.9966, 1.9795, 1.9631], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.0709623396396637; velocity_v: 0.1177356019616127; specific_humidity: 0.037100907415151596; velocity_z: 0.5686661601066589; temperature: 0.09134743362665176; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.053549595177173615; velocity_v: 0.08754580467939377; specific_humidity: 0.04713498055934906; velocity_z: 0.5425529479980469; temperature: 0.12912943959236145; total_precip: nan; 
0: epoch: 15 [1/5 (20%)]	Loss: nan : nan :: 0.14411 (2.58 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.058972667902708054; velocity_v: 0.1100597158074379; specific_humidity: 0.03624342754483223; velocity_z: 0.5758772492408752; temperature: 0.0909019261598587; total_precip: nan; 
0: epoch: 15 [2/5 (40%)]	Loss: nan : nan :: 0.14033 (16.27 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.0641305148601532; velocity_v: 0.10028691589832306; specific_humidity: 0.04642123356461525; velocity_z: 0.44058868288993835; temperature: 0.140554741024971; total_precip: nan; 
0: epoch: 15 [3/5 (60%)]	Loss: nan : nan :: 0.15587 (16.14 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.04810091853141785; velocity_v: 0.08073049038648605; specific_humidity: 0.041055042296648026; velocity_z: 0.4505217373371124; temperature: 0.11181455850601196; total_precip: nan; 
0: epoch: 15 [4/5 (80%)]	Loss: nan : nan :: 0.13477 (16.14 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [9.5367432e-07 4.7684443e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.7684443e-07
0:  9.5367432e-07 1.4305042e-06 1.9073486e-06 2.8610229e-06 4.2915344e-06
0:  1.3828278e-05 1.7166138e-05 2.3841858e-05 3.6716461e-05 3.6239624e-05
0:  4.2915344e-05 4.9114227e-05 5.2452087e-05 4.3869015e-05 3.5285950e-05
0:  2.8610229e-05 2.6226044e-05 2.4795532e-05 3.8146973e-05 5.8650970e-05
0:  8.0108643e-05 7.0095062e-05 8.0108643e-05 7.4863434e-05 3.9100647e-05
0:  2.0503998e-05 1.2397766e-05 5.7220459e-06 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 4.7684443e-07 4.7684443e-07 4.7684443e-07
0:  4.7684443e-07 9.5367432e-07 1.9073486e-06 1.4305042e-06 1.4305042e-06
0:  1.4305042e-06 4.7684443e-07 9.5367432e-07 1.4305042e-06 1.4305042e-06
0:  1.4305042e-06 9.5367432e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 4.7684443e-07 4.7684443e-07 4.7684443e-07 4.7684443e-07
0:  4.7684443e-07 4.7684443e-07 4.7684443e-07 9.5367432e-07 9.5367432e-07
0:  4.7684443e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  9.5367432e-07 1.4305042e-06 1.9073486e-06 2.8610229e-06 5.2452087e-06
0:  8.5830688e-06 1.0967255e-05 2.4318695e-05 3.7193298e-05 4.5776364e-05
0:  5.0544739e-05 5.8650970e-05 5.1021576e-05 3.9100647e-05 3.0040741e-05
0:  3.1471252e-05 4.9114227e-05 6.8664551e-05 7.3432922e-05 6.8664551e-05
0:  7.8678131e-05 1.0108948e-04 8.7738037e-05 4.9114227e-05 7.1525574e-06
0:  1.4305042e-06 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]
0: Target values (first 200):
0: [4.76844434e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 4.76844434e-07 9.53674316e-07 1.43050420e-06
0:  2.38418579e-06 2.38418579e-06 6.19888306e-06 1.00135803e-05
0:  1.28746033e-05 1.00135803e-05 6.67572021e-06 4.76837158e-06
0:  6.67572021e-06 7.62939453e-06 7.62939453e-06 7.62939453e-06
0:  6.67572021e-06 8.10623169e-06 1.00135803e-05 1.04904175e-05
0:  8.10623169e-06 5.72204590e-06 5.24520874e-06 5.24520874e-06
0:  5.72204590e-06 2.62260437e-05 4.38690149e-05 5.05447388e-05
0:  4.52995300e-05 3.48091125e-05 2.47955322e-05 1.47819519e-05
0:  6.19888306e-06 3.33786011e-06 1.43050420e-06 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.76844434e-07
0:  4.76844434e-07 4.76844434e-07 9.53674316e-07 9.53674316e-07
0:  4.76844434e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  1.90734863e-06 4.76844434e-07 4.76844434e-07 4.76844434e-07
0:  4.76844434e-07 4.76844434e-07 9.53674316e-07 9.53674316e-07
0:  1.43051147e-05 2.33650208e-05 2.43186951e-05 2.71797180e-05
0:  2.81333923e-05 2.19345093e-05 1.62124634e-05 1.95503235e-05
0:  2.14576721e-05 2.00271606e-05 1.23977661e-05 3.33786011e-06
0:  4.29153442e-06 5.24520874e-06 5.72204590e-06 5.24520874e-06
0:  4.76837158e-06 4.76837158e-06 5.72204590e-06 6.67572021e-06
0:  6.67572021e-06 4.29153442e-06 4.29153442e-06 4.76837158e-06
0:  1.19209290e-05 3.71932983e-05 5.81741333e-05 5.91278076e-05
0:  5.10215759e-05 3.91006470e-05 2.05039978e-05 8.10623169e-06
0:  3.81469727e-06 3.33786011e-06 1.43050420e-06 4.76844434e-07
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 4.76844434e-07 4.76844434e-07 4.76844434e-07]
0: Prediction values (first 20):
0: [6.111483  6.4396243 6.7360783 6.974141  7.147421  7.2689996 7.3533144
0:  7.3114176 7.198825  6.9802904 6.662929  6.2536564 5.831749  5.3903685
0:  4.950251  4.5216637 4.1379943 3.843609  3.471774  3.3662798]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -1.970, max = 1.944, mean = 0.040
0:          sample (first 20): tensor([-0.0005,  0.0271,  0.0521,  0.0721,  0.0867,  0.0970,  0.1041,  0.1005,  0.0911,  0.0727,  0.0459,  0.0115,
0:         -0.0240, -0.0612, -0.0982, -0.1343, -0.1666, -0.1914, -0.0299,  0.0073])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [34.977062 34.828533 34.57544  34.29542  34.025127 33.748455 33.543602
0:  33.176773 32.858612 32.525448 32.15069  31.808727 31.51441  31.280462
0:  31.082026 30.91986  30.785011 30.64118  30.84667  30.841938]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.239588 16.25775  16.298138 16.343182 16.411076 16.489243 16.672186
0:  16.76155  16.93556  17.1496   17.371304 17.684351 18.027119 18.381601
0:  18.75753  19.084627 19.400345 19.653475 19.565912 19.647644]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.7699604 2.7171645 2.7285504 2.7343674 2.7162623 2.671927  2.563325
0:  2.4403863 2.3562584 2.2898068 2.325161  2.3633418 2.4583511 2.653316
0:  2.8935852 3.2163327 3.5332305 3.8329842 3.7397168 3.8097043]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.071319 10.415215 10.788042 11.215229 11.605614 11.946106 12.316452
0:  12.542808 12.813438 13.055876 13.307311 13.584986 13.931876 14.251104
0:  14.567127 14.849136 15.086342 15.342701 16.133614 16.55857 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.6921268 6.598372  6.563607  6.535872  6.5264125 6.4846177 6.4697437
0:  6.3730874 6.2256203 6.0265102 5.7455263 5.395703  5.009448  4.6255207
0:  4.204877  3.8380284 3.5311759 3.2822466 1.9492164 1.649837 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.3765955 -8.246655  -8.027502  -7.7478867 -7.4665585 -7.244071
0:  -7.1031446 -7.0977573 -7.1756887 -7.3049355 -7.4461613 -7.599016
0:  -7.7212706 -7.787959  -7.844202  -7.861726  -7.861005  -7.823162
0:  -7.843586  -7.851447 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.8513756 5.1466184 5.482817  5.7980227 6.1171894 6.3916297 6.682992
0:  6.927324  7.2225976 7.561408  7.9273157 8.247159  8.509121  8.7253475
0:  8.870159  9.042918  9.2301445 9.43561   8.877079  8.94257  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.897051  12.745155  12.609917  12.448271  12.248344  12.003899
0:  11.7859745 11.538303  11.308294  11.058959  10.767481  10.477718
0:  10.200514   9.974371   9.772908   9.597005   9.371804   9.118956
0:   8.4590225  8.262758 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.562901    1.2316661   0.94670343  0.6957898   0.4659853   0.27117825
0:   0.15094805  0.02727795 -0.0811491  -0.19443035 -0.26590347 -0.3714323
0:  -0.441267   -0.4625635  -0.5109935  -0.53900623 -0.5667558  -0.5982475
0:  -0.87659645 -0.8605151 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.321444   8.500961   8.730894   8.973812   9.245125   9.53736
0:   9.825984  10.107644  10.386052  10.677776  10.999082  11.309204
0:  11.617191  11.889202  12.141287  12.377875  12.60954   12.83827
0:  12.7389145 13.085335 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.2296367 6.2211156 6.206618  6.1620836 6.0990853 6.017618  5.9732156
0:  5.8905306 5.8503675 5.8071165 5.7410984 5.6533003 5.54857   5.4566383
0:  5.3619633 5.3142886 5.268755  5.2493525 5.02249   4.961712 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.359581  -3.327612  -3.31433   -3.3725405 -3.4712744 -3.6827755
0:  -3.8977385 -4.1722946 -4.375782  -4.494384  -4.525176  -4.5238504
0:  -4.48744   -4.3754835 -4.261508  -4.055255  -3.7851334 -3.483921
0:  -3.3074121 -3.126875 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.0646944 2.2098408 2.3247185 2.41885   2.5193949 2.597712  2.699925
0:  2.7650127 2.824027  2.8639617 2.880991  2.8466582 2.8205051 2.7985072
0:  2.76202   2.7235556 2.6434364 2.53331   2.1029649 1.915195 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.140253  18.983452  18.73518   18.379559  17.938618  17.42949
0:  16.843113  16.174768  15.529976  14.898161  14.296955  13.79713
0:  13.435213  13.1875925 13.051567  13.006763  13.058603  13.146984
0:  12.691597  12.704058 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.767841   9.607828   9.396972   9.090216   8.758955   8.323111
0:  7.852375   7.306796   6.753      6.2195826  5.702872   5.1602283
0:  4.5979915  4.0494914  3.488708   2.9866116  2.544695   2.1929035
0:  0.8721566  0.66969204]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.094152 19.95035  19.820276 19.672075 19.495573 19.298912 19.15322
0:  18.91624  18.707743 18.508213 18.238863 17.960001 17.714218 17.479015
0:  17.271069 17.070635 16.87243  16.67332  16.112812 15.800041]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.134617  15.012032  14.915104  14.833889  14.7497635 14.674534
0:  14.664606  14.636379  14.641937  14.619106  14.524884  14.389449
0:  14.237213  14.030424  13.837275  13.595238  13.322166  12.996481
0:  12.542591  12.393759 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.1209192  -2.1813745  -2.2359896  -2.2785444  -2.314765   -2.3624554
0:  -2.3786793  -2.3880186  -2.31145    -2.15409    -1.8809843  -1.5892086
0:  -1.256753   -0.90326214 -0.59246874 -0.32401657 -0.14351511  0.02169752
0:   0.23284435  0.10439348]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.43729   -4.408164  -4.3893986 -4.3885317 -4.4023914 -4.4733276
0:  -4.501876  -4.548849  -4.585973  -4.59146   -4.568345  -4.5554285
0:  -4.521557  -4.4537697 -4.405039  -4.2958727 -4.181713  -4.060914
0:  -4.332239  -4.205881 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.850787  -5.931549  -5.9103746 -5.7789516 -5.5416317 -5.278574
0:  -4.992689  -4.7489614 -4.51248   -4.2751474 -4.0360374 -3.8232498
0:  -3.6289034 -3.4267702 -3.2437925 -3.0142899 -2.7311687 -2.4204016
0:  -2.2085295 -2.000825 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.5698638 3.5387576 3.4922438 3.4195757 3.3417466 3.2263129 3.1418045
0:  3.034223  2.9614806 2.907188  2.8454657 2.7583022 2.6560678 2.5527573
0:  2.4326153 2.3681903 2.3064308 2.2464833 1.7954922 1.7420125]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.994504   -1.8566332  -1.71486    -1.6076345  -1.5003142  -1.4273753
0:  -1.3299575  -1.2474632  -1.1211314  -0.9713025  -0.7761235  -0.590085
0:  -0.41076994 -0.22143364 -0.08647776  0.04820967  0.17526293  0.31104755
0:   0.33448172  0.4487872 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.196793 27.560406 27.974339 28.364029 28.708061 29.004276 29.338112
0:  29.612022 29.940403 30.262638 30.52956  30.753902 30.978687 31.189922
0:  31.374233 31.55191  31.666935 31.779343 31.013279 31.262245]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.1415462  -0.8773842  -0.6318636  -0.4705763  -0.3808689  -0.40774298
0:  -0.5181174  -0.7453418  -1.0130568  -1.2832375  -1.478548   -1.5886116
0:  -1.5914373  -1.4743586  -1.362916   -1.2304358  -1.1656322  -1.1819344
0:  -1.1309791  -0.84558725]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.5734773 -6.8029666 -7.0578904 -7.3391633 -7.5783753 -7.8109384
0:  -7.955375  -8.078022  -8.136885  -8.140135  -8.087433  -8.053728
0:  -8.027433  -7.9769893 -7.975496  -7.9280477 -7.846248  -7.7432494
0:  -7.746388  -7.8803096]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.2648797   2.2705657   2.3366635   2.4189413   2.4511282   2.3966033
0:   2.2930806   2.1007962   1.8570065   1.5601807   1.1603694   0.66911936
0:   0.16500092 -0.34167147 -0.8122473  -1.2444181  -1.64709    -1.9704332
0:  -2.4472818  -2.6545296 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.817894  14.549761  14.355089  14.233082  14.14447   14.012988
0:  13.870041  13.595555  13.254719  12.796904  12.197041  11.535418
0:  10.85913   10.2437     9.689757   9.208357   8.772725   8.356565
0:   6.6343713  5.9784374]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.8980536  -3.1336923  -3.513269   -3.9922233  -4.524011   -5.118692
0:  -5.5902486  -5.9805713  -6.097202   -5.9449363  -5.532224   -4.9453187
0:  -4.2439446  -3.4403253  -2.6185632  -1.7221255  -0.7287679   0.23254776
0:   2.0083222   2.827276  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.253242 19.431341 19.614347 19.759796 19.902752 20.069466 20.28075
0:  20.443348 20.676071 20.902325 21.101116 21.265232 21.413042 21.521591
0:  21.638742 21.749962 21.926357 22.15828  22.773045 22.905537]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.678901  5.7126904 5.8152637 5.973109  6.140463  6.303768  6.485485
0:  6.629355  6.7929835 6.95725   7.0925393 7.2464232 7.4133224 7.5451493
0:  7.6821094 7.7809873 7.8634324 7.9621506 7.890703  7.930101 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.17074919  0.49730682  0.91713333  1.42455     2.0105495   2.6347506
0:   3.2789607   3.8802717   4.4930353   5.0876737   5.7201753   6.418415
0:   7.179507    7.9506016   8.65917     9.199911    9.605779    9.89719
0:  10.5471115  10.885662  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.843063 9.67251  9.517654 9.370972 9.241524 9.138149 9.119608 9.096455
0:  9.15773  9.246819 9.33005  9.389713 9.450105 9.448146 9.386398 9.259885
0:  9.10016  8.921338 8.49825  8.062947]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.981834 19.593006 20.10987  20.532768 20.902355 21.278387 21.701967
0:  22.144619 22.642246 23.174805 23.708035 24.237759 24.79879  25.366379
0:  25.96313  26.564804 27.139381 27.617378 28.536266 29.173489]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.399739   -4.327988   -4.270785   -4.173631   -4.0360675  -3.8945947
0:  -3.7144952  -3.5553908  -3.3711677  -3.129683   -2.8256555  -2.4760604
0:  -2.0861564  -1.6863303  -1.3284726  -0.9864712  -0.6612501  -0.32499123
0:  -0.0679636   0.26410627]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.852793 23.642681 23.442513 23.167627 22.822184 22.421286 22.02024
0:  21.584433 21.19401  20.826199 20.373869 19.918365 19.4693   19.03844
0:  18.686882 18.416277 18.231195 18.142561 18.157906 17.907991]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.270527  11.444123  11.614407  11.649286  11.613045  11.515406
0:  11.388262  11.299238  11.292334  11.3607025 11.449833  11.463282
0:  11.346552  11.11076   10.736843  10.347621  10.000656   9.704785
0:   9.243833   9.003304 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.870743  4.939944  5.024552  5.1867504 5.405842  5.676196  6.0290165
0:  6.357395  6.762532  7.193041  7.6533113 8.114837  8.570698  8.949901
0:  9.250645  9.440789  9.547229  9.546015  7.5887427 7.6923113]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.353954 22.34384  22.356714 22.334814 22.289835 22.18178  22.080362
0:  21.875586 21.703459 21.560894 21.405254 21.276155 21.252008 21.255516
0:  21.315302 21.36935  21.431118 21.500645 21.443655 21.82987 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.737587  11.686171  11.639778  11.576508  11.518497  11.466035
0:  11.473564  11.449581  11.495647  11.523645  11.529633  11.455672
0:  11.372592  11.261503  11.1493845 11.090872  11.112635  11.171789
0:  10.891851  10.843965 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.6771727 -3.8759289 -4.074292  -4.286681  -4.4909945 -4.7337217
0:  -4.9885035 -5.3050165 -5.641823  -5.9767847 -6.285515  -6.6124964
0:  -6.9013968 -7.1249733 -7.3442507 -7.486924  -7.5758476 -7.613349
0:  -8.058011  -8.116374 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.199779  -3.079101  -2.9693189 -2.9046369 -2.8296762 -2.824102
0:  -2.8498874 -2.9381814 -3.046517  -3.1510606 -3.2286782 -3.302487
0:  -3.3484674 -3.3216548 -3.2671885 -3.1041245 -2.8506389 -2.5331836
0:  -2.223257  -1.9009886]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.506011  -4.44794   -4.3485775 -4.145214  -3.9004545 -3.7132635
0:  -3.5578852 -3.5080633 -3.4824247 -3.4621458 -3.4252071 -3.3947525
0:  -3.3460665 -3.3107958 -3.326171  -3.3494778 -3.3735733 -3.3650122
0:  -4.6729937 -4.7783756]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.232526   9.292287   9.44695    9.646006   9.889124  10.148249
0:  10.371436  10.527054  10.594471  10.585432  10.471876  10.284817
0:  10.030196   9.72353    9.382431   9.046751   8.738682   8.480943
0:   7.9482613  7.755584 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.999113  -6.783737  -6.509471  -6.184141  -5.800432  -5.4220953
0:  -5.0116177 -4.6330233 -4.2639866 -3.871439  -3.4556189 -3.0594206
0:  -2.6896486 -2.3602495 -2.1383324 -1.9492817 -1.7518129 -1.5355091
0:  -1.9116068 -1.8235731]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.019264   3.1567144  3.4111097  3.6404421  3.9045322  4.369385
0:   5.1791463  6.3354197  7.7970753  9.13625    9.995313  10.109611
0:   9.582903   8.665222   7.6433845  6.830634   6.2461667  5.887188
0:   4.995989   5.4021797]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.999724  -6.1457705 -6.283135  -6.379517  -6.4454427 -6.4871373
0:  -6.44249   -6.391915  -6.2927423 -6.1670365 -6.0103784 -5.8746305
0:  -5.731891  -5.5864844 -5.482219  -5.3579745 -5.230808  -5.068064
0:  -4.820022  -4.5757537]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.999451  -8.910973  -8.774754  -8.604046  -8.393955  -8.194263
0:  -7.974817  -7.8325057 -7.7562013 -7.75038   -7.798301  -7.916229
0:  -8.047119  -8.137676  -8.232269  -8.274309  -8.262022  -8.225531
0:  -8.258316  -8.190668 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.048579  13.052129  13.045232  12.998234  12.955181  12.883434
0:  12.809828  12.678722  12.591986  12.545034  12.536644  12.538683
0:  12.549455  12.561604  12.559457  12.595428  12.677864  12.7939825
0:  12.826013  12.974764 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.6595654 -3.6512856 -3.6119676 -3.5171895 -3.4553418 -3.4463496
0:  -3.4035115 -3.451137  -3.4758515 -3.4779239 -3.4933305 -3.4746318
0:  -3.4207273 -3.326713  -3.1710582 -2.9570708 -2.7880578 -2.5683866
0:  -2.54802   -2.3584828]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.566975   8.737108   9.020008   9.357367   9.718234  10.108258
0:  10.480097  10.815172  11.174871  11.476933  11.788523  12.034649
0:  12.294985  12.529797  12.750904  12.918995  13.081287  13.2315235
0:  14.091995  14.509077 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.031351  10.776233  10.4415865 10.029102   9.620066   9.230088
0:   8.874052   8.573814   8.3581085  8.242353   8.213596   8.16909
0:   8.160021   8.111227   8.033428   8.021434   8.101809   8.240987
0:   8.536584   8.580332 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.0505352  0.13356829 0.21548223 0.2693901  0.29529905 0.29938984
0:  0.2811861  0.24412632 0.23202372 0.26042366 0.3029375  0.31559753
0:  0.3316698  0.31952524 0.29090166 0.28640747 0.32161427 0.38442516
0:  0.22553921 0.34096384]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.964659  16.929108  16.925303  16.945738  16.892687  16.76355
0:  16.6136    16.375338  16.170378  15.9647255 15.718687  15.472286
0:  15.243309  15.017199  14.809864  14.5958805 14.367178  14.077982
0:  13.731541  13.260277 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.511839 8.581655 8.665689 8.727516 8.733931 8.710262 8.68234  8.60794
0:  8.583114 8.552244 8.521761 8.485238 8.479611 8.49181  8.520107 8.555841
0:  8.575502 8.611234 8.163743 8.228953]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.929386 21.954304 21.989288 22.039364 22.071312 22.135075 22.270332
0:  22.347404 22.469028 22.606445 22.682556 22.744514 22.801434 22.833271
0:  22.870914 22.86942  22.843567 22.77692  22.723412 22.575474]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.346241  4.604082  4.964565  5.3222456 5.6884956 5.968982  6.1660943
0:  6.210378  6.06682   5.7044    5.1912055 4.5375834 3.9288757 3.4935505
0:  3.2928684 3.4566567 3.905159  4.549794  6.375584  6.697845 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.0816183  -2.0045004  -1.8980999  -1.7479935  -1.578207   -1.4325876
0:  -1.280757   -1.1835327  -1.0898609  -1.0124502  -0.92557526 -0.85552454
0:  -0.7775974  -0.68174744 -0.61331844 -0.53578806 -0.4786024  -0.41097355
0:  -0.61373377 -0.6706314 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.576242 15.584599 15.637945 15.684127 15.702101 15.708413 15.671571
0:  15.566514 15.441299 15.329477 15.209238 15.093519 15.081596 15.111992
0:  15.22333  15.348113 15.487537 15.608521 16.12268  16.154411]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.348183 33.41861  33.54129  33.7383   33.96439  34.24293  34.659153
0:  34.999    35.419025 35.799442 36.09476  36.34037  36.621567 36.870125
0:  37.06657  37.22559  37.328827 37.356655 38.601894 39.28901 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.9582102 3.2783482 3.501115  3.6643894 3.750001  3.8098595 3.9043477
0:  3.9838364 4.071608  4.190922  4.2846785 4.3548765 4.426216  4.4290385
0:  4.400777  4.321582  4.1984043 4.0585356 3.660781  3.9164672]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.805363 19.966854 20.130966 20.272697 20.401825 20.510616 20.610426
0:  20.630722 20.668919 20.643723 20.513685 20.318636 20.099531 19.857328
0:  19.633333 19.424301 19.255793 19.138784 18.534182 18.633549]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.216141  8.223494  8.223269  8.186601  8.130795  8.016878  7.854329
0:  7.5953693 7.2818756 6.940238  6.592515  6.285266  6.0676703 5.986139
0:  6.012694  6.1591187 6.376878  6.6141334 7.2816954 7.12729  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.29006  14.166807 14.063112 13.946114 13.807329 13.598927 13.307677
0:  12.89554  12.419132 11.888118 11.319085 10.762096 10.255219  9.848555
0:   9.53396   9.351347  9.278806  9.278029  9.288415  9.192257]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.205956 18.080997 17.92591  17.670292 17.36755  17.052267 16.718649
0:  16.361647 16.00247  15.627054 15.206858 14.722618 14.233009 13.747995
0:  13.291648 12.89685  12.588512 12.33438  11.495201 11.211543]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.968712 12.088938 12.273991 12.502328 12.713108 12.884307 13.05526
0:  13.17931  13.312731 13.431431 13.507925 13.532452 13.504478 13.424383
0:  13.30493  13.153099 13.00429  12.868919 12.404979 12.271549]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.762785 23.73394  23.761765 23.745768 23.693958 23.559067 23.339924
0:  22.964003 22.519712 21.997349 21.42994  20.889898 20.458946 20.05466
0:  19.62226  19.074318 18.39027  17.664991 15.330494 15.150295]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-16.152756  -15.98809   -15.869794  -15.655898  -15.375115  -15.053443
0:  -14.630404  -14.239373  -13.8877535 -13.568528  -13.281171  -13.079665
0:  -12.89276   -12.721686  -12.4442835 -12.133262  -11.804271  -11.480042
0:  -11.206334  -10.931529 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.863701  8.619673  8.331563  8.039463  7.7062693 7.3077383 6.9373474
0:  6.4998    6.086297  5.6750464 5.2371597 4.8182626 4.4318733 4.090665
0:  3.779839  3.474548  3.170592  2.9268405 1.176259  1.0226011]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.507622 20.946795 21.3937   21.847649 22.29094  22.774393 23.361698
0:  23.906933 24.519354 25.044428 25.471785 25.779089 26.018755 26.205986
0:  26.324451 26.353212 26.296432 26.096935 23.72207  23.77101 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.55214   2.5301137 2.5262833 2.5248616 2.516563  2.5002692 2.4777691
0:  2.427656  2.381323  2.3476024 2.302189  2.2360365 2.1750057 2.1109588
0:  2.0551693 2.0468438 2.0775657 2.1437938 1.9481988 1.946846 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.2339058 2.318368  2.4536552 2.602995  2.780892  2.9437199 3.1176963
0:  3.2510397 3.371283  3.4739282 3.5432162 3.556205  3.5418882 3.5045354
0:  3.4247499 3.3556523 3.298928  3.2628458 2.5702968 2.4886537]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.273363 20.465832 19.528679 18.529207 17.511898 16.542034 15.748842
0:  15.097502 14.845815 14.911928 15.316889 16.041218 17.038921 18.189138
0:  19.343163 20.411512 21.370861 22.124298 22.655708 22.87613 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.5508304 -6.5470824 -6.4979033 -6.438681  -6.373696  -6.3324227
0:  -6.2648425 -6.2089076 -6.0917    -5.90208   -5.604028  -5.2502027
0:  -4.845988  -4.402226  -4.038571  -3.7464852 -3.563089  -3.5029263
0:  -4.4353213 -4.606754 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.45555   19.359766  19.18986   18.905201  18.53108   18.076366
0:  17.629972  17.112532  16.649351  16.183403  15.740889  15.3188
0:  15.010544  14.8002205 14.677317  14.618467  14.528278  14.398199
0:  14.764185  14.560219 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.650532  3.5449562 3.441196  3.3497608 3.2925062 3.2544053 3.2100804
0:  3.139285  3.067362  2.9828649 2.92689   2.8717477 2.8217983 2.7902935
0:  2.7356641 2.666463  2.5613477 2.459962  2.4730372 2.2463145]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.698515  2.7132988 2.7645316 2.839036  2.9125583 2.966591  3.0258374
0:  3.0608394 3.107883  3.1567247 3.2004313 3.2329473 3.2730947 3.3094592
0:  3.3657107 3.431618  3.51758   3.6271307 3.6167567 3.662138 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.97744   -5.9780235 -5.9517927 -5.896309  -5.912284  -5.997596
0:  -6.093622  -6.2493477 -6.383298  -6.496232  -6.6202974 -6.770668
0:  -6.921753  -7.02528   -7.112859  -7.1277227 -7.136652  -7.0847216
0:  -7.0850115 -7.0171556]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.407194 15.905489 15.294113 14.65542  14.061718 13.597941 13.321994
0:  13.189638 13.236719 13.453821 13.77735  14.158009 14.596811 15.071722
0:  15.576242 16.082708 16.609587 17.114042 17.148577 17.35224 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.0825934 -2.9312444 -2.7662969 -2.6313062 -2.5063472 -2.4285007
0:  -2.3304162 -2.282539  -2.22475   -2.1663022 -2.1127954 -2.103373
0:  -2.1217284 -2.1282172 -2.1773286 -2.1845326 -2.1771178 -2.1329074
0:  -2.5494618 -2.6182017]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.6987767 -4.5929255 -4.4605117 -4.3373256 -4.2514844 -4.2720046
0:  -4.3392615 -4.5123496 -4.718325  -4.9374404 -5.1806664 -5.484262
0:  -5.830277  -6.1820626 -6.563082  -6.8718724 -7.127868  -7.290215
0:  -8.030838  -8.095314 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [  4.0367737    3.5818164    3.1133888    2.6979144    2.2912402
0:    1.8950272    1.5338206    1.1657419    0.75813866   0.29654455
0:   -0.23607397  -0.8804574   -1.5418258   -2.2941852   -3.1351495
0:   -4.092731    -5.1974177   -6.2749743   -9.024418   -10.008331  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.131992   -9.950462   -9.576302   -9.043085   -8.411894   -7.820701
0:   -7.36377    -7.146667   -7.1223893  -7.2179894  -7.291947   -7.3045135
0:   -7.1876664  -6.9626584  -6.734775   -6.508018   -6.318215   -6.1513343
0:   -6.3826194  -6.3039613]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.1003428 2.1951976 2.3578053 2.5879781 2.8824115 3.1630418 3.444081
0:  3.6794405 3.924863  4.1851277 4.4735756 4.76383   5.082888  5.4204984
0:  5.74819   6.078047  6.4302764 6.7893567 6.7341237 7.161826 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.1081228 2.2317743 2.36449   2.4740229 2.5573115 2.625524  2.6875167
0:  2.746047  2.795033  2.8343415 2.8600392 2.8639207 2.867166  2.8871188
0:  2.9036117 2.9406223 3.0000749 3.0833714 2.9347982 3.0186028]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.26375  17.190853 17.114395 16.962    16.763662 16.507961 16.226059
0:  15.908775 15.617359 15.335049 15.069225 14.770334 14.461941 14.160042
0:  13.841069 13.566062 13.323387 13.123804 12.686327 12.533274]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.167519 17.512875 17.825489 18.119707 18.346365 18.477524 18.737278
0:  18.830221 18.982216 19.204033 19.373188 19.615425 19.980083 20.403233
0:  20.823746 21.281578 21.635614 21.87166  20.186556 20.27951 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-11.664576  -11.637777  -11.521332  -11.317366  -11.000387  -10.610434
0:  -10.116453   -9.657604   -9.250349   -8.878782   -8.506817   -8.182428
0:   -7.8675     -7.55946    -7.4112706  -7.260408   -7.15733    -7.087769
0:   -7.1757674  -7.1179414]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.243694 24.260603 24.227684 24.104792 23.928253 23.709925 23.45722
0:  23.158037 22.880123 22.621094 22.364641 22.085754 21.80304  21.481209
0:  21.119505 20.77127  20.479868 20.2495   19.594711 19.47464 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.5122619  -2.2864861  -2.0229096  -1.7299399  -1.4332142  -1.2236414
0:  -1.1125879  -1.1816788  -1.3691959  -1.5932751  -1.7856622  -1.90097
0:  -1.902163   -1.7610049  -1.5811229  -1.3174787  -1.0297332  -0.7475562
0:  -0.26413488 -0.05959558]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.2932744 -7.082129  -6.780356  -6.388081  -5.9295983 -5.4978986
0:  -5.051374  -4.7284827 -4.49313   -4.351087  -4.2484765 -4.224549
0:  -4.1818414 -4.087499  -4.0129237 -3.8716683 -3.7287354 -3.5932574
0:  -4.139444  -4.082113 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.764565 19.974277 20.185293 20.367676 20.532051 20.66886  20.794209
0:  20.829105 20.854774 20.850899 20.798426 20.708012 20.618858 20.491873
0:  20.301907 20.102312 19.912525 19.781633 19.758074 19.766941]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.821749 15.833107 15.883812 15.974903 16.08734  16.196459 16.323334
0:  16.404932 16.503843 16.619242 16.69903  16.814785 16.967167 17.113642
0:  17.263384 17.320969 17.344616 17.296377 16.172865 16.005035]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -5.1162014  -5.262251   -5.4394293  -5.692436   -6.010009   -6.3873386
0:   -6.7636147  -7.166383   -7.597927   -8.020078   -8.431331   -8.861095
0:   -9.23879    -9.632524  -10.04379   -10.451079  -10.86836   -11.2429
0:  -12.085061  -12.109267 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.5294142 -3.1976137 -2.9298744 -2.6559267 -2.437995  -2.267127
0:  -2.0762749 -1.9524393 -1.8518047 -1.7536812 -1.676404  -1.5919218
0:  -1.4897842 -1.3813591 -1.2871428 -1.2109747 -1.1617136 -1.0390759
0:  -1.2894201 -1.0428443]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.518865  4.2588644 3.882826  3.4339774 2.980663  2.548538  2.2241633
0:  2.015624  1.935432  1.9774265 2.085878  2.1937609 2.2754107 2.3478258
0:  2.3642328 2.3871045 2.4176042 2.4665294 2.153683  2.217459 ]
0: validation loss for strategy=forecast at epoch 15 : nan
0: validation loss for velocity_u : 0.03135352209210396
0: validation loss for velocity_v : 0.05469677969813347
0: validation loss for specific_humidity : 0.025684209540486336
0: validation loss for velocity_z : 0.3889477550983429
0: validation loss for temperature : 0.07218960672616959
0: validation loss for total_precip : nan
0: 16 : 10:50:43 :: batch_size = 96, lr = 1.4154543915199217e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 16, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2146, 0.2241, 0.2372, 0.2557, 0.2760, 0.2941, 0.3106, 0.3270, 0.3418, 0.3511, 0.3546, 0.3544, 0.3509, 0.3427,
0:         0.3304, 0.3180, 0.3077, 0.2988, 0.3269, 0.3334, 0.3423, 0.3539, 0.3668, 0.3813, 0.3981], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.0062, -1.0121, -1.0138, -1.0125, -1.0081, -1.0016, -0.9937, -0.9869, -0.9823, -0.9796, -0.9790, -0.9801,
0:         -0.9832, -0.9862, -0.9871, -0.9853, -0.9823, -0.9786, -0.9711, -0.9812, -0.9906, -0.9965, -0.9967, -0.9941,
0:         -0.9919], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6413, -0.6363, -0.6302, -0.6211, -0.6117, -0.6039, -0.5974, -0.5890, -0.5811, -0.5756, -0.5703, -0.5529,
0:         -0.5378, -0.5259, -0.4992, -0.4519, -0.4187, -0.3833, -0.6487, -0.6488, -0.6454, -0.6433, -0.6367, -0.6333,
0:         -0.6299], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.1481, 0.2501, 0.2206, 0.2411, 0.4135, 0.5746, 0.5791, 0.5451, 0.6109, 0.6880, 0.6540, 0.5677, 0.5451, 0.5541,
0:         0.5133, 0.4543, 0.4589, 0.5201, 0.2343, 0.3069, 0.2864, 0.3137, 0.4362, 0.5224, 0.5133], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-1.7385, -1.7411, -1.7447, -1.7485, -1.7514, -1.7533, -1.7554, -1.7582, -1.7607, -1.7612, -1.7597, -1.7583,
0:         -1.7576, -1.7570, -1.7557, -1.7544, -1.7545, -1.7558, -1.7577, -1.7589, -1.7596, -1.7593, -1.7578, -1.7563,
0:         -1.7554], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 16, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan, -0.2600,     nan,     nan, -0.2600,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2600,     nan,     nan,     nan,     nan,     nan, -0.2600, -0.2600,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2600,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2600,     nan, -0.2600,     nan,     nan,     nan,     nan,
0:         -0.2600,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2600,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2600,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2600, -0.2600,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2600,     nan,     nan,     nan, -0.2600,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2600,     nan,     nan,     nan,     nan,     nan,     nan, -0.2600,
0:             nan,     nan,     nan, -0.2600,     nan,     nan,     nan,     nan,     nan,     nan, -0.2600,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2600,     nan,     nan,     nan, -0.2600,     nan,
0:             nan, -0.2600,     nan,     nan,     nan,     nan,     nan, -0.2600,     nan,     nan,     nan, -0.2600,
0:         -0.2600,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2600,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2600,     nan,     nan,     nan,     nan,     nan,     nan, -0.2600, -0.2600,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 16, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-1.4690, -1.4496, -1.4226, -1.3880, -1.3488, -1.3101, -1.2675, -1.2292, -1.1896, -1.1520, -1.1164, -1.0866,
0:         -1.0553, -1.0266, -0.9955, -0.9680, -0.9435, -0.9220, -1.4932, -1.4783, -1.4577, -1.4320, -1.3998, -1.3689,
0:         -1.3372], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.3790, -0.4187, -0.4666, -0.5116, -0.5551, -0.5913, -0.6224, -0.6459, -0.6643, -0.6786, -0.6896, -0.6942,
0:         -0.6959, -0.6974, -0.7041, -0.7125, -0.7251, -0.7392, -0.3737, -0.4075, -0.4466, -0.4827, -0.5125, -0.5399,
0:         -0.5636], device='cuda:1', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.5202, -0.5268, -0.5242, -0.5106, -0.4984, -0.4797, -0.4563, -0.4261, -0.3948, -0.3610, -0.3300, -0.2983,
0:         -0.2745, -0.2548, -0.2477, -0.2449, -0.2518, -0.2698, -0.5400, -0.5472, -0.5489, -0.5464, -0.5410, -0.5335,
0:         -0.5172], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.4710, 0.4565, 0.4102, 0.3277, 0.2403, 0.2055, 0.1820, 0.1246, 0.1000, 0.0877, 0.0632, 0.0677, 0.0636, 0.0616,
0:         0.1129, 0.1660, 0.2304, 0.3047, 0.4611, 0.4481, 0.4110, 0.3697, 0.3175, 0.3003, 0.2903], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([-1.2142, -1.1958, -1.1809, -1.1728, -1.1705, -1.1730, -1.1774, -1.1828, -1.1848, -1.1835, -1.1800, -1.1754,
0:         -1.1698, -1.1665, -1.1641, -1.1619, -1.1585, -1.1548, -1.1514, -1.1525, -1.1593, -1.1722, -1.1891, -1.2079,
0:         -1.2271], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.050363607704639435; velocity_v: 0.08671645820140839; specific_humidity: 0.04030710458755493; velocity_z: 0.5177913904190063; temperature: 0.11204732954502106; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05076094716787338; velocity_v: 0.08931079506874084; specific_humidity: 0.03629540279507637; velocity_z: 0.5037345290184021; temperature: 0.09721335768699646; total_precip: nan; 
0: epoch: 16 [1/5 (20%)]	Loss: nan : nan :: 0.13708 (2.40 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05344308912754059; velocity_v: 0.09510091692209244; specific_humidity: 0.03935414180159569; velocity_z: 0.5052202343940735; temperature: 0.10159733891487122; total_precip: nan; 
0: epoch: 16 [2/5 (40%)]	Loss: nan : nan :: 0.14007 (16.12 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.08465655893087387; velocity_v: 0.12465774267911911; specific_humidity: 0.03956672176718712; velocity_z: 0.530024528503418; temperature: 0.09551192075014114; total_precip: nan; 
0: epoch: 16 [3/5 (60%)]	Loss: nan : nan :: 0.16465 (16.25 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.052005834877491; velocity_v: 0.09175307303667068; specific_humidity: 0.033854931592941284; velocity_z: 0.5310392379760742; temperature: 0.09609824419021606; total_precip: nan; 
0: epoch: 16 [4/5 (80%)]	Loss: nan : nan :: 0.13876 (16.13 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [0.00000000e+00 2.86102295e-06 6.67572021e-06 8.58306885e-06
0:  4.76837158e-06 2.86102295e-06 1.90734863e-06 9.53674316e-07
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 9.53674316e-07
0:  3.81469727e-06 5.72204590e-06 1.14440918e-05 9.53674316e-06
0:  4.76837158e-06 9.53674316e-07 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 9.53674316e-07
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  1.90734863e-06 4.76837158e-06 4.76837158e-06 3.81469727e-06
0:  3.81469727e-06 4.95910645e-05 3.05175781e-05 4.48226929e-05
0:  7.62939453e-06 9.53674316e-07 0.00000000e+00 1.90734863e-06
0:  3.81469727e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.86102295e-06
0:  2.86102295e-06 1.90734863e-06 0.00000000e+00 1.90734863e-06
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  1.90734863e-06 7.62939453e-06 9.53674316e-06 8.58306885e-06
0:  6.67572021e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  9.53674316e-06 1.14440918e-05 1.14440918e-05 1.04904175e-05
0:  1.04904175e-05 3.31878662e-04 1.37329102e-04 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]
0: Target values (first 200):
0: [4.76837158e-07 2.86102295e-06 6.67572021e-06 1.43051147e-06
0:  9.53674316e-07 9.53674316e-07 1.43051147e-06 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  4.76837158e-07 0.00000000e+00 4.76837158e-07 2.38418579e-06
0:  2.86102295e-06 0.00000000e+00 2.38418579e-06 4.76837158e-06
0:  7.62939453e-06 7.62939453e-06 4.76837158e-06 7.62939453e-06
0:  8.10623169e-06 9.05990601e-06 6.67572021e-06 3.33786011e-06
0:  9.53674316e-07 4.76837158e-07 4.76837158e-07 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 1.90734863e-06 4.76837158e-06
0:  0.00000000e+00 1.90734863e-06 1.57356262e-05 1.95503235e-05
0:  4.76837158e-07 1.04904175e-05 6.05583191e-05 8.58306885e-05
0:  4.81605530e-05 4.95910645e-05 5.67436218e-05 4.14848364e-05
0:  2.38418579e-06 1.52587891e-05 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 7.15255737e-06 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 4.76837158e-07 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  9.53674316e-07 3.33786011e-06 6.67572021e-06 1.90734863e-06
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 9.53674316e-07 1.43051147e-06
0:  1.90734863e-06 4.76837158e-07 6.67572021e-06 4.76837158e-06
0:  3.33786011e-06 3.81469727e-06 4.29153442e-06 2.86102295e-06
0:  2.86102295e-06 3.81469727e-06 2.86102295e-06 2.38418579e-06
0:  9.53674316e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 3.81469727e-06 8.58306885e-06
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.95639038e-05
0:  3.05175781e-05 1.90734863e-05 1.38282776e-05 6.77108765e-05
0:  1.06334686e-04 1.26361847e-04 1.04427338e-04 5.00679016e-05]
0: Prediction values (first 20):
0: [6.9638386 6.8466406 6.7072487 6.5197453 6.3413534 6.1657934 6.014941
0:  5.825703  5.608877  5.3611755 5.0808935 4.7616467 4.4624133 4.2212915
0:  4.033636  3.9579818 3.9514582 4.0094852 4.065419  3.9996471]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -1.356, max = 1.440, mean = -0.169
0:          sample (first 20): tensor([-0.0123, -0.0220, -0.0335, -0.0490, -0.0638, -0.0783, -0.0907, -0.1064, -0.1243, -0.1448, -0.1679, -0.1943,
0:         -0.2190, -0.2390, -0.2545, -0.2607, -0.2613, -0.2565, -0.0144, -0.0271])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.8632157  3.7906773  3.8269129  3.9788527  4.207137   4.49172
0:   4.886676   5.314857   5.9127073  6.6433973  7.495879   8.4848175
0:   9.555849  10.645792  11.641733  12.481061  13.195036  13.762508
0:  13.730612  14.293026 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.4221206 -6.3122735 -6.1229386 -5.837649  -5.479131  -5.130569
0:  -4.8178067 -4.658088  -4.60424   -4.6709495 -4.797974  -4.9548306
0:  -5.0979514 -5.169066  -5.224336  -5.2312217 -5.2357297 -5.2510734
0:  -6.18792   -6.1491656]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.403734  11.5762825 11.530241  11.196737  10.823452  10.451496
0:  10.190378  10.05748   10.076487  10.260699  10.589634  10.983773
0:  11.43316   11.813655  12.090813  12.377287  12.7070465 13.157824
0:  14.258949  14.864943 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.6746445 4.8227997 4.968462  4.986742  4.903475  4.669559  4.2721977
0:  3.7119968 3.1031785 2.5263996 2.1419396 2.032281  2.2492867 2.7726426
0:  3.4218361 4.1140804 4.697389  5.1021757 5.0574255 5.106611 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.884748 17.150667 17.548368 18.062899 18.631245 19.180973 19.63157
0:  19.89889  20.10879  20.249355 20.409058 20.60507  20.862328 21.077507
0:  21.27346  21.312462 21.261463 21.10244  19.441832 19.563877]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-18.930893 -18.804588 -18.572384 -18.234865 -17.836103 -17.48957
0:  -17.116644 -16.837414 -16.544071 -16.222116 -15.859661 -15.495373
0:  -15.186453 -14.951773 -14.806349 -14.666092 -14.486301 -14.233839
0:  -14.480507 -13.991434]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [30.23646  30.36169  30.537205 30.669357 30.781628 30.866291 30.959574
0:  31.018269 31.137922 31.238592 31.324123 31.353535 31.384445 31.453033
0:  31.476292 31.569605 31.623358 31.649498 31.572672 31.743008]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-14.404477 -14.201638 -14.093404 -13.999997 -13.999335 -14.136073
0:  -14.320985 -14.615705 -14.918967 -15.198653 -15.447213 -15.604369
0:  -15.645715 -15.594853 -15.454917 -15.281198 -15.015355 -14.720059
0:  -13.811292 -13.923459]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.223991  16.149178  16.078394  15.968428  15.894941  15.832258
0:  15.801123  15.803805  15.872135  15.997607  16.14318   16.227474
0:  16.235632  16.17825   16.013248  15.834868  15.674671  15.563643
0:  14.9081335 14.986012 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.4114623  -2.3594584  -2.3247228  -2.281777   -2.2340407  -2.2042193
0:  -2.144421   -2.1144624  -2.0615783  -1.977592   -1.8609691  -1.7413211
0:  -1.5997214  -1.4265218  -1.2705531  -1.0614476  -0.8516989  -0.59714603
0:  -0.2835784  -0.03905106]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.559034  8.6301365 8.698523  8.794305  8.899029  8.9811945 9.114351
0:  9.211437  9.320853  9.413518  9.469923  9.519367  9.580281  9.640015
0:  9.697178  9.7225895 9.696058  9.6328    9.227047  9.101466 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.02845   12.546093  13.049091  13.444835  13.746915  13.942091
0:  14.063955  14.08345   14.070374  14.085475  14.1743355 14.351199
0:  14.583435  14.820435  15.006865  15.121257  15.186676  15.260724
0:  15.342619  15.594381 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.5536971   0.4827838   0.45330572  0.43667316  0.41086483  0.35281134
0:   0.28923368  0.197927    0.12279367  0.0754056   0.03182411 -0.02832031
0:  -0.08093023 -0.15049028 -0.22867727 -0.2875886  -0.30922508 -0.28821373
0:  -0.5895047  -0.5842643 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -5.747174   -5.9995284  -6.216038   -6.4240994  -6.685245   -7.009645
0:   -7.3408513  -7.727095   -8.051849   -8.324032   -8.572639   -8.830233
0:   -9.0404     -9.2319355  -9.43775    -9.663097   -9.970425  -10.2675495
0:  -11.102526  -11.422161 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.5469604  -4.208915   -3.8023067  -3.2984881  -2.749002   -2.1626506
0:  -1.4858842  -0.8303313  -0.15030241  0.5214596   1.1518407   1.726378
0:   2.2552538   2.6799169   3.019826    3.2742488   3.4564936   3.6108987
0:   3.2761183   3.3519502 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.371007  -4.4090405 -4.4354696 -4.4448547 -4.4299746 -4.4339437
0:  -4.4327717 -4.482048  -4.5215454 -4.553384  -4.55188   -4.5458393
0:  -4.5213566 -4.4526854 -4.40617   -4.3255587 -4.221323  -4.079626
0:  -3.99094   -3.9021807]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.268413  5.1612515 5.108823  5.0818887 5.0565906 5.031487  4.983906
0:  4.9108334 4.8615065 4.8139176 4.7916985 4.7433815 4.7188935 4.7016296
0:  4.6909146 4.677498  4.648184  4.6154423 4.5278654 4.4423   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.441276  6.098937  5.7006392 5.181898  4.5677004 3.8172688 3.0527334
0:  2.29944   1.7270718 1.3773956 1.269331  1.3304782 1.5001202 1.7532125
0:  1.9956989 2.2818975 2.5631356 2.8254662 3.1351404 3.33784  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.111515    2.1084628   2.107338    2.1392894   2.1339226   2.045672
0:   1.9234028   1.7002096   1.4502702   1.1983762   0.97305775  0.76528835
0:   0.5849681   0.433887    0.25512123  0.10965967 -0.00670242 -0.08313036
0:  -0.27824688 -0.26636362]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.0905802   1.9834175   1.8523426   1.6582468   1.4437418   1.1936288
0:   0.9601989   0.72613     0.46489763  0.23279762  0.02012444 -0.19221783
0:  -0.34564257 -0.45064878 -0.5215149  -0.5280099  -0.51252604 -0.4636793
0:  -0.68374157 -0.6801977 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.973818  7.867853  7.8177695 7.7797804 7.761254  7.746426  7.69079
0:  7.603983  7.5191636 7.428538  7.359604  7.273045  7.19748   7.110818
0:  7.0303593 6.93611   6.835855  6.715865  6.4842734 6.4033833]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.366701 18.327944 18.208143 18.040087 17.843258 17.667477 17.528536
0:  17.386692 17.302094 17.264725 17.234371 17.230225 17.28672  17.340622
0:  17.387493 17.354757 17.282818 17.179289 16.683558 16.579935]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.573715  4.5950947 4.6248436 4.661557  4.681346  4.6501384 4.602476
0:  4.496362  4.38089   4.238937  4.068036  3.8521457 3.6071243 3.3650596
0:  3.1176813 2.9275837 2.792964  2.7263556 2.3115802 2.321044 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.6209822 -2.6642752 -2.6780128 -2.6530685 -2.6149578 -2.6264734
0:  -2.6436787 -2.720026  -2.8094625 -2.8637218 -2.911684  -2.9833794
0:  -3.0653448 -3.147397  -3.2411108 -3.281703  -3.283699  -3.2192402
0:  -3.6341686 -3.6693897]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.0499234 -3.1800447 -3.248304  -3.2424846 -3.2040477 -3.1898856
0:  -3.195067  -3.279161  -3.412436  -3.5551324 -3.6701818 -3.7693105
0:  -3.834661  -3.86552   -3.9252353 -3.9871488 -4.0698276 -4.1599956
0:  -4.5851884 -4.689033 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.68049383  0.4827714   0.20005655 -0.186512   -0.63760424 -1.138361
0:  -1.6762991  -2.2469425  -2.822898   -3.3632097  -3.8438187  -4.2796583
0:  -4.5757856  -4.7447386  -4.8278627  -4.804289   -4.7467766  -4.681574
0:  -4.937048   -5.030221  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.296878   -5.2703753  -5.1445646  -4.939473   -4.5835867  -4.123788
0:  -3.5904055  -3.0353146  -2.4646873  -1.8666668  -1.1786165  -0.4650836
0:   0.32470417  1.1613255   1.917697    2.643332    3.2429445   3.6796196
0:   3.8444462   3.5821435 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.7340298 3.9302912 4.194292  4.480148  4.704671  4.8201733 4.8304863
0:  4.748707  4.666647  4.63587   4.6778574 4.7579556 4.8749385 4.975806
0:  5.04856   5.107226  5.184427  5.316099  5.1832533 5.37614  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.318068  18.3264    18.296043  18.206234  18.03438   17.774027
0:  17.521225  17.184576  16.889296  16.600191  16.277618  16.000652
0:  15.8249035 15.732777  15.731905  15.787653  15.892693  16.016241
0:  16.35762   16.564837 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [39.94068  39.665947 39.509083 39.451847 39.369762 39.173267 38.900272
0:  38.501873 38.244347 38.02714  37.831085 37.826202 37.996567 38.41906
0:  38.879635 39.292015 39.669147 39.75802  46.397316 46.722076]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.505863 17.694164 17.926636 18.397871 18.960657 19.663956 20.476368
0:  21.195267 21.96108  22.762253 23.55907  24.3773   25.187157 25.796577
0:  26.143131 26.25093  26.19315  26.147938 23.89188  24.304081]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.1033816  -0.97715616 -0.84814024 -0.7332339  -0.6810436  -0.67657995
0:  -0.67384243 -0.7074747  -0.7448745  -0.76904964 -0.80430365 -0.8306713
0:  -0.83573294 -0.80322456 -0.780478   -0.7641568  -0.7899561  -0.81587124
0:  -1.072186   -0.9747987 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.413452  18.299124  18.097418  17.736015  17.339302  16.88549
0:  16.426292  15.976118  15.555786  15.183967  14.821717  14.435734
0:  14.019492  13.63773   13.224644  12.880449  12.5926075 12.372529
0:  11.830214  11.599161 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.4616799 1.5743637 1.7215586 1.8556576 1.977149  2.082767  2.2017121
0:  2.283607  2.3817077 2.5007539 2.6375551 2.7590208 2.8929925 3.0348709
0:  3.1519365 3.2802224 3.4371731 3.6299186 3.416899  3.5243728]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.2598803 3.4173675 3.6013596 3.7641306 3.9040272 3.9959998 4.099682
0:  4.1826296 4.301634  4.446141  4.601365  4.7588134 4.887501  5.029069
0:  5.1397104 5.268077  5.38654   5.512484  5.324664  5.360988 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.280405 16.492004 16.708376 16.840654 16.927172 16.979803 17.004044
0:  16.99591  17.017689 17.051788 17.083633 17.056377 17.035177 17.005985
0:  16.95616  16.91837  16.90768  16.900711 16.684704 16.796852]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.846634 33.87228  33.952045 34.041786 34.169582 34.361332 34.579014
0:  34.75868  34.95426  35.127697 35.264053 35.3112   35.332985 35.258934
0:  35.06874  34.77914  34.45802  34.12913  32.455887 32.092552]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.059302  8.146572  8.239133  8.286074  8.315129  8.306451  8.3146105
0:  8.306056  8.330085  8.367225  8.390601  8.371325  8.356998  8.314813
0:  8.26467   8.267517  8.306393  8.420579  8.134319  8.224579 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.10215  12.247837 12.377574 12.455765 12.544739 12.627024 12.750256
0:  12.896686 13.09646  13.356763 13.643086 13.908312 14.136852 14.355518
0:  14.525511 14.69519  14.878235 15.064594 14.902759 14.966548]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.807444 26.510553 26.311272 25.956852 25.606106 25.220987 24.872438
0:  24.446602 24.01367  23.439056 22.605804 21.66924  20.678516 19.730558
0:  18.968235 18.398838 17.993095 17.7616   18.42078  18.156404]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.00974   -5.0784006 -5.1878786 -5.3394623 -5.479431  -5.6070585
0:  -5.6872396 -5.7768946 -5.7886734 -5.733465  -5.5609283 -5.3417006
0:  -5.045636  -4.6686907 -4.2750473 -3.7993927 -3.275506  -2.724104
0:  -2.2347918 -1.7311492]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [44.800827 44.24214  43.723434 43.31509  42.89163  42.476025 42.10714
0:  41.675682 41.39688  41.019096 40.483345 39.878017 39.296627 38.833977
0:  38.434795 38.108593 37.787205 37.307827 39.401405 39.134216]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [43.394176 43.554134 43.67242  43.766567 43.812187 43.834923 43.89763
0:  43.864525 43.918003 43.904    43.845604 43.745384 43.653084 43.601254
0:  43.506695 43.45291  43.35605  43.095116 42.85799  42.91774 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.524655  11.632658  10.482526   9.083916   7.693447   6.4158745
0:   5.37809    4.736935   4.650217   5.0023947  5.6909633  6.6033072
0:   7.604136   8.407278   9.201372   9.795461  10.327507  10.835562
0:  11.502394  11.844538 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.0835333 5.8119283 5.5020933 5.1309667 4.740764  4.3289757 3.9666972
0:  3.64514   3.4177406 3.321847  3.3400173 3.4381063 3.6229544 3.8709757
0:  4.1102605 4.3490734 4.528135  4.615905  4.1764936 3.9868178]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.990143  -8.835945  -8.721386  -8.682344  -8.699366  -8.783226
0:  -8.835978  -8.902571  -8.888742  -8.815784  -8.670286  -8.512033
0:  -8.346209  -8.175293  -8.089376  -8.016405  -7.96162   -7.897699
0:  -7.8924994 -7.8179517]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.8747063 7.8797135 7.909463  7.943036  7.958621  7.974169  7.9961076
0:  7.979727  7.98788   8.000478  8.009816  8.001613  8.004016  7.9997954
0:  8.000934  8.022452  8.077133  8.16014   8.044457  8.037894 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.59526  15.596918 15.58557  15.618082 15.65337  15.734428 15.885157
0:  16.032158 16.22781  16.443497 16.638155 16.839333 17.072586 17.246239
0:  17.401707 17.440624 17.399174 17.31607  15.680698 15.433138]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.018063 9.124469 9.203048 9.240702 9.26119  9.264239 9.279886 9.289404
0:  9.310396 9.34524  9.371046 9.368629 9.359915 9.341462 9.322655 9.341461
0:  9.383774 9.451131 9.234159 9.349493]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.7266545 -2.650351  -2.5446315 -2.4110503 -2.2878528 -2.2223058
0:  -2.1942544 -2.2404876 -2.2879558 -2.3372855 -2.2911105 -2.2257533
0:  -2.1000113 -1.9180379 -1.7848563 -1.6238823 -1.4650717 -1.3274436
0:  -1.1098375 -1.0069971]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.431957  11.421936  11.42421   11.393244  11.328346  11.2753935
0:  11.251233  11.183691  11.145333  11.104174  11.031933  10.928266
0:  10.850232  10.7919235 10.76314   10.739941  10.743517  10.755533
0:  10.756119  10.721931 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.1257553 6.173495  6.2224784 6.2728043 6.3338957 6.3734665 6.4224386
0:  6.4499254 6.498393  6.558302  6.6305203 6.686359  6.755909  6.8375664
0:  6.891489  6.969796  7.071913  7.192206  6.8910794 6.9551296]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.855646  -8.933935  -8.887747  -8.775181  -8.624937  -8.48764
0:  -8.378103  -8.343288  -8.307814  -8.277601  -8.229567  -8.182161
0:  -8.111162  -8.018023  -7.945575  -7.884275  -7.8642526 -7.814793
0:  -8.061022  -8.137381 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.5765257 1.5994954 1.6192608 1.6356592 1.6477895 1.6374111 1.6452074
0:  1.6184335 1.6045876 1.5833755 1.5638952 1.5172467 1.4623575 1.4356413
0:  1.3825688 1.3670444 1.3805451 1.4250145 1.3680682 1.2680802]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.097651  12.868273  12.58424   12.243083  11.893227  11.543007
0:  11.215285  10.918433  10.7157135 10.605676  10.564566  10.559135
0:  10.5506    10.543362  10.501675  10.459339  10.42358   10.377059
0:  10.063548  10.1314745]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [38.499348 38.65433  38.828686 38.987743 39.123707 39.282463 39.506786
0:  39.621773 39.782696 39.88298  39.885532 39.785652 39.64814  39.501175
0:  39.357655 39.286083 39.31284  39.4128   39.85021  39.982887]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.3240113 5.9561377 5.755135  5.627883  5.603978  5.677128  5.772044
0:  5.830269  5.789039  5.5327115 5.052557  4.298683  3.4570012 2.7479634
0:  2.2229004 1.966742  1.8891053 1.8547997 1.4495349 1.436337 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.7979689   2.1242418   1.316917    0.47634602 -0.3151679  -1.1170592
0:  -1.9027495  -2.6930013  -3.3065429  -3.7791314  -4.0698514  -4.2250705
0:  -4.2976384  -4.3448577  -4.446405   -4.519462   -4.602445   -4.663056
0:  -6.425696   -6.2579474 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.2570457 -6.2444916 -6.2031546 -6.170267  -6.1446886 -6.103837
0:  -5.969262  -5.8203554 -5.5986147 -5.3788795 -5.192171  -5.1533623
0:  -5.210063  -5.2627697 -5.3372374 -5.2919846 -5.17031   -5.002879
0:  -5.7795277 -6.1210356]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.776275  5.5360174 5.2530274 4.906505  4.5214767 4.119323  3.7624376
0:  3.4434052 3.2217624 3.0765054 2.9854174 2.8856509 2.7925763 2.7341783
0:  2.655128  2.607443  2.5773504 2.5171273 1.9908235 1.715888 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.442551  -10.559807  -10.709068  -10.875187  -11.092503  -11.386486
0:  -11.706167  -12.057917  -12.324038  -12.4776325 -12.516621  -12.498882
0:  -12.440752  -12.298576  -12.186747  -12.015434  -11.832581  -11.64451
0:  -11.791733  -11.717037 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.0444512 -2.9541078 -2.9186883 -2.9145732 -2.9202113 -2.969561
0:  -2.9827275 -3.033421  -3.0851836 -3.1412807 -3.2042346 -3.2682843
0:  -3.3119674 -3.3555608 -3.3920732 -3.4023042 -3.3749614 -3.311893
0:  -3.7546248 -3.5955997]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.207929   8.551468   8.803289   9.014776   9.236954   9.575633
0:   9.980078  10.361224  10.617027  10.746806  10.734171  10.600761
0:  10.475943  10.317812  10.1263     9.921599   9.688761   9.466106
0:   9.443809   9.4901085]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.704798   5.867573   6.275318   6.831146   7.3834906  7.909882
0:   8.43181    8.788208   9.182083   9.563283   9.840071  10.076037
0:  10.387824  10.749138  11.1285305 11.556727  12.005715  12.513493
0:  12.474409  12.832232 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.573624  4.6112156 4.6529813 4.6998625 4.7433453 4.7798586 4.8364363
0:  4.864569  4.927588  4.983271  5.033561  5.0714154 5.1054473 5.139949
0:  5.1663556 5.2124605 5.2863674 5.422044  5.26915   5.2958164]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.889221  11.682081  11.324232  10.921462  10.448053   9.931964
0:   9.455785   8.969132   8.57905    8.271346   8.006414   7.7800946
0:   7.6059523  7.415886   7.2560616  7.087187   6.942066   6.8985734
0:   6.763496   6.888674 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.61577   -8.634771  -8.653992  -8.666176  -8.678345  -8.729149
0:  -8.764143  -8.8494    -8.933508  -8.98101   -9.003859  -9.032415
0:  -9.041021  -9.0181675 -9.015995  -8.979298  -8.9413395 -8.883785
0:  -9.331701  -9.301399 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.9440866 4.9662676 5.086042  5.2476115 5.432747  5.561815  5.650994
0:  5.6509924 5.606259  5.4863353 5.3152304 5.070695  4.8010635 4.4964886
0:  4.1803045 3.8889694 3.609444  3.3603935 3.0802453 2.7963915]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.048385 8.173101 8.32903  8.551022 8.805262 9.085587 9.399405 9.622564
0:  9.808612 9.946496 9.991259 9.995655 9.969848 9.914287 9.849061 9.772293
0:  9.721084 9.678195 9.404458 9.305807]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.73123    8.81939    8.972435   9.135063   9.3544445  9.562829
0:   9.780442   9.962887  10.140248  10.314991  10.487215  10.602329
0:  10.654556  10.724627  10.737954  10.759697  10.774755  10.787122
0:  10.300763  10.275137 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.3896627  3.246339   3.3384943  3.7189946  4.1965647  4.6996474
0:   5.3209653  5.8512144  6.4817247  7.1427746  7.751729   8.435436
0:   9.210632  10.010746  10.907915  11.817916  12.769901  13.869436
0:  12.913935  13.556835 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.158354 22.682426 22.274908 21.996447 21.798222 21.748156 21.914114
0:  22.143778 22.563948 23.23647  23.967974 24.886839 25.952652 27.001835
0:  28.159197 29.246986 30.239727 31.055958 31.257128 31.805025]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.90691805 1.0144672  1.1473703  1.3948631  1.7735229  2.2007341
0:  2.679966   3.0643547  3.3995054  3.6692886  3.9111428  4.16914
0:  4.489149   4.9202976  5.4241977  6.017825   6.6295633  7.178266
0:  8.110992   8.352095  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.3733673  8.359062   9.086739   9.860026  10.5092125 11.006225
0:  11.3695135 11.538724  11.566862  11.581503  11.662863  11.681257
0:  11.773729  11.803267  11.824475  11.831327  11.970076  12.257544
0:  11.957577  11.954388 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.49235  22.217789 22.047297 21.918602 21.880816 21.849318 21.925884
0:  21.824778 21.681303 21.431519 20.969395 20.479656 19.984512 19.498163
0:  19.06569  18.666739 18.34504  18.10111  18.116735 17.614227]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.0974088 -3.1084685 -3.1238427 -3.1364026 -3.1405225 -3.158628
0:  -3.1535306 -3.169372  -3.188725  -3.2053351 -3.2345977 -3.3042493
0:  -3.3998065 -3.4954438 -3.6454158 -3.77634   -3.8962111 -4.0084357
0:  -4.715915  -5.003616 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.2937965   3.1700444   3.0316904   2.8717995   2.6731353   2.4268522
0:   2.1728187   1.8997312   1.6451359   1.4230137   1.2045479   0.96851444
0:   0.74115896  0.53066874  0.31861687  0.14748764  0.01353836 -0.07087135
0:  -0.48234272 -0.54495096]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.23241282 -0.08106565  0.08027887  0.28723097  0.4983654   0.7095256
0:   0.9110036   1.0555439   1.2014375   1.3702688   1.5951152   1.8702235
0:   2.2168746   2.6089664   3.0120106   3.4199874   3.8120043   4.166789
0:   4.3444724   4.3903866 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.610878 20.489784 20.392448 20.23155  20.128084 20.1188   20.074974
0:  20.05497  20.105787 20.121325 20.12654  20.058466 19.961142 19.801964
0:  19.604162 19.404596 19.324999 19.296648 17.913742 18.005058]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.9210477 -4.9080167 -4.906386  -4.9040027 -4.925964  -4.9803224
0:  -5.0048795 -5.063353  -5.1236253 -5.1863675 -5.248098  -5.3278174
0:  -5.3906045 -5.4172444 -5.4238505 -5.3979    -5.39148   -5.3536716
0:  -5.59668   -5.551513 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [35.996525 36.010918 36.119183 36.32665  36.56273  36.760437 37.04764
0:  37.277893 37.588455 37.99153  38.359562 38.751133 39.179356 39.56184
0:  39.931202 40.228504 40.46686  40.65346  39.709717 39.775932]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.843197    7.592841    7.339893    7.040761    6.786739    6.531865
0:   6.328503    6.102648    5.8561172   5.557291    5.1697416   4.62795
0:   3.9634562   3.2561476   2.4557898   1.709167    1.0146995   0.42335606
0:  -0.1891036  -0.6223402 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.6534586 2.6599698 2.6680727 2.626141  2.6058602 2.5696998 2.5730224
0:  2.551168  2.5515647 2.5609827 2.6034498 2.6549735 2.692123  2.7305417
0:  2.7161674 2.731155  2.7727647 2.9069123 2.597002  2.588931 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.541332 17.56902  17.569283 17.484407 17.378357 17.228281 17.0908
0:  16.933918 16.777363 16.673683 16.589367 16.521036 16.480589 16.44294
0:  16.368452 16.314283 16.26493  16.227472 16.075119 15.961098]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.88133   16.864262  16.77412   16.641     16.464323  16.29099
0:  16.155037  15.976496  15.870188  15.7790165 15.678064  15.603577
0:  15.589657  15.618511  15.701054  15.785532  15.893909  15.999424
0:  15.752024  15.927378 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.2032952  -1.2557731  -1.2872863  -1.3132548  -1.3417401  -1.393971
0:  -1.459228   -1.533176   -1.5620055  -1.5212674  -1.3779874  -1.204145
0:  -0.99319696 -0.74041605 -0.5298972  -0.33863592 -0.1904192  -0.04090166
0:  -0.03138494  0.02376604]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.532509  10.195961   9.589822   8.795801   8.0069     7.304935
0:   6.7690563  6.3365088  5.9769807  5.602783   5.173058   4.6736364
0:   4.139569   3.684269   3.2874966  3.0265155  2.8777318  2.7928486
0:   2.668278   2.433679 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.6110096 2.4944015 2.3380847 2.151147  1.9982653 1.8594422 1.7320819
0:  1.5918021 1.4833045 1.413219  1.44419   1.5543151 1.7442732 1.9983997
0:  2.2328262 2.475059  2.7133603 2.9580784 2.8190536 2.972846 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.4020925 5.516157  5.6341414 5.72567   5.7903705 5.8303947 5.8677506
0:  5.8767753 5.903722  5.918068  5.923001  5.925026  5.927679  5.9382024
0:  5.958156  5.9968166 6.0361724 6.123214  5.910796  5.9731236]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [64.900246 64.79143  64.53892  64.21203  63.737713 63.29557  62.848434
0:  62.217216 61.91121  61.24807  60.70891  59.876114 59.012615 58.38555
0:  57.782173 57.424206 57.075542 56.519863 56.794292 56.569862]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.586752 17.660135 17.793007 17.928429 18.061605 18.166695 18.340593
0:  18.413752 18.528313 18.679935 18.816422 18.96804  19.186016 19.401081
0:  19.647583 19.87428  20.076204 20.214897 20.266201 20.641556]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.711339  -5.727809  -5.7234592 -5.6945457 -5.6188593 -5.53629
0:  -5.4418087 -5.3921194 -5.3226185 -5.238987  -5.098798  -4.9539967
0:  -4.7818995 -4.5497494 -4.32261   -4.0697403 -3.8154945 -3.533372
0:  -3.5053425 -3.3030386]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.885088  -6.93995   -6.971881  -6.952896  -6.895817  -6.8562756
0:  -6.838608  -6.907836  -6.9818983 -7.0515966 -7.0949144 -7.1501226
0:  -7.1799564 -7.1863775 -7.2019978 -7.177867  -7.133665  -7.0251894
0:  -7.548584  -7.624386 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.3503942   3.145084    2.9988797   2.92945     2.9038024   2.8266
0:   2.7149515   2.4768968   2.1457276   1.7780361   1.3601642   0.9080243
0:   0.38701534 -0.1863718  -0.8634572  -1.6056056  -2.3863683  -3.0965257
0:  -2.636928   -2.92518   ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.39703  21.018631 21.75565  22.571297 23.413542 24.29171  25.190321
0:  25.965681 26.707129 27.28955  27.690046 27.814583 27.78973  27.545584
0:  27.142313 26.64577  26.18359  25.786886 24.966787 24.448967]
0: validation loss for strategy=forecast at epoch 16 : nan
0: validation loss for velocity_u : 0.034339334815740585
0: validation loss for velocity_v : 0.06695336848497391
0: validation loss for specific_humidity : 0.02616117335855961
0: validation loss for velocity_z : 0.5007418990135193
0: validation loss for temperature : 0.0748755931854248
0: validation loss for total_precip : nan
0: 17 : 10:54:45 :: batch_size = 96, lr = 1.3809311136779726e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 17, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.4718, -0.4614, -0.4507, -0.4397, -0.4283, -0.4167, -0.4048, -0.3927, -0.3805, -0.3683, -0.3560, -0.3439,
0:         -0.3319, -0.3199, -0.3082, -0.2965, -0.2852, -0.2741, -0.5745, -0.5667, -0.5588, -0.5505, -0.5418, -0.5329,
0:         -0.5234], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.9317, 0.9250, 0.9167, 0.9066, 0.8949, 0.8812, 0.8657, 0.8482, 0.8283, 0.8065, 0.7824, 0.7560, 0.7272, 0.6966,
0:         0.6642, 0.6304, 0.5950, 0.5591, 1.0024, 0.9966, 0.9895, 0.9806, 0.9700, 0.9575, 0.9429], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6422, -0.6417, -0.6413, -0.6409, -0.6407, -0.6404, -0.6401, -0.6398, -0.6396, -0.6394, -0.6393, -0.6391,
0:         -0.6389, -0.6386, -0.6384, -0.6382, -0.6383, -0.6385, -0.6407, -0.6404, -0.6400, -0.6395, -0.6391, -0.6385,
0:         -0.6381], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.0861, 0.0917, 0.0917, 0.0883, 0.0827, 0.0771, 0.0759, 0.0782, 0.0838, 0.0917, 0.0996, 0.1019, 0.0996, 0.0917,
0:         0.0816, 0.0703, 0.0635, 0.0624, 0.0658, 0.0726, 0.0759, 0.0748, 0.0703, 0.0647, 0.0590], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0.3700, -0.3822, -0.3931, -0.4032, -0.4127, -0.4207, -0.4286, -0.4355, -0.4421, -0.4479, -0.4532, -0.4576,
0:         -0.4618, -0.4652, -0.4679, -0.4701, -0.4711, -0.4714, -0.4707, -0.4687, -0.4656, -0.4610, -0.4559, -0.4499,
0:         -0.4430], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 17, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2193,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2367, -0.2367,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2402,     nan,     nan,     nan, -0.2402,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2402,     nan,     nan,     nan,     nan,     nan, -0.2414,
0:             nan, -0.2414,     nan,     nan,     nan, -0.2414,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2263,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2332,     nan, -0.2321,     nan,     nan,     nan, -0.2228,
0:             nan,     nan,     nan, -0.2367, -0.2367,     nan,     nan,     nan,     nan, -0.2391,     nan,     nan,
0:         -0.2391,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2402,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2402,     nan,     nan,
0:             nan, -0.2414,     nan, -0.2414,     nan,     nan, -0.2414,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2414,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2344,     nan, -0.2321,     nan, -0.2298, -0.2274,     nan,     nan,     nan,
0:         -0.2379, -0.2379,     nan,     nan,     nan,     nan, -0.2391,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2391,     nan,     nan,     nan, -0.2402,     nan,     nan, -0.2402,     nan,     nan,     nan,
0:             nan, -0.2414, -0.2414,     nan, -0.2414,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2414,     nan, -0.2414, -0.2414,     nan,     nan,     nan,     nan, -0.2414,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 17, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.8895, -0.8814, -0.8760, -0.8695, -0.8625, -0.8529, -0.8427, -0.8346, -0.8301, -0.8276, -0.8247, -0.8228,
0:         -0.8183, -0.8115, -0.8027, -0.7945, -0.7897, -0.7822, -0.9449, -0.9379, -0.9312, -0.9276, -0.9233, -0.9202,
0:         -0.9118], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.6799, 0.6726, 0.6613, 0.6496, 0.6336, 0.6243, 0.6139, 0.6039, 0.5941, 0.5835, 0.5688, 0.5528, 0.5281, 0.5017,
0:         0.4726, 0.4468, 0.4289, 0.4157, 0.7154, 0.7072, 0.6941, 0.6802, 0.6661, 0.6540, 0.6444], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.6359, -0.6360, -0.6369, -0.6356, -0.6365, -0.6360, -0.6364, -0.6359, -0.6365, -0.6367, -0.6348, -0.6343,
0:         -0.6338, -0.6329, -0.6333, -0.6333, -0.6348, -0.6359, -0.6302, -0.6306, -0.6311, -0.6304, -0.6304, -0.6298,
0:         -0.6291], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([ 0.0052,  0.0437,  0.0450,  0.0559,  0.0744,  0.0662,  0.0657,  0.0762,  0.0847,  0.0669,  0.0399,  0.0313,
0:          0.0175, -0.0029, -0.0153, -0.0264, -0.0200,  0.0148, -0.0059,  0.0416,  0.0451,  0.0484,  0.0442,  0.0198,
0:          0.0242], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([-0.7521, -0.7615, -0.7663, -0.7701, -0.7720, -0.7719, -0.7692, -0.7643, -0.7586, -0.7531, -0.7518, -0.7536,
0:         -0.7580, -0.7603, -0.7609, -0.7569, -0.7537, -0.7507, -0.7482, -0.7451, -0.7410, -0.7345, -0.7273, -0.7225,
0:         -0.7176], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.0638979822397232; velocity_v: 0.11035268008708954; specific_humidity: 0.03938892111182213; velocity_z: 0.5249762535095215; temperature: 0.13366803526878357; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06178345903754234; velocity_v: 0.11061929911375046; specific_humidity: 0.046752382069826126; velocity_z: 0.5711779594421387; temperature: 0.12817026674747467; total_precip: nan; 
0: epoch: 17 [1/5 (20%)]	Loss: nan : nan :: 0.14905 (2.66 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.048853907734155655; velocity_v: 0.085086889564991; specific_humidity: 0.03572230041027069; velocity_z: 0.4392288327217102; temperature: 0.0761311948299408; total_precip: nan; 
0: epoch: 17 [2/5 (40%)]	Loss: nan : nan :: 0.13582 (16.00 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05439721420407295; velocity_v: 0.10036059468984604; specific_humidity: 0.050033945590257645; velocity_z: 0.5557194352149963; temperature: 0.11580829322338104; total_precip: nan; 
0: epoch: 17 [3/5 (60%)]	Loss: nan : nan :: 0.14626 (16.15 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05048136040568352; velocity_v: 0.08825428038835526; specific_humidity: 0.03260146453976631; velocity_z: 0.4424048960208893; temperature: 0.07990375906229019; total_precip: nan; 
0: epoch: 17 [4/5 (80%)]	Loss: nan : nan :: 0.14009 (16.23 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [4.13894653e-04 7.24792480e-05 2.05516815e-04 2.31742859e-04
0:  1.08242035e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 7.15255737e-06
0:  4.76837158e-07 0.00000000e+00 0.00000000e+00 1.26361847e-04
0:  3.03268433e-04 6.98089600e-04 2.86102295e-06 4.76837158e-07
0:  0.00000000e+00 2.76565552e-05 4.33921850e-05 3.52859497e-05
0:  9.05990601e-06 4.76837158e-07 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  4.26292419e-04 2.37941742e-04 2.78472900e-04 4.57763672e-05
0:  1.14107132e-03 1.40476227e-03 1.00183487e-03 1.32799149e-03
0:  1.13439560e-03 1.57928467e-03 1.43623352e-03 1.11436844e-03
0:  5.70297241e-04 2.53677368e-04 2.52246857e-04 3.25679750e-04
0:  4.52995300e-04 4.53948975e-04 3.69071960e-04 4.62055206e-04
0:  1.57833099e-04 1.19209290e-04 7.43865967e-05 1.66893005e-05
0:  1.33514404e-05 1.33514404e-05 1.04904175e-05 1.28746033e-05
0:  1.33514404e-05 1.62124634e-05 1.43051147e-05 1.14440918e-05
0:  9.05990601e-06 5.96046448e-05 3.72886658e-04 2.00366951e-03
0:  1.65271759e-03 2.91824341e-03 2.07853317e-03 4.91523743e-03
0:  4.44936752e-03 3.70693207e-03 3.58581543e-03 3.39460373e-03
0:  2.67601013e-03 1.38616562e-03 1.61314011e-03 1.02710724e-03
0:  1.48296356e-03 1.59549713e-03 1.05619419e-03 5.82695007e-04
0:  1.75952911e-04 6.62803650e-05 2.57492065e-05 5.72204590e-06
0:  4.76837158e-06 3.33786011e-06 1.90734863e-06 7.62939453e-06
0:  2.76565552e-05 5.00679016e-05 7.86781311e-05 9.25064087e-05
0:  5.10215759e-05 2.71797180e-05 3.19480896e-05 4.95910645e-05
0:  5.76972961e-05 8.05854797e-05 1.38759613e-04 1.14917755e-04
0:  1.26361847e-04 1.38282776e-05 1.32083893e-04 2.29835510e-04
0:  1.63555145e-04 3.48091125e-05 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 5.96046448e-05
0:  1.52587891e-05 0.00000000e+00 0.00000000e+00 7.62939453e-05
0:  2.99453735e-04 9.53674316e-07 0.00000000e+00 4.76837158e-07
0:  0.00000000e+00 1.90734863e-06 3.33786011e-06 2.38418579e-06
0:  4.76837158e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.95639038e-05
0:  1.24502182e-03 7.94887543e-04 1.96456909e-04 1.52587891e-05
0:  1.35898590e-04 3.09467316e-04 6.61373138e-04 1.01947784e-03
0:  7.45296478e-04 1.56021118e-03 1.21879578e-03 1.01804733e-03
0:  4.70638275e-04 2.84671783e-04 3.09944153e-04 4.03881073e-04
0:  5.38825989e-04 5.64098358e-04 4.51564789e-04 2.99453735e-04
0:  1.99317932e-04 1.86443329e-04 8.96453857e-05 1.00135803e-05
0:  1.00135803e-05 1.38282776e-05 1.28746033e-05 1.19209290e-05
0:  8.58306885e-06 1.04904175e-05 5.72204590e-06 4.76837158e-06
0:  3.81469727e-06 3.64780426e-04 9.86576080e-04 7.78675079e-04
0:  1.14917755e-03 6.36577606e-04 2.89392471e-03 4.42504883e-03
0:  6.20508194e-03 6.11495972e-03 3.49187851e-03 1.60264969e-03
0:  3.40938568e-03 3.23534012e-03 1.95789337e-03 1.61266327e-03
0:  2.01606750e-03 2.01940536e-03 1.37996674e-03 6.78062439e-04
0:  2.66551971e-04 1.29699707e-04 6.29425049e-05 1.62124634e-05]
0: Target values (first 200):
0: [3.45706940e-03 9.69886780e-04 4.25338745e-04 1.22261047e-03
0:  6.70909882e-04 2.01225281e-04 8.10623169e-05 1.28269196e-04
0:  1.71661377e-04 2.49385834e-04 9.20295715e-05 4.42504883e-04
0:  1.80435181e-03 1.61695480e-03 1.27363205e-03 1.26934052e-03
0:  1.06620777e-03 4.38213348e-03 2.02655792e-04 1.82867039e-03
0:  1.50966644e-03 1.26791000e-03 8.08238983e-04 6.29425049e-05
0:  2.86102295e-06 4.76837158e-07 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 1.85966492e-05 1.05381012e-04 6.26087189e-04
0:  9.39369202e-04 8.22544098e-04 5.27858734e-04 3.98635864e-04
0:  1.25885010e-04 7.72476196e-05 1.53541565e-04 1.61647797e-04
0:  1.96456909e-04 2.46047974e-04 1.00851059e-03 1.91688538e-03
0:  1.97410583e-04 1.44004822e-04 6.01291656e-04 5.37204742e-03
0:  4.51326370e-03 2.67219543e-03 4.15992737e-03 4.90665436e-03
0:  2.78711319e-03 5.27906418e-03 2.32410431e-03 1.69754028e-03
0:  1.05237961e-03 3.86714935e-04 1.84059143e-04 3.91006470e-05
0:  1.86920166e-04 3.97205353e-04 1.66368484e-03 2.14576721e-05
0:  4.95910645e-05 2.14576721e-05 1.85966492e-05 2.62260437e-05
0:  3.43322754e-05 2.57492065e-05 1.38282776e-05 1.38282776e-05
0:  3.71932983e-05 1.71661377e-05 1.72615051e-04 1.33514404e-04
0:  6.48498535e-05 2.81333923e-05 2.86102295e-05 1.85966492e-05
0:  1.43051147e-05 6.67572021e-06 9.53674316e-06 1.43051147e-05
0:  2.00271606e-05 6.50405884e-04 8.74519348e-04 6.92367554e-04
0:  9.57489014e-04 4.41551208e-03 2.30550766e-03 3.67164612e-05
0:  2.67028809e-05 1.66893005e-05 2.33650208e-05 2.00271606e-05
0:  1.76429749e-05 2.47955322e-05 3.67164612e-05 1.57356262e-05
0:  1.09672546e-05 3.81469727e-06 9.53674316e-07 4.76837158e-07
0:  4.29153442e-06 1.66893005e-05 2.24113464e-05 9.05990601e-06
0:  3.61108803e-03 2.21252441e-04 1.53446198e-03 9.61303769e-04
0:  1.05619419e-03 9.44137573e-04 7.29560852e-05 1.54495239e-04
0:  1.12533569e-04 1.86920166e-04 3.68595123e-04 7.29560852e-05
0:  3.66830849e-03 2.46191025e-03 1.94406509e-03 2.88867950e-03
0:  1.08957291e-03 3.88574577e-03 1.43527985e-04 4.50849533e-03
0:  1.98268890e-03 1.90210342e-03 8.48293304e-04 7.48634338e-05
0:  3.52859497e-05 3.14712524e-05 4.76837158e-07 9.53674316e-07
0:  1.43051147e-06 2.86102295e-06 6.00814819e-05 2.20298767e-04
0:  4.20093536e-04 5.59806824e-04 6.70909882e-04 6.58988953e-04
0:  2.08854675e-04 1.00135803e-04 9.96589661e-05 1.16825104e-04
0:  1.60694122e-04 2.36034393e-04 2.72750854e-04 2.42233276e-04
0:  3.20434541e-04 3.52859497e-04 1.51062012e-03 6.42299652e-04
0:  3.06653976e-03 3.59773636e-03 4.81176376e-03 7.52305984e-03
0:  8.67605209e-03 6.90650940e-03 4.55379486e-03 4.14466858e-03
0:  2.41661072e-03 5.71250916e-04 6.86645508e-05 4.62532043e-05
0:  1.48296356e-04 4.91619110e-04 9.34600830e-05 2.62260437e-05
0:  3.71932983e-05 2.14576721e-05 1.76429749e-05 3.29017639e-05
0:  4.19616663e-05 4.00543213e-05 6.00814819e-05 1.19209290e-05
0:  7.29560852e-05 2.14576721e-05 3.95774841e-05 1.27315521e-04
0:  1.27315521e-04 6.91413879e-05 3.76701355e-05 3.86238098e-05
0:  2.71797180e-05 1.90734863e-06 8.10623169e-06 1.33514404e-05
0:  1.95503235e-05 1.52587891e-05 1.04904175e-05 2.57968903e-04
0:  1.54733658e-03 3.39984894e-03 7.85923097e-03 1.52349472e-03]
0: Prediction values (first 20):
0: [-6.594521  -6.5676255 -6.4311376 -6.268473  -6.106714  -5.994577
0:  -5.9243016 -5.950217  -5.9819026 -5.977592  -5.9045234 -5.753114
0:  -5.529226  -5.2271457 -4.9753995 -4.7037253 -4.4251914 -4.1713233
0:  -5.414248  -5.784703 ]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -1.812, max = 0.698, mean = -0.510
0:          sample (first 20): tensor([-1.1266, -1.1244, -1.1128, -1.0991, -1.0854, -1.0759, -1.0699, -1.0721, -1.0748, -1.0744, -1.0683, -1.0555,
0:         -1.0365, -1.0110, -0.9897, -0.9667, -0.9431, -0.9216, -1.1277, -1.1356])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.9862146   3.9970675   3.9821117   3.9530907   3.9381118   3.8805802
0:   3.8137715   3.7051938   3.5697658   3.4108698   3.2233646   2.9721522
0:   2.688455    2.3482432   1.938829    1.5514393   1.2127628   0.9838271
0:  -0.0607357  -0.08323669]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.9849586 -3.9704075 -3.9710598 -3.947379  -3.947092  -3.951727
0:  -3.9372168 -3.9467754 -3.9255562 -3.8914661 -3.8595629 -3.8131714
0:  -3.7370825 -3.637516  -3.5152273 -3.3931751 -3.2930298 -3.1814146
0:  -2.8122625 -2.6489925]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.467976  14.485188  14.563429  14.603966  14.659931  14.698996
0:  14.705666  14.664436  14.623461  14.579466  14.564934  14.484133
0:  14.39333   14.315605  14.1803875 14.0741005 13.980978  13.916481
0:  13.443167  13.233282 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.558592 21.831593 22.099104 22.32176  22.542696 22.779926 23.074305
0:  23.39033  23.746122 24.190191 24.65531  25.115847 25.59494  26.048723
0:  26.516903 27.029444 27.609781 28.221745 29.235872 29.88598 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.0254154 4.206276  4.4429502 4.7141294 4.982105  5.195098  5.374288
0:  5.4340506 5.4358664 5.348963  5.209956  5.016697  4.833804  4.6710835
0:  4.498724  4.364813  4.2606716 4.2111506 3.606402  3.7142441]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.9877615 13.217963  13.49601   13.721693  13.898481  14.016998
0:  14.106265  14.150816  14.210371  14.273258  14.338615  14.400543
0:  14.508125  14.662071  14.910121  15.215302  15.564985  15.920147
0:  16.201153  16.39399  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.687479  2.560529  2.4742534 2.400864  2.321561  2.2498107 2.2495844
0:  2.2115562 2.2076144 2.2063863 2.1730175 2.175789  2.2112277 2.2918622
0:  2.4428053 2.651593  2.8645792 3.048539  3.5877588 3.651605 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.071843  5.1009064 5.124509  5.1307316 5.13199   5.1030955 5.074125
0:  5.0257688 5.0027    4.9931507 4.993741  4.966627  4.9383526 4.9141846
0:  4.8816175 4.883884  4.8932333 4.936612  4.5181885 4.540924 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.6642103 2.9613447 3.3644052 3.7991889 4.1921434 4.5051527 4.788806
0:  5.007574  5.2240667 5.4614997 5.7106547 5.972802  6.2275496 6.456164
0:  6.62731   6.7621756 6.8376584 6.8853974 6.616916  6.739769 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.3715568 -7.421512  -7.4396024 -7.3987374 -7.283088  -7.1388135
0:  -6.9409614 -6.752712  -6.5439277 -6.3194337 -6.075029  -5.8450093
0:  -5.621902  -5.3886914 -5.201901  -5.0148244 -4.8353276 -4.6796536
0:  -4.9534554 -4.883285 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.321955  -5.487181  -5.6466985 -5.847199  -6.047067  -6.2902827
0:  -6.52177   -6.799093  -7.084372  -7.3574014 -7.6238885 -7.922253
0:  -8.228512  -8.500256  -8.788898  -8.992809  -9.123285  -9.15082
0:  -9.437233  -9.371548 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.227841  9.284734  9.317715  9.35012   9.3570175 9.323016  9.287374
0:  9.182942  9.08806   8.995609  8.880823  8.7868185 8.716951  8.63038
0:  8.550642  8.46778   8.391102  8.334865  7.9488125 7.9081063]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.4388785 -4.3298926 -4.218448  -4.091349  -3.947122  -3.8439689
0:  -3.7302833 -3.675075  -3.618215  -3.5527081 -3.467876  -3.3703694
0:  -3.2659135 -3.125856  -3.0154872 -2.868507  -2.694223  -2.489139
0:  -2.6371026 -2.512545 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.057331 13.002651 12.982796 12.943815 12.921137 12.894501 12.891432
0:  12.873793 12.892178 12.933369 12.965796 12.969621 12.94806  12.91454
0:  12.861776 12.821059 12.814546 12.800846 12.531469 12.391931]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.116994  2.2340207 2.353201  2.5197935 2.676055  2.8095894 2.9824338
0:  3.0783238 3.1554282 3.2003415 3.216026  3.253878  3.3836458 3.5727544
0:  3.857668  4.228286  4.5053844 4.78785   4.894905  5.0127506]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.8260214 3.0103028 3.1535234 3.2813845 3.3838747 3.4755201 3.5883844
0:  3.6596358 3.7469003 3.8408787 3.9218082 3.995738  4.087001  4.1730947
0:  4.258228  4.3532696 4.4481306 4.5650787 4.900626  5.1638584]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.14331   -5.2095275 -5.2622886 -5.2681108 -5.247685  -5.199166
0:  -5.0858617 -4.9775777 -4.8324914 -4.6812387 -4.5257697 -4.4094996
0:  -4.281424  -4.189813  -4.136767  -4.0933967 -4.0427594 -3.9381928
0:  -4.148668  -4.133161 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.510243 10.600798 10.73502  10.850807 10.985584 11.124478 11.25358
0:  11.358956 11.51133  11.657303 11.845816 12.003255 12.152768 12.305298
0:  12.437481 12.598712 12.792699 13.011357 13.31538  13.457638]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.7994866 3.7950056 3.8158004 3.8478196 3.890103  3.9281516 3.9668703
0:  3.9687533 3.9825861 4.02552   4.0909557 4.1705356 4.2639866 4.3165126
0:  4.374331  4.4343243 4.5015383 4.585785  4.552865  4.615177 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.291143   -4.0054     -3.6635108  -3.2492967  -2.7802777  -2.3290048
0:  -1.864039   -1.5089269  -1.2301011  -1.0339203  -0.90296793 -0.8738742
0:  -0.89270973 -0.9272046  -1.025846   -1.0774627  -1.0669913  -0.9820099
0:  -1.2706895  -1.2990155 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.6915836 6.5257597 6.3534913 6.1709337 5.9925    5.811564  5.6081533
0:  5.377024  5.1532683 4.9399757 4.7324095 4.5073833 4.2946763 4.087112
0:  3.8872318 3.714913  3.6007757 3.5419881 3.3367207 3.237973 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -3.4963899  -4.400253   -5.114739   -5.578735   -5.7998767  -5.9145045
0:   -6.036738   -6.257198   -6.6151595  -7.06276    -7.5690503  -8.191431
0:   -8.74353    -9.062128   -9.280573   -9.2129135  -9.04496    -8.900574
0:  -10.01408   -10.732401 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [30.115307 30.10186  30.179222 30.312489 30.445614 30.50462  30.529598
0:  30.478386 30.439411 30.40813  30.350567 30.283588 30.292934 30.334496
0:  30.39124  30.398891 30.386555 30.352745 29.797527 29.817013]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.461239  7.2058153 6.959692  6.7040997 6.4221725 6.111737  5.82211
0:  5.5345306 5.340306  5.2279024 5.189349  5.2004776 5.2468824 5.323126
0:  5.4028926 5.4899726 5.5620556 5.633777  5.799954  5.8728123]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.6002073e-01 -2.0872068e-01 -1.4585066e-01 -6.3979626e-02
0:   7.9884529e-03  3.7544250e-02  6.0438633e-02 -1.4920235e-03
0:  -7.6155186e-02 -1.9178057e-01 -3.5470915e-01 -5.8734894e-01
0:  -8.2321739e-01 -1.0567265e+00 -1.2982626e+00 -1.4756231e+00
0:  -1.6007824e+00 -1.6999264e+00 -2.2799778e+00 -2.3071928e+00]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.0851107 5.6010404 5.139828  4.737744  4.448491  4.316597  4.426911
0:  4.66359   5.087769  5.605201  6.1478324 6.63844   7.147565  7.5128016
0:  7.798108  7.9896865 8.067833  8.101799  8.328589  8.508539 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.94781  29.677017 29.351883 29.010881 28.671036 28.377872 28.199448
0:  28.014624 27.925228 27.855583 27.686953 27.46045  27.196976 26.864418
0:  26.49539  26.090752 25.660955 25.217558 24.618635 24.098839]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.2800994  -3.5916572  -3.8226323  -3.9194283  -3.8767943  -3.7599435
0:  -3.5833716  -3.456572   -3.358646   -3.2702136  -3.1352096  -2.9677043
0:  -2.7021317  -2.3239455  -1.9082808  -1.4176264  -0.8771944  -0.30771542
0:   0.5528207   1.3307266 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.033071  1.98982   2.085073  2.283483  2.59202   2.9222293 3.2538576
0:  3.4430356 3.5319815 3.5211763 3.4105754 3.1909752 2.9459329 2.6838508
0:  2.3768544 2.1448169 1.9610701 1.8399277 1.3701043 1.2084684]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.750862  -10.722855  -10.735037  -10.7756    -10.782682  -10.788006
0:  -10.685455  -10.563948  -10.352322  -10.049612   -9.669361   -9.273264
0:   -8.893976   -8.517397   -8.248449   -8.005846   -7.8018365  -7.6193757
0:   -7.7941375  -7.702954 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.3530316 -4.2365813 -4.1609063 -4.1301475 -4.103995  -4.1550965
0:  -4.192353  -4.297052  -4.3509927 -4.335961  -4.2366614 -4.115667
0:  -3.9892888 -3.8255715 -3.7365127 -3.6306968 -3.503323  -3.365106
0:  -3.4993644 -3.4232497]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.1304812 -2.103849  -2.0626235 -1.9968123 -1.916678  -1.8852324
0:  -1.8045812 -1.8158984 -1.7916093 -1.7740808 -1.7453074 -1.7294497
0:  -1.6774144 -1.6255174 -1.5706048 -1.4939971 -1.4412847 -1.4036803
0:  -1.6633134 -1.4584775]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.8435378 2.8755064 2.9479551 3.040258  3.1060605 3.1473637 3.1820745
0:  3.1659946 3.159429  3.1263661 3.0605998 2.9618554 2.8642259 2.7542558
0:  2.6808019 2.6424632 2.666038  2.7824736 3.2365289 3.4281282]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.8515296  -1.6669879  -1.4965239  -1.3292656  -1.2176771  -1.132534
0:  -1.0500407  -1.0146127  -0.9544544  -0.87998533 -0.80551004 -0.73138046
0:  -0.6212878  -0.52479315 -0.4139104  -0.30792713 -0.21244049 -0.10094929
0:   0.1963911   0.45630646]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.168673  -7.0038104 -6.9545474 -7.0390496 -7.16248   -7.2783284
0:  -7.258124  -7.288716  -7.2988305 -7.393558  -7.5856566 -7.8384204
0:  -8.056843  -8.086401  -8.033466  -7.8624625 -7.7865586 -7.7639318
0:  -7.0395207 -6.903251 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.5750794 -7.519503  -7.4586196 -7.422996  -7.440315  -7.512154
0:  -7.60374   -7.726931  -7.836476  -7.9497705 -8.05846   -8.194847
0:  -8.281681  -8.371386  -8.47714   -8.577328  -8.682653  -8.692146
0:  -8.842953  -8.823957 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.0754962  -2.0350308  -1.9768062  -1.9391398  -1.9431739  -2.0360055
0:  -2.148542   -2.299438   -2.430264   -2.4884477  -2.5015273  -2.4703012
0:  -2.4185357  -2.3036113  -2.1641374  -1.9131398  -1.6015296  -1.2557449
0:  -0.2601924   0.17186737]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.266157 16.384556 16.480385 16.542562 16.619432 16.713566 16.878422
0:  17.10279  17.43488  17.879433 18.384073 18.891567 19.395378 19.855778
0:  20.247969 20.567013 20.898846 21.22664  21.374744 21.729427]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.8353696  7.8077116  7.8505583  7.9411783  8.091411   8.318527
0:   8.551779   8.790881   9.049768   9.315085   9.636141   9.962564
0:  10.324083  10.704948  11.07515   11.416723  11.7065525 11.968421
0:  12.718845  12.97598  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.618849 17.495544 17.360157 17.235558 17.134865 17.105522 17.179686
0:  17.24138  17.365074 17.569813 17.806147 18.11781  18.500172 18.879265
0:  19.283567 19.600199 19.875195 20.116932 20.062912 20.250788]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.861588   8.171615   8.489427   8.846622   9.377987   9.955124
0:  10.324423  10.349194   9.924643   9.286378   8.691976   8.410591
0:   8.551101   8.930555   9.358801   9.606618   9.567115   9.309132
0:   7.499414   6.7346387]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.287722  11.239379  11.198341  11.138329  11.029364  10.859221
0:  10.646819  10.342611  10.013757   9.621158   9.206045   8.775618
0:   8.377143   8.005277   7.678688   7.4089513  7.1548114  6.9272604
0:   6.6080356  6.564714 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 6.452312   7.097045   7.9086304  8.8566885  9.828515  10.732609
0:  11.561398  12.161629  12.57243   12.673981  12.5255785 12.138838
0:  11.643753  11.035383  10.350691   9.616156   8.863506   8.194117
0:   6.5774593  6.308106 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.1580286 1.0334549 0.8974891 0.7598753 0.6897192 0.7195959 0.8764744
0:  1.1084237 1.3645453 1.5797062 1.7008848 1.6467633 1.4886589 1.2956262
0:  1.102016  1.0191655 1.0546107 1.1296353 1.5997152 1.6884751]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.21472883 0.20483589 0.20574713 0.26045036 0.37361002 0.48229027
0:  0.6181221  0.70469666 0.8003421  0.88503027 0.97227144 0.9975643
0:  0.9972725  1.0070128  0.96655655 0.95725393 0.99384737 1.0569353
0:  0.48834372 0.45698786]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.085861 17.209562 17.351969 17.468615 17.573326 17.686495 17.808805
0:  17.881636 17.964306 18.005676 17.977123 17.920694 17.859728 17.811533
0:  17.783901 17.781218 17.8366   17.920332 17.971163 17.98711 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 5.024987    4.759576    4.5604362   4.354622    4.1557918   3.947996
0:   3.7662761   3.5687149   3.3847263   3.1933744   2.9868526   2.7082396
0:   2.4208758   2.1277418   1.7563839   1.3761449   0.95959187  0.55797577
0:  -0.34943247 -0.4882655 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [36.686546 36.050713 35.426025 34.81699  34.24043  33.615658 33.032112
0:  32.387997 31.824993 31.190596 30.417845 29.564682 28.622406 27.684973
0:  26.705898 25.77997  24.905455 24.016964 23.620234 22.914804]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-34.151676 -34.37852  -34.583008 -34.730038 -34.91045  -35.109203
0:  -35.29499  -35.55182  -35.83676  -36.07543  -36.316555 -36.510674
0:  -36.569546 -36.61585  -36.545    -36.488823 -36.382423 -36.24038
0:  -37.291237 -37.51911 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.753561 16.844854 16.886652 16.858273 16.78293  16.685244 16.60529
0:  16.50192  16.393564 16.260761 16.087917 15.883984 15.702454 15.546682
0:  15.423523 15.314644 15.178276 14.975379 14.188444 14.169819]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.305741  -4.261869  -4.230882  -4.2264285 -4.2437644 -4.316753
0:  -4.4093757 -4.552977  -4.7078595 -4.8581796 -5.013903  -5.1720366
0:  -5.305367  -5.407623  -5.5038333 -5.5527225 -5.5896907 -5.598866
0:  -5.7966924 -5.797546 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.6179585 2.8474612 3.1459835 3.4961908 3.8976052 4.283521  4.706381
0:  5.0755377 5.4460745 5.802839  6.1346335 6.4124775 6.6548777 6.8801894
0:  7.0752645 7.2763557 7.483719  7.6686764 7.53214   7.596508 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-11.318937 -11.208466 -11.185448 -11.208042 -11.256878 -11.354824
0:  -11.414761 -11.53413  -11.68889  -11.825363 -11.940378 -12.043465
0:  -12.108389 -12.136402 -12.157537 -12.129662 -12.072424 -11.927023
0:  -12.149765 -12.004259]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-11.263056  -11.027618  -10.713505  -10.322222   -9.875978   -9.444292
0:   -9.028402   -8.696409   -8.434465   -8.234554   -8.075008   -7.972258
0:   -7.8508477  -7.7135034  -7.557737   -7.367862   -7.1443906  -6.8848195
0:   -6.9154716  -6.621363 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.7607265  -1.7533889  -1.584414   -1.3121557  -0.9971938  -0.7090349
0:  -0.50096226 -0.4162593  -0.3915019  -0.43802118 -0.49020386 -0.5199075
0:  -0.44372272 -0.27202988  0.03844023  0.4934864   1.0596776   1.6883082
0:   2.5881066   3.1134272 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [32.21579  31.929089 31.529184 30.93592  30.375893 29.77749  29.163847
0:  28.461662 27.77777  27.07464  26.279894 25.57971  24.940947 24.360218
0:  23.925453 23.526686 23.232388 22.950779 21.758156 21.73465 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.2019615 10.224085  10.314045  10.440968  10.574855  10.70215
0:  10.845315  10.937286  11.039656  11.150809  11.237183  11.335664
0:  11.439501  11.550531  11.67102   11.78923   11.919537  12.088078
0:  12.32872   12.444492 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.370909  15.2087345 15.083475  14.922876  14.740131  14.52981
0:  14.303111  14.0166235 13.752813  13.506899  13.257013  13.04985
0:  12.950968  12.931179  13.026039  13.176596  13.404567  13.675359
0:  13.653894  13.798353 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.071724  12.8879795 12.756638  12.552031  12.385692  12.247955
0:  12.084772  11.909441  11.833006  11.718528  11.6160755 11.407785
0:  11.218679  10.937761  10.638471  10.304474  10.0319605  9.857101
0:   9.615194   9.828447 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.291154   -9.950519   -9.509526   -8.961483   -8.390067   -7.851923
0:   -7.3363934  -6.9535627  -6.608733   -6.3523846  -6.1855507  -6.0052414
0:   -5.699233   -5.3061     -4.837783   -4.457862   -4.2068663  -4.115327
0:   -4.540329   -4.1008587]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.66564083 -0.2847824   0.16968584  0.64380693  1.1420312   1.5987353
0:   2.0542889   2.4255738   2.7622962   3.045307    3.298435    3.491173
0:   3.651028    3.7763994   3.8190682   3.859289    3.8917394   3.9612644
0:   3.810946    4.0977993 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -9.217742   -9.334176   -9.459418   -9.572579   -9.715137   -9.94131
0:  -10.140304  -10.449624  -10.7442255 -11.058375  -11.368262  -11.674396
0:  -11.968598  -12.21252   -12.460929  -12.717484  -12.958198  -13.169824
0:  -13.806449  -14.006661 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.3616166 -1.2004857 -2.141107  -3.0534234 -3.7880626 -4.2987514
0:  -4.543822  -4.6359086 -4.650001  -4.646458  -4.6536307 -4.705031
0:  -4.724087  -4.628613  -4.49213   -4.285048  -4.0939775 -3.9829907
0:  -4.118632  -4.3471465]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.200773  10.225203  10.42003   10.686758  10.914444  10.91135
0:  10.631849  10.058838   9.265882   8.365706   7.419099   6.420808
0:   5.4162498  4.4771843  3.6054046  2.973784   2.6198978  2.515283
0:   2.3868012  2.5894198]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.477434 25.096167 24.708511 24.290932 23.853827 23.40846  23.019348
0:  22.5902   22.24058  21.95769  21.65255  21.349554 21.097605 20.902466
0:  20.769962 20.688648 20.690811 20.759708 21.37982  21.399883]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.5580869  -0.45867252 -0.350039   -0.29911995 -0.18371296  0.00264692
0:   0.3054738   0.6096015   0.9361882   1.170207    1.3661189   1.4196849
0:   1.3941522   1.2857141   0.99027014  0.61013937  0.18165112 -0.1745162
0:  -0.24161196 -0.34922552]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.645319  9.9348   10.204355 10.455029 10.692652 10.964307 11.240554
0:  11.515725 11.774721 11.980847 12.140942 12.188794 12.285086 12.445396
0:  12.662494 12.904406 13.208536 13.539614 13.774233 13.755053]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.21331   15.069899  14.957855  14.87302   14.774823  14.6566305
0:  14.542534  14.321434  14.027372  13.62503   13.079494  12.447712
0:  11.829107  11.224474  10.664197  10.139251   9.645897   9.243396
0:   8.747487   8.332831 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.46444  17.444689 17.383286 17.226185 16.957342 16.608145 16.293947
0:  15.909321 15.565561 15.198044 14.775867 14.31938  13.90423  13.531519
0:  13.200195 12.852326 12.421969 11.907087 11.727869 11.28718 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.030494  -7.160357  -7.243174  -7.2649713 -7.231583  -7.2124352
0:  -7.177525  -7.1926646 -7.1867127 -7.1648602 -7.0818963 -6.993425
0:  -6.8821664 -6.732385  -6.6196065 -6.50184   -6.4263444 -6.339624
0:  -6.6875014 -6.6855397]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.99522  22.82039  22.69253  22.50652  22.23019  21.835072 21.386684
0:  20.818172 20.250885 19.683205 19.071726 18.514526 18.09303  17.768816
0:  17.63978  17.592783 17.639845 17.751305 18.522472 18.630276]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.702864   9.6892805  9.712841   9.750298   9.768295   9.759897
0:   9.756225   9.699849   9.668674   9.659221   9.647957   9.642473
0:   9.655544   9.661272   9.676968   9.701723   9.781329   9.93503
0:  10.444662  10.746647 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 6.474711    6.666063    6.9650297   7.1862235   7.2890835   7.197595
0:   6.9456363   6.535655    6.037434    5.520721    4.993057    4.444305
0:   3.922964    3.406305    2.863253    2.3726306   1.8940048   1.479681
0:   0.4719653  -0.11819077]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.1360025  -2.9583492  -2.7388601  -2.501689   -2.2660294  -2.0492363
0:  -1.7995844  -1.5671725  -1.3144722  -1.0550556  -0.7810979  -0.50725317
0:  -0.19913626  0.10759163  0.44911623  0.783257    1.0720077   1.3410616
0:   0.8573756   1.047164  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.316399  8.55476   8.843597  9.194165  9.65044  10.10178  10.608146
0:  11.026203 11.464858 11.870333 12.260302 12.57338  12.81503  12.96162
0:  12.985773 12.910812 12.866884 12.816977 11.750667 11.289747]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.018236 18.12791  18.300121 18.448172 18.572372 18.675669 18.75607
0:  18.811415 18.892372 19.008549 19.15266  19.247307 19.336544 19.402355
0:  19.443974 19.48853  19.540459 19.618744 19.463844 19.554476]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.253113  7.247963  7.396408  7.674605  7.9905615 8.307311  8.60116
0:  8.827333  9.003865  9.129029  9.167595  9.137716  9.041758  8.869812
0:  8.66964   8.446528  8.256192  8.123097  7.8134775 7.8746266]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.040907 16.182808 16.363844 16.521984 16.68592  16.827759 16.973408
0:  17.10419  17.222042 17.324629 17.383635 17.359095 17.266296 17.126648
0:  16.941822 16.76334  16.604753 16.45673  16.020222 15.805467]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.436943  10.206917  10.017486   9.86374    9.695519   9.50137
0:   9.285711   8.958953   8.620848   8.247906   7.818671   7.3506594
0:   6.9017158  6.4927936  6.107798   5.7842855  5.525769   5.3256226
0:   5.194347   4.8775835]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.16816  17.511984 17.828344 18.159185 18.486908 18.817133 19.180187
0:  19.455318 19.811615 20.184248 20.537613 20.91293  21.33912  21.785408
0:  22.2722   22.750963 23.259907 23.766949 24.108711 24.841959]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.198238 24.16875  24.185791 24.231682 24.273506 24.279179 24.275383
0:  24.13895  24.055561 23.977741 23.913311 23.892056 23.96577  24.118057
0:  24.351418 24.632767 24.923431 25.194351 25.881004 26.181698]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.358197  13.561022  13.806956  14.0212345 14.242158  14.445038
0:  14.665256  14.851232  15.000355  15.124527  15.215993  15.287165
0:  15.373219  15.407769  15.406623  15.400344  15.395606  15.388227
0:  14.358197  14.735153 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.856856  6.9834957 7.1569343 7.320601  7.499611  7.6827545 7.8729157
0:  8.022734  8.14796   8.215813  8.204435  8.072038  7.883774  7.6378417
0:  7.350836  7.049234  6.757409  6.5253224 5.1428494 4.936532 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.16309881 0.16259718 0.18823767 0.24446201 0.32742977 0.40234137
0:  0.4701228  0.48953533 0.5024152  0.4922514  0.4779148  0.44986963
0:  0.43613815 0.43028593 0.40476513 0.38497543 0.39023685 0.41203022
0:  0.1598916  0.16222858]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.6222167  -0.45535088 -0.22913027 -0.00589943  0.19195127  0.28102255
0:   0.22046614 -0.04467201 -0.43749762 -0.92804    -1.4241424  -1.8773522
0:  -2.2106624  -2.3569474  -2.374333   -2.242763   -2.0225663  -1.7869496
0:  -1.5551782  -1.5078754 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.447571  4.3752646 4.3752933 4.394555  4.450451  4.4822993 4.4909487
0:  4.4109764 4.3449793 4.292085  4.28648   4.240835  4.299143  4.3905697
0:  4.468814  4.5795364 4.6688347 4.764906  4.124174  4.2070427]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.231213 29.32663  29.389347 29.378998 29.33183  29.303082 29.308712
0:  29.342705 29.452976 29.617966 29.794228 29.985703 30.190414 30.38338
0:  30.517933 30.568836 30.556103 30.437195 30.16888  30.006237]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.461728  11.475343  11.432892  11.223585  10.94803   10.630606
0:  10.3095875 10.041069   9.8599205  9.787621   9.807634   9.855459
0:   9.9165     9.97741    9.927356   9.805862   9.581318   9.293385
0:   9.005068   9.057142 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.5896254 -5.3337574 -5.1998205 -5.2087364 -5.277235  -5.3563986
0:  -5.3320255 -5.2279987 -4.990937  -4.7140827 -4.3909492 -4.1370935
0:  -3.9603539 -3.832923  -3.9139442 -4.1260033 -4.4742365 -4.891979
0:  -7.108136  -7.7739363]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.134797  7.5396338 6.878292  6.15736   5.441082  4.8001595 4.260727
0:  3.825925  3.5125935 3.2689726 3.1572762 3.085062  3.0739834 3.1675239
0:  3.257885  3.3117766 3.288563  3.2048616 2.9819562 2.6497917]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.066725   9.263694   9.490236   9.655243   9.815984   9.998959
0:  10.178239  10.39587   10.611804  10.815596  10.966315  11.023638
0:  11.021305  10.947304  10.79147   10.5551405 10.248795   9.843414
0:   7.937708   7.55562  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.156703 10.188831 10.339945 10.560522 10.882853 11.256037 11.717969
0:  12.192167 12.702929 13.174496 13.527909 13.656765 13.601185 13.405819
0:  13.137338 12.918657 12.784763 12.748438 12.707298 13.018062]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.814888 25.619198 25.556828 25.561016 25.610046 25.673847 25.79187
0:  25.850903 25.968372 26.108505 26.174335 26.219666 26.265816 26.299366
0:  26.354782 26.40446  26.478191 26.609562 27.042892 27.095394]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.150713 20.202143 20.275305 20.276747 20.2175   20.067001 19.84001
0:  19.505917 19.179274 18.793064 18.36895  17.859768 17.303984 16.74099
0:  16.157253 15.637024 15.211891 14.819727 14.395088 13.972905]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.16995  32.886475 32.71041  32.66513  32.721874 32.843643 33.100765
0:  33.33868  33.75598  34.256573 34.700214 35.12622  35.504295 35.82369
0:  36.095707 36.28189  36.379128 36.29306  35.840958 35.865555]
0: validation loss for strategy=forecast at epoch 17 : nan
0: validation loss for velocity_u : 0.03294210880994797
0: validation loss for velocity_v : 0.061791181564331055
0: validation loss for specific_humidity : 0.025823116302490234
0: validation loss for velocity_z : 0.5622778534889221
0: validation loss for temperature : 0.07893809676170349
0: validation loss for total_precip : nan
0: 18 : 10:58:46 :: batch_size = 96, lr = 1.3472498670029002e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 18, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.9615, -0.9613, -0.9598, -0.9646, -0.9803, -0.9804, -0.9688, -0.9806, -1.0141, -1.0437, -1.0457, -1.0216,
0:         -0.9957, -1.0014, -1.0384, -1.0739, -1.1039, -1.1237, -0.9352, -0.9660, -0.9871, -1.0145, -1.0491, -1.0510,
0:         -1.0297], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.2510,  0.2450,  0.2679,  0.3263,  0.4065,  0.4794,  0.5153,  0.5219,  0.5228,  0.5017,  0.4230,  0.2850,
0:          0.1421, -0.0128, -0.1931, -0.3047, -0.3216, -0.2896,  0.2565,  0.2571,  0.2840,  0.3336,  0.3966,  0.4583,
0:          0.4924], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([2.3746, 2.4243, 2.4633, 2.5156, 2.5894, 2.6954, 2.8251, 2.9292, 2.9750, 2.9839, 3.1833, 3.3148, 3.5076, 3.5393,
0:         3.4336, 3.1713, 2.8165, 2.4507, 2.3573, 2.4796, 2.5210, 2.5127, 2.5829, 2.7433, 2.8911], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0587, -0.1813, -0.2780, -0.5060, -0.2565,  0.1025,  0.0789,  0.2445,  0.4573,  0.6831,  0.5326,  0.4767,
0:          0.5261,  0.5154,  0.5885,  0.3520,  0.1993,  0.0531,  0.4143,  0.2939,  0.1477,  0.0617,  0.3778,  0.5003,
0:          0.4702], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([ 1.1094,  1.2293,  1.3558,  1.5812,  1.8693,  2.1777,  2.3445,  2.3815,  2.3339,  2.1187,  1.7390,  1.2773,
0:          1.0328,  0.6621,  0.0550, -0.1453,  0.0072,  0.2237,  0.4733,  0.6854,  0.7497,  0.7320,  0.7405,  0.8380,
0:          1.0373], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 18, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  1.9444,
0:             nan,     nan,     nan,     nan,  0.3564,     nan,  0.5688,     nan,     nan,  3.2103,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,  1.2264,     nan,     nan,     nan, -0.0172,     nan,     nan,
0:             nan,     nan,     nan,  0.9692,     nan,     nan,  0.0410,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,  1.0274,     nan,     nan,     nan,  3.1410,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,  3.1321,     nan,     nan,     nan,     nan,     nan,
0:          0.7232,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,  1.7610,     nan,     nan, -0.2140,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:          0.8551,     nan,  0.7165,  2.7473,     nan,     nan,     nan,     nan,  0.0745,  1.0766,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.1849,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,  2.0406,  1.6693,     nan,     nan,     nan,     nan, -0.0798,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.1939, -0.0798,     nan,     nan,     nan,  3.0985,
0:             nan,     nan,     nan,     nan,     nan,  2.7921,     nan,  1.6939,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,  2.0540,     nan,     nan,     nan,     nan,     nan,  0.4660,     nan,
0:             nan,     nan,     nan,     nan,     nan,  1.3047,     nan,     nan,  0.7433,     nan,  2.3000,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 18, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-1.2935, -1.3020, -1.3018, -1.2956, -1.2892, -1.2884, -1.2871, -1.2944, -1.2977, -1.3038, -1.3087, -1.3155,
0:         -1.3226, -1.3217, -1.3234, -1.3192, -1.3078, -1.2986, -1.2516, -1.2729, -1.2883, -1.2955, -1.2980, -1.2980,
0:         -1.2921], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.3669, -0.3716, -0.3863, -0.4000, -0.4075, -0.3938, -0.3618, -0.3231, -0.2839, -0.2532, -0.2268, -0.2091,
0:         -0.1992, -0.1960, -0.1990, -0.2047, -0.2042, -0.1941, -0.4225, -0.4134, -0.4117, -0.4148, -0.4124, -0.4013,
0:         -0.3813], device='cuda:1', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([3.0901, 3.1501, 3.1613, 3.1147, 3.0642, 3.0067, 2.9884, 2.9879, 3.0234, 3.0707, 3.1171, 3.1234, 3.0919, 3.0185,
0:         2.9113, 2.8146, 2.7541, 2.7398, 2.9315, 3.0392, 3.0969, 3.0982, 3.0860, 3.0655, 3.0598], device='cuda:2',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.2222, -0.1399, -0.1198, -0.2766, -0.2909, -0.3964, -0.3294,  0.1764,  0.3130,  0.1273,  0.1695,  0.2346,
0:          0.0781, -0.2287, -0.4576, -0.6177, -0.5936, -0.1802,  0.0348,  0.1574,  0.2244,  0.0705, -0.0378, -0.4192,
0:         -0.5753], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([ 0.2482,  0.2174,  0.1938,  0.1722,  0.1494,  0.1073,  0.0298, -0.0853, -0.1997, -0.2488, -0.1793,  0.0073,
0:          0.2640,  0.5088,  0.6782,  0.7584,  0.7648,  0.7387,  0.7096,  0.6890,  0.6860,  0.6932,  0.7019,  0.6973,
0:          0.6658], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.052759017795324326; velocity_v: 0.08494170755147934; specific_humidity: 0.04153134301304817; velocity_z: 0.5512980222702026; temperature: 0.10973580926656723; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05525277182459831; velocity_v: 0.10017702728509903; specific_humidity: 0.03593366593122482; velocity_z: 0.5704357624053955; temperature: 0.09177068620920181; total_precip: nan; 
0: epoch: 18 [1/5 (20%)]	Loss: nan : nan :: 0.14346 (3.02 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.05605250224471092; velocity_v: 0.08512011170387268; specific_humidity: 0.03869714215397835; velocity_z: 0.5041807889938354; temperature: 0.09961441159248352; total_precip: nan; 
0: epoch: 18 [2/5 (40%)]	Loss: nan : nan :: 0.13801 (16.04 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.058352310210466385; velocity_v: 0.09457555413246155; specific_humidity: 0.038464922457933426; velocity_z: 0.5149126052856445; temperature: 0.10223313421010971; total_precip: nan; 
0: epoch: 18 [3/5 (60%)]	Loss: nan : nan :: 0.14200 (16.17 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06214391812682152; velocity_v: 0.10026656836271286; specific_humidity: 0.04380405694246292; velocity_z: 0.5845488905906677; temperature: 0.12207259237766266; total_precip: nan; 
0: epoch: 18 [4/5 (80%)]	Loss: nan : nan :: 0.14322 (16.19 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [2.13146210e-04 2.28881836e-04 2.41279602e-04 2.55584717e-04
0:  2.73704529e-04 2.91824341e-04 3.08990479e-04 3.20434541e-04
0:  3.28063965e-04 3.36170197e-04 3.45230103e-04 3.41892242e-04
0:  3.28540802e-04 3.15189362e-04 3.06606264e-04 2.88009644e-04
0:  2.62737274e-04 2.37464905e-04 2.20775604e-04 2.05039978e-04
0:  1.88350677e-04 1.72138214e-04 1.59263611e-04 1.46865845e-04
0:  1.34468079e-04 1.21593475e-04 1.08718872e-04 1.00135803e-04
0:  9.29832458e-05 8.58306885e-05 7.62939453e-05 7.15255737e-05
0:  6.72340393e-05 6.29425049e-05 6.15119934e-05 5.96046448e-05
0:  5.76972961e-05 5.53131104e-05 5.48362732e-05 5.24520874e-05
0:  4.95910645e-05 4.67300415e-05 4.38690186e-05 4.10079956e-05
0:  3.86238062e-05 3.57627869e-05 3.33786011e-05 3.05175781e-05
0:  2.81333923e-05 2.57492065e-05 2.33650208e-05 2.19345093e-05
0:  2.00271606e-05 1.81198120e-05 1.57356262e-05 1.47819519e-05
0:  1.33514404e-05 1.23977661e-05 1.09672546e-05 1.04904175e-05
0:  9.53674316e-06 8.58306885e-06 7.62939453e-06 7.15255737e-06
0:  6.67572021e-06 6.19888306e-06 5.72204590e-06 5.24520874e-06
0:  4.76837158e-06 4.29153442e-06 3.81469727e-06 3.81469727e-06
0:  3.33786011e-06 3.33786011e-06 2.86102295e-06 2.86102295e-06
0:  2.38418579e-06 2.38418579e-06 1.90734863e-06 1.90734863e-06
0:  1.43051147e-06 1.43051147e-06 9.53674316e-07 9.53674316e-07
0:  9.53674316e-07 9.53674316e-07 9.53674316e-07 4.76837158e-07
0:  4.76837158e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  2.77996063e-04 3.00407410e-04 3.22818756e-04 3.35693359e-04
0:  3.48567963e-04 3.64780426e-04 3.82900238e-04 3.90052795e-04
0:  3.91006470e-04 3.80039215e-04 3.69071960e-04 3.46660614e-04
0:  3.24726105e-04 3.08513641e-04 2.95162201e-04 2.70366669e-04
0:  2.45094299e-04 2.18391418e-04 1.92165375e-04 1.78813934e-04
0:  1.65939331e-04 1.50680542e-04 1.34468079e-04 1.22070312e-04
0:  1.13010406e-04 1.10149384e-04 1.07288361e-04 1.06811523e-04
0:  1.06334686e-04 1.01566315e-04 9.48905945e-05 9.05990601e-05
0:  8.63075256e-05 8.10623169e-05 7.62939453e-05 7.15255737e-05
0:  6.72340393e-05 6.38961792e-05 6.19888306e-05 5.91278076e-05
0:  5.57899475e-05 5.24520874e-05 4.86373901e-05 4.57763672e-05
0:  4.24385071e-05 3.95774841e-05 3.71932983e-05 3.48091125e-05
0:  3.24249268e-05 2.95639038e-05 2.67028809e-05 2.43186951e-05
0:  2.19345093e-05 2.00271606e-05 1.81198120e-05 1.66893005e-05
0:  1.52587891e-05 1.38282776e-05 1.19209290e-05 1.09672546e-05
0:  9.53674316e-06 8.58306885e-06 7.62939453e-06 7.15255737e-06
0:  6.67572021e-06 6.19888306e-06 5.72204590e-06 5.24520874e-06
0:  5.24520874e-06 4.76837158e-06 4.29153442e-06 4.29153442e-06
0:  3.81469727e-06 3.33786011e-06 2.86102295e-06 2.38418579e-06
0:  2.38418579e-06 1.90734863e-06 1.90734863e-06 1.90734863e-06
0:  1.43051147e-06 1.43051147e-06 9.53674316e-07 9.53674316e-07
0:  9.53674316e-07 9.53674316e-07 9.53674316e-07 9.53674316e-07
0:  4.76837158e-07 4.76837158e-07 0.00000000e+00 0.00000000e+00]
0: Target values (first 200):
0: [2.91347504e-04 2.86579132e-04 2.75611877e-04 2.63690948e-04
0:  2.53677368e-04 2.43663788e-04 2.31742859e-04 2.17914581e-04
0:  2.03609467e-04 1.89781189e-04 1.80721283e-04 1.68800354e-04
0:  1.54018402e-04 1.39713287e-04 1.33991241e-04 1.22547150e-04
0:  1.05381012e-04 8.86917114e-05 8.20159912e-05 7.24792480e-05
0:  6.00814819e-05 4.76837158e-05 4.19616663e-05 3.76701355e-05
0:  3.24249268e-05 2.76565552e-05 3.05175781e-05 3.14712524e-05
0:  3.24249268e-05 3.29017639e-05 4.48226965e-05 4.95910645e-05
0:  5.24520874e-05 5.53131104e-05 5.86509705e-05 6.05583191e-05
0:  6.24656677e-05 6.38961792e-05 6.19888306e-05 6.38961792e-05
0:  6.58035278e-05 6.77108765e-05 6.91413879e-05 7.39097595e-05
0:  7.82012939e-05 8.24928284e-05 8.67843628e-05 9.39369202e-05
0:  1.00135803e-04 1.05857849e-04 1.11579895e-04 1.20639801e-04
0:  1.29222870e-04 1.37805939e-04 1.45435333e-04 1.44481659e-04
0:  1.49250031e-04 1.54018402e-04 1.57356262e-04 1.51634216e-04
0:  1.51157379e-04 1.50203705e-04 1.48296356e-04 1.41620636e-04
0:  1.37329102e-04 1.33514404e-04 1.28746033e-04 1.23023987e-04
0:  1.19209290e-04 1.14917755e-04 1.10626221e-04 1.05857849e-04
0:  1.02519989e-04 9.91821289e-05 9.63211060e-05 9.34600830e-05
0:  9.20295715e-05 9.10758972e-05 8.96453857e-05 8.86917114e-05
0:  8.77380371e-05 8.67843628e-05 8.58306885e-05 8.44001770e-05
0:  8.29696655e-05 8.15391541e-05 8.05854797e-05 7.96318054e-05
0:  7.91549683e-05 7.82012939e-05 7.77244568e-05 7.67707825e-05
0:  7.43865967e-05 7.20024109e-05 6.96182251e-05 6.62803650e-05
0:  6.15119934e-05 5.67436218e-05 5.19752502e-05 4.76837158e-05
0:  4.24385071e-05 3.71932983e-05 3.29017639e-05 2.86102295e-05
0:  2.47955322e-05 2.05039978e-05 1.66893005e-05 1.43051147e-05
0:  3.53336334e-04 3.69071960e-04 3.84807587e-04 3.80039215e-04
0:  3.75747681e-04 3.67641449e-04 3.58581543e-04 3.44276428e-04
0:  3.25679779e-04 2.98500061e-04 2.71797180e-04 2.45571136e-04
0:  2.19345093e-04 2.00748444e-04 1.86443329e-04 1.69754028e-04
0:  1.50203705e-04 1.25885010e-04 1.01566315e-04 8.63075256e-05
0:  7.10487366e-05 5.76972961e-05 4.52995264e-05 4.05311584e-05
0:  3.57627869e-05 3.09944153e-05 2.57492065e-05 2.38418579e-05
0:  2.19345093e-05 2.19345093e-05 2.24113464e-05 2.57492065e-05
0:  2.71797180e-05 2.71797180e-05 2.67028809e-05 2.67028809e-05
0:  2.71797180e-05 2.81333923e-05 3.00407410e-05 3.19480896e-05
0:  3.38554382e-05 3.52859497e-05 3.67164612e-05 3.91006433e-05
0:  4.14848364e-05 4.52995264e-05 5.00679016e-05 5.57899475e-05
0:  6.05583191e-05 6.38961792e-05 6.72340393e-05 7.29560852e-05
0:  7.82012939e-05 8.58306885e-05 9.39369202e-05 9.91821289e-05
0:  1.04427338e-04 1.09672546e-04 1.15394592e-04 1.18732452e-04
0:  1.22070312e-04 1.22547150e-04 1.22070312e-04 1.17778778e-04
0:  1.15394592e-04 1.16348267e-04 1.16825104e-04 1.15394592e-04
0:  1.13964081e-04 1.11103058e-04 1.07288361e-04 1.03950500e-04
0:  1.01089478e-04 1.00135803e-04 9.91821289e-05 9.82284546e-05
0:  9.77516174e-05 9.67979431e-05 9.53674316e-05 9.44137573e-05
0:  9.39369202e-05 9.39369202e-05 9.44137573e-05 9.44137573e-05
0:  9.48905945e-05 9.39369202e-05 9.29832458e-05 9.20295715e-05
0:  9.10758972e-05 9.10758972e-05 9.05990601e-05 8.72612000e-05]
0: Prediction values (first 20):
0: [-10.275699   -10.620427   -10.853871   -10.944476   -10.898053
0:  -10.793984   -10.554172   -10.260575    -9.799588    -9.209284
0:   -8.471556    -7.6569214   -6.807478    -5.9603786   -5.110835
0:   -4.2553024   -3.4816103   -2.79735     -0.27774382   0.21116257]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -2.959, max = 1.194, mean = 0.108
0:          sample (first 20): tensor([-1.2820, -1.3085, -1.3265, -1.3334, -1.3299, -1.3219, -1.3034, -1.2808, -1.2454, -1.2000, -1.1433, -1.0806,
0:         -1.0153, -0.9502, -0.8849, -0.8191, -0.7596, -0.7070, -0.8574, -0.8605])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.60482  13.381884 13.153425 12.89699  12.637226 12.390085 12.200039
0:  12.009803 11.882803 11.796877 11.722288 11.6257   11.504988 11.358664
0:  11.148654 10.899632 10.63265  10.397876 10.060272  9.69861 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-12.430179 -12.584851 -12.683562 -12.713738 -12.672719 -12.641164
0:  -12.531154 -12.459224 -12.346404 -12.192149 -12.009704 -11.828927
0:  -11.631713 -11.385821 -11.150687 -10.873725 -10.576726 -10.289369
0:  -10.670758 -10.871629]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.206654  11.086824  10.967909  10.826894  10.658408  10.443872
0:  10.195622   9.883784   9.516703   9.140468   8.753898   8.3690815
0:   8.06321    7.835405   7.7434955  7.8202677  8.040909   8.368645
0:   9.369617   9.570398 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.0958734 5.094639  5.1887007 5.410901  5.71832   6.026732  6.3650312
0:  6.5516024 6.695351  6.814728  6.8904257 6.9492807 7.0921836 7.200765
0:  7.3047466 7.4086    7.4361806 7.463735  6.9069505 7.0580807]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.4809961 2.690855  2.93442   3.1707027 3.3979418 3.5664926 3.7060778
0:  3.7941346 3.8844159 3.976049  4.078907  4.15812   4.2360272 4.305291
0:  4.33071   4.367169  4.4080915 4.455406  4.424245  4.4545484]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.260138  9.288334  9.359043  9.362182  9.285739  9.1505375 9.035315
0:  8.859823  8.7162075 8.571968  8.368117  8.159253  7.9306135 7.5862274
0:  7.086836  6.388765  5.505414  4.6128063 2.6520483 3.2822099]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.6981988 2.7106242 2.8013813 2.9306588 3.1023393 3.2037606 3.337597
0:  3.3677452 3.4242833 3.4976673 3.6006238 3.719875  3.826522  3.9323087
0:  3.9985728 4.0858192 4.150475  4.302335  4.1272206 4.2156014]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.3293242 7.20958   7.093734  6.9614525 6.802204  6.6113176 6.403523
0:  6.171866  5.937287  5.7112017 5.4621115 5.186306  4.885887  4.5440197
0:  4.160953  3.7569878 3.349956  2.9629626 2.026866  1.6553769]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 6.1867557  6.360226   6.604126   6.8924403  7.222109   7.548882
0:   7.8676586  8.10306    8.300317   8.420704   8.563204   8.700812
0:   8.932327   9.202523   9.502046   9.779688  10.009084  10.217856
0:   9.732255   9.9963665]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.8522105  -0.70708466 -0.54096365 -0.3759489  -0.19106674 -0.04350853
0:   0.06406498  0.09353352  0.06539822 -0.00986433 -0.09317493 -0.2005763
0:  -0.2902913  -0.29571724 -0.2823987  -0.19302893 -0.08688688 -0.01930189
0:  -0.25519753 -0.18561506]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.22615   2.315671  2.4393435 2.5469613 2.6134076 2.6169648 2.6275415
0:  2.5904317 2.5956802 2.6350312 2.666719  2.6848583 2.7003312 2.710865
0:  2.7023225 2.7508392 2.8072734 2.9161706 2.5435905 2.6272373]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-26.18193  -26.107178 -26.00108  -25.812778 -25.699867 -25.694427
0:  -25.569626 -25.567207 -25.524012 -25.453484 -25.468082 -25.481434
0:  -25.407637 -25.40972  -25.347986 -25.372503 -25.480133 -25.674187
0:  -26.039112 -25.981857]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.865734 -8.903923 -8.899668 -8.843832 -8.749802 -8.681749 -8.610748
0:  -8.621178 -8.650822 -8.647501 -8.610113 -8.564583 -8.479078 -8.383736
0:  -8.322041 -8.240124 -8.123695 -7.948816 -8.199295 -8.229036]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.26808   14.937277  14.558378  14.056259  13.523745  12.953529
0:  12.379959  11.790034  11.284063  10.844061  10.448409  10.142219
0:   9.8902645  9.654526   9.413264   9.150626   8.832124   8.542658
0:   7.7175193  7.2802596]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.8044634  1.2755494  1.9302115  2.6986122  3.5461702  4.3946657
0:   5.2655463  6.0763083  6.8770213  7.6712914  8.455225   9.178397
0:   9.870792  10.515352  11.116722  11.719486  12.363083  13.028025
0:  14.074232  15.039085 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.7620997 6.703568  6.7407017 6.783476  6.829127  6.841757  6.8302894
0:  6.7957063 6.7664404 6.8166366 6.9045463 7.018633  7.170781  7.3502097
0:  7.5237107 7.723558  7.95212   8.198197  8.8527355 9.013321 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.3966422 1.5988836 1.8315563 2.067133  2.3142776 2.5096536 2.7127695
0:  2.8729835 3.0131414 3.143183  3.2581604 3.323231  3.3677998 3.4193745
0:  3.4461856 3.5230293 3.6174386 3.7201505 3.4471073 3.5071247]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.514366 16.797256 17.12087  17.44835  17.76432  18.040985 18.309164
0:  18.464071 18.606272 18.67304  18.720718 18.785553 18.911722 19.037727
0:  19.211855 19.332968 19.434015 19.465185 19.676554 19.740587]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.607141 18.464022 18.381702 18.33007  18.312607 18.321447 18.401157
0:  18.441486 18.492575 18.534323 18.44752  18.286165 18.085356 17.839891
0:  17.659655 17.555912 17.580992 17.760279 19.123224 19.967892]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.163103   -9.788919   -9.369009   -8.906332   -8.419149   -7.91493
0:   -7.2929244  -6.663833   -6.0000205  -5.307176   -4.639213   -4.085591
0:   -3.499662   -3.0020213  -2.4546056  -1.8747725  -1.2942734  -0.8472209
0:    1.3369575   2.1406894]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.299201  4.4077125 4.623662  4.896178  5.1885133 5.4518275 5.718378
0:  5.956323  6.2563553 6.6237426 7.062179  7.497055  7.9350796 8.30905
0:  8.544328  8.671476  8.682698  8.625814  8.426866  8.416725 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.2492485 4.2212343 4.219619  4.188979  4.131876  4.0346403 3.9287791
0:  3.7722788 3.643379  3.465121  3.306867  3.1148975 2.94766   2.8193593
0:  2.6967125 2.620669  2.5067868 2.3598304 2.1487346 1.9869156]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.7936888 2.9401875 3.0729575 3.2004285 3.3238182 3.4054298 3.4839313
0:  3.526672  3.580191  3.6457348 3.7050025 3.7571363 3.8267732 3.8812199
0:  3.9300401 3.9909673 4.0342374 4.084379  4.146065  4.260326 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [14.943666 15.249535 15.593458 15.998114 16.427464 16.888758 17.405142
0:  17.891092 18.424318 18.923538 19.373877 19.779041 20.127596 20.339273
0:  20.433071 20.370464 20.227293 20.07862  18.435307 18.37072 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.1560082 -1.2352824 -1.367661  -1.5870309 -1.8564906 -2.181293
0:  -2.496529  -2.8059907 -3.034639  -3.1947742 -3.2989545 -3.383593
0:  -3.4735427 -3.5279117 -3.5914226 -3.6081786 -3.550877  -3.4189363
0:  -3.392201  -3.4379907]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.9255486  3.1337883  3.355123   3.4887567  3.471659   3.1653473
0:   2.5190744  1.5072436  0.2042489 -1.2334619 -2.6722083 -3.9864326
0:  -5.0152764 -5.775684  -6.2483706 -6.3839927 -6.314759  -5.975179
0:  -5.0186067 -4.6857324]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.5314531 -2.747367  -2.960412  -3.1386414 -3.3148775 -3.5158587
0:  -3.7585773 -4.09505   -4.410611  -4.6337633 -4.71461   -4.7425547
0:  -4.699402  -4.6374454 -4.648796  -4.6140814 -4.50264   -4.344002
0:  -3.9376326 -3.7137232]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.0234971  -0.24182415 -0.47280455 -0.71311665 -0.942883   -1.1517005
0:  -1.3146844  -1.4702363  -1.5887151  -1.691195   -1.7795339  -1.9205232
0:  -2.058536   -2.1886315  -2.3185496  -2.3942208  -2.428018   -2.4093184
0:  -2.6018958  -2.4860177 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.874475  -2.8429847 -2.777367  -2.6863313 -2.6030927 -2.555245
0:  -2.503409  -2.4912667 -2.4663787 -2.4417853 -2.41048   -2.3969007
0:  -2.3803    -2.342525  -2.3090215 -2.241571  -2.1750636 -2.0926251
0:  -2.472155  -2.4664598]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.1179347  -3.0427165  -2.9049954  -2.7088141  -2.457107   -2.1861577
0:  -1.8807559  -1.5997834  -1.3163142  -1.0401287  -0.7427254  -0.478611
0:  -0.22149277  0.00448847  0.15401459  0.27640152  0.35022688  0.37484884
0:  -0.33695078 -0.6397648 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.116104   6.9712014  6.880267   6.89869    7.021854   7.2195444
0:   7.562991   7.959187   8.476106   9.016302   9.518612   9.901495
0:  10.155737  10.248765  10.200623  10.076375   9.930936   9.749892
0:   8.742365   8.728883 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.3345127 3.4519227 3.6076632 3.7448592 3.9018872 4.082929  4.3191357
0:  4.5883083 4.8790455 5.1648617 5.447342  5.675991  5.870282  5.9817758
0:  5.951305  5.772215  5.454694  5.090566  3.8181252 3.6056201]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.687168  3.7591124 3.8254237 3.9201443 4.0175285 4.10274   4.214877
0:  4.2914386 4.359852  4.412287  4.419632  4.4147215 4.4290195 4.4291954
0:  4.4485016 4.487383  4.52029   4.568103  4.6735363 4.642319 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.578403 22.706226 22.752205 22.70159  22.579662 22.41521  22.253883
0:  22.066347 21.911547 21.805744 21.705046 21.592241 21.482052 21.332186
0:  21.150658 20.963675 20.79791  20.652803 20.600237 20.462257]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.37061548  0.30738306  0.26739454  0.28016472  0.33988047  0.40359735
0:   0.44957876  0.42218304  0.34194756  0.23354626  0.1164093  -0.01807642
0:  -0.14833689 -0.25808573 -0.39331913 -0.4949112  -0.5904741  -0.69346046
0:  -1.0681329  -1.2788529 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.129825  -8.023855  -7.9062147 -7.798254  -7.6704483 -7.579712
0:  -7.469386  -7.4417944 -7.3937416 -7.334469  -7.248576  -7.188382
0:  -7.1242857 -7.027116  -6.952524  -6.8250513 -6.6734257 -6.5032024
0:  -6.7529354 -6.633541 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.2067757 5.9190893 6.703293  7.472788  8.152904  8.718321  9.1799
0:  9.490511  9.652692  9.695533  9.617731  9.462451  9.317684  9.194743
0:  9.115951  9.084028  9.0488205 9.036374  7.823676  7.83181  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.798985 22.860432 22.914658 22.943827 22.935217 22.924847 22.925158
0:  22.866121 22.86733  22.869032 22.842514 22.82239  22.832077 22.869661
0:  22.93481  22.985659 23.021097 23.049194 23.142038 23.38721 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.366476 25.244795 25.160778 25.018566 24.890266 24.769606 24.63289
0:  24.430874 24.217573 23.924469 23.550488 23.12589  22.721895 22.332146
0:  21.948416 21.602747 21.318514 21.08638  20.615677 20.549738]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.4310062 3.376176  3.3179798 3.219119  3.1004891 2.9344099 2.781191
0:  2.5877209 2.3909435 2.2058172 2.0322652 1.8432717 1.6878233 1.5962987
0:  1.52389   1.527463  1.554491  1.5724564 1.5907979 1.5303798]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.435845  -4.286902  -4.1729665 -4.0590167 -3.978272  -3.9430413
0:  -3.8940597 -3.9144883 -3.92664   -3.9471946 -3.9674792 -3.9583888
0:  -3.9199061 -3.8488584 -3.7864537 -3.7170844 -3.65      -3.553084
0:  -3.5637078 -3.5035768]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 4.23879     4.2304106   4.04876     3.752469    3.3680418   2.9037716
0:   2.3720012   1.7470512   1.1294799   0.5674162   0.0611558  -0.321095
0:  -0.5875921  -0.7770529  -0.91193485 -0.9701195  -0.89524984 -0.62234735
0:  -0.36203003 -0.01138115]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.42448  18.575975 18.753008 18.852306 18.86582  18.843748 18.77066
0:  18.647974 18.500074 18.30229  18.081324 17.818928 17.578897 17.376566
0:  17.202677 17.055418 16.921022 16.798115 16.497513 16.47133 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.13175   8.276228  8.398821  8.419647  8.432727  8.456537  8.432507
0:  8.381479  8.332413  8.279097  8.284141  8.261215  8.237168  8.216564
0:  8.157329  8.119953  8.123756  8.177286  7.5900545 7.754862 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.5009675  -0.23723364  0.10024357  0.47917795  0.92169285  1.3565922
0:   1.8376002   2.2797337   2.7571545   3.2549908   3.8061655   4.347645
0:   4.9087315   5.421707    5.916707    6.3891287   6.8576574   7.349395
0:   7.581219    7.9690347 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.89073   13.009971  13.11463   13.073055  12.916758  12.669647
0:  12.372922  11.999044  11.579571  11.062069  10.385566   9.515203
0:   8.503668   7.468421   6.495288   5.748484   5.28339    5.0995874
0:   5.943807   5.9968824]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.27719   -9.209338  -9.100441  -8.885384  -8.622347  -8.375759
0:  -8.009707  -7.698653  -7.340662  -6.990694  -6.6929245 -6.4151297
0:  -6.120181  -5.808139  -5.464526  -5.07584   -4.673006  -4.251669
0:  -4.748391  -4.584195 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.4953704  -1.9522939  -1.3581319  -0.8076339  -0.35635662 -0.02421093
0:   0.19159174  0.22511101  0.15615845 -0.04975271 -0.32073402 -0.6659298
0:  -0.9839411  -1.2093835  -1.3300681  -1.2825541  -1.0681195  -0.73167276
0:  -0.99777365 -1.0788331 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.408827  23.071064  22.791893  22.503036  22.165516  21.756945
0:  21.253767  20.591707  19.868708  19.086996  18.200527  17.324844
0:  16.580639  15.88439   15.362741  14.933327  14.564298  14.2994995
0:  14.839687  14.647034 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.762789 21.123096 20.432125 19.719122 19.131998 18.72778  18.62065
0:  18.605759 18.809307 19.07619  19.31852  19.51621  19.610312 19.618221
0:  19.57383  19.476788 19.350214 19.22205  19.087982 19.09961 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.824156 25.814007 26.06167  26.374254 26.75133  27.05227  27.088366
0:  26.765488 26.10942  24.947351 23.399166 21.50603  19.607525 17.78471
0:  16.405626 15.522238 15.038708 14.680803 17.674194 17.23817 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.3708682 0.5270524 0.7120547 0.9568267 1.2323742 1.510128  1.8420534
0:  2.1410522 2.4628038 2.774343  3.0962954 3.4009626 3.708196  4.0361104
0:  4.3414    4.673935  5.0122533 5.333141  5.7570724 5.8957453]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [38.38558  38.485462 38.577515 38.61705  38.64372  38.672104 38.770874
0:  38.810566 38.916363 38.975246 38.970203 38.864155 38.772266 38.691833
0:  38.636585 38.66882  38.746586 38.818382 39.44934  39.60026 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.2677736 7.2350836 7.21377   7.2207637 7.220168  7.216162  7.256028
0:  7.2792835 7.35941   7.4470625 7.4915323 7.496652  7.474628  7.437485
0:  7.385192  7.3288198 7.2269535 7.108722  7.000368  7.127079 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.4866934 7.4579673 7.3299594 7.1855874 7.023182  6.8719406 6.750612
0:  6.5931606 6.4364853 6.2596254 6.0820174 5.9268646 5.7861667 5.6607533
0:  5.5171776 5.335182  5.14493   4.982055  4.619953  4.6723003]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -7.7373867  -7.7704773  -7.7789536  -7.827224   -7.9172745  -8.096393
0:   -8.346833   -8.687233   -9.034141   -9.343818   -9.575927   -9.759044
0:   -9.866786   -9.908576   -9.967473  -10.006438  -10.029965  -10.04629
0:  -10.516412  -10.564359 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [9.342812  9.334196  9.269257  9.202109  9.145475  9.0306225 8.936475
0:  8.719538  8.452488  8.085971  7.6945996 7.267352  6.8452487 6.4806013
0:  6.1399655 5.839202  5.4987154 5.1333094 3.5669708 2.9894593]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.5341983 7.31142   7.1496844 6.9976416 6.8729043 6.738341  6.565674
0:  6.3761053 6.1880527 6.055518  5.973813  5.9456596 5.983894  6.0692964
0:  6.1885543 6.3399067 6.522418  6.7447143 6.4578443 6.478503 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.881165  6.0930705 6.2177863 6.3142467 6.3523474 6.354063  6.364688
0:  6.2634964 6.1132793 5.909425  5.583449  5.258177  4.974555  4.70683
0:  4.5093913 4.2943234 4.06888   3.8299246 4.1120005 3.8246257]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.790123   7.91955    8.115251   8.356937   8.605328   8.835616
0:   9.061361   9.251828   9.430548   9.617237   9.799407   9.994282
0:  10.206608  10.413733  10.622509  10.779554  10.907796  11.013298
0:  10.6081085 10.748098 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.010572  4.6683674 4.401546  4.245028  4.194434  4.121401  4.1422415
0:  4.042223  3.9590712 3.8261504 3.6304884 3.444875  3.2509444 3.0797927
0:  2.8232298 2.5575528 2.2004852 1.8333793 1.6871564 1.5759282]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.8811274 2.036386  2.23778   2.4654775 2.7331314 2.9991398 3.2770545
0:  3.5330632 3.7822118 4.026088  4.2760353 4.481344  4.677464  4.87749
0:  5.0571504 5.290586  5.570881  5.8738227 5.948162  5.9055524]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.9975271 -1.8955789 -1.8200502 -1.7772136 -1.7107396 -1.6676731
0:  -1.590641  -1.5267677 -1.4632425 -1.3985353 -1.3383412 -1.3191395
0:  -1.3281436 -1.3222227 -1.350378  -1.3338513 -1.2618055 -1.1444774
0:  -1.8871989 -1.7980204]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 8.524322  8.793054  9.110458  9.401623  9.680726  9.899633 10.033845
0:  10.147298 10.242239 10.372622 10.515092 10.663502 10.92931  11.160824
0:  11.412582 11.619908 11.805914 12.030594 11.90247  12.237272]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.025392   -4.6395144  -4.2312407  -4.0546765  -4.110767   -4.2694745
0:  -4.4449773  -4.6291404  -4.747872   -4.783458   -4.749004   -4.6004376
0:  -4.179173   -3.1887298  -1.7916846   0.09185028  2.2129745   4.1856437
0:   6.7549677   6.7013083 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.5331807 -4.433886  -4.308205  -4.154899  -3.9700255 -3.824736
0:  -3.6845765 -3.6149526 -3.5331864 -3.4468627 -3.336475  -3.2467513
0:  -3.1458707 -3.0277753 -2.9628396 -2.8732486 -2.769052  -2.6301856
0:  -2.8072944 -2.6279912]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.67749   -6.380186  -6.228693  -5.9997654 -5.7898073 -5.659874
0:  -5.4360847 -5.301591  -5.232913  -5.161148  -5.1287394 -5.070094
0:  -4.9987135 -4.8773746 -4.7557096 -4.6260214 -4.492917  -4.3576136
0:  -4.4064064 -4.2020226]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.6130743  -0.5454216  -0.46189642 -0.3786626  -0.30868244 -0.28637886
0:  -0.2651143  -0.3023758  -0.3476467  -0.38507223 -0.41682434 -0.45071888
0:  -0.47163153 -0.46972322 -0.5102711  -0.5450597  -0.621243   -0.72187567
0:  -1.2762351  -1.4698758 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.836048  4.8530774 4.8662133 4.922183  4.965475  4.961784  4.946075
0:  4.84116   4.7546635 4.698709  4.6928635 4.8242755 5.1107354 5.5025854
0:  5.9837985 6.4920144 7.008124  7.5175457 8.681712  8.827259 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.5466933   0.6887579   0.79619217  0.8990884   0.9760809   1.0171223
0:   1.0757594   1.1168275   1.2022057   1.3039131   1.4061837   1.4522214
0:   1.4674239   1.4144816   1.3077245   1.1741419   1.0427232   0.9446635
0:  -0.03027821 -0.11903191]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.8282595 5.872076  5.9128485 5.931511  5.949931  5.931754  5.953973
0:  5.952485  5.9745183 6.0001264 6.0077    5.9889073 5.9739304 5.964896
0:  5.9503956 5.993559  6.0619054 6.1639905 5.8764896 5.894115 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.870855  10.746517  10.575505  10.392939  10.163371   9.916526
0:   9.69136    9.418262   9.168407   8.902909   8.590153   8.2284975
0:   7.887711   7.5615215  7.2604856  7.0039473  6.8140187  6.672245
0:   6.834684   6.895186 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.1722817 -4.2324166 -4.2955728 -4.3803115 -4.4550147 -4.542624
0:  -4.5997787 -4.6733565 -4.714667  -4.7302737 -4.7255664 -4.7509427
0:  -4.8019967 -4.8555818 -4.9776177 -5.0788684 -5.1713653 -5.2345996
0:  -5.4891143 -5.623858 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.6483126 2.7354076 2.8418005 2.9509432 3.0870018 3.200138  3.3193395
0:  3.3890793 3.463852  3.5252364 3.6004794 3.641652  3.661757  3.691378
0:  3.6738863 3.6839113 3.7391317 3.832028  3.5795338 3.7285807]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.2312193 4.319309  4.4873066 4.6984572 4.924605  5.144499  5.343846
0:  5.4793773 5.617294  5.7748694 5.9473433 6.1031046 6.338233  6.5446997
0:  6.7507663 6.9366255 7.0639124 7.1398497 7.171319  7.4497623]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [31.631233 31.89607  32.15649  32.3621   32.55151  32.706467 32.917923
0:  33.082787 33.320396 33.58355  33.8262   34.003273 34.142635 34.25649
0:  34.327103 34.404583 34.513466 34.579144 34.630394 34.78933 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [43.743805 43.73883  43.41213  42.750225 41.894104 40.92263  39.959133
0:  39.031372 38.28561  37.685852 37.20541  36.90606  36.768524 36.739803
0:  36.772434 36.788147 36.69619  36.397327 36.13668  35.95622 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-23.42717  -23.401035 -23.264301 -23.006325 -22.735764 -22.504292
0:  -22.248386 -22.074348 -21.890945 -21.696205 -21.492805 -21.26788
0:  -20.955608 -20.632233 -20.26654  -19.967518 -19.78178  -19.679317
0:  -19.965118 -19.627075]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [33.398464 32.400997 31.618496 31.003147 30.646816 30.350597 30.212238
0:  29.981369 29.923128 29.875704 29.71477  29.554457 29.454456 29.383856
0:  29.350925 29.32125  29.31083  29.294827 29.872875 29.372862]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [32.084255 31.13581  30.250021 29.358599 28.454882 27.589022 26.802298
0:  25.97751  25.15259  24.322704 23.372314 22.32935  21.263823 20.237236
0:  19.24993  18.343275 17.447178 16.608898 16.245142 15.93228 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.808847 19.893322 20.095604 20.374052 20.746971 21.170605 21.572487
0:  21.878202 22.082937 22.103828 21.939615 21.553917 21.071077 20.584267
0:  20.165144 19.907604 19.803068 19.801468 19.562035 19.582031]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.8702655 3.067256  3.2749186 3.4146738 3.5554583 3.6909275 3.7961698
0:  3.8866043 4.0043983 4.1498528 4.3118353 4.4358134 4.5663013 4.6784444
0:  4.7812853 4.9353647 5.180772  5.47867   5.3875923 5.657326 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -9.962907 -10.204751 -10.338149 -10.394103 -10.430907 -10.584685
0:  -10.6963   -10.939086 -11.146989 -11.425672 -11.783059 -12.240972
0:  -12.764144 -13.296849 -13.76209  -14.085652 -14.314311 -14.462029
0:  -15.090793 -15.21008 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.8457751 3.742715  3.7284381 3.827943  4.011547  4.199623  4.446686
0:  4.6573267 4.886239  5.1062355 5.25773   5.3204737 5.297212  5.2530856
0:  5.1882772 5.2103076 5.322817  5.5136023 6.725167  6.9849396]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.85569  18.91467  19.025297 19.14765  19.262604 19.344036 19.407959
0:  19.358044 19.331198 19.260212 19.120304 18.948423 18.816927 18.67622
0:  18.541502 18.3818   18.20329  18.006643 17.17062  16.785078]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [37.956463 37.361794 36.789486 36.319664 35.911858 35.517307 35.06242
0:  34.44061  33.833626 33.233154 32.597755 31.96814  31.476376 31.061073
0:  30.726486 30.517502 30.400032 30.304115 31.717884 31.507565]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 3.9924457e+00  4.0140018e+00  4.0389361e+00  4.0180464e+00
0:   3.9712443e+00  3.8516018e+00  3.6862128e+00  3.4301941e+00
0:   3.0783226e+00  2.6191993e+00  2.0735621e+00  1.4124303e+00
0:   7.0423841e-01  4.0335655e-03 -7.0335531e-01 -1.3132520e+00
0:  -1.8279614e+00 -2.1850009e+00 -2.4122720e+00 -2.4698005e+00]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.242885  -6.075112  -5.9168687 -5.761664  -5.610376  -5.51106
0:  -5.39535   -5.3400235 -5.278749  -5.2056346 -5.1244025 -5.0581555
0:  -4.976052  -4.8876224 -4.816296  -4.7135777 -4.6113505 -4.4835467
0:  -4.867004  -4.65599  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.146156 26.547932 26.965923 27.367718 27.776215 28.221561 28.614986
0:  28.922352 29.144695 29.243927 29.22858  29.081882 28.87716  28.559093
0:  28.18686  27.78077  27.455242 27.204563 26.65998  26.416027]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.0844212  -2.3742924  -2.4855509  -2.3736553  -2.038391   -1.5727234
0:  -1.0871105  -0.62232304 -0.24117804  0.12767458  0.49206066  0.77696705
0:   1.14116     1.4646068   1.7346244   2.0186186   2.3153415   2.623272
0:   2.7536817   2.8882952 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.02059364 -0.13339043 -0.22702265 -0.25391388 -0.11644363  0.10129118
0:   0.34838295  0.46230745  0.42288828  0.22818041 -0.00771666 -0.22103977
0:  -0.31835556 -0.2781     -0.21508646 -0.14607477 -0.12382698 -0.16278553
0:  -0.4406209  -0.5358205 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.5414071  0.6662402  0.82821274 1.0196466  1.2188196  1.4037213
0:  1.6106591  1.8004379  1.9959826  2.168522   2.3162572  2.4605136
0:  2.60346    2.7355142  2.8675334  2.9700859  3.0686624  3.1554108
0:  2.5913687  2.7507749 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.111288 17.037659 17.04153  17.093653 17.117752 17.091787 17.110088
0:  16.99313  16.87719  16.723183 16.469425 16.237501 16.08005  15.987179
0:  15.996012 16.01281  16.049156 16.12004  16.276604 16.261312]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.734478 24.812675 24.855267 24.880062 24.865055 24.84885  24.91032
0:  24.887226 24.898563 24.907661 24.84019  24.75932  24.731384 24.706871
0:  24.744564 24.76653  24.753418 24.669567 24.074726 24.12302 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.18061304 -0.32773972 -0.44112825 -0.6506591  -0.9929056  -1.4968977
0:  -2.1510277  -2.9576645  -3.7659273  -4.522113   -5.0740995  -5.382553
0:  -5.3827314  -5.115733   -4.714197   -4.3248177  -4.105997   -4.011507
0:  -3.748725   -3.7612972 ]
0: validation loss for strategy=forecast at epoch 18 : nan
0: validation loss for velocity_u : 0.03234973922371864
0: validation loss for velocity_v : 0.062350522726774216
0: validation loss for specific_humidity : 0.022931084036827087
0: validation loss for velocity_z : 0.4266842305660248
0: validation loss for temperature : 0.05901288986206055
0: validation loss for total_precip : nan
0: 19 : 11:02:47 :: batch_size = 96, lr = 1.3143901141491711e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 19, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.1065, 0.1185, 0.1303, 0.1420, 0.1538, 0.1655, 0.1772, 0.1888, 0.2005, 0.2120, 0.2234, 0.2348, 0.2458, 0.2567,
0:         0.2674, 0.2778, 0.2880, 0.2981, 0.1924, 0.2028, 0.2130, 0.2229, 0.2327, 0.2423, 0.2517], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.5237, 0.5315, 0.5391, 0.5467, 0.5541, 0.5614, 0.5684, 0.5751, 0.5819, 0.5884, 0.5945, 0.6006, 0.6065, 0.6122,
0:         0.6175, 0.6228, 0.6276, 0.6323, 0.6257, 0.6321, 0.6382, 0.6441, 0.6496, 0.6550, 0.6603], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.7002, -0.7010, -0.7015, -0.7019, -0.7022, -0.7026, -0.7030, -0.7033, -0.7035, -0.7037, -0.7039, -0.7043,
0:         -0.7045, -0.7048, -0.7051, -0.7052, -0.7054, -0.7056, -0.7022, -0.7025, -0.7026, -0.7027, -0.7028, -0.7030,
0:         -0.7032], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.3615, 0.3638, 0.3638, 0.3593, 0.3504, 0.3371, 0.3193, 0.3015, 0.2793, 0.2593, 0.2415, 0.2282, 0.2171, 0.2126,
0:         0.2104, 0.2126, 0.2148, 0.2171, 0.3215, 0.3215, 0.3149, 0.3038, 0.2860, 0.2660, 0.2393], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0.8682, -0.8656, -0.8627, -0.8595, -0.8565, -0.8535, -0.8503, -0.8473, -0.8445, -0.8418, -0.8391, -0.8363,
0:         -0.8337, -0.8309, -0.8283, -0.8259, -0.8235, -0.8211, -0.8190, -0.8170, -0.8153, -0.8138, -0.8124, -0.8114,
0:         -0.8106], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 19, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2523,     nan, -0.2523,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2523,     nan,     nan,     nan, -0.2523,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2511,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2499,     nan, -0.2499,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2511,     nan,     nan,     nan, -0.2511,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2523,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2523,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2523,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2523,     nan,     nan,     nan, -0.2523,     nan,     nan, -0.2523, -0.2523,
0:             nan,     nan, -0.2523,     nan, -0.2523,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan, -0.2523,     nan,     nan,     nan,     nan,     nan, -0.2523,     nan, -0.2523,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.2523, -0.2523,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2523,     nan,     nan,     nan,     nan,     nan, -0.2523,     nan,
0:             nan, -0.2523, -0.2523,     nan,     nan,     nan,     nan,     nan,     nan, -0.2523, -0.2523,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2523,     nan,     nan])
0: [DEBUG] Epoch 19, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.4490, -0.4416, -0.4328, -0.4261, -0.4189, -0.4144, -0.4104, -0.4074, -0.4038, -0.3980, -0.3907, -0.3852,
0:         -0.3812, -0.3785, -0.3825, -0.3864, -0.3903, -0.3922, -0.4061, -0.4044, -0.4012, -0.3986, -0.3939, -0.3918,
0:         -0.3875], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.1433, 0.1611, 0.1772, 0.1937, 0.2054, 0.2231, 0.2415, 0.2653, 0.2915, 0.3213, 0.3512, 0.3806, 0.4070, 0.4320,
0:         0.4556, 0.4771, 0.4991, 0.5198, 0.1752, 0.1945, 0.2154, 0.2345, 0.2533, 0.2712, 0.2922], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.6996, -0.6992, -0.7000, -0.6990, -0.7010, -0.7015, -0.7044, -0.7053, -0.7076, -0.7081, -0.7055, -0.7034,
0:         -0.7015, -0.7004, -0.7018, -0.7042, -0.7078, -0.7125, -0.7027, -0.7046, -0.7041, -0.7032, -0.7028, -0.7032,
0:         -0.7020], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.0945, 0.1249, 0.1559, 0.1711, 0.1796, 0.1715, 0.1488, 0.1212, 0.1197, 0.1143, 0.0870, 0.0926, 0.1171, 0.1295,
0:         0.1431, 0.1492, 0.1522, 0.1560, 0.1095, 0.1311, 0.1509, 0.1585, 0.1591, 0.1607, 0.1601], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([-1.2982, -1.2971, -1.2885, -1.2761, -1.2626, -1.2535, -1.2466, -1.2423, -1.2365, -1.2276, -1.2165, -1.2048,
0:         -1.1949, -1.1851, -1.1771, -1.1683, -1.1585, -1.1484, -1.1381, -1.1294, -1.1231, -1.1180, -1.1139, -1.1126,
0:         -1.1123], device='cuda:3', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.0467473603785038; velocity_v: 0.08010151982307434; specific_humidity: 0.03391377627849579; velocity_z: 0.47159823775291443; temperature: 0.09173569083213806; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.061756785959005356; velocity_v: 0.09687471389770508; specific_humidity: 0.04538221284747124; velocity_z: 0.47547662258148193; temperature: 0.11070630699396133; total_precip: nan; 
0: epoch: 19 [1/5 (20%)]	Loss: nan : nan :: 0.14415 (2.30 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.07156748324632645; velocity_v: 0.10926133394241333; specific_humidity: 0.04285905510187149; velocity_z: 0.5146649479866028; temperature: 0.11475623399019241; total_precip: nan; 
0: epoch: 19 [2/5 (40%)]	Loss: nan : nan :: 0.15824 (16.08 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.050166141241788864; velocity_v: 0.08781677484512329; specific_humidity: 0.0355188250541687; velocity_z: 0.46271082758903503; temperature: 0.08952610939741135; total_precip: nan; 
0: epoch: 19 [3/5 (60%)]	Loss: nan : nan :: 0.13938 (16.20 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.070520780980587; velocity_v: 0.10946226865053177; specific_humidity: 0.04904653877019882; velocity_z: 0.4927540421485901; temperature: 0.13329321146011353; total_precip: nan; 
0: epoch: 19 [4/5 (80%)]	Loss: nan : nan :: 0.16256 (16.23 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [5.92708588e-04 5.87940216e-04 5.85079193e-04 5.71250857e-04
0:  5.57899417e-04 5.64098358e-04 5.73635043e-04 5.66959381e-04
0:  5.66959381e-04 5.87463379e-04 6.01291656e-04 6.23703003e-04
0:  6.59465790e-04 6.89983368e-04 7.39097595e-04 7.62462616e-04
0:  7.48634338e-04 7.38143921e-04 7.09533691e-04 7.12394714e-04
0:  6.70909882e-04 6.84738159e-04 6.79016113e-04 6.58035278e-04
0:  6.48498535e-04 6.68525696e-04 6.89506531e-04 6.82830811e-04
0:  7.14778900e-04 7.07626343e-04 7.41958618e-04 7.53402710e-04
0:  7.63416290e-04 7.50541687e-04 7.11441040e-04 6.65664673e-04
0:  5.94615936e-04 5.31196594e-04 4.48226929e-04 3.59058380e-04
0:  2.70366669e-04 1.76429749e-04 1.03950500e-04 5.96046448e-05
0:  2.57492065e-05 1.66893005e-05 4.76837158e-06 1.90734863e-06
0:  9.53674316e-07 4.76837158e-07 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 4.76837158e-07 9.53674316e-07
0:  1.90734863e-06 3.81469727e-06 6.19888306e-06 9.53674316e-06
0:  1.23977661e-05 1.52587891e-05 1.52587891e-05 1.47819519e-05
0:  1.52587891e-05 1.28746033e-05 1.09672546e-05 1.04904175e-05
0:  1.04904175e-05 1.00135803e-05 9.05990601e-06 6.19888306e-06
0:  5.24520874e-06 2.86102295e-06 1.90734863e-06 1.43051147e-06
0:  1.43051147e-06 1.43051147e-06 9.53674316e-07 9.53674316e-07
0:  9.53674316e-07 9.53674316e-07 1.43051147e-06 1.43051147e-06
0:  1.90734863e-06 1.90734863e-06 2.38418579e-06 2.38418579e-06
0:  6.46591187e-04 6.42299652e-04 6.39438629e-04 6.44207001e-04
0:  6.68525696e-04 6.93798065e-04 7.02857971e-04 6.97135925e-04
0:  6.81400299e-04 6.78062439e-04 6.91413879e-04 7.13825226e-04
0:  7.23361969e-04 7.60555267e-04 8.29696655e-04 8.52584839e-04
0:  8.29219818e-04 8.52584839e-04 8.62598419e-04 8.65936279e-04
0:  8.24928284e-04 7.99655914e-04 7.51495361e-04 7.20977783e-04
0:  7.11917877e-04 7.22885132e-04 7.27653503e-04 7.29560852e-04
0:  7.61508942e-04 7.54356384e-04 7.44819641e-04 7.43389130e-04
0:  7.59601593e-04 7.47203827e-04 7.06195831e-04 6.79969788e-04
0:  6.24656677e-04 5.62191010e-04 4.79698181e-04 3.90052795e-04
0:  2.90393829e-04 1.92642212e-04 1.20639801e-04 7.39097595e-05
0:  3.48091125e-05 2.14576721e-05 9.53674316e-06 7.15255737e-06
0:  3.33786011e-06 9.53674316e-07 4.76837158e-07 4.76837158e-07
0:  4.76837158e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 4.76837158e-07 9.53674316e-07
0:  3.81469727e-06 6.19888306e-06 9.05990601e-06 1.14440918e-05
0:  1.23977661e-05 1.23977661e-05 1.28746033e-05 1.19209290e-05
0:  1.09672546e-05 1.00135803e-05 9.05990601e-06 8.58306885e-06
0:  9.05990601e-06 7.15255737e-06 5.72204590e-06 2.86102295e-06]
0: Target values (first 200):
0: [2.00271606e-05 1.81198120e-05 1.62124634e-05 1.52587891e-05
0:  1.43051147e-05 1.33514404e-05 1.33514404e-05 1.43051147e-05
0:  1.43051147e-05 1.43051147e-05 1.62124634e-05 1.90734863e-05
0:  2.00271606e-05 2.19345093e-05 2.47955322e-05 2.86102295e-05
0:  3.24249268e-05 3.43322754e-05 3.81469727e-05 4.48226929e-05
0:  5.14984131e-05 5.81741333e-05 6.67572021e-05 7.62939453e-05
0:  8.48770142e-05 9.44137573e-05 1.02043152e-04 1.04904175e-04
0:  1.02996826e-04 9.05990601e-05 8.10623169e-05 6.86645508e-05
0:  5.24520874e-05 3.81469727e-05 2.76565552e-05 1.81198120e-05
0:  1.33514404e-05 8.58306885e-06 6.67572021e-06 4.76837158e-06
0:  3.81469727e-06 1.90734863e-06 1.90734863e-06 9.53674316e-07
0:  9.53674316e-07 9.53674316e-07 9.53674316e-07 9.53674316e-07
0:  9.53674316e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  1.62124634e-05 1.43051147e-05 1.33514404e-05 1.14440918e-05
0:  1.23977661e-05 1.14440918e-05 1.14440918e-05 1.23977661e-05
0:  1.52587891e-05 1.81198120e-05 1.90734863e-05 2.28881836e-05
0:  2.67028809e-05 3.33786011e-05 3.81469727e-05 4.29153406e-05
0:  4.67300415e-05 5.34057617e-05 6.00814819e-05 6.67572021e-05
0:  7.34329224e-05 8.10623169e-05 8.77380371e-05 9.72747803e-05
0:  1.05857849e-04 1.14440918e-04 1.14440918e-04 1.09672546e-04
0:  1.06811523e-04 9.44137573e-05 8.10623169e-05 6.58035278e-05
0:  4.86373901e-05 3.52859497e-05 2.38418579e-05 1.71661377e-05
0:  1.33514404e-05 8.58306885e-06 5.72204590e-06 3.81469727e-06
0:  2.86102295e-06 1.90734863e-06 9.53674316e-07 9.53674316e-07
0:  9.53674316e-07 9.53674316e-07 9.53674316e-07 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
0:  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]
0: Prediction values (first 20):
0: [25.472174 25.29528  25.363577 25.579876 25.956144 26.374243 26.763145
0:  27.05455  27.384396 27.737051 28.037449 28.370462 28.712831 29.045282
0:  29.425293 29.747177 30.088022 30.37015  30.135128 30.350555]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -1.216, max = 4.298, mean = 0.985
0:          sample (first 20): tensor([1.5456, 1.5308, 1.5365, 1.5546, 1.5860, 1.6210, 1.6536, 1.6779, 1.7055, 1.7350, 1.7601, 1.7880, 1.8166, 1.8445,
0:         1.8762, 1.9032, 1.9317, 1.9553, 1.5787, 1.5700])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.5466356 7.262147  7.074917  7.0230265 7.0738087 7.189381  7.3755445
0:  7.543174  7.732377  7.924699  8.109629  8.277474  8.446255  8.600378
0:  8.749748  8.907501  9.057973  9.181104  8.519505  8.594051 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.328888 21.201288 21.069027 20.902727 20.634373 20.29458  19.853037
0:  19.298897 18.709429 18.089556 17.446312 16.86614  16.44329  16.100935
0:  15.926464 15.791452 15.651123 15.510466 15.089123 14.762077]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.5266652   1.2910137   1.0739317   0.8670807   0.6804695   0.48146725
0:   0.28721046  0.06855774 -0.12823391 -0.2935624  -0.45184326 -0.6157479
0:  -0.77627563 -0.9164796  -1.0517645  -1.1278849  -1.1690111  -1.1760025
0:  -1.7180996  -1.740098  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.111275 23.989151 23.833485 23.634285 23.391003 23.091927 22.825523
0:  22.488667 22.191177 21.926435 21.604477 21.323847 21.124472 20.962587
0:  20.878536 20.812256 20.728943 20.589752 21.158848 20.985884]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.428986 25.367218 25.39228  25.40745  25.389427 25.32428  25.2808
0:  25.149231 25.154337 25.187502 25.212053 25.186237 25.166597 25.155355
0:  25.156713 25.22889  25.321022 25.484655 26.31971  26.596077]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.24307156 0.41030502 0.5971737  0.80222464 1.0048995  1.1611605
0:  1.3048244  1.3932166  1.5017076  1.6331248  1.7992592  1.9633632
0:  2.1303782  2.2890515  2.4138432  2.5620322  2.740554   2.9636009
0:  3.083263   3.3009908 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.8173952 -2.8449373 -2.867052  -2.8997984 -2.9518557 -3.0534601
0:  -3.1474562 -3.2783356 -3.39122   -3.4740133 -3.5683165 -3.6950455
0:  -3.812273  -3.936081  -4.051093  -4.1069    -4.1469    -4.14404
0:  -4.507243  -4.5832186]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.3072753  -1.2858624  -1.2555404  -1.1597686  -1.0473266  -0.9834728
0:  -0.94071007 -0.96270657 -1.008429   -1.0301318  -1.0753369  -1.1518312
0:  -1.2537074  -1.3517585  -1.4672055  -1.5598607  -1.6523347  -1.7284808
0:  -3.1159616  -3.3322425 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.6628833 -2.6205373 -2.5351949 -2.4306884 -2.3503966 -2.340366
0:  -2.3890433 -2.514975  -2.6177726 -2.6631513 -2.6747603 -2.6701007
0:  -2.6602473 -2.6488996 -2.6868644 -2.716416  -2.738071  -2.7442012
0:  -2.998321  -2.968556 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [25.870176 25.648504 25.537493 25.441    25.34376  25.19493  24.983084
0:  24.661077 24.376015 24.060722 23.73373  23.409311 23.106153 22.76395
0:  22.431662 22.031836 21.633528 21.26324  20.105492 19.739817]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [40.702343 40.690125 40.70064  40.688625 40.635273 40.540676 40.4573
0:  40.24627  40.08848  39.82     39.48689  39.099308 38.72354  38.411293
0:  38.077034 37.77642  37.407246 36.962364 36.902428 36.97818 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.921072    1.0295558   1.1334095   1.2345519   1.343318    1.4104018
0:   1.4574051   1.4256773   1.3623548   1.2714634   1.1792588   1.0556536
0:   0.9167328   0.7732992   0.56449413  0.3533187   0.15687704 -0.00611591
0:  -0.5607929  -0.7553468 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-7.857377  -7.762618  -7.539316  -7.2335577 -6.933194  -6.6873627
0:  -6.571205  -6.583786  -6.63396   -6.6791744 -6.6488123 -6.6260624
0:  -6.5215225 -6.337125  -6.1813602 -6.022871  -5.947035  -5.9401035
0:  -6.5305595 -6.5933027]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-10.709212 -10.739766 -10.741834 -10.702241 -10.619292 -10.543555
0:  -10.454453 -10.44337  -10.465617 -10.500056 -10.547263 -10.621276
0:  -10.700389 -10.737794 -10.809712 -10.841393 -10.834043 -10.785592
0:  -11.206798 -11.206426]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.15813875 -0.19302368 -0.2107997  -0.21338177 -0.21717978 -0.23882723
0:  -0.27561235 -0.33407545 -0.3539586  -0.34319735 -0.26898766 -0.19131708
0:  -0.08715153  0.04336071  0.17911243  0.32094574  0.45540333  0.6093464
0:   0.9904442   1.0736489 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 7.9291077  8.151653   8.439916   8.766499   9.094104   9.418944
0:   9.767942  10.036448  10.293016  10.506045  10.628588  10.689998
0:  10.73177   10.715296  10.692528  10.624935  10.575929  10.532838
0:  10.191816  10.102023 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [36.579617 36.61646  36.599167 36.581512 36.565903 36.53704  36.5726
0:  36.4947   36.51053  36.477314 36.390358 36.27556  36.163414 36.062775
0:  35.95487  35.885433 35.757248 35.48594  35.232136 35.040382]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [8.415878  8.4855175 8.545704  8.536648  8.529928  8.508783  8.470872
0:  8.405762  8.3325    8.282708  8.249934  8.194371  8.147839  8.089737
0:  8.011537  7.966391  7.955552  7.9929137 7.7187076 7.6986403]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [27.054407 26.09458  25.621256 25.46661  25.493856 25.621464 25.767076
0:  25.957935 26.17146  26.251722 25.89355  24.990124 23.695488 22.209944
0:  20.784033 19.599718 18.67274  17.951109 16.714996 16.438444]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [41.1123   40.4304   39.84801  39.3322   38.81688  38.37984  38.08012
0:  37.84598  37.840115 37.830513 37.660393 37.378345 37.078217 36.899837
0:  36.831017 36.88074  36.829887 36.452423 34.754295 34.509964]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.6405435   2.4399552   2.190662    1.8901372   1.5452943   1.1610942
0:   0.8192382   0.4657402   0.16607666 -0.0788641  -0.2592144  -0.42698336
0:  -0.56153107 -0.6742263  -0.81131697 -0.93678427 -1.0662789  -1.1523662
0:  -1.3422227  -1.4050584 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.179874 20.235287 20.376244 20.625395 20.933033 21.263897 21.656403
0:  21.91999  22.170856 22.354774 22.44042  22.513584 22.56687  22.563492
0:  22.536495 22.391079 22.168917 21.977596 21.496687 21.584137]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [19.353905 19.234108 19.18882  19.138336 19.06305  18.961765 18.89252
0:  18.7556   18.7006   18.683315 18.660103 18.592918 18.550957 18.488277
0:  18.411598 18.377554 18.434093 18.562561 18.36267  18.293314]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 4.4648614  4.306451   4.245525   4.1604176  4.007083   3.8250582
0:   3.7237902  3.764214   4.1341753  4.778      5.6728387  6.6798162
0:   7.7548256  8.8563385  9.89814   10.830167  11.550311  12.002847
0:  11.2574835 10.969411 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.556358  -8.6185465 -8.623747  -8.623465  -8.63419   -8.663812
0:  -8.673557  -8.744482  -8.828951  -8.963193  -9.144837  -9.344508
0:  -9.497352  -9.549134  -9.554854  -9.531053  -9.546853  -9.603379
0:  -9.802289  -9.770442 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.205246  23.30089   23.334255  23.262743  23.167967  23.041561
0:  22.978102  22.783075  22.527456  22.098284  21.454943  20.65827
0:  19.795689  18.82322   17.78238   16.727179  15.675909  14.7122555
0:  13.447542  13.259352 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.1195297 5.2222285 5.358714  5.4530845 5.529069  5.579544  5.593695
0:  5.592148  5.600144  5.6400824 5.687899  5.705154  5.7307057 5.7666855
0:  5.769193  5.786866  5.838307  5.8682365 6.0327196 6.1974664]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.884575 21.93583  21.982656 21.995687 21.980532 21.961985 21.95941
0:  21.883696 21.92033  21.91682  21.92065  21.912794 21.909798 21.907368
0:  21.861334 21.800875 21.683496 21.506239 20.989708 21.037735]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.80325   -4.8484273 -4.733845  -4.4978127 -4.1389346 -3.767035
0:  -3.3615928 -3.0206532 -2.6779065 -2.402143  -2.1601877 -2.0130029
0:  -1.8764095 -1.7026987 -1.5988822 -1.4868798 -1.4337869 -1.3791533
0:  -1.0614777 -0.9026308]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.5438986  -0.14309359  0.26184225  0.5505662   0.7295141   0.76706934
0:   0.74264383  0.63027143  0.5473752   0.50861263  0.53707457  0.5912485
0:   0.6892023   0.843318    0.97403526  1.1887007   1.4474349   1.7441239
0:   2.384458    2.7818763 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.506569  21.17153   20.847124  20.493156  20.07755   19.598705
0:  19.138271  18.594568  18.07999   17.593456  17.086245  16.65153
0:  16.341164  16.098783  15.971233  15.8847275 15.785009  15.661161
0:  16.035421  15.831778 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.8512559  -1.6837106  -1.5551133  -1.4687705  -1.3636022  -1.3132977
0:  -1.226747   -1.1728339  -1.1005635  -1.0027261  -0.8927264  -0.8086562
0:  -0.7449322  -0.6673665  -0.62654114 -0.51457787 -0.351274   -0.1494422
0:   0.01437187  0.21627665]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [18.504507 18.585365 18.706371 18.780594 18.859465 18.918478 18.929625
0:  18.886208 18.794035 18.791454 18.85009  18.97949  19.194479 19.444347
0:  19.743816 20.091663 20.551962 21.050652 22.227896 22.336447]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.675962  16.423952  16.132343  15.747118  15.255131  14.7082615
0:  14.145798  13.549509  13.019682  12.544158  12.085738  11.697061
0:  11.3591385 11.057468  10.842377  10.658924  10.540367  10.468975
0:  10.716663  10.432484 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.727955  -9.70866   -9.625412  -9.476322  -9.272095  -9.070412
0:  -8.836859  -8.655867  -8.478132  -8.280294  -8.055464  -7.8252435
0:  -7.5657496 -7.2716517 -7.0091577 -6.7413335 -6.495251  -6.2549005
0:  -6.6298423 -6.681681 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.928759 21.418335 21.782703 21.944473 21.950115 21.847029 21.63797
0:  21.339464 21.103886 20.85881  20.646538 20.454887 20.32304  20.239576
0:  20.16828  20.140453 20.161392 20.20738  18.989939 19.204025]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.760139  15.847986  15.974346  16.020353  16.022852  16.012373
0:  15.9658165 15.890347  15.75458   15.521193  15.124922  14.462751
0:  13.637831  12.67482   11.691698  10.7961445 10.070445   9.569541
0:   7.930072   7.96038  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.871727 24.060946 24.223225 24.313393 24.560507 24.939054 25.431559
0:  26.052465 26.763084 27.627504 28.542822 29.389929 30.026066 30.320993
0:  30.174135 29.779568 29.351807 29.147657 30.246685 30.41218 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.516335 16.51559  16.658768 16.75415  16.70451  16.480682 16.266033
0:  16.166542 16.396954 16.989487 17.742344 18.463623 19.016594 19.32983
0:  19.4122   19.43099  19.440659 19.461508 19.291592 19.258186]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.362792  1.4487529 1.6191249 1.8024988 1.9909844 2.1676369 2.3587437
0:  2.5290997 2.7349522 2.9766026 3.2530425 3.523548  3.7930102 4.082904
0:  4.350126  4.631259  4.9301634 5.253106  5.490597  5.6057067]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.240268  10.115862  10.031416   9.951701   9.846962   9.671774
0:   9.46459    9.19825    8.925233   8.628696   8.318668   7.987034
0:   7.6598434  7.331984   6.98946    6.6659417  6.353385   6.0850973
0:   5.7617126  5.683171 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 6.8833027  6.9101815  7.003387   7.2255054  7.499803   7.7908735
0:   8.093693   8.310034   8.519646   8.655183   8.768849   8.807924
0:   8.89204    8.980257   9.082088   9.258677   9.453058   9.763609
0:  10.388123  10.6536665]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.4698    13.25147   12.895161  12.35929   11.704215  10.977367
0:  10.196781   9.4070635  8.685269   8.087139   7.6121655  7.2522354
0:   6.9921613  6.815279   6.677923   6.596895   6.5867944  6.6390996
0:   7.171017   7.513621 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.6076288  -2.6940632  -2.6183386  -2.4126368  -2.1595516  -1.9074821
0:  -1.6395006  -1.4722524  -1.310699   -1.2026877  -1.125567   -1.1039133
0:  -1.0240827  -0.8445215  -0.646101   -0.36955404 -0.16345263 -0.06527281
0:  -1.145443   -1.3750796 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [29.409084 29.41404  29.398554 29.29051  29.151413 29.02177  28.865673
0:  28.690554 28.552193 28.435314 28.33028  28.191017 28.036356 27.862722
0:  27.6703   27.47767  27.350422 27.253613 26.791021 26.76831 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.774488 15.779719 15.85015  15.936033 16.011196 16.106812 16.212673
0:  16.296144 16.42977  16.533905 16.627075 16.70102  16.747185 16.785286
0:  16.799847 16.792332 16.795513 16.782993 16.993221 17.029154]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.704351  3.5567708 3.4679844 3.4123046 3.3920536 3.3706424 3.3709755
0:  3.3578007 3.3726704 3.4048064 3.4806063 3.5791311 3.741264  3.915315
0:  4.095269  4.2919073 4.5015106 4.7182956 5.0293956 5.188082 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.1837506   1.6613355   1.0720034   0.4491663  -0.10111761 -0.508204
0:  -0.74943495 -0.8582597  -0.8779912  -0.8753066  -0.8913646  -0.99615
0:  -1.1324873  -1.249794   -1.3965273  -1.495162   -1.5522757  -1.5684423
0:  -1.7638407  -1.8283644 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.443846 -8.54344  -8.626001 -8.685884 -8.737961 -8.822327 -8.895283
0:  -9.016371 -9.128836 -9.215702 -9.267406 -9.3151   -9.342165 -9.332115
0:  -9.336973 -9.309849 -9.265854 -9.184452 -9.282789 -9.187952]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.8396068 -2.160956  -2.4886727 -2.8352141 -3.1884227 -3.5753026
0:  -3.9263701 -4.2066073 -4.3351207 -4.3079047 -4.112537  -3.8581758
0:  -3.59763   -3.3537478 -3.2443843 -3.2710624 -3.4366765 -3.6425605
0:  -4.5580096 -4.940841 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.8121204   1.906507    1.9159708   1.709867    1.3380513   0.9142227
0:   0.61413527  0.4962926   0.63765574  0.9389529   1.271945    1.470017
0:   1.4323516   1.1830211   0.71888447  0.23036051 -0.18168259 -0.4381404
0:  -0.8256817  -0.8074546 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.40445662 -0.35790586 -0.3312087  -0.33787107 -0.33516455 -0.35764742
0:  -0.4220705  -0.5686536  -0.7705221  -1.0383906  -1.3161979  -1.6326232
0:  -1.9421401  -2.2009597  -2.4747748  -2.677709   -2.793755   -2.8337636
0:  -3.180657   -3.2342362 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.542879  6.595579  6.6328816 6.6563725 6.6494083 6.6316624 6.636969
0:  6.6198277 6.626245  6.6574593 6.6872563 6.706873  6.748115  6.8078732
0:  6.888988  6.991509  7.1129017 7.261327  7.3877473 7.567467 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [24.506203 24.47588  24.421017 24.25822  24.093609 23.917618 23.695992
0:  23.428764 23.127092 22.788128 22.40979  21.961357 21.484188 20.986797
0:  20.452032 19.965956 19.564032 19.261684 18.426464 18.311625]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.2673564 3.3990822 3.5544643 3.7367842 3.9399579 4.1110735 4.3077097
0:  4.460635  4.6191044 4.7785797 4.9364367 5.0596085 5.154336  5.2460732
0:  5.295736  5.363615  5.4485874 5.5460844 5.4766207 5.542303 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.912994 22.690392 22.542408 22.42902  22.303493 22.186687 22.134644
0:  22.055885 22.161427 22.323952 22.477146 22.599037 22.69923  22.769035
0:  22.806297 22.830963 22.86044  22.785522 22.964478 22.877426]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [20.176064 20.358585 20.664043 21.018412 21.415264 21.830734 22.294506
0:  22.706665 23.138615 23.595497 23.983032 24.366222 24.762787 25.12096
0:  25.495472 25.820862 26.148712 26.439949 26.26128  26.763588]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.248796  21.694815  21.040108  20.258612  19.426445  18.530857
0:  17.61882   16.70606   15.843433  15.073542  14.364103  13.673433
0:  13.002336  12.390588  11.778486  11.2475815 10.796711  10.438976
0:   9.355806   8.941063 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.330149 10.501043 10.668051 10.794893 10.89415  10.968665 11.03989
0:  11.082593 11.13925  11.19649  11.241341 11.259829 11.273533 11.268376
0:  11.251409 11.259846 11.304004 11.350192 11.10695  11.133045]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.766075 13.948839 14.152996 14.37983  14.593557 14.797679 15.01474
0:  15.151903 15.301254 15.469465 15.636417 15.839834 16.108582 16.381832
0:  16.71614  17.017107 17.342424 17.68377  18.092354 18.533825]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.023975   9.998649   9.96383    9.904427   9.817693   9.703496
0:   9.601924   9.46301    9.356366   9.253188   9.127322   8.966066
0:   8.801496   8.632763   8.4428625  8.289484   8.175355   8.096883
0:   7.95848    7.932771 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.291309  -8.644243  -7.791899  -6.88903   -6.0860257 -5.5621476
0:  -5.330302  -5.4161143 -5.658833  -5.937343  -6.0861955 -6.0863404
0:  -5.8965535 -5.5194974 -5.0970197 -4.6244493 -4.2022004 -3.8542542
0:  -3.9988322 -3.9107337]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.7985153 7.827733  7.8442526 7.795338  7.7282763 7.611324  7.4708652
0:  7.3013153 7.151261  7.0194554 6.903899  6.7737064 6.6332235 6.496766
0:  6.329958  6.2150993 6.1296062 6.0752525 5.651625  5.478072 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.13938  26.148787 26.159788 26.169327 26.126883 26.022703 25.95972
0:  25.762907 25.665972 25.650433 25.690168 25.896692 26.326414 26.89725
0:  27.655514 28.427969 29.115505 29.543518 28.228237 27.622519]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.8451624 1.0402522 1.3403778 1.7761679 2.3222144 2.8929503 3.5005326
0:  4.019891  4.4566455 4.805645  5.0709724 5.255827  5.483257  5.6847177
0:  5.841926  6.0011816 6.123965  6.215137  5.590444  5.5919437]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.8190637 -3.6715379 -3.4844556 -3.3333879 -3.2104983 -3.1673656
0:  -3.192474  -3.3130984 -3.4827905 -3.6590343 -3.7798991 -3.8756318
0:  -3.9128728 -3.876182  -3.8651567 -3.818726  -3.743918  -3.627254
0:  -4.038919  -4.134998 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.287348  10.256394  10.179808  10.09375    9.985035   9.847168
0:   9.734086   9.59968    9.527813   9.474229   9.444558   9.397566
0:   9.324905   9.169156   8.896994   8.553161   8.177594   7.8209276
0:   7.3440485  7.07881  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.4347334 6.6075273 6.843213  7.0863876 7.3694234 7.6305237 7.848791
0:  7.955415  7.9069567 7.6910377 7.3065906 6.7440677 6.136553  5.5391674
0:  4.9904346 4.563944  4.259822  4.1076303 3.415432  3.4416976]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.582142 26.398602 26.173803 25.949314 25.686913 25.397432 25.11221
0:  24.747543 24.43582  24.11439  23.701271 23.281376 22.865078 22.437757
0:  22.036903 21.558718 21.044546 20.494555 20.454807 20.176224]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.291157  10.270892  10.279714  10.309327  10.324621  10.332749
0:  10.36451   10.356249  10.359371  10.3603325 10.331489  10.249564
0:  10.145348  10.004733   9.843267   9.683008   9.563502   9.50274
0:   8.975394   8.862835 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.9848738  -1.057476   -1.0607476  -1.0092449  -0.9395156  -0.88981867
0:  -0.8646054  -0.87592554 -0.85358    -0.79973745 -0.7303729  -0.700686
0:  -0.69869184 -0.694726   -0.74586105 -0.7863226  -0.8638034  -0.9599805
0:  -1.1618347  -1.3275871 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.489716  -3.5565133 -3.631617  -3.7163186 -3.8219647 -3.9758162
0:  -4.119122  -4.299169  -4.4389567 -4.572966  -4.703319  -4.8735423
0:  -5.0500436 -5.195952  -5.3595376 -5.467385  -5.5688205 -5.650495
0:  -6.3500123 -6.45254  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.546066  4.5088544 4.492224  4.472268  4.429497  4.3585863 4.2942796
0:  4.1809635 4.0717216 3.9697819 3.8607173 3.7178714 3.619295  3.540674
0:  3.4681203 3.4427097 3.4605212 3.5218713 3.497778  3.5388234]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [32.360245 32.124195 31.811958 31.440655 31.052507 30.647661 30.306719
0:  29.864231 29.460882 29.02597  28.514864 28.064837 27.704681 27.366695
0:  27.115726 26.840807 26.568111 26.277317 27.244968 27.259588]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.398196  5.333646  5.3113704 5.332144  5.2860875 5.1814456 5.007695
0:  4.7618456 4.5109425 4.269517  4.0259113 3.8012347 3.646655  3.5489593
0:  3.544288  3.526068  3.5298195 3.5549288 3.47184   3.39202  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [12.19706   12.657996  13.08956   13.486395  13.871733  14.2434025
0:  14.618462  14.960059  15.365253  15.814207  16.29153   16.78432
0:  17.314072  17.86765   18.464289  19.06921   19.718649  20.342701
0:  21.350164  21.975346 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.2406783 -2.2852988 -2.2806392 -2.251721  -2.2080922 -2.199144
0:  -2.2002892 -2.2478766 -2.2629743 -2.2400594 -2.1933894 -2.1587996
0:  -2.1211753 -2.1046634 -2.121303  -2.125071  -2.087605  -2.022715
0:  -2.2304091 -2.2127824]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [0.31190157 0.57155275 0.9621396  1.4009724  1.8565044  2.2231412
0:  2.4732895  2.563343   2.5294695  2.414534   2.2478714  2.0112686
0:  1.7170982  1.4498825  1.169805   1.0050812  0.9567056  1.0393181
0:  0.39015007 0.54001427]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-6.312424  -6.306292  -6.2637134 -6.1836743 -6.084162  -6.0201554
0:  -5.922581  -5.852636  -5.743418  -5.6043754 -5.4585004 -5.3353143
0:  -5.204203  -5.055776  -4.9035068 -4.724437  -4.5509105 -4.366156
0:  -4.618853  -4.536966 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.88619  16.011105 16.218523 16.514688 16.852663 17.160791 17.427364
0:  17.549597 17.602903 17.57208  17.47622  17.331066 17.249514 17.225264
0:  17.246412 17.280825 17.280024 17.253143 17.418362 17.359707]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.1404338  -2.93292    -2.547546   -2.101954   -1.6586595  -1.3050056
0:  -1.0399623  -0.920516   -0.88681555 -0.9245348  -1.0254064  -1.199161
0:  -1.4167924  -1.627974   -1.8828378  -2.070591   -2.2360315  -2.3544784
0:  -2.6929717  -2.9180512 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [17.111956 17.259125 17.399223 17.459131 17.476639 17.433971 17.335363
0:  17.200558 17.04386  16.893799 16.75976  16.610052 16.496483 16.467724
0:  16.489836 16.59183  16.78244  17.022903 18.184538 18.46247 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.248295  7.346348  7.3891807 7.397337  7.4569798 7.629294  7.989558
0:  8.479836  9.073704  9.505536  9.690451  9.435586  8.880944  8.075424
0:  7.123158  6.2572646 5.5741625 5.280294  5.832759  5.631014 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.417593 26.57582  26.747715 26.832054 26.808756 26.670944 26.498758
0:  26.197636 25.931494 25.688025 25.436392 25.226841 25.10451  25.096216
0:  25.24716  25.538687 25.883875 26.261019 27.98722  28.288406]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [1.6324449 1.7456532 1.9465294 2.2749996 2.731488  3.2473922 3.7963161
0:  4.270465  4.738644  5.152183  5.553955  5.9281917 6.2746596 6.6158094
0:  6.862617  7.0589066 7.176282  7.162984  7.5830984 7.688896 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.045641   -3.9609175  -3.856226   -3.7511225  -3.665946   -3.6384554
0:  -3.656804   -3.7487774  -3.818469   -3.8390837  -3.8448439  -3.9397287
0:  -4.065815   -4.0095043  -3.6309433  -2.641797   -1.0252504   0.87077045
0:   4.903048    6.105507  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.380165 16.318806 16.281408 16.240192 16.162815 16.075096 15.995696
0:  15.878988 15.787992 15.696716 15.539454 15.355204 15.177923 14.952534
0:  14.727728 14.449552 14.17576  13.938122 13.558933 13.420486]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.514847 -8.694908 -8.878201 -9.030863 -9.134367 -9.227417 -9.24416
0:  -9.264584 -9.225571 -9.12187  -8.987448 -8.852238 -8.73353  -8.60688
0:  -8.535858 -8.447346 -8.34774  -8.2341   -8.777748 -8.785143]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-5.657696  -5.5302916 -5.3363037 -5.1927204 -5.155774  -5.3063793
0:  -5.6495075 -6.146593  -6.6180344 -6.983533  -7.088372  -6.996112
0:  -6.6873693 -6.2187996 -5.7660036 -5.3763885 -5.128585  -4.995413
0:  -5.262084  -5.341365 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [23.391874 22.851137 22.074905 21.12998  20.274796 19.727894 19.724287
0:  20.323317 21.548264 23.1905   24.924297 26.350538 27.3068   27.624285
0:  27.368122 26.76922  26.055042 25.456306 24.6832   25.073866]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [15.152607 15.290739 15.555482 15.837119 16.064491 16.272305 16.45866
0:  16.551872 16.65447  16.779331 16.823776 16.8423   16.92698  17.009346
0:  17.135569 17.244236 17.368729 17.535591 17.208044 17.241753]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.1849165 10.158094  10.129425  10.128948  10.185049  10.353813
0:  10.650937  10.980936  11.355065  11.709985  12.054022  12.365567
0:  12.684963  12.984592  13.25796   13.482318  13.645911  13.675814
0:  13.2802925 13.321287 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.61743  26.714125 26.761648 26.668293 26.508482 26.282478 26.025646
0:  25.681185 25.369606 25.025707 24.657063 24.24541  23.843493 23.434532
0:  22.986614 22.56273  22.169796 21.789516 20.260141 20.102825]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-19.037207 -18.969995 -18.81927  -18.606419 -18.38642  -18.229597
0:  -18.034645 -17.91085  -17.788383 -17.658266 -17.52897  -17.406336
0:  -17.252626 -17.094843 -16.917555 -16.73414  -16.58953  -16.462904
0:  -16.639593 -16.530037]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [28.131413 28.153362 28.160957 28.058128 27.88034  27.57777  27.175953
0:  26.619701 25.98082  25.28122  24.48988  23.686749 22.973465 22.358757
0:  21.927706 21.609863 21.404808 21.260374 21.45364  21.313393]
0: validation loss for strategy=forecast at epoch 19 : nan
0: validation loss for velocity_u : 0.033356923609972
0: validation loss for velocity_v : 0.06192298233509064
0: validation loss for specific_humidity : 0.02383369766175747
0: validation loss for velocity_z : 0.4527808129787445
0: validation loss for temperature : 0.07479438185691833
0: validation loss for total_precip : nan
0: 20 : 11:06:50 :: batch_size = 96, lr = 1.2823318186821183e-05
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: [DEBUG] Epoch 20, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.1911, -1.2079, -1.2142, -1.2248, -1.2467, -1.2816, -1.3314, -1.3598, -1.3345, -1.2825, -1.2443, -1.2387,
0:         -1.2730, -1.3173, -1.3290, -1.2807, -1.1709, -1.0602, -1.1886, -1.2073, -1.2058, -1.2055, -1.2123, -1.2348,
0:         -1.2803], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1034, -0.1086, -0.1127, -0.1229, -0.1423, -0.1751, -0.1900, -0.1546, -0.0812, -0.0072,  0.0314,  0.0361,
0:          0.0355,  0.0473,  0.0640,  0.0616,  0.0318, -0.0131, -0.0340,  0.0120,  0.0443,  0.0491,  0.0290, -0.0087,
0:         -0.0441], device='cuda:1')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.3129, 0.4510, 0.6330, 0.8084, 0.9571, 1.0126, 0.8996, 0.9009, 0.9484, 1.1545, 1.1890, 0.9479, 0.4848, 0.2869,
0:         0.2635, 0.2670, 0.2415, 0.1314, 0.1877, 0.3092, 0.5103, 0.7040, 0.8154, 0.8565, 0.8575], device='cuda:2')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.4188,  0.3855,  0.4366,  0.2953, -0.0595,  0.0117,  0.5924,  1.0118,  1.1320,  0.6358, -0.0562, -0.0996,
0:          0.1730,  0.4244,  0.4244, -0.1241, -1.1554, -2.2590,  0.5891,  0.5401,  0.6536,  0.6825,  0.3410,  0.0595,
0:          0.3955], device='cuda:3')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([ 0.0734,  0.0238, -0.0711, -0.1618, -0.3616, -0.5368, -0.5149, -0.4994, -0.5432, -0.5215, -0.4149, -0.2911,
0:         -0.2546, -0.4269, -0.7525, -0.9824, -0.9308, -0.4339,  0.3520,  0.9864,  1.0163,  0.3975, -0.2515, -0.5689,
0:         -0.6949], device='cuda:3')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0')
0: [DEBUG] Epoch 20, batch 0 - Sparse-masked 'total_precip' shape target data: torch.Size([13824, 243])
0: [DEBUG] First 243 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2481,     nan, -0.2481,     nan,     nan, -0.2481,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2481, -0.2481,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan, -0.2481,     nan,     nan,     nan, -0.2481,     nan, -0.2481,     nan,     nan,     nan, -0.2481,
0:             nan,     nan,     nan,     nan,     nan, -0.2481,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2481, -0.2481,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.2481, -0.2481,     nan,     nan, -0.2481,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.2481,     nan, -0.2481,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2481,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2481,     nan,     nan,     nan,
0:             nan, -0.2481, -0.2481, -0.2481,     nan,     nan, -0.2481,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.2481,     nan, -0.2481,     nan,     nan,     nan,     nan, -0.2481,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2481,     nan, -0.2481,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2481,     nan,     nan,     nan, -0.2481,
0:             nan,     nan,     nan,     nan,     nan, -0.2481,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan])
0: [DEBUG] Epoch 20, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-1.0947, -1.1108, -1.1254, -1.1335, -1.1328, -1.1294, -1.1180, -1.1074, -1.0969, -1.0870, -1.0814, -1.0813,
0:         -1.0907, -1.1040, -1.1259, -1.1458, -1.1606, -1.1686, -1.0685, -1.0852, -1.1012, -1.1115, -1.1131, -1.1093,
0:         -1.0978], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.1240, 0.1322, 0.1430, 0.1537, 0.1645, 0.1765, 0.1853, 0.1952, 0.2066, 0.2166, 0.2249, 0.2277, 0.2245, 0.2146,
0:         0.1965, 0.1767, 0.1553, 0.1393, 0.1278, 0.1495, 0.1759, 0.2025, 0.2275, 0.2446, 0.2555], device='cuda:1',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([-0.2221, -0.1285,  0.0122,  0.1777,  0.3297,  0.4485,  0.5251,  0.5707,  0.5817,  0.5687,  0.5323,  0.4721,
0:          0.3932,  0.2927,  0.1695,  0.0628, -0.0270, -0.0792, -0.0635,  0.0786,  0.2739,  0.4701,  0.6349,  0.7412,
0:          0.7940], device='cuda:2', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([17280, 972])
0:      first 25 pred values: tensor([0.4007, 0.3899, 0.3342, 0.3255, 0.3850, 0.4637, 0.4720, 0.4360, 0.4522, 0.4539, 0.4672, 0.5242, 0.4861, 0.4201,
0:         0.4013, 0.3379, 0.3090, 0.3465, 0.3358, 0.3330, 0.3260, 0.3756, 0.4159, 0.4958, 0.5429], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([7680, 2187])
0:      first 25 pred values: tensor([1.5732, 1.5220, 1.3734, 1.1318, 0.8400, 0.5659, 0.3704, 0.2832, 0.2943, 0.3700, 0.4739, 0.5863, 0.6976, 0.7994,
0:         0.8764, 0.9143, 0.9146, 0.9057, 0.9244, 0.9886, 1.0925, 1.1978, 1.2686, 1.2852, 1.2562], device='cuda:3',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([13824, 243])
0:      first 25 pred values: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
0:        device='cuda:0', grad_fn=<SliceBackward0>)
0: velocity_u: 0.052493173629045486; velocity_v: 0.08853568881750107; specific_humidity: 0.03581532463431358; velocity_z: 0.4995594024658203; temperature: 0.09549161046743393; total_precip: nan; 
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.047019489109516144; velocity_v: 0.081487275660038; specific_humidity: 0.04062218591570854; velocity_z: 0.43034353852272034; temperature: 0.09828700125217438; total_precip: nan; 
0: epoch: 20 [1/5 (20%)]	Loss: nan : nan :: 0.13418 (2.87 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.08489324152469635; velocity_v: 0.13925771415233612; specific_humidity: 0.05050065368413925; velocity_z: 0.6246287226676941; temperature: 0.11746226996183395; total_precip: nan; 
0: epoch: 20 [2/5 (40%)]	Loss: nan : nan :: 0.16674 (16.20 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.056514594703912735; velocity_v: 0.09250253438949585; specific_humidity: 0.03348401188850403; velocity_z: 0.48266810178756714; temperature: 0.08273638784885406; total_precip: nan; 
0: epoch: 20 [3/5 (60%)]	Loss: nan : nan :: 0.14044 (16.06 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: velocity_u: 0.06311142444610596; velocity_v: 0.09503892064094543; specific_humidity: 0.041302621364593506; velocity_z: 0.4316699206829071; temperature: 0.14450614154338837; total_precip: nan; 
0: epoch: 20 [4/5 (80%)]	Loss: nan : nan :: 0.14562 (16.33 s/sec)
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: 
0: [DEBUG] Denormalized values for total_precip:
0: Source values (first 200):
0: [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 9.5367432e-07 9.5367432e-07 9.5367432e-07
0:  9.5367432e-07 9.5844263e-04 1.9741058e-03 9.5367432e-07 6.6757202e-06
0:  2.8610229e-05 3.2424927e-05 3.0708313e-04 2.9850006e-04 4.6730042e-05
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 9.5367432e-07 0.0000000e+00 0.0000000e+00
0:  0.0000000e+00 0.0000000e+00 7.6293945e-06 2.5749207e-05 2.8610229e-05]
0: Target values (first 200):
0: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0:  0. 0. 0. 0. 0. 0. 0. 0.]
0: Prediction values (first 20):
0: [10.562826 10.639873 10.697702 10.712044 10.727928 10.740858 10.773539
0:  10.78032  10.789936 10.792824 10.756225 10.645742 10.509444 10.351414
0:  10.198351 10.120708 10.151586 10.299724 11.107093 11.197683]
0: [DEBUG] Validation prediction values for 'velocity_u' with shape: torch.Size([180, 972])
0:          min = -1.843, max = 3.271, mean = 0.331
0:          sample (first 20): tensor([0.3249, 0.3314, 0.3363, 0.3375, 0.3389, 0.3400, 0.3427, 0.3433, 0.3441, 0.3444, 0.3413, 0.3319, 0.3204, 0.3070,
0:         0.2941, 0.2875, 0.2901, 0.3027, 0.3876, 0.3967])
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 6.2347097  6.620144   7.130644   7.593296   7.9987574  8.252626
0:   8.381413   8.393141   8.394316   8.461958   8.626622   8.885175
0:   9.226746   9.648458  10.082376  10.583121  11.117417  11.668614
0:  12.349022  12.609694 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [22.22764  22.239773 22.2083   22.166037 22.14234  22.14312  22.200817
0:  22.240278 22.359276 22.514246 22.655334 22.776905 22.8845   22.95858
0:  23.042183 23.137506 23.29613  23.514168 23.82133  23.979761]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.445839 13.578685 13.722    13.766834 13.799095 13.791376 13.797262
0:  13.790564 13.844728 13.918885 13.98873  14.006676 13.995659 13.910227
0:  13.757953 13.638575 13.632645 13.682943 13.738621 13.845091]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.4092941 -2.345272  -2.30118   -2.2617216 -2.2743368 -2.3275118
0:  -2.393036  -2.4964924 -2.5627966 -2.596654  -2.6171856 -2.6335459
0:  -2.6223812 -2.6131039 -2.604085  -2.5850582 -2.5573177 -2.4784012
0:  -2.5684204 -2.5009747]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [2.1439044 2.044042  2.0353117 2.056644  2.0692768 2.0579686 2.033265
0:  1.9466763 1.9286895 1.9029064 1.9064078 1.8931861 1.9000206 1.8961287
0:  1.8489408 1.7896256 1.6976242 1.6018319 1.1708007 1.050323 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-0.6177983  -0.81937647 -1.0267777  -1.1478381  -1.2155805  -1.3404913
0:  -1.4737387  -1.7664518  -2.0824661  -2.4373198  -2.7612429  -3.0619116
0:  -3.2748585  -3.4196587  -3.539935   -3.5333652  -3.3808193  -3.0739012
0:  -3.142023   -2.8215075 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.1779165 -1.2743211 -1.3139057 -1.3829155 -1.4530611 -1.5911841
0:  -1.7431531 -1.9696231 -2.2297392 -2.5228877 -2.8477302 -3.2340703
0:  -3.6702085 -4.1208167 -4.661713  -5.216434  -5.7919908 -6.325585
0:  -7.9508853 -8.429895 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.6971612  -2.4937978  -2.2316413  -1.9992871  -1.7995481  -1.6667886
0:  -1.5844536  -1.5768533  -1.594532   -1.5997524  -1.5742698  -1.5270791
0:  -1.428287   -1.258534   -1.0796561  -0.8524003  -0.60905933 -0.38386774
0:  -0.322865   -0.2946329 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [5.4099827 5.261283  5.083381  4.848123  4.5983834 4.3470144 4.1206665
0:  3.9211366 3.7718756 3.6803293 3.6663487 3.6623795 3.689848  3.750817
0:  3.7990346 3.8803174 3.9958    4.141529  3.6659107 3.6234012]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-1.9635057  -1.8295684  -1.6613116  -1.49054    -1.3167768  -1.1580195
0:  -1.0040612  -0.8825908  -0.7466631  -0.61207676 -0.4606614  -0.33461905
0:  -0.23339748 -0.14599514 -0.11665916 -0.10227633 -0.08423519 -0.0535531
0:  -0.4378729  -0.55766773]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [37.438786 37.534523 37.638554 37.793022 37.863605 37.894127 37.879917
0:  37.77575  37.77423  37.700077 37.56249  37.481655 37.4476   37.528355
0:  37.556507 37.46358  37.251675 36.84945  38.284645 38.476723]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.5758395 3.8081176 4.043272  4.3036156 4.546154  4.7616315 4.996503
0:  5.1839743 5.352209  5.521692  5.622093  5.744793  5.8510222 5.9277067
0:  6.0072923 5.9934382 5.906827  5.7617397 4.7693133 4.80032  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.2153645 4.3197765 4.436988  4.5532675 4.648489  4.685715  4.686655
0:  4.654278  4.6527963 4.6903644 4.788011  4.9159737 5.0905266 5.2803607
0:  5.478606  5.6431518 5.7569714 5.827573  6.0529494 6.019654 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.752396 16.95307  17.273066 17.520994 17.78533  17.992184 18.218636
0:  18.441072 18.751476 19.148499 19.615198 20.092035 20.552011 21.005188
0:  21.31267  21.631792 21.922909 22.175928 23.162798 23.267485]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.616262  10.6125145 10.62025   10.609158  10.602011  10.611951
0:  10.635052  10.627836  10.629595  10.608546  10.562239  10.477291
0:  10.3903265 10.308913  10.243177  10.20072   10.171673  10.140324
0:  10.0951    10.042927 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 0.81022596  0.69275904  0.5523248   0.39461422  0.2275176   0.05283833
0:  -0.10582495 -0.2843299  -0.44904757 -0.5892582  -0.70159245 -0.8049512
0:  -0.86479187 -0.9026294  -0.9141326  -0.89878845 -0.85754013 -0.78045034
0:  -0.89718866 -0.960711  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.362583  6.4375944 6.5012503 6.52479   6.5184875 6.4933906 6.4820156
0:  6.4586916 6.475704  6.4723    6.45272   6.380623  6.302738  6.205766
0:  6.115875  6.051784  6.0586023 6.1167207 5.5538483 5.511996 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-9.1838837e-04  3.8554335e-01  8.3227205e-01  1.3741598e+00
0:   2.0256553e+00  2.7266767e+00  3.5207393e+00  4.3050604e+00
0:   5.1220255e+00  5.9358864e+00  6.8057709e+00  7.6933870e+00
0:   8.6492529e+00  9.6480312e+00  1.0621620e+01  1.1553513e+01
0:   1.2432046e+01  1.3177461e+01  1.3987808e+01  1.4657469e+01]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.0753446  -2.5839467  -1.8992028  -1.1221657  -0.29049158  0.5195446
0:   1.3904243   2.1973758   3.0664678   3.9832122   4.9530554   5.9935174
0:   7.1302824   8.2786045   9.392384   10.362495   11.16613    11.80863
0:  10.797747   11.169522  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.2064514 -3.9319134 -3.529539  -3.0658655 -2.582285  -2.2164574
0:  -1.9918952 -1.9794855 -2.0930452 -2.292738  -2.5099611 -2.8146658
0:  -3.138589  -3.4753475 -3.8883505 -4.189211  -4.3598967 -4.3629713
0:  -4.4353113 -4.3413553]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-2.2894597 -2.365683  -2.3978763 -2.3963876 -2.382547  -2.3743424
0:  -2.3669543 -2.3664327 -2.3442693 -2.3125787 -2.2379289 -2.1625447
0:  -2.0580363 -1.9428782 -1.8308206 -1.7656255 -1.7712073 -1.8044248
0:  -1.6865335 -1.6235509]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-12.609948  -12.569627  -12.53847   -12.526414  -12.50311   -12.409802
0:  -12.082318  -11.581079  -10.826005   -9.921952   -8.975963   -8.125858
0:   -7.4323263  -6.899273   -6.580679   -6.38519    -6.274103   -6.191306
0:   -6.069294   -5.901663 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-13.722534  -13.677359  -13.663395  -13.617485  -13.592276  -13.6230545
0:  -13.609062  -13.663748  -13.727062  -13.787773  -13.847929  -13.887329
0:  -13.907623  -13.898491  -13.865919  -13.846733  -13.854164  -13.808853
0:  -14.144962  -14.102404 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 6.894908   7.3090186  7.81404    8.338188   8.903206   9.491743
0:  10.10634   10.680883  11.246947  11.788507  12.291178  12.710617
0:  13.098355  13.434267  13.744872  14.0473    14.348222  14.606478
0:  14.3937    14.697388 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [3.9163191 3.9199164 3.9518266 4.0490704 4.19625   4.3578744 4.545385
0:  4.6966286 4.861808  5.0082836 5.153106  5.3025503 5.4809775 5.684732
0:  5.902681  6.1161757 6.334601  6.5502195 6.5082    6.588614 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [13.5559635 13.442592  13.260935  12.914551  12.484859  11.896681
0:  11.140869  10.2199135  9.265458   8.300002   7.4081216  6.617102
0:   5.964592   5.4565034  5.1060224  4.958252   4.976982   5.0962343
0:   5.683777   5.8081584]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -7.668587   -7.471947   -7.2389092  -7.089994   -7.0786414  -7.2887435
0:   -7.6785665  -8.223709   -8.796495   -9.34429    -9.819532  -10.212984
0:  -10.515091  -10.755371  -10.873087  -10.931414  -10.919909  -10.851727
0:   -9.900724   -9.407421 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-3.4242148 -3.377932  -3.2953687 -3.204702  -3.1310668 -3.0868878
0:  -3.0204167 -2.9873204 -2.8919683 -2.734385  -2.5895982 -2.4837298
0:  -2.3787332 -2.3378158 -2.3358521 -2.3171935 -2.236607  -2.0675273
0:  -2.1042666 -2.0697875]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [26.020716 26.159294 26.348572 26.549292 26.73993  26.93113  27.183329
0:  27.354496 27.571157 27.771084 27.856474 27.897234 27.91176  27.905502
0:  27.895449 27.862318 27.783009 27.648998 27.647522 27.469488]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.117379  7.2703843 7.471478  7.6613884 7.864145  8.025089  8.108425
0:  8.067061  7.93816   7.7543645 7.5782976 7.4319143 7.3952713 7.430238
0:  7.5079727 7.623299  7.7655635 7.9273148 7.7156467 8.061212 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [16.88091  16.95587  17.034504 17.060183 17.077713 17.087769 17.11253
0:  17.10529  17.125107 17.154877 17.19994  17.226467 17.265213 17.300219
0:  17.303509 17.333696 17.37463  17.432793 17.407593 17.362455]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ -8.795956  -8.740014  -8.694201  -8.686245  -8.712365  -8.796288
0:   -8.880922  -9.021347  -9.13567   -9.226696  -9.307837  -9.409059
0:   -9.495683  -9.542308  -9.632947  -9.688079  -9.796687  -9.884734
0:  -10.170108 -10.090985]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-4.193193  -4.2103343 -4.2338843 -4.2685275 -4.324289  -4.414602
0:  -4.494654  -4.603616  -4.699674  -4.7706065 -4.828398  -4.9017386
0:  -4.9678836 -5.0054383 -5.054936  -5.054152  -5.025945  -4.9650626
0:  -5.310119  -5.290172 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [11.610031  11.648457  11.682276  11.668659  11.657707  11.632609
0:  11.6218195 11.594418  11.615551  11.651218  11.684847  11.6884
0:  11.693103  11.677658  11.639824  11.652652  11.70874   11.788369
0:  11.528527  11.575137 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [10.349021 10.560008 10.974447 11.544964 12.255719 13.029233 13.873659
0:  14.715287 15.534651 16.298016 16.88349  17.17058  17.158087 16.891554
0:  16.43806  15.968306 15.528591 15.195097 15.354133 15.524374]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.8757756   2.642465    2.4384437   2.2714891   2.1585984   2.0407715
0:   1.9247975   1.7410178   1.5346828   1.2745891   0.9583883   0.5747442
0:   0.16067696 -0.27215338 -0.70213604 -1.0797219  -1.3767862  -1.6079907
0:  -2.860314   -2.778173  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [4.6270504 4.6454144 4.6631513 4.6881804 4.712756  4.71918   4.743046
0:  4.73069   4.754622  4.7757616 4.783674  4.775754  4.771911  4.752385
0:  4.735148  4.7396116 4.7519608 4.8035707 4.699456  4.72712  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 2.0628657   2.2007127   2.2845464   2.3716097   2.4045467   2.334056
0:   2.1726398   1.9050522   1.5684977   1.1915388   0.7449999   0.28536558
0:  -0.17546129 -0.72197676 -1.3201547  -2.0034337  -2.764668   -3.4759002
0:  -4.836078   -4.6303296 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.6315026   0.82023907 -0.01832008 -0.6725745  -1.0767422  -1.3336692
0:  -1.5271182  -1.8144145  -2.1526852  -2.4360209  -2.5636854  -2.5095825
0:  -2.3238888  -2.0507584  -1.873898   -1.7893081  -1.788477   -1.8326554
0:  -2.0954733  -2.4017286 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 9.282923  9.296638  9.330018  9.395942  9.46372   9.521591  9.61001
0:   9.66708   9.730143  9.778062  9.791615  9.7907    9.802459  9.844139
0:   9.907866 10.004927 10.083158 10.162666  9.687523  9.6829  ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [-8.528259  -8.388904  -8.23277   -8.077601  -7.9771814 -7.942498
0:  -7.885865  -7.9079227 -7.9343157 -7.950824  -7.9931526 -7.9917517
0:  -7.89225   -7.8039694 -7.698516  -7.6685762 -7.7325907 -7.8803377
0:  -7.588044  -7.4231443]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [ 1.1604662   1.1035872   1.0457177   0.97440624  0.88428926  0.76109505
0:   0.6555848   0.5237918   0.40568638  0.3056035   0.19996214  0.0648365
0:  -0.06636333 -0.17650414 -0.2912283  -0.3510208  -0.4144292  -0.45960903
0:  -0.819077   -0.8702965 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [6.064874  6.0438643 6.0253577 6.025258  6.0204687 6.0298877 6.0740414
0:  6.0987325 6.1421275 6.177331  6.2081456 6.2295547 6.293929  6.37762
0:  6.507111  6.6667395 6.8480973 7.059215  7.3051033 7.4636507]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [7.1567874 7.229816  7.2824173 7.3321753 7.3549514 7.3552814 7.3964415
0:  7.4078126 7.44772   7.4902654 7.5218215 7.547588  7.593634  7.6302705
0:  7.659607  7.6857295 7.7052402 7.722488  7.553965  7.6411657]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
0: Prediction values (first 20):
0: [21.668562 21.793865 21.92815  22.106115 22.277931 22.426216 22.570957
0:  22.540058 22.542755 22.4999   22.416046 22.310669 22.231491 22.164108
0:  22.16523  22.195473 22.250923 22.439255 22.089588 22.31247 ]
0: [DEBUG] Masked all input tokens for field 'total_precip'
0: Created sparse mask for total_precip with 10.0% data retained
