0: Wandb run: atmorep-skplvp5a-18524597
0: l50003:1836456:1836456 [0] NCCL INFO Bootstrap : Using ib0:10.128.11.108<0>
0: l50003:1836456:1836456 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
0: l50003:1836456:1836456 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
0: l50003:1836456:1836456 [0] NCCL INFO NET/Plugin: Using internal network plugin.
0: l50003:1836456:1836456 [0] NCCL INFO cudaDriverVersion 12060
0: NCCL version 2.21.5+cuda12.4
1: l50027:815174:815174 [0] NCCL INFO cudaDriverVersion 12060
1: l50027:815174:815174 [0] NCCL INFO Bootstrap : Using ib0:10.128.11.124<0>
1: l50027:815174:815174 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
1: l50027:815174:815174 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
1: l50027:815174:815174 [0] NCCL INFO NET/Plugin: Using internal network plugin.
0: l50003:1836456:1836974 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:10.128.11.108<0>
0: l50003:1836456:1836974 [0] NCCL INFO Using non-device net plugin version 0
0: l50003:1836456:1836974 [0] NCCL INFO Using network IB
1: l50027:815174:815413 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:10.128.11.124<0>
1: l50027:815174:815413 [0] NCCL INFO Using non-device net plugin version 0
1: l50027:815174:815413 [0] NCCL INFO Using network IB
0: l50003:1836456:1836974 [0] NCCL INFO DMA-BUF is available on GPU device 0
1: l50027:815174:815413 [0] NCCL INFO DMA-BUF is available on GPU device 0
0: l50003:1836456:1836974 [0] NCCL INFO ncclCommInitRank comm 0x55555f0e84a0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 3000 commId 0x9e48f41dc4e5dc30 - Init START
1: l50027:815174:815413 [0] NCCL INFO ncclCommInitRank comm 0x55555ec9f650 rank 1 nranks 2 cudaDev 0 nvmlDev 0 busId 3000 commId 0x9e48f41dc4e5dc30 - Init START
1: l50027:815174:815413 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
0: l50003:1836456:1836974 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
0: l50003:1836456:1836974 [0] NCCL INFO comm 0x55555f0e84a0 rank 0 nRanks 2 nNodes 2 localRanks 1 localRank 0 MNNVL 0
0: l50003:1836456:1836974 [0] NCCL INFO Channel 00/04 :    0   1
0: l50003:1836456:1836974 [0] NCCL INFO Channel 01/04 :    0   1
0: l50003:1836456:1836974 [0] NCCL INFO Channel 02/04 :    0   1
0: l50003:1836456:1836974 [0] NCCL INFO Channel 03/04 :    0   1
0: l50003:1836456:1836974 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] -1/-1/-1->0->1 [3] -1/-1/-1->0->1
0: l50003:1836456:1836974 [0] NCCL INFO P2P Chunksize set to 131072
1: l50027:815174:815413 [0] NCCL INFO comm 0x55555ec9f650 rank 1 nRanks 2 nNodes 2 localRanks 1 localRank 0 MNNVL 0
1: l50027:815174:815413 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] 0/-1/-1->1->-1 [3] 0/-1/-1->1->-1
1: l50027:815174:815413 [0] NCCL INFO P2P Chunksize set to 131072
0: l50003:1836456:1836974 [0] NCCL INFO Channel 00/0 : 1[0] -> 0[0] [receive] via NET/IB/0
0: l50003:1836456:1836974 [0] NCCL INFO Channel 01/0 : 1[0] -> 0[0] [receive] via NET/IB/1
0: l50003:1836456:1836974 [0] NCCL INFO Channel 02/0 : 1[0] -> 0[0] [receive] via NET/IB/0
0: l50003:1836456:1836974 [0] NCCL INFO Channel 03/0 : 1[0] -> 0[0] [receive] via NET/IB/1
0: l50003:1836456:1836974 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[0] [send] via NET/IB/0
0: l50003:1836456:1836974 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[0] [send] via NET/IB/1
1: l50027:815174:815413 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[0] [receive] via NET/IB/0
0: l50003:1836456:1836974 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[0] [send] via NET/IB/0
0: l50003:1836456:1836974 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[0] [send] via NET/IB/1
1: l50027:815174:815413 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[0] [receive] via NET/IB/1
1: l50027:815174:815413 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[0] [receive] via NET/IB/0
1: l50027:815174:815413 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[0] [receive] via NET/IB/1
1: l50027:815174:815413 [0] NCCL INFO Channel 00/0 : 1[0] -> 0[0] [send] via NET/IB/0
1: l50027:815174:815413 [0] NCCL INFO Channel 01/0 : 1[0] -> 0[0] [send] via NET/IB/1
1: l50027:815174:815413 [0] NCCL INFO Channel 02/0 : 1[0] -> 0[0] [send] via NET/IB/0
1: l50027:815174:815413 [0] NCCL INFO Channel 03/0 : 1[0] -> 0[0] [send] via NET/IB/1
1: l50027:815174:815416 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 250.
1: l50027:815174:815416 [0] NCCL INFO NCCL_IB_RETRY_CNT set by environment to 50.
0: l50003:1836456:1836977 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 250.
0: l50003:1836456:1836977 [0] NCCL INFO NCCL_IB_RETRY_CNT set by environment to 50.
1: l50027:815174:815413 [0] NCCL INFO Connected all rings
1: l50027:815174:815413 [0] NCCL INFO Connected all trees
1: l50027:815174:815413 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
1: l50027:815174:815413 [0] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
0: l50003:1836456:1836974 [0] NCCL INFO Connected all rings
0: l50003:1836456:1836974 [0] NCCL INFO Connected all trees
0: l50003:1836456:1836974 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
0: l50003:1836456:1836974 [0] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
0: l50003:1836456:1836974 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
0: l50003:1836456:1836974 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
0: l50003:1836456:1836974 [0] NCCL INFO ncclCommInitRank comm 0x55555f0e84a0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 3000 commId 0x9e48f41dc4e5dc30 - Init COMPLETE
1: l50027:815174:815413 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
1: l50027:815174:815413 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
1: l50027:815174:815413 [0] NCCL INFO ncclCommInitRank comm 0x55555ec9f650 rank 1 nranks 2 cudaDev 0 nvmlDev 0 busId 3000 commId 0x9e48f41dc4e5dc30 - Init COMPLETE
0: with_ddp : True
0: num_accs_per_task : 1
0: par_rank : 0
0: par_size : 2
0: fields : [['velocity_u', [1, 1024, ['velocity_v', 'temperature'], 0, ['j8dwr5qj', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.5, 0.9, 0.2, 0.05]], ['velocity_v', [1, 1024, ['velocity_u', 'temperature'], 0, ['0tlnm5up', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.5, 0.9, 0.2, 0.05]], ['specific_humidity', [1, 1024, ['velocity_u', 'velocity_v', 'temperature'], 0, ['v63l01zu', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.5, 0.9, 0.2, 0.05]], ['velocity_z', [1, 1024, ['velocity_u', 'velocity_v', 'temperature'], 0, ['9l1errbo', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.5, 0.9, 0.2, 0.05]], ['temperature', [1, 1024, ['velocity_u', 'velocity_v', 'specific_humidity'], 0, ['7ojls62c', -2]], [96, 105, 114, 123, 137], [12, 2, 4], [3, 27, 27], [0.5, 0.9, 0.2, 0.05], 'Local'], ['total_precip', [1, 1024, ['velocity_u', 'velocity_v', 'velocity_z', 'specific_humidity'], 0], [0], [12, 6, 12], [3, 9, 9], [0.25, 0.9, 0.1, 0.05]], ['t2m', [1, 1024, ['velocity_u', '
0: velocity_v', 'velocity_z', 'specific_humidity'], 0], [0], [12, 2, 4], [3, 27, 27], [0.5, 0.9, 0.2, 0.05], 'Local']]
0: fields_prediction : [['velocity_u', 0.225], ['velocity_v', 0.225], ['specific_humidity', 0.1125], ['velocity_z', 0.01875], ['temperature', 0.15], ['total_precip', 0.01875], ['t2m', 0.25]]
0: fields_targets : []
0: years_train : [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]
0: years_val : [2021]
0: month : None
0: geo_range_sampling : [[0.0, 360.0], [0.0, 360.0]]
0: time_sampling : 1
0: torch_seed : 5521420987310380410
0: batch_size_validation : 1
0: batch_size : 96
0: num_epochs : 128
0: num_samples_per_epoch : 480
0: num_samples_validate : 128
0: num_loader_workers : 5
0: size_token_info : 8
0: size_token_info_net : 16
0: grad_checkpointing : True
0: with_cls : False
0: with_mixed_precision : True
0: with_layernorm : True
0: coupling_num_heads_per_field : 1
0: dropout_rate : 0.05
0: with_qk_lnorm : True
0: encoder_num_layers : 6
0: encoder_num_heads : 16
0: encoder_num_mlp_layers : 2
0: encoder_att_type : dense
0: decoder_num_layers : 6
0: decoder_num_heads : 16
0: decoder_num_mlp_layers : 2
0: decoder_self_att : False
0: decoder_cross_att_ratio : 0.5
0: decoder_cross_att_rate : 1.0
0: decoder_att_type : dense
0: net_tail_num_nets : 16
0: net_tail_num_layers : 0
0: losses : ['mse_ensemble']
0: optimizer_zero : False
0: lr_start : 1e-05
0: lr_max : 2e-05
0: lr_min : 1e-05
0: weight_decay : 0.025
0: lr_decay_rate : 1.025
0: lr_start_epochs : 3
0: model_log_frequency : 256
0: BERT_strategy : BERT
0: forecast_num_tokens : 2
0: BERT_fields_synced : False
0: BERT_mr_max : 2
0: log_test_num_ranks : 0
0: save_grads : False
0: profile : False
0: test_initial : False
0: attention : False
0: rng_seed : None
0: with_wandb : True
0: slurm_job_id : 18524597
0: wandb_id : skplvp5a
0: file_path : /work/ab1412/atmorep/data/era5_y2010_2020_res25_with_t2m.zarr
0: n_size : [36, 13.5, 27.0]
0: model_id : wc5e2i3t
0: sparse_target : True
0: sparse_target_field : t2m
0: sparse_target_sparsity : 0.9
0: mask_input_field : t2m
0: mask_input_value : 0
0: years_test : [2021]
1: Available keys in the Zarr dataset: ['data', 'data_sfc', 'lats', 'lons', 'time']
1: self.ds['data'] : (105192, 7, 5, 721, 1440) :: (105192,)
1: self.lats : (721,)
1: self.lons : (1440,)
0: Available keys in the Zarr dataset: ['data', 'data_sfc', 'lats', 'lons', 'time']
0: self.ds['data'] : (105192, 7, 5, 721, 1440) :: (105192,)
0: self.lats : (721,)
0: self.lons : (1440,)
1: Available keys in the Zarr dataset: ['data', 'data_sfc', 'lats', 'lons', 'time']
0: Available keys in the Zarr dataset: ['data', 'data_sfc', 'lats', 'lons', 'time']
1: self.ds['data'] : (105192, 7, 5, 721, 1440) :: (105192,)
1: self.lats : (721,)
1: self.lons : (1440,)
0: self.ds['data'] : (105192, 7, 5, 721, 1440) :: (105192,)
0: self.lats : (721,)
0: self.lons : (1440,)
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: Loaded AtmoRep: ignoring 208 elements: ['embeds_token_info.6.weight', 'embeds_token_info.6.bias', 'embeds.6.weight', 'embeds.6.bias', 'encoders.6.embed.weight', 'encoders.6.embed.bias', 'encoders.6.heads.0.proj_out.weight', 'encoders.6.heads.0.proj_heads.weight', 'encoders.6.heads.0.proj_heads_other.0.weight', 'encoders.6.heads.0.proj_heads_other.1.weight', 'encoders.6.heads.0.proj_heads_other.2.weight', 'encoders.6.heads.0.proj_heads_other.3.weight', 'encoders.6.heads.0.proj_heads_other.4.weight', 'encoders.6.heads.1.proj_out.weight', 'encoders.6.heads.1.proj_heads.weight', 'encoders.6.heads.1.proj_heads_other.0.weight', 'encoders.6.heads.1.proj_heads_other.1.weight', 'encoders.6.heads.1.proj_heads_other.2.weight', 'encoders.6.heads.1.proj_heads_other.3.weight', 'encoders.6.heads.1.proj_heads_other.4.weight', 'encoders.6.heads.2.proj_out.weight', 'encoders.6.heads.2.proj_heads.weight', 'encoders.6.heads.2.proj_heads_other.0.weight', 'encoders.6.heads.2.proj_heads_other.1.weight', 'encoders.6.heads.2.proj_hea
1: ds_other.2.weight', 'encoders.6.heads.2.proj_heads_other.3.weight', 'encoders.6.heads.2.proj_heads_other.4.weight', 'encoders.6.heads.3.proj_out.weight', 'encoders.6.heads.3.proj_heads.weight', 'encoders.6.heads.3.proj_heads_other.0.weight', 'encoders.6.heads.3.proj_heads_other.1.weight', 'encoders.6.heads.3.proj_heads_other.2.weight', 'encoders.6.heads.3.proj_heads_other.3.weight', 'encoders.6.heads.3.proj_heads_other.4.weight', 'encoders.6.heads.4.proj_out.weight', 'encoders.6.heads.4.proj_heads.weight', 'encoders.6.heads.4.proj_heads_other.0.weight', 'encoders.6.heads.4.proj_heads_other.1.weight', 'encoders.6.heads.4.proj_heads_other.2.weight', 'encoders.6.heads.4.proj_heads_other.3.weight', 'encoders.6.heads.4.proj_heads_other.4.weight', 'encoders.6.heads.5.proj_out.weight', 'encoders.6.heads.5.proj_heads.weight', 'encoders.6.heads.5.proj_heads_other.0.weight', 'encoders.6.heads.5.proj_heads_other.1.weight', 'encoders.6.heads.5.proj_heads_other.2.weight', 'encoders.6.heads.5.proj_heads_other.3.weight', 'e
1: ncoders.6.heads.5.proj_heads_other.4.weight', 'encoders.6.mlps.0.blocks.0.weight', 'encoders.6.mlps.0.blocks.0.bias', 'encoders.6.mlps.0.blocks.3.weight', 'encoders.6.mlps.0.blocks.3.bias', 'encoders.6.mlps.1.blocks.0.weight', 'encoders.6.mlps.1.blocks.0.bias', 'encoders.6.mlps.1.blocks.3.weight', 'encoders.6.mlps.1.blocks.3.bias', 'encoders.6.mlps.2.blocks.0.weight', 'encoders.6.mlps.2.blocks.0.bias', 'encoders.6.mlps.2.blocks.3.weight', 'encoders.6.mlps.2.blocks.3.bias', 'encoders.6.mlps.3.blocks.0.weight', 'encoders.6.mlps.3.blocks.0.bias', 'encoders.6.mlps.3.blocks.3.weight', 'encoders.6.mlps.3.blocks.3.bias', 'encoders.6.mlps.4.blocks.0.weight', 'encoders.6.mlps.4.blocks.0.bias', 'encoders.6.mlps.4.blocks.3.weight', 'encoders.6.mlps.4.blocks.3.bias', 'encoders.6.mlps.5.blocks.0.weight', 'encoders.6.mlps.5.blocks.0.bias', 'encoders.6.mlps.5.blocks.3.weight', 'encoders.6.mlps.5.blocks.3.bias', 'decoders.6.blocks.0.proj_heads.weight', 'decoders.6.blocks.0.proj_heads_o_q.weight', 'decoders.6.blocks.0.proj_he
1: ads_o_kv.weight', 'decoders.6.blocks.0.ln_q.weight', 'decoders.6.blocks.0.ln_q.bias', 'decoders.6.blocks.0.ln_k.weight', 'decoders.6.blocks.0.ln_k.bias', 'decoders.6.blocks.0.proj_out.weight', 'decoders.6.blocks.1.blocks.0.weight', 'decoders.6.blocks.1.blocks.0.bias', 'decoders.6.blocks.1.blocks.3.weight', 'decoders.6.blocks.1.blocks.3.bias', 'decoders.6.blocks.2.proj_heads.weight', 'decoders.6.blocks.2.proj_heads_o_q.weight', 'decoders.6.blocks.2.proj_heads_o_kv.weight', 'decoders.6.blocks.2.ln_q.weight', 'decoders.6.blocks.2.ln_q.bias', 'decoders.6.blocks.2.ln_k.weight', 'decoders.6.blocks.2.ln_k.bias', 'decoders.6.blocks.2.proj_out.weight', 'decoders.6.blocks.3.blocks.0.weight', 'decoders.6.blocks.3.blocks.0.bias', 'decoders.6.blocks.3.blocks.3.weight', 'decoders.6.blocks.3.blocks.3.bias', 'decoders.6.blocks.4.proj_heads.weight', 'decoders.6.blocks.4.proj_heads_o_q.weight', 'decoders.6.blocks.4.proj_heads_o_kv.weight', 'decoders.6.blocks.4.ln_q.weight', 'decoders.6.blocks.4.ln_q.bias', 'decoders.6.blocks.4
1: .ln_k.weight', 'decoders.6.blocks.4.ln_k.bias', 'decoders.6.blocks.4.proj_out.weight', 'decoders.6.blocks.5.blocks.0.weight', 'decoders.6.blocks.5.blocks.0.bias', 'decoders.6.blocks.5.blocks.3.weight', 'decoders.6.blocks.5.blocks.3.bias', 'decoders.6.blocks.6.proj_heads.weight', 'decoders.6.blocks.6.proj_heads_o_q.weight', 'decoders.6.blocks.6.proj_heads_o_kv.weight', 'decoders.6.blocks.6.ln_q.weight', 'decoders.6.blocks.6.ln_q.bias', 'decoders.6.blocks.6.ln_k.weight', 'decoders.6.blocks.6.ln_k.bias', 'decoders.6.blocks.6.proj_out.weight', 'decoders.6.blocks.7.blocks.0.weight', 'decoders.6.blocks.7.blocks.0.bias', 'decoders.6.blocks.7.blocks.3.weight', 'decoders.6.blocks.7.blocks.3.bias', 'decoders.6.blocks.8.proj_heads.weight', 'decoders.6.blocks.8.proj_heads_o_q.weight', 'decoders.6.blocks.8.proj_heads_o_kv.weight', 'decoders.6.blocks.8.ln_q.weight', 'decoders.6.blocks.8.ln_q.bias', 'decoders.6.blocks.8.ln_k.weight', 'decoders.6.blocks.8.ln_k.bias', 'decoders.6.blocks.8.proj_out.weight', 'decoders.6.blocks.
1: 9.blocks.0.weight', 'decoders.6.blocks.9.blocks.0.bias', 'decoders.6.blocks.9.blocks.3.weight', 'decoders.6.blocks.9.blocks.3.bias', 'decoders.6.blocks.10.proj_heads.weight', 'decoders.6.blocks.10.proj_heads_o_q.weight', 'decoders.6.blocks.10.proj_heads_o_kv.weight', 'decoders.6.blocks.10.ln_q.weight', 'decoders.6.blocks.10.ln_q.bias', 'decoders.6.blocks.10.ln_k.weight', 'decoders.6.blocks.10.ln_k.bias', 'decoders.6.blocks.10.proj_out.weight', 'decoders.6.blocks.11.blocks.0.weight', 'decoders.6.blocks.11.blocks.0.bias', 'decoders.6.blocks.11.blocks.3.weight', 'decoders.6.blocks.11.blocks.3.bias', 'tails.6.tail_nets.0.0.weight', 'tails.6.tail_nets.0.0.bias', 'tails.6.tail_nets.0.1.weight', 'tails.6.tail_nets.0.1.bias', 'tails.6.tail_nets.1.0.weight', 'tails.6.tail_nets.1.0.bias', 'tails.6.tail_nets.1.1.weight', 'tails.6.tail_nets.1.1.bias', 'tails.6.tail_nets.2.0.weight', 'tails.6.tail_nets.2.0.bias', 'tails.6.tail_nets.2.1.weight', 'tails.6.tail_nets.2.1.bias', 'tails.6.tail_nets.3.0.weight', 'tails.6.tail_ne
1: ts.3.0.bias', 'tails.6.tail_nets.3.1.weight', 'tails.6.tail_nets.3.1.bias', 'tails.6.tail_nets.4.0.weight', 'tails.6.tail_nets.4.0.bias', 'tails.6.tail_nets.4.1.weight', 'tails.6.tail_nets.4.1.bias', 'tails.6.tail_nets.5.0.weight', 'tails.6.tail_nets.5.0.bias', 'tails.6.tail_nets.5.1.weight', 'tails.6.tail_nets.5.1.bias', 'tails.6.tail_nets.6.0.weight', 'tails.6.tail_nets.6.0.bias', 'tails.6.tail_nets.6.1.weight', 'tails.6.tail_nets.6.1.bias', 'tails.6.tail_nets.7.0.weight', 'tails.6.tail_nets.7.0.bias', 'tails.6.tail_nets.7.1.weight', 'tails.6.tail_nets.7.1.bias', 'tails.6.tail_nets.8.0.weight', 'tails.6.tail_nets.8.0.bias', 'tails.6.tail_nets.8.1.weight', 'tails.6.tail_nets.8.1.bias', 'tails.6.tail_nets.9.0.weight', 'tails.6.tail_nets.9.0.bias', 'tails.6.tail_nets.9.1.weight', 'tails.6.tail_nets.9.1.bias', 'tails.6.tail_nets.10.0.weight', 'tails.6.tail_nets.10.0.bias', 'tails.6.tail_nets.10.1.weight', 'tails.6.tail_nets.10.1.bias', 'tails.6.tail_nets.11.0.weight', 'tails.6.tail_nets.11.0.bias', 'tails.6.tai
1: l_nets.11.1.weight', 'tails.6.tail_nets.11.1.bias', 'tails.6.tail_nets.12.0.weight', 'tails.6.tail_nets.12.0.bias', 'tails.6.tail_nets.12.1.weight', 'tails.6.tail_nets.12.1.bias', 'tails.6.tail_nets.13.0.weight', 'tails.6.tail_nets.13.0.bias', 'tails.6.tail_nets.13.1.weight', 'tails.6.tail_nets.13.1.bias', 'tails.6.tail_nets.14.0.weight', 'tails.6.tail_nets.14.0.bias', 'tails.6.tail_nets.14.1.weight', 'tails.6.tail_nets.14.1.bias', 'tails.6.tail_nets.15.0.weight', 'tails.6.tail_nets.15.0.bias', 'tails.6.tail_nets.15.1.weight', 'tails.6.tail_nets.15.1.bias']
0: Loaded AtmoRep: ignoring 208 elements: ['embeds_token_info.6.weight', 'embeds_token_info.6.bias', 'embeds.6.weight', 'embeds.6.bias', 'encoders.6.embed.weight', 'encoders.6.embed.bias', 'encoders.6.heads.0.proj_out.weight', 'encoders.6.heads.0.proj_heads.weight', 'encoders.6.heads.0.proj_heads_other.0.weight', 'encoders.6.heads.0.proj_heads_other.1.weight', 'encoders.6.heads.0.proj_heads_other.2.weight', 'encoders.6.heads.0.proj_heads_other.3.weight', 'encoders.6.heads.0.proj_heads_other.4.weight', 'encoders.6.heads.1.proj_out.weight', 'encoders.6.heads.1.proj_heads.weight', 'encoders.6.heads.1.proj_heads_other.0.weight', 'encoders.6.heads.1.proj_heads_other.1.weight', 'encoders.6.heads.1.proj_heads_other.2.weight', 'encoders.6.heads.1.proj_heads_other.3.weight', 'encoders.6.heads.1.proj_heads_other.4.weight', 'encoders.6.heads.2.proj_out.weight', 'encoders.6.heads.2.proj_heads.weight', 'encoders.6.heads.2.proj_heads_other.0.weight', 'encoders.6.heads.2.proj_heads_other.1.weight', 'encoders.6.heads.2.proj_hea
0: ds_other.2.weight', 'encoders.6.heads.2.proj_heads_other.3.weight', 'encoders.6.heads.2.proj_heads_other.4.weight', 'encoders.6.heads.3.proj_out.weight', 'encoders.6.heads.3.proj_heads.weight', 'encoders.6.heads.3.proj_heads_other.0.weight', 'encoders.6.heads.3.proj_heads_other.1.weight', 'encoders.6.heads.3.proj_heads_other.2.weight', 'encoders.6.heads.3.proj_heads_other.3.weight', 'encoders.6.heads.3.proj_heads_other.4.weight', 'encoders.6.heads.4.proj_out.weight', 'encoders.6.heads.4.proj_heads.weight', 'encoders.6.heads.4.proj_heads_other.0.weight', 'encoders.6.heads.4.proj_heads_other.1.weight', 'encoders.6.heads.4.proj_heads_other.2.weight', 'encoders.6.heads.4.proj_heads_other.3.weight', 'encoders.6.heads.4.proj_heads_other.4.weight', 'encoders.6.heads.5.proj_out.weight', 'encoders.6.heads.5.proj_heads.weight', 'encoders.6.heads.5.proj_heads_other.0.weight', 'encoders.6.heads.5.proj_heads_other.1.weight', 'encoders.6.heads.5.proj_heads_other.2.weight', 'encoders.6.heads.5.proj_heads_other.3.weight', 'e
0: ncoders.6.heads.5.proj_heads_other.4.weight', 'encoders.6.mlps.0.blocks.0.weight', 'encoders.6.mlps.0.blocks.0.bias', 'encoders.6.mlps.0.blocks.3.weight', 'encoders.6.mlps.0.blocks.3.bias', 'encoders.6.mlps.1.blocks.0.weight', 'encoders.6.mlps.1.blocks.0.bias', 'encoders.6.mlps.1.blocks.3.weight', 'encoders.6.mlps.1.blocks.3.bias', 'encoders.6.mlps.2.blocks.0.weight', 'encoders.6.mlps.2.blocks.0.bias', 'encoders.6.mlps.2.blocks.3.weight', 'encoders.6.mlps.2.blocks.3.bias', 'encoders.6.mlps.3.blocks.0.weight', 'encoders.6.mlps.3.blocks.0.bias', 'encoders.6.mlps.3.blocks.3.weight', 'encoders.6.mlps.3.blocks.3.bias', 'encoders.6.mlps.4.blocks.0.weight', 'encoders.6.mlps.4.blocks.0.bias', 'encoders.6.mlps.4.blocks.3.weight', 'encoders.6.mlps.4.blocks.3.bias', 'encoders.6.mlps.5.blocks.0.weight', 'encoders.6.mlps.5.blocks.0.bias', 'encoders.6.mlps.5.blocks.3.weight', 'encoders.6.mlps.5.blocks.3.bias', 'decoders.6.blocks.0.proj_heads.weight', 'decoders.6.blocks.0.proj_heads_o_q.weight', 'decoders.6.blocks.0.proj_he
0: ads_o_kv.weight', 'decoders.6.blocks.0.ln_q.weight', 'decoders.6.blocks.0.ln_q.bias', 'decoders.6.blocks.0.ln_k.weight', 'decoders.6.blocks.0.ln_k.bias', 'decoders.6.blocks.0.proj_out.weight', 'decoders.6.blocks.1.blocks.0.weight', 'decoders.6.blocks.1.blocks.0.bias', 'decoders.6.blocks.1.blocks.3.weight', 'decoders.6.blocks.1.blocks.3.bias', 'decoders.6.blocks.2.proj_heads.weight', 'decoders.6.blocks.2.proj_heads_o_q.weight', 'decoders.6.blocks.2.proj_heads_o_kv.weight', 'decoders.6.blocks.2.ln_q.weight', 'decoders.6.blocks.2.ln_q.bias', 'decoders.6.blocks.2.ln_k.weight', 'decoders.6.blocks.2.ln_k.bias', 'decoders.6.blocks.2.proj_out.weight', 'decoders.6.blocks.3.blocks.0.weight', 'decoders.6.blocks.3.blocks.0.bias', 'decoders.6.blocks.3.blocks.3.weight', 'decoders.6.blocks.3.blocks.3.bias', 'decoders.6.blocks.4.proj_heads.weight', 'decoders.6.blocks.4.proj_heads_o_q.weight', 'decoders.6.blocks.4.proj_heads_o_kv.weight', 'decoders.6.blocks.4.ln_q.weight', 'decoders.6.blocks.4.ln_q.bias', 'decoders.6.blocks.4
0: .ln_k.weight', 'decoders.6.blocks.4.ln_k.bias', 'decoders.6.blocks.4.proj_out.weight', 'decoders.6.blocks.5.blocks.0.weight', 'decoders.6.blocks.5.blocks.0.bias', 'decoders.6.blocks.5.blocks.3.weight', 'decoders.6.blocks.5.blocks.3.bias', 'decoders.6.blocks.6.proj_heads.weight', 'decoders.6.blocks.6.proj_heads_o_q.weight', 'decoders.6.blocks.6.proj_heads_o_kv.weight', 'decoders.6.blocks.6.ln_q.weight', 'decoders.6.blocks.6.ln_q.bias', 'decoders.6.blocks.6.ln_k.weight', 'decoders.6.blocks.6.ln_k.bias', 'decoders.6.blocks.6.proj_out.weight', 'decoders.6.blocks.7.blocks.0.weight', 'decoders.6.blocks.7.blocks.0.bias', 'decoders.6.blocks.7.blocks.3.weight', 'decoders.6.blocks.7.blocks.3.bias', 'decoders.6.blocks.8.proj_heads.weight', 'decoders.6.blocks.8.proj_heads_o_q.weight', 'decoders.6.blocks.8.proj_heads_o_kv.weight', 'decoders.6.blocks.8.ln_q.weight', 'decoders.6.blocks.8.ln_q.bias', 'decoders.6.blocks.8.ln_k.weight', 'decoders.6.blocks.8.ln_k.bias', 'decoders.6.blocks.8.proj_out.weight', 'decoders.6.blocks.
0: 9.blocks.0.weight', 'decoders.6.blocks.9.blocks.0.bias', 'decoders.6.blocks.9.blocks.3.weight', 'decoders.6.blocks.9.blocks.3.bias', 'decoders.6.blocks.10.proj_heads.weight', 'decoders.6.blocks.10.proj_heads_o_q.weight', 'decoders.6.blocks.10.proj_heads_o_kv.weight', 'decoders.6.blocks.10.ln_q.weight', 'decoders.6.blocks.10.ln_q.bias', 'decoders.6.blocks.10.ln_k.weight', 'decoders.6.blocks.10.ln_k.bias', 'decoders.6.blocks.10.proj_out.weight', 'decoders.6.blocks.11.blocks.0.weight', 'decoders.6.blocks.11.blocks.0.bias', 'decoders.6.blocks.11.blocks.3.weight', 'decoders.6.blocks.11.blocks.3.bias', 'tails.6.tail_nets.0.0.weight', 'tails.6.tail_nets.0.0.bias', 'tails.6.tail_nets.0.1.weight', 'tails.6.tail_nets.0.1.bias', 'tails.6.tail_nets.1.0.weight', 'tails.6.tail_nets.1.0.bias', 'tails.6.tail_nets.1.1.weight', 'tails.6.tail_nets.1.1.bias', 'tails.6.tail_nets.2.0.weight', 'tails.6.tail_nets.2.0.bias', 'tails.6.tail_nets.2.1.weight', 'tails.6.tail_nets.2.1.bias', 'tails.6.tail_nets.3.0.weight', 'tails.6.tail_ne
0: ts.3.0.bias', 'tails.6.tail_nets.3.1.weight', 'tails.6.tail_nets.3.1.bias', 'tails.6.tail_nets.4.0.weight', 'tails.6.tail_nets.4.0.bias', 'tails.6.tail_nets.4.1.weight', 'tails.6.tail_nets.4.1.bias', 'tails.6.tail_nets.5.0.weight', 'tails.6.tail_nets.5.0.bias', 'tails.6.tail_nets.5.1.weight', 'tails.6.tail_nets.5.1.bias', 'tails.6.tail_nets.6.0.weight', 'tails.6.tail_nets.6.0.bias', 'tails.6.tail_nets.6.1.weight', 'tails.6.tail_nets.6.1.bias', 'tails.6.tail_nets.7.0.weight', 'tails.6.tail_nets.7.0.bias', 'tails.6.tail_nets.7.1.weight', 'tails.6.tail_nets.7.1.bias', 'tails.6.tail_nets.8.0.weight', 'tails.6.tail_nets.8.0.bias', 'tails.6.tail_nets.8.1.weight', 'tails.6.tail_nets.8.1.bias', 'tails.6.tail_nets.9.0.weight', 'tails.6.tail_nets.9.0.bias', 'tails.6.tail_nets.9.1.weight', 'tails.6.tail_nets.9.1.bias', 'tails.6.tail_nets.10.0.weight', 'tails.6.tail_nets.10.0.bias', 'tails.6.tail_nets.10.1.weight', 'tails.6.tail_nets.10.1.bias', 'tails.6.tail_nets.11.0.weight', 'tails.6.tail_nets.11.0.bias', 'tails.6.tai
0: l_nets.11.1.weight', 'tails.6.tail_nets.11.1.bias', 'tails.6.tail_nets.12.0.weight', 'tails.6.tail_nets.12.0.bias', 'tails.6.tail_nets.12.1.weight', 'tails.6.tail_nets.12.1.bias', 'tails.6.tail_nets.13.0.weight', 'tails.6.tail_nets.13.0.bias', 'tails.6.tail_nets.13.1.weight', 'tails.6.tail_nets.13.1.bias', 'tails.6.tail_nets.14.0.weight', 'tails.6.tail_nets.14.0.bias', 'tails.6.tail_nets.14.1.weight', 'tails.6.tail_nets.14.1.bias', 'tails.6.tail_nets.15.0.weight', 'tails.6.tail_nets.15.0.bias', 'tails.6.tail_nets.15.1.weight', 'tails.6.tail_nets.15.1.bias']
1: Loaded model id = wc5e2i3t.
1: Loaded run 'wc5e2i3t' at epoch -2.
0: Loaded model id = wc5e2i3t.
0: Loaded run 'wc5e2i3t' at epoch -2.
1: -1 : 00:00:37 :: batch_size = 96, lr = 1e-05
0: Number of trainable parameters: 886,234,640
0: -1 : 00:00:37 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch -1, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.4991, -1.5050, -1.5107, -1.5167, -1.5226, -1.5285, -1.5344, -1.5403, -1.5461, -1.5520, -1.5578, -1.5635,
1:         -1.5693, -1.5750, -1.5806, -1.5862, -1.5920, -1.5976, -1.5440, -1.5517, -1.5595, -1.5672, -1.5749, -1.5825,
1:         -1.5901], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0018, -0.0472,  0.0129,  0.0893,  0.0852,  0.0633,  0.0575, -0.0685, -0.0225,  0.0684,  0.0453, -0.0430,
1:          0.1428,  0.0320, -0.0423,  0.0785, -0.0890, -0.1053, -0.0288, -0.0110,  0.0188,  0.0303, -0.0424,  0.1287,
1:          0.0256], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.1931, -0.1945, -0.1956, -0.1966, -0.1977, -0.1985, -0.1989, -0.1991, -0.1995, -0.2000, -0.2004, -0.2006,
1:         -0.2006, -0.2006, -0.2006, -0.2004, -0.2000, -0.1995, -0.1700, -0.1714, -0.1725, -0.1735, -0.1743, -0.1754,
1:         -0.1764], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.8967, 0.8969, 0.8971, 0.8974, 0.8970, 0.8974, 0.8969, 0.8973, 0.8967, 0.8971, 0.8964, 0.8966, 0.8968, 0.8970,
1:         0.8971, 0.8973, 0.8974, 0.8975, 0.8984, 0.8985, 0.8996, 0.8998, 0.9007, 0.9017, 0.9030], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1659, -0.1681, -0.1681, -0.1681, -0.1681, -0.1659, -0.1659, -0.1659, -0.1659, -0.1458, -0.1458, -0.1436,
1:         -0.1436, -0.1436, -0.1436, -0.1436, -0.1436, -0.1436, -0.1235, -0.1213, -0.1213, -0.1235, -0.1257, -0.1280,
1:         -0.1302], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch -1, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan, 0.3931,    nan,    nan, 0.3273,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch -1, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-1.6890, -1.6911, -1.6925, -1.6954, -1.6969, -1.7029, -1.7052, -1.7097, -1.7163, -1.7192, -1.7239, -1.7235,
1:         -1.7254, -1.7289, -1.7355, -1.7428, -1.7508, -1.7516, -1.7593, -1.7660, -1.7718, -1.7771, -1.7853, -1.7882,
1:         -1.7908], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.1780,  0.1765,  0.1708,  0.1608,  0.1449,  0.1287,  0.1112,  0.0928,  0.0761,  0.0588,  0.0426,  0.0238,
1:          0.0025, -0.0196, -0.0419, -0.0643, -0.0878, -0.1117,  0.1776,  0.1725,  0.1657,  0.1550,  0.1424,  0.1266,
1:          0.1100], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.3552, -0.3462, -0.3414, -0.3389, -0.3378, -0.3385, -0.3406, -0.3437, -0.3487, -0.3544, -0.3590, -0.3613,
1:         -0.3632, -0.3631, -0.3639, -0.3668, -0.3723, -0.3801, -0.3365, -0.3304, -0.3292, -0.3279, -0.3271, -0.3259,
1:         -0.3253], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.1741, -0.1615, -0.1742, -0.1632, -0.1533, -0.1519, -0.1450, -0.1626, -0.1868, -0.2091, -0.2227, -0.2284,
1:         -0.2234, -0.1969, -0.1725, -0.1927, -0.2158, -0.2329, -0.2263, -0.1935, -0.1978, -0.1817, -0.1748, -0.1797,
1:         -0.1685], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.3211, -0.3129, -0.3056, -0.2996, -0.2945, -0.2914, -0.2891, -0.2879, -0.2875, -0.2872, -0.2853, -0.2829,
1:         -0.2806, -0.2779, -0.2749, -0.2734, -0.2726, -0.2735, -0.2729, -0.2697, -0.2626, -0.2517, -0.2389, -0.2261,
1:         -0.2126], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2031, -0.2033, -0.2003, -0.2009, -0.1981, -0.1999, -0.2010, -0.2009, -0.1989, -0.2138, -0.2116, -0.2102,
1:         -0.2105, -0.2102, -0.2081, -0.2088, -0.2087, -0.2081, -0.2209, -0.2218, -0.2210, -0.2199, -0.2172, -0.2186,
1:         -0.2186], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0017,  0.0127, -0.0558,  0.0415, -0.2595, -0.0845,  0.0308, -0.3086, -0.0151, -0.3216,  0.0537, -0.1073,
1:          0.2168,  0.0711,  0.0630, -0.0577,  0.0322, -0.0572, -0.1503, -0.1045,  0.0490,  0.3207,  0.1478, -0.1719,
1:          0.1177], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch -1, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.4991, -1.5050, -1.5107, -1.5167, -1.5226, -1.5285, -1.5344, -1.5403, -1.5461, -1.5520, -1.5578, -1.5635,
0:         -1.5693, -1.5750, -1.5806, -1.5862, -1.5920, -1.5976, -1.5440, -1.5517, -1.5595, -1.5672, -1.5749, -1.5825,
0:         -1.5901], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.5486, -0.5445, -0.5407, -0.5365, -0.5323, -0.5278, -0.5234, -0.5187, -0.5139, -0.5088, -0.5035, -0.4982,
0:         -0.4925, -0.4868, -0.4809, -0.4745, -0.4682, -0.4614, -0.6268, -0.6232, -0.6194, -0.6154, -0.6109, -0.6063,
0:         -0.6014], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.2006,  0.1939,  0.1895,  0.1828,  0.1740,  0.1651,  0.1540,  0.1429,  0.1296,  0.1163,  0.1008,  0.0875,
0:          0.0742,  0.0609,  0.0498,  0.0387,  0.0299,  0.0232,  0.0631,  0.0520,  0.0410,  0.0321,  0.0210,  0.0099,
0:         -0.0012], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1659, -0.1681, -0.1681, -0.1681, -0.1681, -0.1659, -0.1659, -0.1659, -0.1659, -0.1458, -0.1458, -0.1436,
0:         -0.1436, -0.1436, -0.1436, -0.1436, -0.1436, -0.1436, -0.1235, -0.1213, -0.1213, -0.1235, -0.1257, -0.1280,
0:         -0.1302], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch -1, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan, 0.3731,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan, 0.8168,    nan,    nan,    nan,    nan,    nan,    nan, 1.0701,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch -1, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.8456, -0.8369, -0.8310, -0.8274, -0.8237, -0.8183, -0.8099, -0.7991, -0.7875, -0.7749, -0.7623, -0.7517,
0:         -0.7403, -0.7275, -0.7128, -0.6960, -0.6781, -0.6627, -0.8873, -0.8795, -0.8745, -0.8736, -0.8721, -0.8681,
0:         -0.8611], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.0714, -0.0684, -0.0624, -0.0559, -0.0512, -0.0484, -0.0462, -0.0418, -0.0348, -0.0275, -0.0213, -0.0179,
0:         -0.0168, -0.0155, -0.0140, -0.0101, -0.0081, -0.0078, -0.0714, -0.0702, -0.0666, -0.0598, -0.0531, -0.0504,
0:         -0.0486], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.3139, -0.3055, -0.3020, -0.3005, -0.3019, -0.3009, -0.3020, -0.2978, -0.2922, -0.2858, -0.2783, -0.2705,
0:         -0.2633, -0.2555, -0.2488, -0.2459, -0.2454, -0.2504, -0.4255, -0.4191, -0.4117, -0.4043, -0.3989, -0.3939,
0:         -0.3868], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.0296,  0.0376,  0.0405,  0.0576,  0.0754,  0.0755,  0.0665,  0.0569,  0.0475,  0.0454,  0.0417,  0.0393,
0:          0.0430,  0.0391,  0.0364,  0.0313,  0.0227,  0.0415, -0.0540, -0.0575, -0.0510, -0.0411, -0.0338, -0.0327,
0:         -0.0299], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.1742, -0.1522, -0.1318, -0.1099, -0.0860, -0.0614, -0.0407, -0.0243, -0.0126, -0.0020,  0.0105,  0.0235,
0:          0.0357,  0.0466,  0.0570,  0.0687,  0.0818,  0.0961,  0.1103,  0.1222,  0.1314,  0.1364,  0.1384,  0.1378,
0:          0.1343], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2445, -0.2473, -0.2454, -0.2444, -0.2439, -0.2424, -0.2436, -0.2428, -0.2438, -0.2433, -0.2448, -0.2441,
0:         -0.2447, -0.2432, -0.2429, -0.2458, -0.2442, -0.2445, -0.2423, -0.2456, -0.2450, -0.2446, -0.2421, -0.2426,
0:         -0.2441], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0094, -0.0295, -0.0966,  0.0824, -0.2619, -0.2565, -0.0304, -0.2591,  0.0388, -0.2960,  0.1029, -0.0928,
0:          0.1612,  0.0142,  0.1313, -0.0327, -0.0651, -0.0492, -0.2259, -0.0075,  0.1288,  0.1194,  0.0320, -0.1820,
0:          0.1037], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: -1 [1/5 (20%)]	Loss: 0.34184 : 0.19928 :: 0.05403 (1.70 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: -1 [2/5 (40%)]	Loss: 0.31239 : 0.17675 :: 0.03951 (8.50 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: -1 [3/5 (60%)]	Loss: 0.36197 : 0.22633 :: 0.03648 (8.50 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: -1 [4/5 (80%)]	Loss: 0.33531 : 0.19488 :: 0.03894 (8.50 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch -1 : 0.21399837732315063
0: validation loss for velocity_u : 0.0038952259346842766
0: validation loss for velocity_v : 0.0053076548501849174
0: validation loss for specific_humidity : 0.008052235469222069
0: validation loss for velocity_z : 0.10754537582397461
0: validation loss for temperature : 0.022597700357437134
0: validation loss for total_precip : 0.29872968792915344
0: validation loss for t2m : 1.0518609285354614
0: 0 : 00:07:03 :: batch_size = 96, lr = 1e-05
1: 0 : 00:07:12 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 0, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.6670, 0.6757, 0.6816, 0.6861, 0.6905, 0.6961, 0.7041, 0.7153, 0.7297, 0.7474, 0.7673, 0.7887, 0.8104, 0.8321,
0:         0.8537, 0.8750, 0.8960, 0.9166, 0.6061, 0.6132, 0.6181, 0.6227, 0.6283, 0.6365, 0.6480], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.1052, -1.1655, -1.1986, -1.2095, -1.2038, -1.1849, -1.1536, -1.1111, -1.0592, -1.0016, -0.9428, -0.8863,
0:         -0.8340, -0.7873, -0.7471, -0.7137, -0.6866, -0.6645, -1.0909, -1.1507, -1.1832, -1.1936, -1.1874, -1.1678,
0:         -1.1363], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.8731, -0.8927, -0.8948, -0.8905, -0.8927, -0.9101, -0.9427, -0.9949, -1.0689, -1.1689, -1.2821, -1.4017,
0:         -1.5083, -1.5975, -1.6650, -1.7128, -1.7302, -1.7063, -0.9536, -0.9666, -0.9666, -0.9644, -0.9688, -0.9884,
0:         -1.0275], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([0.5181, 0.5193, 0.4899, 0.4606, 0.4066, 0.3397, 0.2764, 0.2060, 0.1332, 0.5439, 0.5439, 0.5240, 0.5052, 0.4618,
0:         0.4066, 0.3515, 0.2822, 0.2142, 0.5615, 0.5592, 0.5451, 0.5322, 0.4981, 0.4547, 0.4078], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 0, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan, 1.1451,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:         1.0451,    nan,    nan, 0.9491,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 0, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.8554, 0.8380, 0.8214, 0.8029, 0.7920, 0.7801, 0.7779, 0.7790, 0.7815, 0.7865, 0.7955, 0.8027, 0.8170, 0.8235,
0:         0.8322, 0.8398, 0.8478, 0.8500, 0.7682, 0.7527, 0.7401, 0.7320, 0.7282, 0.7224, 0.7225], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-1.1520, -1.1103, -1.0650, -1.0163, -0.9676, -0.9263, -0.8938, -0.8687, -0.8501, -0.8425, -0.8430, -0.8476,
0:         -0.8558, -0.8611, -0.8565, -0.8468, -0.8319, -0.8123, -1.1672, -1.1232, -1.0746, -1.0293, -0.9865, -0.9562,
0:         -0.9287], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.7227, -0.7213, -0.7314, -0.7379, -0.7404, -0.7449, -0.7473, -0.7479, -0.7448, -0.7408, -0.7403, -0.7327,
0:         -0.7249, -0.7157, -0.7099, -0.7042, -0.6985, -0.6947, -0.7282, -0.7350, -0.7397, -0.7477, -0.7528, -0.7545,
0:         -0.7556], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.1204, 0.1515, 0.1860, 0.2830, 0.4042, 0.5139, 0.6613, 0.8048, 0.9537, 1.1175, 1.2938, 1.4213, 1.5423, 1.6858,
0:         1.7794, 1.8687, 1.9505, 1.9578, 0.1962, 0.2961, 0.3818, 0.4936, 0.6541, 0.8053, 0.9580], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([ 0.1903,  0.1766,  0.1604,  0.1395,  0.1229,  0.1099,  0.1066,  0.1193,  0.1425,  0.1740,  0.2058,  0.2343,
0:          0.2570,  0.2710,  0.2710,  0.2617,  0.2404,  0.2097,  0.1744,  0.1337,  0.0942,  0.0520,  0.0105, -0.0336,
0:         -0.0734], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2382, -0.2454, -0.2440, -0.2420, -0.2423, -0.2437, -0.2379, -0.2385, -0.2343, -0.2476, -0.2448, -0.2490,
0:         -0.2478, -0.2502, -0.2439, -0.2385, -0.2391, -0.2385, -0.2445, -0.2498, -0.2471, -0.2488, -0.2436, -0.2438,
0:         -0.2432], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0046,  0.0844, -0.0542,  0.0449, -0.1623, -0.1180, -0.0201, -0.2007,  0.1117, -0.2979,  0.0526, -0.1225,
0:         -0.0326, -0.1862,  0.0658, -0.0897, -0.0316, -0.0680, -0.1108,  0.1347,  0.0642,  0.1262, -0.0425, -0.1680,
0:          0.1695], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 0, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.4549, 0.4499, 0.4451, 0.4405, 0.4364, 0.4326, 0.4291, 0.4260, 0.4225, 0.4186, 0.4138, 0.4082, 0.4019, 0.3953,
1:         0.3888, 0.3826, 0.3769, 0.3718, 0.4389, 0.4356, 0.4321, 0.4290, 0.4263, 0.4243, 0.4229], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0974, -0.0198,  0.0110,  0.0435,  0.0874, -0.0493, -0.0534, -0.0299,  0.0386, -0.0101, -0.0549, -0.0735,
1:          0.0482, -0.0184,  0.0986,  0.2041,  0.0572,  0.0648, -0.1354,  0.0293,  0.1116,  0.0825, -0.0049,  0.1607,
1:         -0.2157], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.4240, -0.4379, -0.4519, -0.4659, -0.4801, -0.4944, -0.5086, -0.5234, -0.5370, -0.5515, -0.5659, -0.5804,
1:         -0.5836, -0.5868, -0.5900, -0.5931, -0.5878, -0.5842, -0.4069, -0.4190, -0.4312, -0.4454, -0.4598, -0.4734,
1:         -0.4869], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.5002, 0.4926, 0.4854, 0.4781, 0.4712, 0.4646, 0.4577, 0.4511, 0.4446, 0.4378, 0.4308, 0.4238, 0.4160, 0.4083,
1:         0.4001, 0.3919, 0.3833, 0.3748, 0.3664, 0.3576, 0.3483, 0.3387, 0.3286, 0.3180, 0.3072], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2387, -0.2387, -0.2365, -0.2365, -0.2321, -0.2277, -0.2233, -0.2166, -0.2233, -0.2409, -0.2409, -0.2409,
1:         -0.2409, -0.2343, -0.2343, -0.2343, -0.2343, -0.2277, -0.2409, -0.2409, -0.2409, -0.2409, -0.2409, -0.2409,
1:         -0.2387], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 0, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan, 4.1951,    nan,    nan,    nan, 4.0793,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 0, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.4151, 0.4139, 0.4144, 0.4141, 0.4172, 0.4161, 0.4178, 0.4207, 0.4215, 0.4178, 0.4131, 0.4054, 0.3993, 0.3881,
1:         0.3821, 0.3715, 0.3608, 0.3514, 0.4468, 0.4529, 0.4573, 0.4657, 0.4718, 0.4710, 0.4700], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.6105, -0.6702, -0.7290, -0.7833, -0.8254, -0.8635, -0.8989, -0.9283, -0.9533, -0.9772, -1.0004, -1.0138,
1:         -1.0266, -1.0317, -1.0342, -1.0377, -1.0460, -1.0572, -0.5202, -0.5721, -0.6193, -0.6707, -0.7168, -0.7644,
1:         -0.8078], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6239, -0.6290, -0.6469, -0.6556, -0.6555, -0.6578, -0.6612, -0.6602, -0.6525, -0.6403, -0.6241, -0.5931,
1:         -0.5554, -0.5008, -0.4367, -0.3683, -0.2979, -0.2384, -0.5822, -0.6059, -0.6235, -0.6377, -0.6499, -0.6552,
1:         -0.6617], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.6639, 0.7433, 0.7297, 0.7411, 0.7756, 0.7605, 0.7720, 0.7665, 0.7191, 0.6859, 0.6830, 0.6674, 0.6532, 0.6104,
1:         0.5453, 0.5221, 0.4832, 0.4224, 0.6576, 0.7203, 0.7352, 0.7797, 0.8515, 0.8580, 0.8500], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.9538, 0.9039, 0.8566, 0.8065, 0.7592, 0.7092, 0.6613, 0.6190, 0.5799, 0.5460, 0.5137, 0.4824, 0.4484, 0.4125,
1:         0.3705, 0.3347, 0.3029, 0.2796, 0.2629, 0.2467, 0.2324, 0.2157, 0.2017, 0.1865, 0.1736], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2321, -0.2361, -0.2337, -0.2320, -0.2349, -0.2364, -0.2320, -0.2349, -0.2317, -0.2363, -0.2362, -0.2371,
1:         -0.2354, -0.2412, -0.2366, -0.2316, -0.2341, -0.2338, -0.2364, -0.2380, -0.2344, -0.2352, -0.2343, -0.2335,
1:         -0.2347], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0330,  0.1142, -0.0711,  0.0006, -0.1902,  0.0154,  0.0708, -0.2151,  0.1149, -0.2705,  0.0449, -0.0870,
1:         -0.0084, -0.1218, -0.0170, -0.1408,  0.0759,  0.0212, -0.0459,  0.0062,  0.0212,  0.2948,  0.0601, -0.1485,
1:          0.1049], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 0 [1/5 (20%)]	Loss: 0.32730 : 0.19350 :: 0.03660 (1.54 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 0 [2/5 (40%)]	Loss: 0.31159 : 0.20688 :: 0.03652 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 0 [3/5 (60%)]	Loss: 0.29151 : 0.19405 :: 0.03497 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 0 [4/5 (80%)]	Loss: 0.34343 : 0.20111 :: 0.03577 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 0 : 0.21842429041862488
0: validation loss for velocity_u : 0.003996603190898895
0: validation loss for velocity_v : 0.005560520105063915
0: validation loss for specific_humidity : 0.007416843436658382
0: validation loss for velocity_z : 0.11240838468074799
0: validation loss for temperature : 0.021644890308380127
0: validation loss for total_precip : 0.31251978874206543
0: validation loss for t2m : 1.0654228925704956
1: 1 : 00:13:12 :: batch_size = 96, lr = 1.5000000000000002e-05
0: 1 : 00:13:12 :: batch_size = 96, lr = 1.5000000000000002e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 1, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.7478, -0.7483, -0.7478, -0.7491, -0.7593, -0.7755, -0.7938, -0.8106, -0.8253, -0.8396, -0.8517, -0.8631,
0:         -0.8750, -0.8896, -0.9053, -0.9202, -0.9328, -0.9424, -0.7687, -0.7637, -0.7587, -0.7567, -0.7620, -0.7711,
0:         -0.7822], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2069, -0.2158, -0.2171, -0.2119, -0.2085, -0.2092, -0.2135, -0.2165, -0.2154, -0.2106, -0.1989, -0.1833,
0:         -0.1628, -0.1422, -0.1251, -0.1099, -0.0986, -0.0888, -0.2064, -0.2133, -0.2156, -0.2163, -0.2188, -0.2208,
0:         -0.2244], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-3.9638e-01, -3.1308e-01, -2.3540e-01, -1.2508e-01, -5.8664e-02,  4.3761e-03,  3.9273e-02,  1.5633e-02,
0:          3.9273e-02, -2.3783e-03, -1.2684e-04,  4.3776e-02,  4.8279e-02,  8.9931e-02,  9.1057e-02,  9.7811e-02,
0:          8.7680e-02,  7.5297e-02, -3.8963e-01, -3.0295e-01, -2.2415e-01, -8.4556e-02,  3.2503e-03,  6.0662e-02,
0:          6.7417e-02], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484,
0:         -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484,
0:         -0.2484], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 1, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.0798,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 1, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.8972, -0.8884, -0.8811, -0.8808, -0.8804, -0.8884, -0.8982, -0.9043, -0.9106, -0.9139, -0.9162, -0.9229,
0:         -0.9289, -0.9508, -0.9746, -1.0043, -1.0365, -1.0613, -0.8697, -0.8666, -0.8698, -0.8693, -0.8711, -0.8825,
0:         -0.8950], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.3865, -0.3711, -0.3520, -0.3316, -0.3118, -0.3012, -0.2929, -0.2767, -0.2553, -0.2332, -0.2106, -0.1928,
0:         -0.1830, -0.1788, -0.1682, -0.1598, -0.1508, -0.1465, -0.3799, -0.3637, -0.3407, -0.3184, -0.2971, -0.2870,
0:         -0.2746], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.4018, -0.4245, -0.4633, -0.4847, -0.4810, -0.4722, -0.4472, -0.4303, -0.4180, -0.4332, -0.4738, -0.5058,
0:         -0.5216, -0.5099, -0.4893, -0.4694, -0.4475, -0.4307, -0.3880, -0.4137, -0.4428, -0.4669, -0.4826, -0.4757,
0:         -0.4649], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.0423,  0.0616,  0.0683,  0.0687,  0.0577,  0.0464,  0.0516,  0.0677,  0.0825,  0.1200,  0.1984,  0.2568,
0:          0.3256,  0.3768,  0.3907,  0.3958,  0.3687,  0.3325, -0.1035, -0.0725, -0.0395, -0.0015,  0.0302,  0.0414,
0:          0.0397], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.9387, -0.8710, -0.8218, -0.8167, -0.8559, -0.9326, -1.0276, -1.1167, -1.2175, -1.3199, -1.4137, -1.4632,
0:         -1.4557, -1.3812, -1.2752, -1.1569, -1.0802, -1.0641, -1.0997, -1.1795, -1.2491, -1.2933, -1.2777, -1.2084,
0:         -1.0790], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([ 1.0715,  0.9054,  0.6467,  0.3483,  0.0513, -0.1467, -0.2578, -0.2858, -0.2258,  1.4735,  1.3386,  1.0725,
0:          0.6780,  0.3186,  0.0720, -0.1389, -0.2160, -0.2133,  1.8019,  1.7316,  1.4823,  1.1034,  0.7012,  0.3512,
0:          0.0743], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0430,  0.0425, -0.0351,  0.0024, -0.1321, -0.0796, -0.0653, -0.1278,  0.0723, -0.2484,  0.0585, -0.1143,
0:         -0.1620, -0.0603, -0.0709, -0.1482, -0.0234, -0.1176, -0.0695,  0.1119, -0.0231,  0.1523, -0.1167, -0.1881,
0:          0.1547], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 1, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.7478, -0.7483, -0.7478, -0.7491, -0.7593, -0.7755, -0.7938, -0.8106, -0.8253, -0.8396, -0.8517, -0.8631,
1:         -0.8750, -0.8896, -0.9053, -0.9202, -0.9328, -0.9424, -0.7687, -0.7637, -0.7587, -0.7567, -0.7620, -0.7711,
1:         -0.7822], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0245,  0.0647, -0.0576,  0.1403, -0.0213,  0.0930,  0.0265,  0.1422, -0.0821, -0.0008,  0.0202, -0.0719,
1:         -0.1218, -0.1503,  0.0287, -0.0988,  0.2130, -0.0245, -0.0575,  0.0872, -0.0141,  0.0555, -0.0358, -0.1649,
1:          0.0524], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0809, -0.1173, -0.1679, -0.2279, -0.3095, -0.3962, -0.4550, -0.5075, -0.5295, -0.5469, -0.5530, -0.5594,
1:         -0.5670, -0.5749, -0.5828, -0.5876, -0.5925, -0.5956,  0.0450,  0.0038, -0.0499, -0.1233, -0.2083, -0.3059,
1:         -0.3901], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.4107, 1.4152, 1.3912, 1.3326, 1.2419, 1.1399, 1.0451, 0.9671, 0.9257, 0.9079, 0.9202, 0.9528, 0.9941, 1.0327,
1:         1.0468, 1.0334, 0.9861, 0.9179, 0.8319, 0.7332, 0.6280, 0.5097, 0.3992, 0.2892, 0.1917], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484,
1:         -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484, -0.2484,
1:         -0.2484], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 1, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan, 0.2755, 0.2055,    nan,    nan,    nan,    nan, 0.1697,    nan, 0.1102,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 1, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.7613, -0.7624, -0.7622, -0.7604, -0.7613, -0.7700, -0.7775, -0.7876, -0.7985, -0.8112, -0.8234, -0.8360,
1:         -0.8388, -0.8445, -0.8454, -0.8446, -0.8461, -0.8408, -0.7601, -0.7639, -0.7715, -0.7734, -0.7827, -0.7989,
1:         -0.8127], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.5995, -0.5876, -0.5790, -0.5706, -0.5601, -0.5529, -0.5435, -0.5247, -0.4929, -0.4561, -0.4116, -0.3600,
1:         -0.3148, -0.2736, -0.2320, -0.1959, -0.1561, -0.1228, -0.5911, -0.5786, -0.5646, -0.5542, -0.5400, -0.5301,
1:         -0.5148], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([3.3098, 3.2482, 3.1639, 3.0944, 3.0563, 3.0465, 3.0736, 3.1343, 3.2132, 3.3018, 3.3822, 3.4533, 3.5080, 3.5354,
1:         3.5331, 3.5018, 3.4658, 3.4243, 3.4783, 3.4189, 3.3615, 3.3030, 3.2741, 3.2871, 3.3277], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.4071, 0.2825, 0.0927, 0.0524, 0.0912, 0.1810, 0.3988, 0.6299, 0.7486, 0.7815, 0.7472, 0.5749, 0.4436, 0.4157,
1:         0.4026, 0.4167, 0.4334, 0.4981, 0.3003, 0.2675, 0.1194, 0.0711, 0.1264, 0.2256, 0.4023], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.0446, -1.0065, -0.9338, -0.8560, -0.7961, -0.7679, -0.7553, -0.7232, -0.6691, -0.5993, -0.5504, -0.5515,
1:         -0.6247, -0.7606, -0.9467, -1.1201, -1.2556, -1.3228, -1.3279, -1.3072, -1.2779, -1.2768, -1.2920, -1.3079,
1:         -1.2931], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2361, -0.2356, -0.2366, -0.2282, -0.2220, -0.2210, -0.2207, -0.2304, -0.2280, -0.2442, -0.2359, -0.2290,
1:         -0.2097, -0.2008, -0.1950, -0.1943, -0.2070, -0.2177, -0.2310, -0.2261, -0.1970, -0.1724, -0.1598, -0.1549,
1:         -0.1651], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0440,  0.1026,  0.0089,  0.0078, -0.1352,  0.0223,  0.0077, -0.2291,  0.0328, -0.2995,  0.0494, -0.0705,
1:         -0.0416, -0.0721, -0.1224, -0.1191,  0.0928, -0.0594, -0.0426, -0.0264, -0.0530,  0.2797,  0.0219, -0.1927,
1:          0.1134], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 1 [1/5 (20%)]	Loss: 0.33582 : 0.22365 :: 0.03206 (1.61 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 1 [2/5 (40%)]	Loss: 0.27363 : 0.17301 :: 0.03201 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 1 [3/5 (60%)]	Loss: 0.33366 : 0.22243 :: 0.03192 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 1 [4/5 (80%)]	Loss: 0.32575 : 0.22087 :: 0.03048 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 1 : 0.1965319812297821
0: validation loss for velocity_u : 0.0038378573954105377
0: validation loss for velocity_v : 0.00522124907001853
0: validation loss for specific_humidity : 0.006499325856566429
0: validation loss for velocity_z : 0.11031584441661835
0: validation loss for temperature : 0.018898148089647293
0: validation loss for total_precip : 0.2215811163187027
0: validation loss for t2m : 1.0093705654144287
0: 2 : 00:19:45 :: batch_size = 96, lr = 2e-05
1: 2 : 00:19:56 :: batch_size = 96, lr = 2e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 2, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.2917,  0.2668,  0.2425,  0.2189,  0.1958,  0.1729,  0.1498,  0.1267,  0.1037,  0.0801,  0.0549,  0.0276,
0:         -0.0015, -0.0312, -0.0601, -0.0861, -0.1086, -0.1261,  0.2642,  0.2391,  0.2140,  0.1889,  0.1642,  0.1398,
0:          0.1160], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.2742, -1.3112, -1.3550, -1.4040, -1.4560, -1.5101, -1.5654, -1.6207, -1.6753, -1.7280, -1.7777, -1.8244,
0:         -1.8676, -1.9077, -1.9445, -1.9780, -2.0082, -2.0347, -1.2878, -1.3250, -1.3700, -1.4212, -1.4763, -1.5341,
0:         -1.5931], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1259, -0.1430, -0.1580, -0.1516, -0.1195, -0.0712, -0.0155,  0.0413,  0.1045,  0.1753,  0.2406,  0.2803,
0:          0.2728,  0.2203,  0.1442,  0.0756,  0.0424,  0.0584, -0.0552, -0.0777, -0.0927, -0.0916, -0.0702, -0.0294,
0:          0.0295], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2450, -0.2450, -0.2450, -0.2438, -0.2426, -0.2403, -0.2380, -0.2380, -0.2392, -0.2450, -0.2450, -0.2450,
0:         -0.2438, -0.2438, -0.2426, -0.2415, -0.2403, -0.2392, -0.2461, -0.2461, -0.2450, -0.2450, -0.2450, -0.2438,
0:         -0.2426], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 2, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([-1.7004,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 2, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.5591, -0.4740, -0.3864, -0.2985, -0.2041, -0.1002,  0.0144,  0.1292,  0.2420,  0.3363,  0.4140,  0.4807,
0:          0.5370,  0.5783,  0.6129,  0.6373,  0.6407,  0.6334, -0.3684, -0.2745, -0.1865, -0.0972, -0.0115,  0.0674,
0:          0.1549], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.0198, -0.0122, -0.0161, -0.0265, -0.0355, -0.0484, -0.0633, -0.0783, -0.0921, -0.1152, -0.1296, -0.1311,
0:         -0.1302, -0.1261, -0.1213, -0.1256, -0.1265, -0.1169,  0.0111,  0.0090,  0.0020, -0.0132, -0.0221, -0.0380,
0:         -0.0501], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([0.6794, 0.6582, 0.6304, 0.6042, 0.5727, 0.5433, 0.5097, 0.4841, 0.4600, 0.4480, 0.4375, 0.4380, 0.4480, 0.4608,
0:         0.4676, 0.4744, 0.4764, 0.4663, 0.6812, 0.6613, 0.6321, 0.6042, 0.5743, 0.5423, 0.5031], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.2263, -0.2897, -0.4207, -0.5387, -0.6317, -0.6853, -0.7156, -0.7665, -0.7724, -0.7554, -0.7216, -0.6891,
0:         -0.6292, -0.5561, -0.5168, -0.4237, -0.3613, -0.3527, -0.5428, -0.5776, -0.6551, -0.7352, -0.8278, -0.9107,
0:         -0.9751], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.8689, -0.8596, -0.8483, -0.8368, -0.8291, -0.8299, -0.8387, -0.8445, -0.8593, -0.8766, -0.9015, -0.9277,
0:         -0.9562, -0.9815, -1.0054, -1.0135, -1.0109, -0.9921, -0.9574, -0.9244, -0.8802, -0.8377, -0.7996, -0.7711,
0:         -0.7406], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2436, -0.2483, -0.2499, -0.2514, -0.2527, -0.2543, -0.2539, -0.2523, -0.2449, -0.2441, -0.2501, -0.2513,
0:         -0.2537, -0.2503, -0.2552, -0.2562, -0.2511, -0.2500, -0.2492, -0.2524, -0.2553, -0.2545, -0.2541, -0.2554,
0:         -0.2529], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0440,  0.0624, -0.0239, -0.0224, -0.1458, -0.0721, -0.1015, -0.0759,  0.0427, -0.1930, -0.0082, -0.0731,
0:         -0.0611, -0.1228, -0.0525, -0.1065, -0.0064, -0.1874, -0.0883,  0.0772, -0.0440,  0.1224, -0.0409, -0.1783,
0:          0.1572], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 2, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.3051, 1.2819, 1.2620, 1.2423, 1.2225, 1.2064, 1.1988, 1.2023, 1.2165, 1.2389, 1.2643, 1.2862, 1.2994, 1.3019,
1:         1.2940, 1.2770, 1.2535, 1.2267, 1.2264, 1.2225, 1.2141, 1.1978, 1.1762, 1.1556, 1.1412], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0217,  0.0309, -0.0815,  0.0628,  0.1435,  0.1730,  0.1408,  0.0933, -0.0394, -0.0617, -0.1220, -0.0246,
1:          0.0064,  0.0698, -0.1170, -0.0067,  0.0184,  0.0370, -0.0227, -0.1799, -0.0359,  0.0087,  0.1195,  0.0436,
1:          0.0400], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.1803,  0.1720,  0.1624,  0.1508,  0.1362,  0.1275,  0.1123,  0.0919,  0.0613,  0.0208, -0.0152, -0.0500,
1:         -0.0780, -0.0963, -0.1026, -0.1128, -0.1134, -0.1139,  0.1637,  0.1563,  0.1533,  0.1376,  0.1229,  0.1104,
1:          0.1065], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.8764, -1.9061, -1.9255, -1.9454, -1.9693, -1.9959, -2.0250, -2.0565, -2.0877, -2.1167, -2.1445, -2.1739,
1:         -2.2061, -2.2397, -2.2754, -2.3145, -2.3575, -2.3999, -2.4385, -2.4726, -2.5017, -2.5238, -2.5369, -2.5420,
1:         -2.5416], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.0116, -0.1508, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.1782, -0.2421, -0.2490,
1:         -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490,
1:         -0.2490], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 2, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,  0.0539,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.7048,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 2, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([1.2300, 1.2443, 1.2627, 1.2811, 1.2969, 1.3125, 1.3267, 1.3410, 1.3549, 1.3642, 1.3712, 1.3747, 1.3772, 1.3769,
1:         1.3787, 1.3847, 1.3870, 1.3947, 1.1892, 1.2097, 1.2261, 1.2450, 1.2636, 1.2747, 1.2892], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.2367, 0.2806, 0.3223, 0.3699, 0.4139, 0.4461, 0.4744, 0.4947, 0.5090, 0.5092, 0.5114, 0.5153, 0.5166, 0.5214,
1:         0.5331, 0.5466, 0.5661, 0.5935, 0.2737, 0.3113, 0.3495, 0.3829, 0.4184, 0.4447, 0.4716], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([1.4925, 1.5091, 1.5131, 1.5188, 1.5206, 1.5133, 1.4867, 1.4576, 1.4165, 1.3649, 1.3105, 1.2560, 1.2101, 1.1652,
1:         1.1214, 1.0795, 1.0392, 0.9982, 1.5263, 1.5360, 1.5298, 1.5232, 1.5154, 1.5079, 1.4738], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-2.2629, -2.7403, -3.1791, -3.4244, -3.3376, -2.7553, -1.8353, -0.8982, -0.1766,  0.1664,  0.2071,  0.1132,
1:          0.1109,  0.2264,  0.3117,  0.3271,  0.2682,  0.2227, -1.1875, -1.5053, -1.8626, -2.0671, -2.0133, -1.5599,
1:         -0.9015], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.6752, -0.6544, -0.6123, -0.5468, -0.4664, -0.3885, -0.3338, -0.3141, -0.3611, -0.4638, -0.6085, -0.7598,
1:         -0.8911, -0.9849, -1.0395, -1.0426, -1.0128, -0.9559, -0.8855, -0.8340, -0.7926, -0.7697, -0.7563, -0.7483,
1:         -0.7237], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2445, -0.2485, -0.2478, -0.2476, -0.2454, -0.2473, -0.2453, -0.2446, -0.2342, -0.2469, -0.2495, -0.2486,
1:         -0.2489, -0.2426, -0.2457, -0.2440, -0.2421, -0.2402, -0.2485, -0.2518, -0.2479, -0.2472, -0.2445, -0.2442,
1:         -0.2416], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0134,  0.0700, -0.0451, -0.0226, -0.1326,  0.0106, -0.0564, -0.1461, -0.0097, -0.2608,  0.0043, -0.0521,
1:         -0.0436, -0.0661, -0.1137, -0.1101,  0.0840, -0.1092, -0.0858,  0.0207, -0.0773,  0.2386,  0.0097, -0.1350,
1:          0.1129], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 2 [1/5 (20%)]	Loss: 0.28131 : 0.18177 :: 0.03017 (1.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 2 [2/5 (40%)]	Loss: 0.37077 : 0.24044 :: 0.03014 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 2 [3/5 (60%)]	Loss: 0.31164 : 0.20094 :: 0.03099 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 2 [4/5 (80%)]	Loss: 0.33098 : 0.19943 :: 0.03096 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 2 : 0.20715032517910004
0: validation loss for velocity_u : 0.003931368701159954
0: validation loss for velocity_v : 0.005355153698474169
0: validation loss for specific_humidity : 0.006718493532389402
0: validation loss for velocity_z : 0.12043352425098419
0: validation loss for temperature : 0.018908290192484856
0: validation loss for total_precip : 0.30795103311538696
0: validation loss for t2m : 0.986754298210144
1: 3 : 00:25:56 :: batch_size = 96, lr = 1.9512195121951222e-05
0: 3 : 00:25:56 :: batch_size = 96, lr = 1.9512195121951222e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 3, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.3326, 0.3406, 0.3364, 0.3168, 0.2905, 0.2719, 0.2683, 0.2836, 0.3150, 0.3494, 0.3718, 0.3698, 0.3437, 0.3126,
0:         0.2934, 0.2915, 0.3055, 0.3190, 0.3460, 0.3517, 0.3460, 0.3261, 0.2994, 0.2796, 0.2746], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.6472, -1.7266, -1.8004, -1.8685, -1.9254, -1.9670, -1.9931, -2.0039, -2.0037, -1.9981, -1.9900, -1.9883,
0:         -2.0050, -2.0425, -2.0970, -2.1610, -2.2241, -2.2810, -1.6776, -1.7607, -1.8366, -1.9050, -1.9616, -2.0028,
0:         -2.0271], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.4393, -0.4131, -0.3755, -0.4302, -0.5612, -0.5567, -0.4883, -0.4302, -0.2786, -0.2091, -0.2980, -0.3378,
0:         -0.3903, -0.4655, -0.4165, -0.4131, -0.4017, -0.1749, -0.4621, -0.4279, -0.4039, -0.4894, -0.6524, -0.6900,
0:         -0.6125], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([ 0.3650,  0.1829, -0.2339, -0.2535, -0.2596, -0.2608, -0.2608, -0.2596, -0.2596,  0.3589,  0.2244, -0.0787,
0:         -0.2144, -0.2571, -0.2608, -0.2608, -0.2584, -0.2584,  0.1438,  0.4261,  0.2220, -0.1557, -0.2327, -0.2535,
0:         -0.2608], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 3, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([-0.7569,     nan,     nan,     nan,     nan,     nan,     nan, -0.6609,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 3, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.1878, 0.1971, 0.2078, 0.2210, 0.2329, 0.2430, 0.2475, 0.2464, 0.2461, 0.2425, 0.2386, 0.2290, 0.2190, 0.2059,
0:         0.1870, 0.1736, 0.1582, 0.1510, 0.1966, 0.2037, 0.2135, 0.2245, 0.2358, 0.2443, 0.2515], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.9464, -0.9990, -1.0691, -1.1376, -1.2058, -1.2721, -1.3236, -1.3768, -1.4274, -1.4772, -1.5166, -1.5536,
0:         -1.5779, -1.5994, -1.6123, -1.6401, -1.6763, -1.7182, -0.9268, -0.9811, -1.0440, -1.1169, -1.1844, -1.2512,
0:         -1.3057], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.5952, -0.5733, -0.5346, -0.4754, -0.4048, -0.3134, -0.2076, -0.0899,  0.0282,  0.1410,  0.2433,  0.3304,
0:          0.4003,  0.4470,  0.4721,  0.4789,  0.4658,  0.4475, -0.5987, -0.5760, -0.5491, -0.5082, -0.4518, -0.3825,
0:         -0.3004], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.5327, -0.6117, -0.7238, -0.8680, -0.8940, -0.8560, -0.8983, -0.9308, -0.9059, -0.9109, -0.8618, -0.7517,
0:         -0.6320, -0.4990, -0.3432, -0.1406,  0.0452,  0.1994, -0.5037, -0.5523, -0.6815, -0.8749, -0.9539, -0.9427,
0:         -0.9717], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.5479, 1.5449, 1.5487, 1.5602, 1.5716, 1.5901, 1.6123, 1.6497, 1.6838, 1.7156, 1.7351, 1.7451, 1.7471, 1.7409,
0:         1.7241, 1.7109, 1.6914, 1.6741, 1.6614, 1.6410, 1.6274, 1.6110, 1.5926, 1.5710, 1.5552], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2255, -0.2169, -0.2107, -0.1919, -0.1700, -0.1460, -0.1157, -0.0937, -0.0713, -0.2636, -0.2595, -0.2349,
0:         -0.2187, -0.1895, -0.1546, -0.1298, -0.1012, -0.0664, -0.2845, -0.2777, -0.2605, -0.2293, -0.2010, -0.1702,
0:         -0.1285], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0272,  0.0212, -0.0072,  0.0252, -0.1387, -0.0308, -0.1220, -0.1076, -0.0025, -0.2629, -0.0125, -0.0125,
0:         -0.0903, -0.0743, -0.0825, -0.0812,  0.0035, -0.1970, -0.1291,  0.0997, -0.0460,  0.0963, -0.0663, -0.1177,
0:          0.1056], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 3, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.3326, 0.3406, 0.3364, 0.3168, 0.2905, 0.2719, 0.2683, 0.2836, 0.3150, 0.3494, 0.3718, 0.3698, 0.3437, 0.3126,
1:         0.2934, 0.2915, 0.3055, 0.3190, 0.3460, 0.3517, 0.3460, 0.3261, 0.2994, 0.2796, 0.2746], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0655,  0.0309, -0.0870, -0.0784, -0.0375, -0.0711,  0.1423, -0.1103,  0.0325,  0.0792, -0.0051, -0.0003,
1:         -0.0596,  0.0294, -0.0150,  0.0409, -0.0609,  0.1437, -0.1416, -0.1757,  0.0353, -0.0409,  0.0244, -0.0440,
1:         -0.0268], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.2331,  0.0554, -0.1486, -0.2524, -0.2774, -0.2533, -0.2134, -0.2201, -0.2637, -0.3444, -0.4286, -0.4960,
1:         -0.5418, -0.5533, -0.5537, -0.5494, -0.5437, -0.5483,  0.2867,  0.1288, -0.0698, -0.1907, -0.2299, -0.2177,
1:         -0.1814], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., 0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.6695, 0.6670, 0.6542, 0.6266, 0.5876, 0.5475, 0.5167, 0.5006, 0.4976, 0.5023, 0.5061, 0.5031, 0.4923, 0.4749,
1:         0.4508, 0.4266, 0.4032, 0.3806, 0.3676, 0.3689, 0.3839, 0.4201, 0.4769, 0.5384, 0.5959], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([ 0.3650,  0.1829, -0.2339, -0.2535, -0.2596, -0.2608, -0.2608, -0.2596, -0.2596,  0.3589,  0.2244, -0.0787,
1:         -0.2144, -0.2571, -0.2608, -0.2608, -0.2584, -0.2584,  0.1438,  0.4261,  0.2220, -0.1557, -0.2327, -0.2535,
1:         -0.2608], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 3, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan, 0.2576,    nan,    nan, 0.5447,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan, 0.4596,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 3, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([ 0.0810,  0.0675,  0.0445,  0.0165, -0.0045, -0.0174, -0.0241, -0.0277, -0.0297, -0.0330, -0.0370, -0.0463,
1:         -0.0538, -0.0669, -0.0830, -0.0875, -0.0917, -0.0862,  0.1175,  0.1053,  0.0868,  0.0637,  0.0426,  0.0298,
1:          0.0231], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-2.1305, -2.1410, -2.1784, -2.2367, -2.3057, -2.3772, -2.4461, -2.5166, -2.5811, -2.6347, -2.6762, -2.7046,
1:         -2.7203, -2.7344, -2.7444, -2.7600, -2.7617, -2.7518, -2.0835, -2.1105, -2.1551, -2.2150, -2.2779, -2.3402,
1:         -2.3952], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.2356, -0.2457, -0.2304, -0.1945, -0.1530, -0.0911, -0.0205,  0.0560,  0.1352,  0.2136,  0.2926,  0.3755,
1:          0.4524,  0.5275,  0.5863,  0.6357,  0.6649,  0.6733, -0.1524, -0.1649, -0.1644, -0.1440, -0.1101, -0.0684,
1:         -0.0148], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.5331,  0.5921,  0.5680,  0.4825,  0.3486,  0.2325,  0.1570,  0.0936,  0.0552,  0.0043, -0.0597, -0.0698,
1:         -0.0273,  0.0245,  0.0546,  0.0336, -0.0337, -0.0865,  0.4833,  0.5291,  0.5116,  0.4705,  0.3710,  0.2610,
1:          0.1889], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.0027, 1.0409, 1.0767, 1.1079, 1.1311, 1.1537, 1.1753, 1.2111, 1.2449, 1.2790, 1.3057, 1.3280, 1.3458, 1.3568,
1:         1.3584, 1.3648, 1.3672, 1.3758, 1.3955, 1.4094, 1.4322, 1.4540, 1.4758, 1.4927, 1.5137], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2460, -0.2405, -0.2404, -0.2425, -0.2365, -0.2413, -0.2430, -0.2451, -0.2464, -0.2510, -0.2531, -0.2432,
1:         -0.2472, -0.2406, -0.2472, -0.2548, -0.2551, -0.2590, -0.2580, -0.2558, -0.2550, -0.2509, -0.2494, -0.2537,
1:         -0.2529], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-8.6989e-03,  1.0020e-01, -2.9627e-05,  2.7330e-02, -1.1928e-01,  1.5575e-02, -7.8392e-02, -1.4762e-01,
1:         -1.0477e-02, -2.4398e-01, -3.8428e-03, -4.2311e-02, -4.3714e-02, -4.1202e-02, -7.9829e-02, -6.7300e-02,
1:          9.2148e-03, -1.5499e-01, -8.1240e-02,  6.9579e-02, -9.8970e-02,  1.8415e-01,  1.1256e-02, -8.6527e-02,
1:          8.1808e-02], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 3 [1/5 (20%)]	Loss: 0.31819 : 0.21558 :: 0.03052 (1.63 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 3 [2/5 (40%)]	Loss: 0.32760 : 0.21702 :: 0.03098 (8.50 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 3 [3/5 (60%)]	Loss: 0.32186 : 0.21517 :: 0.02784 (8.52 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 3 [4/5 (80%)]	Loss: 0.29330 : 0.20416 :: 0.02994 (8.51 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 3 : 0.2179695963859558
0: validation loss for velocity_u : 0.003521735779941082
0: validation loss for velocity_v : 0.005014278460294008
0: validation loss for specific_humidity : 0.006919319741427898
0: validation loss for velocity_z : 0.10538605600595474
0: validation loss for temperature : 0.02080332487821579
0: validation loss for total_precip : 0.375929057598114
0: validation loss for t2m : 1.0082130432128906
1: 4 : 00:32:10 :: batch_size = 96, lr = 1.903628792385485e-05
0: 4 : 00:32:10 :: batch_size = 96, lr = 1.903628792385485e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 4, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0798, -0.0715, -0.0538, -0.0282,  0.0027,  0.0372,  0.0732,  0.1098,  0.1456,  0.1781,  0.2055,  0.2286,
1:          0.2478,  0.2623,  0.2712,  0.2756,  0.2776,  0.2769, -0.0814, -0.0632, -0.0372, -0.0050,  0.0313,  0.0683,
1:          0.1033], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0930, -0.1017,  0.2373, -0.1268, -0.0562,  0.0439,  0.1560,  0.0307,  0.0574, -0.1449, -0.0626,  0.0278,
1:          0.0274,  0.1272, -0.0368, -0.0954,  0.0082,  0.1436,  0.0321,  0.1082,  0.0115, -0.2029, -0.1461, -0.0580,
1:          0.0323], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3130, -0.3672, -0.4187, -0.4692, -0.5148, -0.5517, -0.5698, -0.6012, -0.6058, -0.6013, -0.5949, -0.5930,
1:         -0.5854, -0.5808, -0.5771, -0.5743, -0.5748, -0.5760, -0.3910, -0.4458, -0.4970, -0.5409, -0.5604, -0.5961,
1:         -0.6090], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.7993, 0.7902, 0.7768, 0.7589, 0.7365, 0.7108, 0.6827, 0.6528, 0.6239, 0.5992, 0.5810, 0.5680, 0.5594, 0.5554,
1:         0.5557, 0.5590, 0.5635, 0.5692, 0.5759, 0.5829, 0.5899, 0.5966, 0.6005, 0.5998, 0.5949], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438,
1:         -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438,
1:         -0.2438], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 4, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan, 0.0293,    nan, 0.0009,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 4, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.3373, 0.3551, 0.3720, 0.3939, 0.4166, 0.4419, 0.4689, 0.4941, 0.5201, 0.5445, 0.5683, 0.5909, 0.6138, 0.6407,
1:         0.6593, 0.6815, 0.6954, 0.7037, 0.3161, 0.3364, 0.3565, 0.3762, 0.3970, 0.4221, 0.4466], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.1960, -0.1421, -0.0893, -0.0359,  0.0168,  0.0725,  0.1389,  0.2097,  0.2868,  0.3683,  0.4487,  0.5247,
1:          0.6000,  0.6818,  0.7635,  0.8477,  0.9306,  1.0045, -0.2021, -0.1539, -0.0985, -0.0428,  0.0139,  0.0797,
1:          0.1523], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([ 0.1203,  0.0182, -0.1002, -0.2287, -0.3463, -0.4340, -0.4885, -0.5065, -0.5010, -0.4782, -0.4478, -0.4284,
1:         -0.4210, -0.4231, -0.4324, -0.4393, -0.4432, -0.4438, -0.0449, -0.1365, -0.2435, -0.3537, -0.4449, -0.5133,
1:         -0.5466], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.3528, 0.3805, 0.3744, 0.3822, 0.4134, 0.4218, 0.3816, 0.4022, 0.4955, 0.5635, 0.6138, 0.6498, 0.6008, 0.5305,
1:         0.5058, 0.4676, 0.4721, 0.5038, 0.3544, 0.3730, 0.3680, 0.3795, 0.3980, 0.3785, 0.3515], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.5723, 0.5462, 0.5361, 0.5391, 0.5465, 0.5522, 0.5488, 0.5437, 0.5333, 0.5260, 0.5175, 0.5088, 0.5009, 0.4890,
1:         0.4731, 0.4621, 0.4494, 0.4426, 0.4466, 0.4511, 0.4637, 0.4738, 0.4795, 0.4817, 0.4862], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([0.2066, 0.1938, 0.3086, 0.6063, 1.2019, 1.9837, 2.8566, 3.5658, 3.9274, 0.1813, 0.2150, 0.3580, 0.7346, 1.4075,
1:         2.2642, 3.2025, 3.9513, 4.3315, 0.0597, 0.0900, 0.2890, 0.6853, 1.3213, 2.1620, 3.0186], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0071,  0.0679,  0.0126,  0.0199, -0.1020,  0.0454, -0.0565, -0.1223, -0.0025, -0.2443, -0.0188, -0.0206,
1:         -0.0411, -0.0336, -0.0566, -0.0455,  0.0169, -0.1102, -0.0589,  0.0558, -0.0810,  0.2029, -0.0169, -0.0474,
1:          0.0787], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 4, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0798, -0.0715, -0.0538, -0.0282,  0.0027,  0.0372,  0.0732,  0.1098,  0.1456,  0.1781,  0.2055,  0.2286,
0:          0.2478,  0.2623,  0.2712,  0.2756,  0.2776,  0.2769, -0.0814, -0.0632, -0.0372, -0.0050,  0.0313,  0.0683,
0:          0.1033], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.9801, -0.9964, -0.9933, -0.9718, -0.9337, -0.8854, -0.8335, -0.7839, -0.7399, -0.7034, -0.6760, -0.6575,
0:         -0.6460, -0.6386, -0.6336, -0.6301, -0.6271, -0.6255, -0.9631, -0.9587, -0.9344, -0.8933, -0.8413, -0.7863,
0:         -0.7352], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 1.0371,  0.9221,  0.7782,  0.6388,  0.5326,  0.4508,  0.3600,  0.2494,  0.1432,  0.0547, -0.0139, -0.0759,
0:         -0.1356, -0.1954, -0.2463, -0.2618, -0.2441, -0.2219,  0.7805,  0.6654,  0.5326,  0.3844,  0.2472,  0.1365,
0:          0.0436], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438,
0:         -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438,
0:         -0.2438], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 4, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 1.2710,    nan,    nan,    nan, 1.3335,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 4, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.8813, 0.9163, 0.9541, 1.0006, 1.0466, 1.0913, 1.1286, 1.1633, 1.1941, 1.2277, 1.2613, 1.2951, 1.3266, 1.3574,
0:         1.3761, 1.3930, 1.4021, 1.3981, 0.8839, 0.9207, 0.9603, 0.9979, 1.0337, 1.0687, 1.1007], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.8431, -0.8167, -0.7930, -0.7717, -0.7520, -0.7327, -0.7096, -0.6883, -0.6660, -0.6453, -0.6265, -0.6122,
0:         -0.5951, -0.5752, -0.5564, -0.5368, -0.5217, -0.5139, -0.8031, -0.7806, -0.7567, -0.7316, -0.7105, -0.6848,
0:         -0.6608], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.1364, -0.1870, -0.2223, -0.2615, -0.2851, -0.2948, -0.2974, -0.2859, -0.2707, -0.2599, -0.2515, -0.2524,
0:         -0.2666, -0.2768, -0.2820, -0.2869, -0.2874, -0.2866, -0.1616, -0.2079, -0.2540, -0.2926, -0.3222, -0.3407,
0:         -0.3424], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.5073, -0.5309, -0.5294, -0.5046, -0.5115, -0.5130, -0.5425, -0.5779, -0.6067, -0.6923, -0.7875, -0.8700,
0:         -0.9336, -0.9255, -0.9240, -0.9193, -0.8286, -0.7430, -0.6024, -0.6363, -0.6470, -0.6122, -0.5580, -0.4978,
0:         -0.4790], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.5984, 0.6070, 0.6212, 0.6372, 0.6479, 0.6548, 0.6594, 0.6699, 0.6768, 0.6836, 0.6808, 0.6706, 0.6586, 0.6476,
0:         0.6361, 0.6323, 0.6303, 0.6337, 0.6444, 0.6553, 0.6719, 0.6840, 0.6899, 0.6870, 0.6838], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2458, -0.2467, -0.2500, -0.2545, -0.2467, -0.2502, -0.2491, -0.2518, -0.2506, -0.2472, -0.2491, -0.2509,
0:         -0.2521, -0.2495, -0.2500, -0.2501, -0.2520, -0.2527, -0.2497, -0.2509, -0.2553, -0.2540, -0.2534, -0.2522,
0:         -0.2493], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0427,  0.0577,  0.0095,  0.0319, -0.1013,  0.0165, -0.0934, -0.0853,  0.0247, -0.2358, -0.0220, -0.0465,
0:         -0.0689, -0.0522, -0.0472, -0.0700, -0.0312, -0.1625, -0.0895,  0.1125, -0.0223,  0.1298, -0.0263, -0.0642,
0:          0.1091], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 4 [1/5 (20%)]	Loss: 0.33729 : 0.24704 :: 0.02854 (1.56 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 4 [2/5 (40%)]	Loss: 0.29705 : 0.21590 :: 0.02744 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 4 [3/5 (60%)]	Loss: 0.25943 : 0.18148 :: 0.02938 (8.49 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 4 [4/5 (80%)]	Loss: 0.31394 : 0.22064 :: 0.02755 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 4 : 0.22477450966835022
0: validation loss for velocity_u : 0.0036361459642648697
0: validation loss for velocity_v : 0.00504817720502615
0: validation loss for specific_humidity : 0.006966349668800831
0: validation loss for velocity_z : 0.10823117196559906
0: validation loss for temperature : 0.021336667239665985
0: validation loss for total_precip : 0.39194756746292114
0: validation loss for t2m : 1.0362552404403687
1: 5 : 00:38:23 :: batch_size = 96, lr = 1.857198821839498e-05
0: 5 : 00:38:23 :: batch_size = 96, lr = 1.857198821839498e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 5, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0: Created sparse mask for t2m with 10.0% data retained
1:      first 25 values: tensor([-0.2663, -0.2742, -0.2820, -0.2894, -0.2966, -0.3035, -0.3104, -0.3169, -0.3232, -0.3294, -0.3353, -0.3411,
1:         -0.3467, -0.3524, -0.3578, -0.3635, -0.3692, -0.3750, -0.2809, -0.2891, -0.2972, -0.3050, -0.3124, -0.3196,
1:         -0.3265], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0217,  0.0709, -0.1098,  0.0334, -0.1145,  0.0407,  0.1184,  0.0070,  0.0886, -0.1539,  0.0706,  0.0752,
1:          0.1060, -0.0862,  0.0695, -0.0265, -0.0077, -0.0629, -0.1496,  0.1205, -0.0666, -0.0208, -0.0331, -0.0224,
1:         -0.0997], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6496, -0.6484, -0.6472, -0.6460, -0.6447, -0.6441, -0.6435, -0.6430, -0.6424, -0.6419, -0.6413, -0.6413,
1:         -0.6413, -0.6413, -0.6413, -0.6413, -0.6413, -0.6411, -0.6515, -0.6504, -0.6495, -0.6484, -0.6473, -0.6469,
1:         -0.6465], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.0662, -0.0729, -0.0794, -0.0855, -0.0911, -0.0964, -0.1012, -0.1060, -0.1101, -0.1139, -0.1173, -0.1201,
1:         -0.1227, -0.1246, -0.1261, -0.1272, -0.1278, -0.1283, -0.1284, -0.1282, -0.1278, -0.1271, -0.1266, -0.1262,
1:         -0.1256], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2313, -0.2338, -0.2363, -0.2388, -0.2413, -0.2438, -0.2451, -0.2476, -0.2489, -0.2388, -0.2388, -0.2388,
1:         -0.2388, -0.2401, -0.2413, -0.2426, -0.2451, -0.2464, -0.2363, -0.2363, -0.2363, -0.2363, -0.2363, -0.2376,
1:         -0.2401], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 5, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 5, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.4665, -0.4759, -0.4905, -0.4986, -0.5068, -0.5135, -0.5208, -0.5251, -0.5339, -0.5416, -0.5515, -0.5586,
1:         -0.5664, -0.5708, -0.5780, -0.5852, -0.5929, -0.6057, -0.4759, -0.4856, -0.4948, -0.5043, -0.5129, -0.5149,
1:         -0.5221], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.0995, -0.1042, -0.1040, -0.1101, -0.1135, -0.1161, -0.1205, -0.1265, -0.1326, -0.1383, -0.1441, -0.1540,
1:         -0.1610, -0.1664, -0.1770, -0.1894, -0.2072, -0.2276, -0.0857, -0.0909, -0.0950, -0.0979, -0.1021, -0.1014,
1:         -0.1067], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.4753, -0.4735, -0.4668, -0.4651, -0.4654, -0.4653, -0.4653, -0.4663, -0.4683, -0.4699, -0.4687, -0.4695,
1:         -0.4759, -0.4819, -0.4829, -0.4811, -0.4768, -0.4768, -0.4688, -0.4622, -0.4569, -0.4539, -0.4552, -0.4582,
1:         -0.4598], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([1.0682, 1.0599, 1.0455, 1.0339, 1.0140, 0.9869, 0.9738, 0.9879, 0.9676, 0.9600, 0.9953, 0.9923, 0.9315, 0.9147,
1:         0.8857, 0.7883, 0.8040, 0.8958, 0.9279, 0.8625, 0.7950, 0.7257, 0.6937, 0.6932, 0.6799], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.9888, 0.9984, 1.0060, 1.0058, 0.9999, 0.9942, 0.9887, 0.9826, 0.9762, 0.9702, 0.9584, 0.9450, 0.9317, 0.9135,
1:         0.8939, 0.8740, 0.8517, 0.8306, 0.8111, 0.7901, 0.7713, 0.7488, 0.7240, 0.6984, 0.6713], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2251, -0.2342, -0.2387, -0.2446, -0.2494, -0.2486, -0.2527, -0.2542, -0.2517, -0.2262, -0.2323, -0.2409,
1:         -0.2448, -0.2515, -0.2503, -0.2522, -0.2520, -0.2527, -0.2313, -0.2386, -0.2438, -0.2493, -0.2508, -0.2511,
1:         -0.2514], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-1.4205e-03,  6.0488e-02, -2.9399e-02,  1.6953e-02, -6.7496e-02,  5.4195e-02, -8.1856e-02, -1.0298e-01,
1:          2.0300e-02, -2.5317e-01, -3.4786e-02, -3.4271e-02, -2.2802e-02, -1.8662e-02, -7.3804e-02, -5.2860e-02,
1:          1.3085e-02, -9.5448e-02, -7.7577e-02,  5.0558e-02, -4.2127e-02,  1.8279e-01, -1.3007e-04, -4.5372e-02,
1:          6.0007e-02], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 5, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.4608, 1.4663, 1.4668, 1.4585, 1.4393, 1.4082, 1.3648, 1.3125, 1.2571, 1.2033, 1.1523, 1.1060, 1.0668, 1.0363,
0:         1.0135, 0.9960, 0.9800, 0.9605, 1.4247, 1.4208, 1.4108, 1.3934, 1.3682, 1.3347, 1.2935], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.7588, -0.7093, -0.6558, -0.5998, -0.5443, -0.4924, -0.4467, -0.4093, -0.3815, -0.3615, -0.3457, -0.3314,
0:         -0.3170, -0.3003, -0.2797, -0.2546, -0.2273, -0.2001, -0.8247, -0.7734, -0.7218, -0.6709, -0.6227, -0.5784,
0:         -0.5398], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6610, -0.5668, -0.4103, -0.2823, -0.2287, -0.2593, -0.3709, -0.5220, -0.6456, -0.7168, -0.7660, -0.8142,
0:         -0.8426, -0.8350, -0.7814, -0.6467, -0.4092, -0.1291, -0.5537, -0.4618, -0.3698, -0.3151, -0.3173, -0.3764,
0:         -0.4694], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([ 0.0473,  0.1974,  0.2562,  0.2466,  0.0725, -0.0739, -0.1808, -0.2348, -0.2492,  0.0822,  0.2058,  0.2550,
0:          0.1830,  0.0197, -0.1003, -0.2048, -0.2324, -0.2504,  0.0918,  0.1194,  0.1770,  0.0533, -0.0703, -0.1423,
0:         -0.2312], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 5, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan, -0.3001, -0.3481,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 5, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.7593, 0.7542, 0.7436, 0.7362, 0.7315, 0.7307, 0.7309, 0.7327, 0.7319, 0.7317, 0.7302, 0.7329, 0.7365, 0.7492,
0:         0.7630, 0.7812, 0.8004, 0.8140, 0.7696, 0.7679, 0.7639, 0.7559, 0.7514, 0.7526, 0.7516], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.4909, -0.4637, -0.4283, -0.3900, -0.3427, -0.2972, -0.2469, -0.1991, -0.1501, -0.0977, -0.0478, -0.0085,
0:          0.0291,  0.0567,  0.0693,  0.0778,  0.0764,  0.0691, -0.5360, -0.5069, -0.4692, -0.4292, -0.3855, -0.3366,
0:         -0.2915], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([ 0.2426,  0.2111,  0.1841,  0.1523,  0.1181,  0.0868,  0.0530,  0.0202, -0.0118, -0.0407, -0.0648, -0.0905,
0:         -0.1186, -0.1382, -0.1463, -0.1476, -0.1388, -0.1296,  0.2123,  0.1793,  0.1507,  0.1232,  0.0935,  0.0601,
0:          0.0319], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.0502, -0.1102, -0.1521, -0.2765, -0.4176, -0.5897, -0.7851, -0.9405, -1.0581, -1.0600, -0.9709, -0.8479,
0:         -0.7559, -0.6092, -0.3317, -0.0505,  0.2340,  0.4311, -0.1091, -0.1952, -0.2768, -0.4315, -0.5626, -0.7441,
0:         -0.9709], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.0580, 0.0561, 0.0555, 0.0502, 0.0409, 0.0344, 0.0299, 0.0327, 0.0392, 0.0529, 0.0657, 0.0795, 0.0963, 0.1154,
0:         0.1375, 0.1678, 0.1994, 0.2346, 0.2698, 0.3028, 0.3373, 0.3691, 0.4007, 0.4357, 0.4704], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1365, -0.1449, -0.1527, -0.1560, -0.1588, -0.1524, -0.1562, -0.1567, -0.1519, -0.1358, -0.1433, -0.1576,
0:         -0.1626, -0.1712, -0.1693, -0.1633, -0.1631, -0.1596, -0.1410, -0.1527, -0.1666, -0.1728, -0.1796, -0.1817,
0:         -0.1770], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0152,  0.0630, -0.0264,  0.0413, -0.0795,  0.0129, -0.0663, -0.1095,  0.0335, -0.2330, -0.0628, -0.0629,
0:         -0.0631, -0.0472, -0.0581, -0.0360, -0.0132, -0.1349, -0.0883,  0.0619, -0.0561,  0.1041, -0.0454, -0.0323,
0:          0.0363], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 5 [1/5 (20%)]	Loss: 0.28026 : 0.20747 :: 0.02610 (1.66 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 5 [2/5 (40%)]	Loss: 0.32160 : 0.26806 :: 0.02907 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 5 [3/5 (60%)]	Loss: 0.25680 : 0.18543 :: 0.02727 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 5 [4/5 (80%)]	Loss: 0.26326 : 0.19129 :: 0.02635 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 5 : 0.21125566959381104
0: validation loss for velocity_u : 0.0038262761663645506
0: validation loss for velocity_v : 0.005328204017132521
0: validation loss for specific_humidity : 0.006114666350185871
0: validation loss for velocity_z : 0.12032344192266464
0: validation loss for temperature : 0.018004678189754486
0: validation loss for total_precip : 0.2908729016780853
0: validation loss for t2m : 1.0343196392059326
1: 6 : 00:44:31 :: batch_size = 96, lr = 1.8119012895995104e-05
0: 6 : 00:44:31 :: batch_size = 96, lr = 1.8119012895995104e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 6, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.5721, 0.5690, 0.5702, 0.5777, 0.5898, 0.6070, 0.6306, 0.6589, 0.6893, 0.7208, 0.7508, 0.7777, 0.8011, 0.8217,
1:         0.8400, 0.8574, 0.8755, 0.8963, 0.5243, 0.5336, 0.5480, 0.5687, 0.5943, 0.6235, 0.6559], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0715, -0.0100, -0.0661, -0.0053, -0.0764, -0.0355, -0.1367, -0.0744,  0.0766, -0.0659, -0.0293,  0.0761,
1:          0.0584, -0.0273, -0.0776, -0.0856, -0.0151, -0.1326,  0.0246,  0.1331,  0.0364,  0.1703, -0.0884, -0.0350,
1:          0.0283], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.2926,  0.2487,  0.2002,  0.1704,  0.1394,  0.0779,  0.0403, -0.0031, -0.0695, -0.1179, -0.1737, -0.2374,
1:         -0.2967, -0.3557, -0.4009, -0.4575, -0.5040, -0.5225,  0.2483,  0.1942,  0.1442,  0.0842,  0.0185, -0.0464,
1:         -0.1159], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.2760, 0.2921, 0.3131, 0.3356, 0.3575, 0.3789, 0.3984, 0.4142, 0.4273, 0.4383, 0.4462, 0.4512, 0.4542, 0.4546,
1:         0.4520, 0.4469, 0.4390, 0.4282, 0.4148, 0.3990, 0.3816, 0.3627, 0.3421, 0.3201, 0.2975], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2409, -0.2409, -0.2409, -0.2409, -0.2398, -0.2398, -0.2386, -0.2351, -0.2351, -0.2409, -0.2409, -0.2409,
1:         -0.2409, -0.2409, -0.2409, -0.2409, -0.2409, -0.2398, -0.2409, -0.2409, -0.2409, -0.2409, -0.2409, -0.2409,
1:         -0.2409], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 6, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan, 1.2107,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 6, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([1.4824, 1.5037, 1.5223, 1.5438, 1.5679, 1.5905, 1.6191, 1.6482, 1.6734, 1.6937, 1.7072, 1.7193, 1.7240, 1.7281,
1:         1.7371, 1.7446, 1.7543, 1.7577, 1.4832, 1.5069, 1.5301, 1.5532, 1.5752, 1.6027, 1.6228], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([1.1081, 1.1510, 1.1983, 1.2388, 1.2800, 1.3176, 1.3527, 1.3856, 1.4133, 1.4357, 1.4590, 1.4795, 1.5006, 1.5174,
1:         1.5254, 1.5302, 1.5317, 1.5324, 1.1268, 1.1719, 1.2140, 1.2509, 1.2812, 1.3123, 1.3406], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.5408, -0.5340, -0.5146, -0.4915, -0.4628, -0.4357, -0.4092, -0.3912, -0.3793, -0.3697, -0.3658, -0.3611,
1:         -0.3661, -0.3674, -0.3675, -0.3669, -0.3618, -0.3616, -0.5425, -0.5231, -0.4949, -0.4636, -0.4351, -0.4096,
1:         -0.3899], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.0786,  0.0715,  0.2838,  0.4462,  0.5624,  0.6879,  0.7952,  0.8320,  0.7986,  0.7193,  0.6021,  0.4756,
1:          0.2490, -0.0380, -0.2944, -0.4636, -0.4339, -0.3411, -0.2004,  0.0164,  0.2386,  0.3902,  0.5367,  0.7054,
1:          0.8367], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.7216, 1.6856, 1.6425, 1.5938, 1.5432, 1.4984, 1.4606, 1.4343, 1.4203, 1.4181, 1.4224, 1.4257, 1.4273, 1.4246,
1:         1.4202, 1.4117, 1.3936, 1.3634, 1.3176, 1.2619, 1.2001, 1.1375, 1.0744, 1.0184, 0.9648], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.1897, -0.1866, -0.1728, -0.1482, -0.1301, -0.0996, -0.0879, -0.0697, -0.0489, -0.1968, -0.1848, -0.1649,
1:         -0.1381, -0.1235, -0.1011, -0.0814, -0.0660, -0.0523, -0.1769, -0.1699, -0.1506, -0.1318, -0.1132, -0.0925,
1:         -0.0808], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0140,  0.0607, -0.0365,  0.0094, -0.0777,  0.0169, -0.0785, -0.1315,  0.0108, -0.2106, -0.0373, -0.0568,
1:         -0.0117, -0.0384, -0.1112, -0.0729,  0.0076, -0.0993, -0.0490, -0.0005, -0.0486,  0.1147, -0.0312, -0.0360,
1:          0.0121], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 6, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.5721, 0.5690, 0.5702, 0.5777, 0.5898, 0.6070, 0.6306, 0.6589, 0.6893, 0.7208, 0.7508, 0.7777, 0.8011, 0.8217,
0:         0.8400, 0.8574, 0.8755, 0.8963, 0.5243, 0.5336, 0.5480, 0.5687, 0.5943, 0.6235, 0.6559], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.4079, 0.4541, 0.5030, 0.5527, 0.6035, 0.6557, 0.7085, 0.7621, 0.8172, 0.8711, 0.9229, 0.9726, 1.0186, 1.0598,
0:         1.0975, 1.1325, 1.1638, 1.1905, 0.4208, 0.4701, 0.5204, 0.5703, 0.6213, 0.6747, 0.7282], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.7812, 0.7141, 0.6325, 0.5408, 0.4446, 0.3529, 0.2881, 0.2601, 0.2646, 0.2914, 0.3339, 0.3909, 0.4614, 0.5453,
0:         0.6359, 0.7085, 0.7287, 0.6996, 0.9031, 0.8696, 0.8383, 0.8047, 0.7667, 0.7365, 0.7264], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2409, -0.2409, -0.2409, -0.2409, -0.2398, -0.2398, -0.2386, -0.2351, -0.2351, -0.2409, -0.2409, -0.2409,
0:         -0.2409, -0.2409, -0.2409, -0.2409, -0.2409, -0.2398, -0.2409, -0.2409, -0.2409, -0.2409, -0.2409, -0.2409,
0:         -0.2409], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 6, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan, 0.0902, 0.0651,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 6, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([1.2589, 1.2843, 1.3072, 1.3368, 1.3686, 1.4033, 1.4421, 1.4880, 1.5372, 1.5889, 1.6366, 1.6852, 1.7271, 1.7706,
0:         1.8103, 1.8390, 1.8546, 1.8514, 1.2348, 1.2626, 1.2954, 1.3339, 1.3707, 1.4132, 1.4561], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.3938, 0.4213, 0.4509, 0.4802, 0.5095, 0.5379, 0.5578, 0.5717, 0.5752, 0.5743, 0.5700, 0.5611, 0.5514, 0.5423,
0:         0.5288, 0.5194, 0.5084, 0.4945, 0.3621, 0.3929, 0.4218, 0.4507, 0.4788, 0.5050, 0.5252], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6400, -0.6473, -0.6483, -0.6501, -0.6481, -0.6441, -0.6389, -0.6339, -0.6328, -0.6315, -0.6333, -0.6383,
0:         -0.6472, -0.6554, -0.6593, -0.6616, -0.6582, -0.6510, -0.6374, -0.6404, -0.6375, -0.6362, -0.6338, -0.6319,
0:         -0.6280], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.5572,  0.5400,  0.4573,  0.2665,  0.1106, -0.0353, -0.2173, -0.3591, -0.5106, -0.6836, -0.8923, -1.1555,
0:         -1.4050, -1.4970, -1.4485, -1.3130, -1.0671, -0.8012,  0.0211,  0.1368,  0.2263,  0.1973,  0.1971,  0.1594,
0:         -0.0127], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([ 0.3647,  0.3271,  0.2989,  0.2733,  0.2493,  0.2241,  0.1996,  0.1743,  0.1538,  0.1394,  0.1254,  0.1111,
0:          0.0930,  0.0714,  0.0488,  0.0291,  0.0095, -0.0041, -0.0148, -0.0183, -0.0142, -0.0024,  0.0155,  0.0430,
0:          0.0714], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1761, -0.1848, -0.1950, -0.1783, -0.1487, -0.0689,  0.0387,  0.1434,  0.2541, -0.1800, -0.2026, -0.2110,
0:         -0.1993, -0.1693, -0.0498,  0.0539,  0.1811,  0.3174, -0.1962, -0.2135, -0.2205, -0.2043, -0.1517, -0.0383,
0:          0.1069], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0288,  0.0479, -0.0602,  0.0042, -0.0659, -0.0196, -0.1186, -0.1086,  0.0041, -0.2137, -0.0298, -0.0693,
0:         -0.0412, -0.0481, -0.0594, -0.0641,  0.0223, -0.1511, -0.0721,  0.0547, -0.0398,  0.0914, -0.0691, -0.0438,
0:          0.0506], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 6 [1/5 (20%)]	Loss: 0.27329 : 0.20017 :: 0.02723 (1.66 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 6 [2/5 (40%)]	Loss: 0.28852 : 0.20616 :: 0.02660 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 6 [3/5 (60%)]	Loss: 0.24870 : 0.18244 :: 0.02706 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 6 [4/5 (80%)]	Loss: 0.31511 : 0.24668 :: 0.02727 (8.43 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 6 : 0.20451116561889648
0: validation loss for velocity_u : 0.0035104108974337578
0: validation loss for velocity_v : 0.0048362393863499165
0: validation loss for specific_humidity : 0.006581015884876251
0: validation loss for velocity_z : 0.10734151303768158
0: validation loss for temperature : 0.020114455372095108
0: validation loss for total_precip : 0.25369489192962646
0: validation loss for t2m : 1.0354996919631958
1: 7 : 00:50:40 :: batch_size = 96, lr = 1.7677085752190346e-05
0: 7 : 00:50:40 :: batch_size = 96, lr = 1.7677085752190346e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 7, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.9587, 1.0001, 1.0411, 1.0693, 1.0846, 1.0749, 1.0156, 0.9222, 0.8492, 0.8174, 0.8023, 0.7991, 0.8281, 0.8830,
1:         0.9355, 0.9760, 1.0106, 1.0383, 0.9592, 1.0053, 1.0511, 1.0824, 1.0994, 1.0934, 1.0425], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.1866, -0.1169, -0.2683,  0.0254, -0.0281,  0.0284, -0.0328, -0.0294, -0.0678,  0.1086,  0.0094,  0.0144,
1:         -0.0300,  0.1424, -0.0829,  0.2144,  0.0518,  0.0578, -0.0313,  0.0587,  0.1177,  0.0114, -0.0133, -0.0734,
1:          0.2962], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.5888, 0.5910, 0.5960, 0.6003, 0.5948, 0.5919, 0.5981, 0.6372, 0.5613, 0.4158, 0.5046, 0.5781, 0.6209, 0.6785,
1:         0.7341, 0.7774, 0.8133, 0.8486, 0.5847, 0.5836, 0.5874, 0.5904, 0.5935, 0.5894, 0.5914], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.9019, 0.9192, 0.9252, 0.9340, 0.9552, 0.9659, 0.9593, 0.9893, 1.0829, 1.1679, 1.1720, 1.1233, 1.0845, 1.0669,
1:         1.0651, 1.0917, 1.1470, 1.2104, 1.2680, 1.3117, 1.3319, 1.3329, 1.3302, 1.3277, 1.3207], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([0.5566, 0.9120, 1.4582, 2.2034, 3.1855, 3.9502, 4.4597, 4.3435, 4.2987, 0.4451, 0.6843, 1.2673, 1.8814, 2.5484,
1:         3.4144, 4.1894, 4.1641, 3.8790, 0.3450, 0.5129, 0.9511, 1.5606, 2.0562, 2.8773, 3.6352], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 7, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0541,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  0.3376,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 7, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.8744, 0.8877, 0.9032, 0.9271, 0.9583, 0.9835, 1.0027, 1.0010, 0.9852, 0.9562, 0.9167, 0.8809, 0.8384, 0.7859,
1:         0.7360, 0.6816, 0.6338, 0.5985, 0.8851, 0.8965, 0.9102, 0.9389, 0.9707, 1.0043, 1.0231], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-2.0071, -1.9386, -1.8742, -1.8169, -1.7597, -1.7037, -1.6445, -1.5891, -1.5330, -1.4796, -1.4238, -1.3618,
1:         -1.2964, -1.2241, -1.1509, -1.0749, -0.9999, -0.9251, -2.0838, -2.0089, -1.9368, -1.8701, -1.8100, -1.7522,
1:         -1.6941], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([ 0.0117,  0.0030, -0.0044, -0.0104, -0.0106, -0.0061,  0.0016,  0.0132,  0.0279,  0.0426,  0.0513,  0.0584,
1:          0.0661,  0.0679,  0.0637,  0.0488,  0.0256, -0.0053,  0.0002, -0.0072, -0.0178, -0.0214, -0.0231, -0.0174,
1:         -0.0058], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-1.2441, -1.3908, -1.5503, -1.5521, -1.4501, -1.2888, -1.0069, -0.5920, -0.1247,  0.2652,  0.4930,  0.5584,
1:          0.5351,  0.4415,  0.3266,  0.1769, -0.0125, -0.1596, -1.6853, -1.7894, -1.8987, -1.8354, -1.6696, -1.4276,
1:         -1.1005], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.6820, 0.7296, 0.7735, 0.8097, 0.8381, 0.8606, 0.8796, 0.8934, 0.9072, 0.9203, 0.9338, 0.9467, 0.9592, 0.9699,
1:         0.9833, 0.9978, 1.0102, 1.0219, 1.0322, 1.0463, 1.0641, 1.0860, 1.1065, 1.1273, 1.1400], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2366, -0.2383, -0.2319, -0.2333, -0.2352, -0.2399, -0.2448, -0.2462, -0.2445, -0.2497, -0.2503, -0.2455,
1:         -0.2426, -0.2417, -0.2469, -0.2496, -0.2486, -0.2514, -0.2550, -0.2522, -0.2510, -0.2492, -0.2432, -0.2455,
1:         -0.2490], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0297,  0.0559, -0.0675, -0.0184, -0.0568,  0.0311, -0.0780, -0.1144, -0.0280, -0.1967, -0.0350, -0.0711,
1:         -0.0010, -0.0133, -0.0905, -0.0663,  0.0138, -0.1251, -0.0623, -0.0111, -0.0713,  0.1255,  0.0022, -0.0361,
1:          0.0136], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 7, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.9587, 1.0001, 1.0411, 1.0693, 1.0846, 1.0749, 1.0156, 0.9222, 0.8492, 0.8174, 0.8023, 0.7991, 0.8281, 0.8830,
0:         0.9355, 0.9760, 1.0106, 1.0383, 0.9592, 1.0053, 1.0511, 1.0824, 1.0994, 1.0934, 1.0425], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-2.2378, -2.2101, -2.1698, -2.1120, -2.0375, -1.9459, -1.8455, -1.7573, -1.6824, -1.5893, -1.4610, -1.3273,
0:         -1.2208, -1.1366, -1.0577, -0.9861, -0.9277, -0.8799, -2.2236, -2.2071, -2.1763, -2.1237, -2.0548, -1.9676,
0:         -1.8670], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.4289, -0.4463, -0.1030,  0.2751,  0.2903,  0.6010,  1.4028,  1.0204, -1.3155, -3.4080, -3.3819, -2.3193,
0:         -1.6001, -0.8353,  0.1295,  0.4011, -0.0834, -0.4724, -0.4115, -0.7353, -0.6853, -0.4420, -0.5702, -0.5245,
0:          0.2946], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([0.5566, 0.9120, 1.4582, 2.2034, 3.1855, 3.9502, 4.4597, 4.3435, 4.2987, 0.4451, 0.6843, 1.2673, 1.8814, 2.5484,
0:         3.4144, 4.1894, 4.1641, 3.8790, 0.3450, 0.5129, 0.9511, 1.5606, 2.0562, 2.8773, 3.6352], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 7, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan, 0.7103,    nan,    nan,    nan, 0.7105,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 7, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([1.4279, 1.4145, 1.3964, 1.3761, 1.3537, 1.3369, 1.3216, 1.3089, 1.2977, 1.2820, 1.2628, 1.2405, 1.2142, 1.1933,
0:         1.1764, 1.1620, 1.1532, 1.1463, 1.4039, 1.3849, 1.3625, 1.3384, 1.3114, 1.2875, 1.2622], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([ 0.5365,  0.4697,  0.4041,  0.3410,  0.2762,  0.2143,  0.1520,  0.0937,  0.0399, -0.0055, -0.0444, -0.0785,
0:         -0.1101, -0.1380, -0.1640, -0.1862, -0.2028, -0.2179,  0.5844,  0.5167,  0.4490,  0.3841,  0.3191,  0.2534,
0:          0.1889], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.5656, -0.5682, -0.5757, -0.5882, -0.6058, -0.6267, -0.6505, -0.6747, -0.6966, -0.7146, -0.7326, -0.7462,
0:         -0.7535, -0.7570, -0.7561, -0.7499, -0.7413, -0.7296, -0.5402, -0.5389, -0.5443, -0.5552, -0.5740, -0.5972,
0:         -0.6220], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-1.6134, -1.6652, -2.1636, -2.4956, -2.2970, -2.2810, -1.9341,  0.1071,  2.6158,  2.6160,  0.7425,  0.7385,
0:          2.8231,  3.7787,  2.7388,  0.8776, -1.4680, -3.7093, -1.9064, -1.6254, -1.7360, -1.6844, -1.4013, -1.4786,
0:         -1.2029], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.0304, 1.0111, 0.9921, 0.9674, 0.9409, 0.9092, 0.8777, 0.8437, 0.8141, 0.7868, 0.7616, 0.7323, 0.6998, 0.6674,
0:         0.6381, 0.6104, 0.5782, 0.5398, 0.4914, 0.4406, 0.3892, 0.3412, 0.2957, 0.2595, 0.2231], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1510, -0.1630, -0.1931, -0.1670, -0.1755, -0.1406, -0.0609,  0.0379,  0.1247, -0.1155, -0.1650, -0.2178,
0:         -0.2618, -0.2770, -0.2164, -0.1658, -0.0405,  0.1380, -0.1347, -0.2144, -0.2489, -0.3509, -0.3614, -0.3027,
0:         -0.1595], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0194,  0.0510, -0.0767, -0.0126, -0.0810, -0.0217, -0.0922, -0.1096, -0.0007, -0.1912, -0.0518, -0.0673,
0:         -0.0396, -0.0346, -0.0668, -0.0770, -0.0147, -0.1627, -0.0629,  0.0196, -0.0496,  0.0748, -0.0332, -0.0442,
0:          0.0196], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 7 [1/5 (20%)]	Loss: 0.27086 : 0.20460 :: 0.02557 (1.77 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 7 [2/5 (40%)]	Loss: 0.27312 : 0.19797 :: 0.02592 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 7 [3/5 (60%)]	Loss: 0.26688 : 0.20074 :: 0.02568 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 7 [4/5 (80%)]	Loss: 0.25843 : 0.20305 :: 0.02733 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 7 : 0.2274855077266693
0: validation loss for velocity_u : 0.0035721473395824432
0: validation loss for velocity_v : 0.0051261079497635365
0: validation loss for specific_humidity : 0.007337067276239395
0: validation loss for velocity_z : 0.11970293521881104
0: validation loss for temperature : 0.024302106350660324
0: validation loss for total_precip : 0.4113005995750427
0: validation loss for t2m : 1.021057367324829
1: 8 : 00:56:51 :: batch_size = 96, lr = 1.7245937319210094e-05
0: 8 : 00:56:51 :: batch_size = 96, lr = 1.7245937319210094e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 8, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.4644, -0.4845, -0.5036, -0.5226, -0.5415, -0.5608, -0.5807, -0.6018, -0.6244, -0.6482, -0.6715, -0.6918,
0:         -0.7066, -0.7137, -0.7117, -0.7005, -0.6811, -0.6547, -0.4952, -0.5160, -0.5368, -0.5577, -0.5790, -0.6006,
0:         -0.6232], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-2.8872, -2.8969, -2.9014, -2.8982, -2.8848, -2.8605, -2.8255, -2.7807, -2.7264, -2.6619, -2.5849, -2.4919,
0:         -2.3798, -2.2476, -2.0973, -1.9333, -1.7620, -1.5900, -2.9079, -2.9153, -2.9127, -2.8997, -2.8759, -2.8413,
0:         -2.7956], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2009, -0.1901, -0.1411, -0.0542,  0.0383,  0.0937,  0.1002,  0.0850,  0.0970,  0.1720,  0.3036,  0.4503,
0:          0.5623,  0.6156,  0.6210,  0.6091,  0.6080,  0.6178, -0.3390, -0.2727, -0.2118, -0.1466, -0.0781, -0.0150,
0:          0.0426], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2467, -0.2467, -0.2467, -0.2467, -0.2456, -0.2456, -0.2444, -0.2444, -0.2456, -0.2456, -0.2456, -0.2467,
0:         -0.2467, -0.2456, -0.2456, -0.2444, -0.2444, -0.2456, -0.2467, -0.2467, -0.2467, -0.2467, -0.2467, -0.2456,
0:         -0.2456], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 8, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan, -0.7846,     nan, -0.8257,     nan,     nan,     nan, -0.9021,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 8, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.2206, -0.2308, -0.2378, -0.2406, -0.2418, -0.2417, -0.2398, -0.2399, -0.2360, -0.2332, -0.2273, -0.2182,
0:         -0.2110, -0.2002, -0.1885, -0.1800, -0.1732, -0.1660, -0.2014, -0.2081, -0.2126, -0.2141, -0.2146, -0.2152,
0:         -0.2174], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-1.4600, -1.4070, -1.3538, -1.3002, -1.2381, -1.1668, -1.0899, -1.0092, -0.9317, -0.8667, -0.8208, -0.7905,
0:         -0.7749, -0.7612, -0.7418, -0.7118, -0.6679, -0.6154, -1.6115, -1.5609, -1.5062, -1.4476, -1.3776, -1.3026,
0:         -1.2169], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.1267, -0.1369, -0.1603, -0.2031, -0.2644, -0.3430, -0.4313, -0.5124, -0.5767, -0.6192, -0.6436, -0.6496,
0:         -0.6462, -0.6449, -0.6449, -0.6486, -0.6520, -0.6492, -0.1587, -0.1648, -0.1828, -0.2154, -0.2727, -0.3475,
0:         -0.4315], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.1784, -0.3910, -0.5438, -0.6491, -0.6821, -0.6880, -0.6713, -0.6620, -0.7526, -0.8390, -0.9024, -1.0071,
0:         -1.1301, -1.2677, -1.4052, -1.5147, -1.5569, -1.5799, -0.5470, -0.7379, -0.8483, -0.9218, -0.9195, -0.9048,
0:         -0.9247], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-1.1437, -1.1188, -1.0978, -1.0803, -1.0660, -1.0562, -1.0492, -1.0482, -1.0468, -1.0465, -1.0450, -1.0457,
0:         -1.0489, -1.0549, -1.0581, -1.0599, -1.0598, -1.0550, -1.0495, -1.0424, -1.0367, -1.0294, -1.0242, -1.0150,
0:         -1.0077], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([ 0.2795,  0.2372,  0.1897,  0.1294,  0.0515,  0.0016, -0.0202, -0.0486, -0.0599,  0.4862,  0.4242,  0.3160,
0:          0.2173,  0.1114,  0.0416, -0.0078, -0.0623, -0.0767,  0.8127,  0.7054,  0.5478,  0.3856,  0.2363,  0.1213,
0:          0.0213], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0276,  0.0485, -0.0322,  0.0122, -0.0378, -0.0170, -0.0751, -0.1057, -0.0228, -0.1580, -0.0460, -0.0790,
0:         -0.0355, -0.0159, -0.0431, -0.0495, -0.0267, -0.1225, -0.0447,  0.0355, -0.0497,  0.0472, -0.0497, -0.0302,
0:          0.0033], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 8, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.4644, -0.4845, -0.5036, -0.5226, -0.5415, -0.5608, -0.5807, -0.6018, -0.6244, -0.6482, -0.6715, -0.6918,
1:         -0.7066, -0.7137, -0.7117, -0.7005, -0.6811, -0.6547, -0.4952, -0.5160, -0.5368, -0.5577, -0.5790, -0.6006,
1:         -0.6232], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0357,  0.0298,  0.1328,  0.0355, -0.1175,  0.0739, -0.0398,  0.1109, -0.0437, -0.0631,  0.0914, -0.0041,
1:          0.0185,  0.0279,  0.0891,  0.0540, -0.0855,  0.1136, -0.1100,  0.0137, -0.1146,  0.0302, -0.1516, -0.0043,
1:         -0.1065], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3316, -0.4067, -0.4875, -0.5682, -0.6122, -0.6560, -0.6884, -0.6911, -0.6963, -0.7015, -0.7048, -0.7081,
1:         -0.7122, -0.7156, -0.7197, -0.7239, -0.7237, -0.7234, -0.4159, -0.4879, -0.5598, -0.6274, -0.6489, -0.6739,
1:         -0.6988], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., 0., 0., 0., -0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.3976, -0.4459, -0.4944, -0.5480, -0.6111, -0.6855, -0.7677, -0.8521, -0.9332, -1.0077, -1.0766, -1.1431,
1:         -1.2109, -1.2819, -1.3539, -1.4232, -1.4856, -1.5392, -1.5843, -1.6234, -1.6593, -1.6940, -1.7272, -1.7587,
1:         -1.7878], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2467, -0.2467, -0.2467, -0.2467, -0.2456, -0.2456, -0.2444, -0.2444, -0.2456, -0.2456, -0.2456, -0.2467,
1:         -0.2467, -0.2456, -0.2456, -0.2444, -0.2444, -0.2456, -0.2467, -0.2467, -0.2467, -0.2467, -0.2467, -0.2456,
1:         -0.2456], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 8, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan, -1.0630,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 8, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.3812, 0.3946, 0.4036, 0.4114, 0.4207, 0.4259, 0.4304, 0.4296, 0.4276, 0.4243, 0.4251, 0.4297, 0.4361, 0.4430,
1:         0.4517, 0.4595, 0.4581, 0.4597, 0.3826, 0.3888, 0.3942, 0.3989, 0.4039, 0.4031, 0.4008], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-3.1688, -3.0606, -2.9291, -2.7859, -2.6378, -2.4968, -2.3522, -2.1953, -2.0227, -1.8279, -1.6181, -1.3913,
1:         -1.1619, -0.9345, -0.7152, -0.5166, -0.3255, -0.1392, -3.1071, -3.0045, -2.8720, -2.7209, -2.5724, -2.4273,
1:         -2.2833], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6886, -0.6995, -0.7074, -0.7113, -0.7104, -0.7081, -0.7004, -0.6887, -0.6698, -0.6440, -0.6143, -0.5787,
1:         -0.5372, -0.4970, -0.4592, -0.4256, -0.3972, -0.3746, -0.6880, -0.6963, -0.7021, -0.7049, -0.7065, -0.7031,
1:         -0.6972], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 7.0653e-02,  1.1318e-01,  1.1413e-01,  4.9948e-02,  6.2958e-04, -6.8169e-02, -1.2615e-01, -1.6645e-01,
1:         -2.4498e-01, -3.2198e-01, -3.9437e-01, -4.9304e-01, -5.9798e-01, -6.6941e-01, -6.7908e-01, -6.9033e-01,
1:         -6.9627e-01, -6.4909e-01, -8.3305e-03,  8.3519e-02,  1.2017e-01,  8.4719e-02,  7.9892e-02,  8.2696e-02,
1:          4.4937e-02], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-2.8451, -2.8434, -2.8473, -2.8545, -2.8579, -2.8498, -2.8265, -2.7845, -2.7278, -2.6626, -2.5905, -2.5212,
1:         -2.4549, -2.3899, -2.3233, -2.2523, -2.1815, -2.1082, -2.0358, -1.9647, -1.8977, -1.8334, -1.7742, -1.7142,
1:         -1.6575], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.0231, -0.0684, -0.0942, -0.1149, -0.1667, -0.2062, -0.2392, -0.2603, -0.2720, -0.0795, -0.1122, -0.1436,
1:         -0.1605, -0.1889, -0.2191, -0.2536, -0.2575, -0.2733, -0.1123, -0.1478, -0.1818, -0.1933, -0.1907, -0.2141,
1:         -0.2541], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0375,  0.0612, -0.0306,  0.0068, -0.0688,  0.0027, -0.0680, -0.1026, -0.0014, -0.1535, -0.0396, -0.0798,
1:          0.0245,  0.0057, -0.0964, -0.0610, -0.0079, -0.0864, -0.0455, -0.0027, -0.0591,  0.0864,  0.0003, -0.0258,
1:         -0.0288], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 8 [1/5 (20%)]	Loss: 0.25863 : 0.19758 :: 0.02686 (1.61 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 8 [2/5 (40%)]	Loss: 0.24468 : 0.19102 :: 0.02437 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 8 [3/5 (60%)]	Loss: 0.26228 : 0.20133 :: 0.02775 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 8 [4/5 (80%)]	Loss: 0.25703 : 0.21488 :: 0.02660 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 8 : 0.20769846439361572
0: validation loss for velocity_u : 0.0041842274367809296
0: validation loss for velocity_v : 0.005644889548420906
0: validation loss for specific_humidity : 0.006875024177134037
0: validation loss for velocity_z : 0.1312674582004547
0: validation loss for temperature : 0.019289307296276093
0: validation loss for total_precip : 0.30483192205429077
0: validation loss for t2m : 0.9817963242530823
1: 9 : 01:02:53 :: batch_size = 96, lr = 1.6825304701668386e-05
0: 9 : 01:02:53 :: batch_size = 96, lr = 1.6825304701668386e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 9, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1: Created sparse mask for t2m with 10.0% data retained
0:      first 25 values: tensor([0.0855, 0.0973, 0.1200, 0.1470, 0.1731, 0.1943, 0.2076, 0.2107, 0.2036, 0.1896, 0.1742, 0.1629, 0.1585, 0.1621,
0:         0.1733, 0.1915, 0.2160, 0.2463, 0.0037, 0.0168, 0.0376, 0.0625, 0.0877, 0.1107, 0.1290], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.0496, -1.1192, -1.2062, -1.2964, -1.3752, -1.4325, -1.4661, -1.4782, -1.4708, -1.4429, -1.3927, -1.3207,
0:         -1.2324, -1.1366, -1.0414, -0.9532, -0.8738, -0.8014, -0.9567, -1.0258, -1.1128, -1.2066, -1.2932, -1.3602,
0:         -1.4015], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 2.9468e+00,  2.5253e+00,  2.0993e+00,  1.7510e+00,  1.5313e+00,  1.4404e+00,  1.4182e+00,  1.3694e+00,
0:          1.2296e+00,  9.9888e-01,  7.2156e-01,  4.5089e-01,  2.0684e-01,  7.1682e-03, -1.1707e-01, -1.2595e-01,
0:          2.7310e-03,  2.5787e-01,  2.1725e+00,  1.9795e+00,  1.7843e+00,  1.6090e+00,  1.4515e+00,  1.2895e+00,
0:          1.0943e+00], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384,
0:         -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384,
0:         -0.2384], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 9, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.2136,    nan, 0.1559,
0:            nan,    nan,    nan,    nan,    nan, 0.0086,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 9, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.9578, 0.9842, 1.0115, 1.0376, 1.0602, 1.0774, 1.0884, 1.0889, 1.0875, 1.0796, 1.0720, 1.0645, 1.0563, 1.0524,
0:         1.0495, 1.0509, 1.0505, 1.0513, 0.8908, 0.9158, 0.9380, 0.9622, 0.9810, 0.9946, 1.0027], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-2.3512, -2.4124, -2.4775, -2.5315, -2.5715, -2.5971, -2.6077, -2.6118, -2.6112, -2.6048, -2.5959, -2.5863,
0:         -2.5798, -2.5781, -2.5794, -2.5821, -2.5798, -2.5734, -2.3335, -2.3878, -2.4467, -2.5025, -2.5426, -2.5695,
0:         -2.5872], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6310, -0.6299, -0.6288, -0.6308, -0.6342, -0.6385, -0.6412, -0.6425, -0.6436, -0.6433, -0.6400, -0.6344,
0:         -0.6244, -0.6127, -0.5991, -0.5838, -0.5727, -0.5634, -0.6254, -0.6240, -0.6239, -0.6275, -0.6310, -0.6360,
0:         -0.6408], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.4632,  0.4320,  0.3196,  0.1484,  0.0058, -0.1088, -0.1793, -0.2134, -0.2305, -0.2220, -0.2326, -0.2393,
0:         -0.1891, -0.1134, -0.0412,  0.0269,  0.0859,  0.1746,  0.3187,  0.2266,  0.0765, -0.0937, -0.1907, -0.2531,
0:         -0.2851], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.7491, -0.7509, -0.7453, -0.7270, -0.6927, -0.6407, -0.5728, -0.4937, -0.4041, -0.3103, -0.2109, -0.1143,
0:         -0.0238,  0.0555,  0.1264,  0.1893,  0.2480,  0.3054,  0.3643,  0.4253,  0.4857,  0.5446,  0.5950,  0.6395,
0:          0.6745], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([0.2860, 0.2526, 0.1981, 0.1598, 0.1425, 0.1358, 0.1601, 0.1818, 0.2130, 0.2540, 0.2107, 0.1718, 0.1295, 0.1208,
0:         0.1329, 0.1554, 0.1858, 0.2145, 0.1737, 0.1396, 0.1058, 0.0850, 0.0792, 0.1056, 0.1453], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0212,  0.0762, -0.0279,  0.0432, -0.0412, -0.0277, -0.0575, -0.0993, -0.0023, -0.1179, -0.0009, -0.0641,
0:         -0.0008,  0.0012, -0.0240, -0.0562, -0.0348, -0.1003, -0.0375,  0.0366, -0.0427,  0.0454, -0.0223, -0.0107,
0:          0.0064], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 9, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.0855, 0.0973, 0.1200, 0.1470, 0.1731, 0.1943, 0.2076, 0.2107, 0.2036, 0.1896, 0.1742, 0.1629, 0.1585, 0.1621,
1:         0.1733, 0.1915, 0.2160, 0.2463, 0.0037, 0.0168, 0.0376, 0.0625, 0.0877, 0.1107, 0.1290], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.1118,  0.0792,  0.0652, -0.0142,  0.0204,  0.0671,  0.1423, -0.0358,  0.0515, -0.0933, -0.1085, -0.0343,
1:          0.0055,  0.0002,  0.2048, -0.1021,  0.1693, -0.0990,  0.0672,  0.0158, -0.0294, -0.1058,  0.1401,  0.0113,
1:         -0.1365], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6114, -0.6020, -0.5883, -0.5739, -0.5559, -0.5377, -0.5225, -0.5071, -0.5011, -0.4966, -0.4984, -0.5024,
1:         -0.5090, -0.5173, -0.5269, -0.5381, -0.5494, -0.5613, -0.6145, -0.6060, -0.5939, -0.5814, -0.5660, -0.5501,
1:         -0.5355], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.6453, -0.6413, -0.6451, -0.6531, -0.6622, -0.6696, -0.6754, -0.6807, -0.6865, -0.6937, -0.7036, -0.7179,
1:         -0.7375, -0.7623, -0.7905, -0.8196, -0.8464, -0.8674, -0.8788, -0.8773, -0.8610, -0.8309, -0.7885, -0.7371,
1:         -0.6801], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384,
1:         -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384,
1:         -0.2384], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 9, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan, 0.4746,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:         0.6628,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 9, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.7480, 0.7706, 0.7993, 0.8276, 0.8487, 0.8591, 0.8637, 0.8540, 0.8392, 0.8153, 0.7887, 0.7599, 0.7278, 0.6927,
1:         0.6584, 0.6274, 0.5921, 0.5577, 0.7971, 0.8259, 0.8515, 0.8789, 0.8954, 0.8977, 0.8887], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.6752, -0.5589, -0.4355, -0.3144, -0.2149, -0.1446, -0.1088, -0.1124, -0.1411, -0.1786, -0.2210, -0.2588,
1:         -0.2968, -0.3318, -0.3713, -0.4097, -0.4446, -0.4724, -0.5545, -0.4585, -0.3567, -0.2781, -0.2147, -0.1787,
1:         -0.1687], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.4345, -0.4137, -0.4007, -0.3940, -0.3869, -0.3736, -0.3541, -0.3245, -0.2903, -0.2558, -0.2259, -0.2041,
1:         -0.1922, -0.1872, -0.1899, -0.1931, -0.2020, -0.2090, -0.3812, -0.3615, -0.3481, -0.3402, -0.3341, -0.3241,
1:         -0.3048], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.6141, -0.7536, -0.8132, -0.7846, -0.6974, -0.5954, -0.4608, -0.2670, -0.1409, -0.0874, -0.0233, -0.0352,
1:         -0.1622, -0.3054, -0.3953, -0.4588, -0.5615, -0.6348, -0.4916, -0.7121, -0.8943, -0.9653, -0.9359, -0.8441,
1:         -0.7263], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.9846, -0.9633, -0.9485, -0.9387, -0.9342, -0.9364, -0.9447, -0.9612, -0.9824, -1.0100, -1.0375, -1.0635,
1:         -1.0854, -1.1033, -1.1103, -1.1110, -1.1014, -1.0800, -1.0473, -1.0057, -0.9624, -0.9177, -0.8795, -0.8461,
1:         -0.8196], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.1576, -0.1590, -0.1598, -0.1627, -0.1583, -0.1583, -0.1575, -0.1583, -0.1531, -0.1910, -0.1918, -0.1911,
1:         -0.1917, -0.1879, -0.1835, -0.1810, -0.1781, -0.1825, -0.2199, -0.2197, -0.2212, -0.2148, -0.2112, -0.2067,
1:         -0.2006], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0204,  0.0571, -0.0091,  0.0111, -0.0257,  0.0055, -0.0428, -0.0963, -0.0179, -0.1209,  0.0040, -0.0509,
1:          0.0115,  0.0065, -0.0429, -0.0258,  0.0016, -0.0593, -0.0155,  0.0053, -0.0413,  0.0852,  0.0003, -0.0064,
1:         -0.0063], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 9 [1/5 (20%)]	Loss: 0.29962 : 0.24121 :: 0.02621 (1.73 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 9 [2/5 (40%)]	Loss: 0.24801 : 0.19883 :: 0.02535 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 9 [3/5 (60%)]	Loss: 0.26652 : 0.19555 :: 0.02613 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 9 [4/5 (80%)]	Loss: 0.29689 : 0.20611 :: 0.02579 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 9 : 0.20701506733894348
0: validation loss for velocity_u : 0.0033109006471931934
0: validation loss for velocity_v : 0.004661525133997202
0: validation loss for specific_humidity : 0.005898459814488888
0: validation loss for velocity_z : 0.10284924507141113
0: validation loss for temperature : 0.018557336181402206
0: validation loss for total_precip : 0.2976793050765991
0: validation loss for t2m : 1.0161489248275757
1: 10 : 01:08:59 :: batch_size = 96, lr = 1.6414931416261842e-05
0: 10 : 01:08:59 :: batch_size = 96, lr = 1.6414931416261842e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 10, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.9777, -0.9666, -0.9575, -0.9541, -0.9556, -0.9564, -0.9543, -0.9497, -0.9427, -0.9329, -0.9226, -0.9129,
0:         -0.9031, -0.8902, -0.8711, -0.8447, -0.8128, -0.7777, -1.0485, -1.0467, -1.0448, -1.0485, -1.0577, -1.0660,
0:         -1.0687], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.6476, 0.7166, 0.7757, 0.8259, 0.8668, 0.8927, 0.9027, 0.9067, 0.9144, 0.9259, 0.9369, 0.9438, 0.9417, 0.9292,
0:         0.9115, 0.8925, 0.8706, 0.8453, 0.6820, 0.7373, 0.7853, 0.8237, 0.8518, 0.8702, 0.8806], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.1110, -0.8438, -0.6407, -0.3956, -0.0621,  0.2029,  0.2249,  0.0262, -0.2410, -0.4287, -0.4397, -0.3028,
0:         -0.1505, -0.0643,  0.0218,  0.1609,  0.2514,  0.1940, -0.6561, -0.2785, -0.0798, -0.0246,  0.0240,  0.0527,
0:         -0.0688], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382,
0:         -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382,
0:         -0.2382], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 10, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan, -0.5330,     nan, -0.4613,     nan, -0.3992,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.0556,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  0.2629,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 10, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([ 0.0704,  0.0444,  0.0148, -0.0111, -0.0389, -0.0581, -0.0709, -0.0780, -0.0799, -0.0842, -0.0924, -0.1080,
0:         -0.1259, -0.1464, -0.1676, -0.1876, -0.2064, -0.2206,  0.0858,  0.0707,  0.0521,  0.0319,  0.0083, -0.0119,
0:         -0.0279], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.0332, 0.0473, 0.0605, 0.0749, 0.1003, 0.1295, 0.1641, 0.2010, 0.2351, 0.2582, 0.2715, 0.2740, 0.2680, 0.2560,
0:         0.2372, 0.2089, 0.1771, 0.1423, 0.0216, 0.0420, 0.0627, 0.0872, 0.1212, 0.1653, 0.2113], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([0.2624, 0.2884, 0.3220, 0.3609, 0.4045, 0.4409, 0.4694, 0.4863, 0.4938, 0.4987, 0.5098, 0.5209, 0.5334, 0.5384,
0:         0.5302, 0.5090, 0.4733, 0.4343, 0.2189, 0.2382, 0.2658, 0.2984, 0.3367, 0.3704, 0.3914], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.5843, 0.5668, 0.5249, 0.5236, 0.5240, 0.5152, 0.4739, 0.4058, 0.3831, 0.4175, 0.4437, 0.4623, 0.5202, 0.5605,
0:         0.5996, 0.6489, 0.6526, 0.6339, 0.7562, 0.7504, 0.7358, 0.7658, 0.7692, 0.7535, 0.7125], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.6390, 0.6501, 0.6601, 0.6676, 0.6712, 0.6732, 0.6751, 0.6784, 0.6867, 0.6961, 0.7084, 0.7184, 0.7232, 0.7210,
0:         0.7121, 0.6916, 0.6632, 0.6232, 0.5756, 0.5236, 0.4708, 0.4266, 0.3906, 0.3640, 0.3396], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([ 0.0988,  0.1947,  0.3163,  0.5541,  0.8789,  1.2980,  1.7070,  2.0001,  2.1429, -0.0604, -0.0516,  0.0226,
0:          0.1329,  0.3773,  0.7041,  1.0659,  1.4051,  1.6267, -0.1288, -0.1554, -0.1754, -0.1526, -0.0781,  0.1198,
0:          0.3896], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0015,  0.0436, -0.0421, -0.0004, -0.0179, -0.0449, -0.0506, -0.0665,  0.0002, -0.1027, -0.0185, -0.0566,
0:         -0.0050,  0.0059, -0.0221, -0.0617, -0.0106, -0.1006, -0.0397,  0.0163, -0.0218,  0.0040, -0.0469, -0.0130,
0:         -0.0222], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 10, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.9777, -0.9666, -0.9575, -0.9541, -0.9556, -0.9564, -0.9543, -0.9497, -0.9427, -0.9329, -0.9226, -0.9129,
1:         -0.9031, -0.8902, -0.8711, -0.8447, -0.8128, -0.7777, -1.0485, -1.0467, -1.0448, -1.0485, -1.0577, -1.0660,
1:         -1.0687], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0585,  0.0841, -0.0407, -0.0232, -0.0275,  0.0584, -0.0012,  0.0922,  0.0042, -0.1749,  0.1576, -0.1534,
1:          0.0249, -0.1681, -0.1184, -0.0468,  0.0581, -0.1018, -0.1819, -0.1881,  0.1199, -0.1514, -0.1376,  0.1036,
1:          0.0046], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6764, -0.6819, -0.6799, -0.6770, -0.6731, -0.6689, -0.6666, -0.6626, -0.6586, -0.6569, -0.6571, -0.6586,
1:         -0.6658, -0.6728, -0.6803, -0.6861, -0.6879, -0.6871, -0.6625, -0.6528, -0.6417, -0.6303, -0.6222, -0.6152,
1:         -0.6118], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.2106, 1.2239, 1.2320, 1.2346, 1.2317, 1.2228, 1.2083, 1.1912, 1.1755, 1.1651, 1.1610, 1.1606, 1.1597, 1.1561,
1:         1.1515, 1.1488, 1.1471, 1.1449, 1.1432, 1.1439, 1.1464, 1.1480, 1.1484, 1.1519, 1.1614], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382,
1:         -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382,
1:         -0.2382], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 10, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan, -0.3183,     nan,     nan,     nan,  0.3495,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 10, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.4960, -0.4993, -0.5032, -0.5087, -0.5144, -0.5180, -0.5199, -0.5223, -0.5226, -0.5236, -0.5203, -0.5153,
1:         -0.5067, -0.4920, -0.4717, -0.4471, -0.4279, -0.4102, -0.4891, -0.4885, -0.4910, -0.4913, -0.4932, -0.5004,
1:         -0.5082], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-1.0075, -1.0486, -1.0778, -1.0722, -1.0136, -0.8831, -0.6873, -0.4460, -0.1938,  0.0467,  0.2480,  0.4030,
1:          0.5237,  0.6342,  0.7751,  0.9382,  1.1437,  1.3561, -1.1015, -1.1295, -1.1320, -1.1016, -1.0236, -0.8832,
1:         -0.6963], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-4.6815e-01, -4.3883e-01, -4.1975e-01, -4.1380e-01, -4.1986e-01, -4.2446e-01, -4.1237e-01, -3.7050e-01,
1:         -2.9651e-01, -2.0063e-01, -9.9094e-02, -2.1442e-02,  1.7610e-02,  2.1243e-02, -4.5569e-04, -2.4400e-02,
1:         -3.3305e-02, -2.5404e-02, -4.9864e-01, -4.6663e-01, -4.4407e-01, -4.3723e-01, -4.4219e-01, -4.5076e-01,
1:         -4.4625e-01], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.3117, -0.3655, -0.2804, -0.1673, -0.1074, -0.0158,  0.0742,  0.1548,  0.2129,  0.2360,  0.2228,  0.1671,
1:          0.1839,  0.2408,  0.2900,  0.3616,  0.4573,  0.5534, -0.2550, -0.3068, -0.1765, -0.0502, -0.0324,  0.0246,
1:          0.1073], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.9777, 1.0139, 1.0400, 1.0586, 1.0702, 1.0718, 1.0580, 1.0266, 0.9844, 0.9432, 0.9182, 0.9130, 0.9262, 0.9489,
1:         0.9726, 0.9877, 0.9950, 0.9963, 0.9978, 0.9998, 1.0048, 1.0159, 1.0289, 1.0379, 1.0409], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2246, -0.2253, -0.2233, -0.2254, -0.2257, -0.2258, -0.2282, -0.2328, -0.2294, -0.2293, -0.2311, -0.2329,
1:         -0.2310, -0.2313, -0.2331, -0.2347, -0.2378, -0.2428, -0.2384, -0.2394, -0.2384, -0.2396, -0.2386, -0.2362,
1:         -0.2385], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0094,  0.0697, -0.0269, -0.0152, -0.0159, -0.0071, -0.0424, -0.0860, -0.0083, -0.1153, -0.0004, -0.0551,
1:          0.0222,  0.0100, -0.0275, -0.0397,  0.0134, -0.0722, -0.0330, -0.0064, -0.0606,  0.0665,  0.0007, -0.0108,
1:         -0.0314], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 10 [1/5 (20%)]	Loss: 0.24162 : 0.18859 :: 0.02634 (1.75 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 10 [2/5 (40%)]	Loss: 0.33511 : 0.24954 :: 0.02528 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 10 [3/5 (60%)]	Loss: 0.25055 : 0.18576 :: 0.02515 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 10 [4/5 (80%)]	Loss: 0.25283 : 0.19914 :: 0.02654 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 10 : 0.2216220498085022
0: validation loss for velocity_u : 0.0037773274816572666
0: validation loss for velocity_v : 0.005243790335953236
0: validation loss for specific_humidity : 0.007233613170683384
0: validation loss for velocity_z : 0.11946161091327667
0: validation loss for temperature : 0.0212679672986269
0: validation loss for total_precip : 0.39878153800964355
0: validation loss for t2m : 0.9955886602401733
0: 11 : 01:15:05 :: batch_size = 96, lr = 1.601456723537741e-05
1: 11 : 01:15:05 :: batch_size = 96, lr = 1.601456723537741e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 11, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.5098, -0.5318, -0.5545, -0.5839, -0.6225, -0.6491, -0.6409, -0.6121, -0.6042, -0.6208, -0.6314, -0.6377,
1:         -0.6459, -0.6341, -0.6100, -0.6052, -0.6137, -0.6090, -0.5359, -0.5468, -0.5648, -0.5979, -0.6295, -0.6377,
1:         -0.6246], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0613, -0.1297,  0.0838, -0.1098,  0.0274, -0.0144,  0.0878, -0.0004, -0.0050,  0.0925,  0.0452, -0.1290,
1:         -0.2282, -0.0227, -0.1358, -0.1099,  0.0455,  0.0566,  0.1871, -0.0802,  0.1141,  0.0262,  0.0029, -0.0238,
1:         -0.1169], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.5009, -0.5140, -0.5190, -0.5337, -0.5661, -0.5834, -0.5908, -0.5930, -0.5788, -0.5125, -0.3757, -0.1282,
1:          0.0664,  0.1856,  0.2600,  0.3117,  0.3675,  0.3496, -0.5065, -0.5293, -0.5439, -0.5568, -0.5780, -0.5868,
1:         -0.5794], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., -0., -0., -0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([ 0.3082,  0.4745,  0.6443,  0.7449,  0.7386,  0.6482,  0.5813,  0.5984,  0.6334,  0.6381,  0.6141,  0.5738,
1:          0.5471,  0.5313,  0.4837,  0.4074,  0.3491,  0.2951,  0.2009,  0.0761, -0.0581, -0.1943, -0.2905, -0.3185,
1:         -0.3179], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456,
1:         -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456,
1:         -0.2456], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 11, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([-0.0624,     nan,     nan,  0.0770,     nan,     nan,  0.3992,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 11, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.3017, -0.2974, -0.2963, -0.2985, -0.3024, -0.3103, -0.3190, -0.3334, -0.3544, -0.3792, -0.4035, -0.4241,
1:         -0.4392, -0.4499, -0.4572, -0.4598, -0.4583, -0.4537, -0.3103, -0.3063, -0.3118, -0.3186, -0.3248, -0.3331,
1:         -0.3445], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.1815, 0.1833, 0.1816, 0.1805, 0.1830, 0.1925, 0.2069, 0.2201, 0.2350, 0.2457, 0.2510, 0.2556, 0.2606, 0.2656,
1:         0.2769, 0.2928, 0.3117, 0.3288, 0.1811, 0.1810, 0.1794, 0.1764, 0.1756, 0.1807, 0.1892], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([0.4026, 0.4546, 0.6314, 0.9180, 1.2901, 1.6793, 2.0670, 2.3728, 2.6025, 2.7580, 2.8594, 2.9096, 2.9274, 2.9150,
1:         2.8659, 2.7813, 2.6606, 2.5138, 0.4419, 0.4271, 0.5531, 0.8224, 1.2011, 1.6328, 2.0466], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.5017,  0.5285,  0.4998,  0.3020,  0.0965, -0.0405, -0.2583, -0.4966, -0.5969, -0.3530,  0.0319,  0.1245,
1:          0.0853,  0.1568,  0.2095,  0.1079, -0.2273, -0.6232,  0.4861,  0.5870,  0.7276,  0.6839,  0.6325,  0.5935,
1:          0.3202], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([ 0.0688, -0.0285, -0.1446, -0.2580, -0.3569, -0.4378, -0.5087, -0.5782, -0.6524, -0.7340, -0.8109, -0.8686,
1:         -0.8952, -0.8922, -0.8649, -0.8324, -0.8019, -0.7966, -0.8116, -0.8391, -0.8610, -0.8540, -0.8200, -0.7714,
1:         -0.7202], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2383, -0.2242, -0.1428, -0.0093,  0.2061,  0.4898,  0.7659,  0.9833,  1.1291, -0.2648, -0.2511, -0.1969,
1:         -0.0808,  0.0895,  0.3523,  0.6113,  0.8365,  0.9787, -0.2495, -0.2471, -0.2078, -0.1441, -0.0376,  0.1386,
1:          0.3375], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0074,  0.0747, -0.0246, -0.0165, -0.0133,  0.0098, -0.0344, -0.0721, -0.0072, -0.0486, -0.0005, -0.0597,
1:          0.0265,  0.0262, -0.0260, -0.0590, -0.0140, -0.0443, -0.0345, -0.0017, -0.0275,  0.0540, -0.0048,  0.0035,
1:         -0.0262], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 11, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.5098, -0.5318, -0.5545, -0.5839, -0.6225, -0.6491, -0.6409, -0.6121, -0.6042, -0.6208, -0.6314, -0.6377,
0:         -0.6459, -0.6341, -0.6100, -0.6052, -0.6137, -0.6090, -0.5359, -0.5468, -0.5648, -0.5979, -0.6295, -0.6377,
0:         -0.6246], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.1648,  0.1770,  0.1972,  0.2304,  0.2562,  0.2373,  0.1709,  0.0845,  0.0055, -0.0448, -0.0592, -0.0503,
0:         -0.0366, -0.0238, -0.0042,  0.0248,  0.0463,  0.0374,  0.1051,  0.1397,  0.1794,  0.2104,  0.2195,  0.1848,
0:          0.1156], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.0080,  0.1078,  0.1208,  0.2901,  0.3140, -0.0897, -0.5150, -0.8622, -0.9252, -0.3501,  0.0145, -0.2958,
0:         -0.3653, -0.2763, -0.7147, -1.1704, -1.1899, -1.0272, -0.1179,  0.1925,  0.1903,  0.1577,  0.1925, -0.0549,
0:         -0.4282], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456,
0:         -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456,
0:         -0.2456], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 11, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -1.1791,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 11, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.3174, -0.3105, -0.3071, -0.3013, -0.2935, -0.2828, -0.2687, -0.2564, -0.2424, -0.2290, -0.2143, -0.1955,
0:         -0.1729, -0.1446, -0.1146, -0.0862, -0.0616, -0.0477, -0.2834, -0.2729, -0.2641, -0.2544, -0.2443, -0.2333,
0:         -0.2241], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.5590, 0.5458, 0.5492, 0.5655, 0.5914, 0.6128, 0.6230, 0.6211, 0.6116, 0.5947, 0.5774, 0.5642, 0.5569, 0.5576,
0:         0.5611, 0.5689, 0.5664, 0.5547, 0.5452, 0.5305, 0.5302, 0.5416, 0.5632, 0.5788, 0.5826], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([1.1701, 1.2040, 1.2200, 1.2224, 1.2116, 1.1921, 1.1759, 1.1692, 1.1800, 1.1981, 1.2135, 1.2167, 1.2091, 1.1933,
0:         1.1668, 1.1373, 1.1066, 1.0751, 1.0748, 1.1125, 1.1495, 1.1625, 1.1615, 1.1491, 1.1391], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.1615, -0.1563, -0.1623, -0.1732, -0.0586, -0.0120, -0.1609, -0.1888, -0.1063, -0.1184, -0.0725,  0.0369,
0:          0.0393,  0.0384,  0.0320, -0.0130,  0.0073,  0.0637,  0.0160,  0.0448, -0.0222, -0.1221, -0.0093,  0.0559,
0:         -0.0843], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.3703, -0.3304, -0.2898, -0.2613, -0.2512, -0.2642, -0.2937, -0.3328, -0.3705, -0.4064, -0.4384, -0.4685,
0:         -0.4962, -0.5210, -0.5327, -0.5304, -0.5030, -0.4587, -0.4010, -0.3411, -0.2845, -0.2290, -0.1757, -0.1195,
0:         -0.0597], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2446, -0.2459, -0.2441, -0.2467, -0.2500, -0.2534, -0.2568, -0.2617, -0.2585, -0.2407, -0.2425, -0.2447,
0:         -0.2443, -0.2465, -0.2512, -0.2540, -0.2580, -0.2590, -0.2416, -0.2429, -0.2444, -0.2462, -0.2491, -0.2487,
0:         -0.2522], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0005,  0.0627, -0.0201, -0.0154, -0.0113, -0.0556, -0.0309, -0.0684,  0.0060, -0.0912, -0.0089, -0.0518,
0:          0.0138,  0.0008, -0.0097, -0.0886, -0.0208, -0.0787, -0.0469,  0.0265, -0.0184,  0.0104, -0.0248, -0.0057,
0:         -0.0064], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 11 [1/5 (20%)]	Loss: 0.27826 : 0.21291 :: 0.02498 (1.67 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 11 [2/5 (40%)]	Loss: 0.23684 : 0.19831 :: 0.02558 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 11 [3/5 (60%)]	Loss: 0.22242 : 0.18325 :: 0.02658 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 11 [4/5 (80%)]	Loss: 0.29274 : 0.21047 :: 0.02341 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 11 : 0.19631236791610718
0: validation loss for velocity_u : 0.0036536557599902153
0: validation loss for velocity_v : 0.0050959233194589615
0: validation loss for specific_humidity : 0.006589648313820362
0: validation loss for velocity_z : 0.10813331604003906
0: validation loss for temperature : 0.01907174289226532
0: validation loss for total_precip : 0.3277716636657715
0: validation loss for t2m : 0.9038705825805664
1: 12 : 01:21:27 :: batch_size = 96, lr = 1.5623968034514547e-05
0: 12 : 01:21:37 :: batch_size = 96, lr = 1.5623968034514547e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 12, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.2323, 0.2625, 0.2801, 0.2885, 0.2951, 0.3066, 0.3252, 0.3472, 0.3663, 0.3782, 0.3830, 0.3841, 0.3857, 0.3907,
1:         0.3995, 0.4116, 0.4254, 0.4392, 0.2744, 0.2975, 0.3082, 0.3111, 0.3161, 0.3326, 0.3626], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0226, -0.0453,  0.0331,  0.1010, -0.0892,  0.1414,  0.1519,  0.1198, -0.2102, -0.0120,  0.0573,  0.0551,
1:         -0.1529,  0.1044, -0.0691,  0.0421,  0.1205, -0.0032, -0.0227,  0.0257,  0.2152,  0.0019,  0.0793, -0.0094,
1:          0.0754], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6113, -0.6193, -0.6239, -0.6274, -0.6326, -0.6384, -0.6407, -0.6456, -0.6511, -0.6533, -0.6520, -0.6496,
1:         -0.6493, -0.6501, -0.6496, -0.6479, -0.6471, -0.6450, -0.5991, -0.5958, -0.5979, -0.6015, -0.6063, -0.6084,
1:         -0.6158], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.5398, -0.5540, -0.5696, -0.5874, -0.6082, -0.6309, -0.6532, -0.6735, -0.6904, -0.7053, -0.7197, -0.7347,
1:         -0.7503, -0.7662, -0.7809, -0.7938, -0.8040, -0.8125, -0.8207, -0.8293, -0.8389, -0.8481, -0.8545, -0.8565,
1:         -0.8543], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2251, -0.2251, -0.2251, -0.2229, -0.2206, -0.2206, -0.2184, -0.2184, -0.2184, -0.2273, -0.2273, -0.2251,
1:         -0.2229, -0.2206, -0.2118, -0.2184, -0.2206, -0.2206, -0.2273, -0.2273, -0.2251, -0.2251, -0.2184, -0.2096,
1:         -0.2184], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 12, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -1.0661,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -1.3711,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 12, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.6984, 0.7039, 0.7102, 0.7146, 0.7203, 0.7263, 0.7336, 0.7406, 0.7487, 0.7546, 0.7586, 0.7655, 0.7727, 0.7793,
1:         0.7878, 0.7918, 0.7955, 0.7997, 0.6978, 0.7034, 0.7095, 0.7175, 0.7231, 0.7279, 0.7320], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([1.9911, 2.1048, 2.2314, 2.3624, 2.4862, 2.5820, 2.6477, 2.6704, 2.6579, 2.6115, 2.5449, 2.4625, 2.3723, 2.2828,
1:         2.1906, 2.1065, 2.0286, 1.9492, 2.0011, 2.1096, 2.2337, 2.3496, 2.4576, 2.5488, 2.6207], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.5928, -0.5909, -0.5862, -0.5768, -0.5667, -0.5572, -0.5502, -0.5456, -0.5445, -0.5466, -0.5512, -0.5617,
1:         -0.5758, -0.5921, -0.6076, -0.6211, -0.6263, -0.6235, -0.6133, -0.6154, -0.6108, -0.6020, -0.5924, -0.5834,
1:         -0.5793], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.5717, 0.5845, 0.5769, 0.5489, 0.4589, 0.4525, 0.4956, 0.4257, 0.3662, 0.3733, 0.3798, 0.4039, 0.3923, 0.3548,
1:         0.3615, 0.3372, 0.3112, 0.3152, 0.5958, 0.6609, 0.7005, 0.6935, 0.5985, 0.5926, 0.6568], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.1573, 0.1667, 0.1794, 0.1926, 0.2029, 0.2124, 0.2244, 0.2471, 0.2799, 0.3184, 0.3565, 0.3938, 0.4319, 0.4771,
1:         0.5348, 0.6013, 0.6751, 0.7466, 0.8144, 0.8778, 0.9351, 0.9911, 1.0450, 1.0965, 1.1460], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2189, -0.2208, -0.2151, -0.2142, -0.2121, -0.2096, -0.2128, -0.2128, -0.2122, -0.2205, -0.2206, -0.2188,
1:         -0.2172, -0.2158, -0.2155, -0.2168, -0.2167, -0.2146, -0.2241, -0.2227, -0.2200, -0.2205, -0.2168, -0.2164,
1:         -0.2203], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0025,  0.0487, -0.0026, -0.0282, -0.0143, -0.0204, -0.0162, -0.0548, -0.0115, -0.0533,  0.0054, -0.0444,
1:          0.0276,  0.0129, -0.0124, -0.0582, -0.0035, -0.0395, -0.0106,  0.0123, -0.0306,  0.0447, -0.0040, -0.0144,
1:         -0.0125], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 12, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2424, -0.2441, -0.2270, -0.1948, -0.1717, -0.1636, -0.1615, -0.1633, -0.1715, -0.1827, -0.1909, -0.1946,
0:         -0.1943, -0.1883, -0.1743, -0.1554, -0.1393, -0.1288, -0.2858, -0.2762, -0.2593, -0.2356, -0.2199, -0.2128,
0:         -0.2074], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2123, 0.2603, 0.2936, 0.3137, 0.3263, 0.3460, 0.3789, 0.4090, 0.4212, 0.4221, 0.4231, 0.4212, 0.4096, 0.3907,
0:         0.3706, 0.3510, 0.3305, 0.3059, 0.2032, 0.2448, 0.2662, 0.2790, 0.2952, 0.3250, 0.3678], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.5251,  1.2921,  1.4910,  0.9815,  0.2820,  0.1074,  0.4544,  0.6776,  0.4245, -0.0286, -0.3170, -0.3513,
0:         -0.2673, -0.2982, -0.5358, -0.7668, -0.8198, -0.8563,  1.0102,  1.2070,  1.2456,  0.7958,  0.1184, -0.1634,
0:          0.0687], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.0413, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490,  0.0158, -0.2490, -0.2490,
0:         -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.2490, -0.0356, -0.2478, -0.2490, -0.2490, -0.2490, -0.2490,
0:         -0.2490], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 12, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan, 0.1799,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan, 0.2569, 0.2536,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 12, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.4457, -0.4476, -0.4385, -0.4163, -0.3754, -0.3225, -0.2579, -0.1980, -0.1547, -0.1377, -0.1475, -0.1757,
0:         -0.2111, -0.2501, -0.2846, -0.3186, -0.3533, -0.3863, -0.4875, -0.4660, -0.4309, -0.3851, -0.3254, -0.2583,
0:         -0.1863], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.2828, -0.2479, -0.1991, -0.1379, -0.0684, -0.0056,  0.0411,  0.0663,  0.0721,  0.0573,  0.0300, -0.0139,
0:         -0.0798, -0.1620, -0.2562, -0.3431, -0.4016, -0.4135, -0.2802, -0.2333, -0.1741, -0.1112, -0.0486,  0.0036,
0:          0.0434], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([0.7634, 0.7861, 0.8441, 0.9241, 1.0130, 1.0933, 1.1306, 1.1112, 1.0399, 0.9254, 0.7788, 0.6357, 0.5211, 0.4535,
0:         0.4303, 0.4523, 0.4953, 0.5390, 0.6481, 0.6337, 0.6501, 0.6962, 0.7631, 0.8350, 0.8861], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.3972, -0.4365, -0.4461, -0.4054, -0.4431, -0.5340, -0.5549, -0.5223, -0.4429, -0.3957, -0.4690, -0.4264,
0:         -0.2846, -0.1935, -0.1390, -0.0411,  0.1590,  0.1714, -0.4347, -0.5643, -0.6695, -0.6674, -0.7076, -0.7405,
0:         -0.6325], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.1569, -0.1600, -0.2073, -0.2862, -0.3638, -0.4054, -0.3992, -0.3422, -0.2562, -0.1657, -0.0890, -0.0377,
0:         -0.0125, -0.0070, -0.0106, -0.0133, -0.0033,  0.0140,  0.0298,  0.0332,  0.0209,  0.0020, -0.0123, -0.0087,
0:          0.0085], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2468, -0.2525, -0.2508, -0.2515, -0.2512, -0.2532, -0.2579, -0.2573, -0.2554, -0.2472, -0.2505, -0.2499,
0:         -0.2497, -0.2512, -0.2546, -0.2568, -0.2585, -0.2558, -0.2477, -0.2488, -0.2493, -0.2506, -0.2487, -0.2517,
0:         -0.2552], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0204,  0.0644, -0.0029, -0.0358, -0.0250, -0.0200, -0.0201, -0.0622,  0.0110, -0.0698,  0.0082, -0.0680,
0:          0.0073,  0.0017, -0.0246, -0.0458, -0.0191, -0.0781, -0.0401,  0.0081, -0.0149, -0.0113, -0.0177, -0.0309,
0:         -0.0160], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 12 [1/5 (20%)]	Loss: 0.24144 : 0.19498 :: 0.02696 (1.69 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 12 [2/5 (40%)]	Loss: 0.31679 : 0.21996 :: 0.02629 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 12 [3/5 (60%)]	Loss: 0.28282 : 0.20147 :: 0.02458 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 12 [4/5 (80%)]	Loss: 0.25624 : 0.20202 :: 0.02644 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 12 : 0.20599308609962463
0: validation loss for velocity_u : 0.0035043549723923206
0: validation loss for velocity_v : 0.004920874256640673
0: validation loss for specific_humidity : 0.006814083084464073
0: validation loss for velocity_z : 0.10416821390390396
0: validation loss for temperature : 0.019679607823491096
0: validation loss for total_precip : 0.31192755699157715
0: validation loss for t2m : 0.990937352180481
1: 13 : 01:27:39 :: batch_size = 96, lr = 1.5242895643428828e-05
0: 13 : 01:27:39 :: batch_size = 96, lr = 1.5242895643428828e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 13, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0545, -0.0587, -0.0629, -0.0667, -0.0702, -0.0736, -0.0765, -0.0792, -0.0817, -0.0838, -0.0859, -0.0878,
0:         -0.0895, -0.0910, -0.0925, -0.0939, -0.0953, -0.0967, -0.0824, -0.0892, -0.0956, -0.1020, -0.1080, -0.1138,
0:         -0.1191], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.0043, -1.0098, -1.0157, -1.0216, -1.0280, -1.0343, -1.0409, -1.0477, -1.0546, -1.0616, -1.0690, -1.0764,
0:         -1.0838, -1.0914, -1.0990, -1.1069, -1.1147, -1.1225, -1.0015, -1.0062, -1.0111, -1.0157, -1.0204, -1.0252,
0:         -1.0299], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.9247, 0.9450, 0.9675, 0.9923, 1.0149, 1.0374, 1.0600, 1.0780, 1.0960, 1.1095, 1.1208, 1.1298, 1.1388, 1.1433,
0:         1.1501, 1.1569, 1.1636, 1.1704, 0.7399, 0.7940, 0.8458, 0.8932, 0.9382, 0.9788, 1.0126], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2321, -0.2321, -0.2321, -0.2321, -0.2321, -0.2309, -0.2309, -0.2309, -0.2309, -0.2367, -0.2356, -0.2332,
0:         -0.2321, -0.2321, -0.2309, -0.2309, -0.2309, -0.2309, -0.2414, -0.2402, -0.2402, -0.2391, -0.2391, -0.2379,
0:         -0.2367], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 13, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 1.0781,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 13, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-1.2907, -1.2879, -1.2881, -1.2918, -1.2904, -1.2855, -1.2776, -1.2713, -1.2669, -1.2716, -1.2789, -1.2868,
0:         -1.2927, -1.2922, -1.2876, -1.2819, -1.2743, -1.2637, -1.3673, -1.3653, -1.3662, -1.3701, -1.3733, -1.3713,
0:         -1.3678], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.7935, -0.7903, -0.7869, -0.7804, -0.7746, -0.7711, -0.7660, -0.7636, -0.7592, -0.7549, -0.7485, -0.7418,
0:         -0.7343, -0.7278, -0.7202, -0.7150, -0.7101, -0.7082, -0.8097, -0.8079, -0.8063, -0.7994, -0.7948, -0.7904,
0:         -0.7858], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.5455, -0.5472, -0.5471, -0.5462, -0.5445, -0.5437, -0.5440, -0.5441, -0.5435, -0.5445, -0.5440, -0.5449,
0:         -0.5444, -0.5475, -0.5515, -0.5567, -0.5586, -0.5612, -0.5413, -0.5413, -0.5430, -0.5444, -0.5449, -0.5453,
0:         -0.5479], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.2300, 0.2254, 0.2182, 0.2004, 0.1779, 0.1919, 0.2161, 0.2103, 0.1964, 0.1797, 0.1689, 0.1655, 0.1329, 0.1109,
0:         0.1380, 0.1598, 0.1620, 0.1730, 0.3978, 0.3965, 0.3798, 0.3721, 0.3662, 0.3648, 0.3753], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.0466, 1.0467, 1.0415, 1.0354, 1.0300, 1.0276, 1.0280, 1.0303, 1.0318, 1.0303, 1.0262, 1.0204, 1.0127, 1.0071,
0:         1.0027, 0.9988, 0.9984, 0.9988, 0.9990, 0.9979, 0.9936, 0.9877, 0.9836, 0.9823, 0.9831], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([0.1631, 0.1924, 0.2480, 0.3184, 0.3935, 0.4685, 0.5507, 0.6062, 0.6520, 0.3059, 0.3662, 0.4571, 0.5352, 0.6223,
0:         0.7129, 0.7853, 0.8346, 0.8363, 0.4881, 0.5770, 0.6840, 0.7616, 0.8533, 0.9256, 0.9565], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0090,  0.0434, -0.0256, -0.0228, -0.0138, -0.0191, -0.0032, -0.0462, -0.0146, -0.0466, -0.0067, -0.0510,
0:          0.0061,  0.0022, -0.0171, -0.0308, -0.0134, -0.0760, -0.0162,  0.0147, -0.0110, -0.0107, -0.0029, -0.0361,
0:         -0.0126], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 13, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0545, -0.0587, -0.0629, -0.0667, -0.0702, -0.0736, -0.0765, -0.0792, -0.0817, -0.0838, -0.0859, -0.0878,
1:         -0.0895, -0.0910, -0.0925, -0.0939, -0.0953, -0.0967, -0.0824, -0.0892, -0.0956, -0.1020, -0.1080, -0.1138,
1:         -0.1191], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0672,  0.0943, -0.0404,  0.0154, -0.0602, -0.0558, -0.0307, -0.0462,  0.0242, -0.0506,  0.0222, -0.0483,
1:         -0.1558,  0.0788, -0.0017,  0.1244,  0.0264, -0.0407, -0.1320,  0.1384,  0.0385,  0.0336,  0.0492, -0.0172,
1:          0.2080], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6162, -0.6174, -0.6187, -0.6199, -0.6210, -0.6223, -0.6235, -0.6244, -0.6252, -0.6261, -0.6273, -0.6288,
1:         -0.6303, -0.6318, -0.6333, -0.6348, -0.6362, -0.6375, -0.6169, -0.6175, -0.6182, -0.6187, -0.6192, -0.6198,
1:         -0.6207], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., 0., 0., 0., -0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.3344, 1.3345, 1.3345, 1.3344, 1.3342, 1.3340, 1.3336, 1.3331, 1.3327, 1.3319, 1.3314, 1.3306, 1.3298, 1.3289,
1:         1.3279, 1.3272, 1.3262, 1.3254, 1.3248, 1.3240, 1.3233, 1.3229, 1.3224, 1.3222, 1.3220], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2321, -0.2321, -0.2321, -0.2321, -0.2321, -0.2309, -0.2309, -0.2309, -0.2309, -0.2367, -0.2356, -0.2332,
1:         -0.2321, -0.2321, -0.2309, -0.2309, -0.2309, -0.2309, -0.2414, -0.2402, -0.2402, -0.2391, -0.2391, -0.2379,
1:         -0.2367], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 13, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 13, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.1619, -0.1627, -0.1651, -0.1716, -0.1764, -0.1776, -0.1729, -0.1639, -0.1559, -0.1502, -0.1478, -0.1473,
1:         -0.1470, -0.1466, -0.1430, -0.1387, -0.1356, -0.1325, -0.2654, -0.2698, -0.2723, -0.2796, -0.2849, -0.2879,
1:         -0.2856], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.2263, -0.2122, -0.2020, -0.1916, -0.1787, -0.1607, -0.1362, -0.1092, -0.0882, -0.0709, -0.0609, -0.0579,
1:         -0.0546, -0.0548, -0.0595, -0.0698, -0.0859, -0.1110, -0.3272, -0.3229, -0.3186, -0.3159, -0.3121, -0.3046,
1:         -0.2940], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.5480, -0.5503, -0.5531, -0.5546, -0.5559, -0.5579, -0.5608, -0.5638, -0.5678, -0.5750, -0.5812, -0.5896,
1:         -0.5976, -0.6066, -0.6156, -0.6246, -0.6273, -0.6249, -0.4930, -0.4939, -0.4973, -0.4995, -0.5030, -0.5070,
1:         -0.5109], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.3542, 0.4661, 0.5446, 0.6186, 0.6844, 0.7349, 0.7633, 0.7756, 0.7807, 0.7782, 0.7621, 0.7495, 0.7193, 0.6542,
1:         0.5779, 0.5013, 0.4265, 0.3173, 0.5224, 0.5763, 0.6015, 0.6129, 0.6218, 0.6138, 0.5887], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.9901, 0.9891, 0.9837, 0.9782, 0.9726, 0.9687, 0.9654, 0.9613, 0.9575, 0.9521, 0.9457, 0.9406, 0.9356, 0.9325,
1:         0.9334, 0.9332, 0.9361, 0.9367, 0.9362, 0.9338, 0.9289, 0.9235, 0.9182, 0.9149, 0.9133], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2135, -0.2130, -0.2163, -0.2138, -0.2059, -0.2024, -0.2021, -0.1985, -0.1877, -0.2221, -0.2239, -0.2230,
1:         -0.2229, -0.2202, -0.2199, -0.2153, -0.2096, -0.2041, -0.2220, -0.2256, -0.2284, -0.2243, -0.2235, -0.2253,
1:         -0.2225], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0033,  0.0463, -0.0416, -0.0336, -0.0004,  0.0049,  0.0003, -0.0797, -0.0108, -0.0615, -0.0186, -0.0353,
1:          0.0038, -0.0084, -0.0334, -0.0470, -0.0025, -0.0454, -0.0162, -0.0157, -0.0249,  0.0386,  0.0160, -0.0121,
1:         -0.0305], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 13 [1/5 (20%)]	Loss: 0.24365 : 0.19171 :: 0.02577 (1.87 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 13 [2/5 (40%)]	Loss: 0.24422 : 0.20682 :: 0.02421 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 13 [3/5 (60%)]	Loss: 0.31085 : 0.20840 :: 0.02563 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 13 [4/5 (80%)]	Loss: 0.25939 : 0.19120 :: 0.02473 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 13 : 0.20997267961502075
0: validation loss for velocity_u : 0.0041322181932628155
0: validation loss for velocity_v : 0.005601921118795872
0: validation loss for specific_humidity : 0.0063928840681910515
0: validation loss for velocity_z : 0.12862296402454376
0: validation loss for temperature : 0.01886235550045967
0: validation loss for total_precip : 0.27314886450767517
0: validation loss for t2m : 1.0330477952957153
1: 14 : 01:33:40 :: batch_size = 96, lr = 1.4871117700906175e-05
0: 14 : 01:33:40 :: batch_size = 96, lr = 1.4871117700906175e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 14, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.0975, 1.0616, 1.0257, 0.9900, 0.9552, 0.9187, 0.8840, 0.8533, 0.8266, 0.8089, 0.8000, 0.7963, 0.7969, 0.7981,
1:         0.7972, 0.7946, 0.7909, 0.7860, 1.0148, 0.9793, 0.9429, 0.9077, 0.8731, 0.8388, 0.8083], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0027, -0.0127, -0.1285,  0.2318, -0.0643,  0.0148,  0.0722, -0.0425,  0.0556,  0.0213,  0.1071, -0.1619,
1:          0.0725, -0.0702, -0.0454, -0.0967, -0.0082, -0.0495, -0.1131,  0.0443,  0.1046,  0.0444, -0.0570,  0.2066,
1:         -0.0275], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([2.1316, 2.1162, 2.1187, 2.1295, 2.1446, 2.1678, 2.2001, 2.2382, 2.2890, 2.3376, 2.3798, 2.4145, 2.4393, 2.4491,
1:         2.4533, 2.4438, 2.4176, 2.3760, 2.1473, 2.1451, 2.1534, 2.1635, 2.1752, 2.1964, 2.2254], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.7767, 0.7929, 0.7912, 0.7938, 0.7976, 0.7835, 0.7735, 0.7514, 0.7189, 0.6933, 0.6636, 0.6414, 0.6319, 0.6232,
1:         0.6152, 0.5919, 0.5594, 0.5425, 0.5395, 0.5544, 0.5958, 0.6513, 0.7132, 0.7666, 0.8040], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2476, -0.2476, -0.2454, -0.2454, -0.2476, -0.2454, -0.2476, -0.2499, -0.2476, -0.2454, -0.2454, -0.2431,
1:         -0.2409, -0.2431, -0.2431, -0.2454, -0.2476, -0.2499, -0.2454, -0.2454, -0.2431, -0.2431, -0.2454, -0.2476,
1:         -0.2476], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 14, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan, 1.0140,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan, 1.1128,    nan,    nan,    nan,    nan,    nan, 1.4484, 1.4989,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 14, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.5787, 0.5760, 0.5763, 0.5781, 0.5792, 0.5798, 0.5799, 0.5812, 0.5821, 0.5817, 0.5826, 0.5854, 0.5845, 0.5840,
1:         0.5845, 0.5835, 0.5779, 0.5707, 0.5315, 0.5288, 0.5274, 0.5268, 0.5282, 0.5289, 0.5303], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.3703, 0.3633, 0.3516, 0.3342, 0.3177, 0.3023, 0.2909, 0.2859, 0.2853, 0.2886, 0.2936, 0.2969, 0.2979, 0.2934,
1:         0.2872, 0.2784, 0.2722, 0.2640, 0.3512, 0.3434, 0.3281, 0.3152, 0.2984, 0.2863, 0.2760], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([ 2.1790,  1.9820,  1.7174,  1.4214,  1.1425,  0.9063,  0.7383,  0.6296,  0.5503,  0.4770,  0.3808,  0.2438,
1:          0.0708, -0.1208, -0.3033, -0.4551, -0.5651, -0.6310,  1.9145,  1.6905,  1.4075,  1.1126,  0.8557,  0.6643,
1:          0.5401], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.4932,  0.4260,  0.3116,  0.2118,  0.1558,  0.1218,  0.0710,  0.0399,  0.0165, -0.0247, -0.0809, -0.1457,
1:         -0.1750, -0.1939, -0.2215, -0.2193, -0.2084, -0.1784,  0.4846,  0.3343,  0.1811,  0.0625, -0.0221, -0.0576,
1:         -0.0993], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.5865, 1.6386, 1.6809, 1.7184, 1.7535, 1.7906, 1.8281, 1.8700, 1.9230, 1.9877, 2.0608, 2.1364, 2.2027, 2.2564,
1:         2.2929, 2.3150, 2.3264, 2.3323, 2.3369, 2.3372, 2.3337, 2.3224, 2.3017, 2.2744, 2.2405], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2115, -0.2182, -0.2219, -0.2257, -0.2256, -0.2233, -0.2222, -0.2204, -0.2152, -0.2162, -0.2235, -0.2277,
1:         -0.2322, -0.2323, -0.2342, -0.2315, -0.2306, -0.2296, -0.2226, -0.2282, -0.2280, -0.2346, -0.2358, -0.2395,
1:         -0.2398], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0006,  0.0457, -0.0052, -0.0177,  0.0004,  0.0080, -0.0063, -0.0338,  0.0044, -0.0263,  0.0255, -0.0161,
1:          0.0236,  0.0223, -0.0144, -0.0353, -0.0139, -0.0203,  0.0058, -0.0066, -0.0268,  0.0051,  0.0188, -0.0073,
1:         -0.0282], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 14, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.0975, 1.0616, 1.0257, 0.9900, 0.9552, 0.9187, 0.8840, 0.8533, 0.8266, 0.8089, 0.8000, 0.7963, 0.7969, 0.7981,
0:         0.7972, 0.7946, 0.7909, 0.7860, 1.0148, 0.9793, 0.9429, 0.9077, 0.8731, 0.8388, 0.8083], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.7564, 0.7583, 0.7547, 0.7455, 0.7305, 0.7105, 0.6854, 0.6571, 0.6275, 0.5943, 0.5563, 0.5175, 0.4769, 0.4338,
0:         0.3901, 0.3452, 0.3006, 0.2609, 0.7227, 0.7223, 0.7161, 0.7039, 0.6869, 0.6665, 0.6432], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0523, -0.0340,  0.0049,  0.0189,  0.0254,  0.0394,  0.0297,  0.0329,  0.0232, -0.0038,  0.0189,  0.0415,
0:          0.0566,  0.1030,  0.0739, -0.0005, -0.0145, -0.0329, -0.0145,  0.0178,  0.0869,  0.0707,  0.0707,  0.0696,
0:          0.0124], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2476, -0.2476, -0.2454, -0.2454, -0.2476, -0.2454, -0.2476, -0.2499, -0.2476, -0.2454, -0.2454, -0.2431,
0:         -0.2409, -0.2431, -0.2431, -0.2454, -0.2476, -0.2499, -0.2454, -0.2454, -0.2431, -0.2431, -0.2454, -0.2476,
0:         -0.2476], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 14, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan, 1.0119,    nan, 1.0184,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan, 1.3512, 1.2911,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 14, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.4052, -0.3929, -0.3833, -0.3764, -0.3710, -0.3684, -0.3683, -0.3723, -0.3766, -0.3819, -0.3839, -0.3838,
0:         -0.3817, -0.3766, -0.3717, -0.3656, -0.3593, -0.3528, -0.4242, -0.4155, -0.4093, -0.4058, -0.4044, -0.4039,
0:         -0.4048], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.4829, 0.4742, 0.4624, 0.4480, 0.4323, 0.4124, 0.3893, 0.3645, 0.3384, 0.3184, 0.3026, 0.2913, 0.2848, 0.2811,
0:         0.2804, 0.2836, 0.2900, 0.2948, 0.4779, 0.4697, 0.4566, 0.4412, 0.4242, 0.4031, 0.3791], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([1.9376, 1.8161, 1.6735, 1.5340, 1.4257, 1.3524, 1.3251, 1.3196, 1.3352, 1.3599, 1.3845, 1.4006, 1.4085, 1.4014,
0:         1.3830, 1.3564, 1.3308, 1.3117, 1.5903, 1.4753, 1.3610, 1.2713, 1.2203, 1.2189, 1.2393], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.1316, 0.1497, 0.1724, 0.1920, 0.2124, 0.2475, 0.2754, 0.2711, 0.2870, 0.3059, 0.2739, 0.2459, 0.2415, 0.2464,
0:         0.2706, 0.2924, 0.3259, 0.3790, 0.1739, 0.2013, 0.2186, 0.2435, 0.2606, 0.2717, 0.2826], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([2.3045, 2.3066, 2.2947, 2.2683, 2.2243, 2.1651, 2.0877, 1.9954, 1.8921, 1.7845, 1.6805, 1.5885, 1.5139, 1.4639,
0:         1.4476, 1.4593, 1.5013, 1.5595, 1.6229, 1.6790, 1.7221, 1.7525, 1.7658, 1.7639, 1.7475], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([ 0.1567,  0.1716,  0.1800,  0.1540,  0.1157,  0.0584, -0.0074, -0.0743, -0.1128,  0.0685,  0.0859,  0.0948,
0:          0.0889,  0.0672,  0.0193, -0.0391, -0.0916, -0.1277, -0.0291, -0.0122, -0.0021,  0.0102,  0.0077, -0.0107,
0:         -0.0550], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0044,  0.0161, -0.0135, -0.0098,  0.0051, -0.0199, -0.0339, -0.0111, -0.0226, -0.0300,  0.0057, -0.0243,
0:          0.0042,  0.0057, -0.0129, -0.0179, -0.0429, -0.0416, -0.0019,  0.0438,  0.0018,  0.0082,  0.0033, -0.0168,
0:          0.0118], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 14 [1/5 (20%)]	Loss: 0.24872 : 0.20267 :: 0.02532 (1.61 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 14 [2/5 (40%)]	Loss: 0.26945 : 0.19840 :: 0.02452 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 14 [3/5 (60%)]	Loss: 0.26488 : 0.21613 :: 0.02558 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 14 [4/5 (80%)]	Loss: 0.27216 : 0.19674 :: 0.02576 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 14 : 0.20791934430599213
0: validation loss for velocity_u : 0.0035949526354670525
0: validation loss for velocity_v : 0.004925815388560295
0: validation loss for specific_humidity : 0.006494233850389719
0: validation loss for velocity_z : 0.10364842414855957
0: validation loss for temperature : 0.019760921597480774
0: validation loss for total_precip : 0.29263854026794434
0: validation loss for t2m : 1.0243725776672363
1: 15 : 01:39:57 :: batch_size = 96, lr = 1.4508407513079195e-05
0: 15 : 01:39:57 :: batch_size = 96, lr = 1.4508407513079195e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 15, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6385, -0.6362, -0.6337, -0.6313, -0.6290, -0.6265, -0.6241, -0.6218, -0.6194, -0.6169, -0.6146, -0.6122,
1:         -0.6099, -0.6076, -0.6052, -0.6027, -0.6004, -0.5980, -0.5801, -0.5778, -0.5754, -0.5732, -0.5709, -0.5686,
1:         -0.5664], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.1350, -0.1215,  0.0724,  0.1807,  0.1118, -0.0230, -0.0897,  0.2381, -0.0780,  0.1322, -0.0604,  0.1093,
1:         -0.0891, -0.0435, -0.1232, -0.0979,  0.0647,  0.0272,  0.0874,  0.0255, -0.1039,  0.0604,  0.1132,  0.0568,
1:          0.1950], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6859, -0.6858, -0.6857, -0.6856, -0.6855, -0.6854, -0.6853, -0.6852, -0.6856, -0.6861, -0.6865, -0.6870,
1:         -0.6873, -0.6878, -0.6882, -0.6887, -0.6890, -0.6894, -0.6586, -0.6589, -0.6594, -0.6597, -0.6601, -0.6606,
1:         -0.6609], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.7960, -0.7973, -0.7986, -0.7998, -0.8011, -0.8024, -0.8036, -0.8052, -0.8064, -0.8077, -0.8089, -0.8102,
1:         -0.8114, -0.8129, -0.8142, -0.8154, -0.8169, -0.8182, -0.8195, -0.8210, -0.8222, -0.8234, -0.8249, -0.8261,
1:         -0.8276], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2377, -0.2377, -0.2365, -0.2365, -0.2365, -0.2365, -0.2365, -0.2365, -0.2365, -0.2377, -0.2377, -0.2377,
1:         -0.2377, -0.2365, -0.2365, -0.2365, -0.2365, -0.2365, -0.2253, -0.2253, -0.2253, -0.2253, -0.2253, -0.2253,
1:         -0.2253], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 15, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan, 0.4450,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.3752, 0.3679,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 15, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.6132, -0.6114, -0.6122, -0.6126, -0.6125, -0.6089, -0.6075, -0.6071, -0.6034, -0.6012, -0.5977, -0.5928,
1:         -0.5889, -0.5850, -0.5818, -0.5821, -0.5886, -0.5908, -0.5522, -0.5493, -0.5480, -0.5459, -0.5435, -0.5389,
1:         -0.5348], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.8187, -0.8265, -0.8348, -0.8394, -0.8430, -0.8466, -0.8528, -0.8587, -0.8663, -0.8723, -0.8807, -0.8888,
1:         -0.8987, -0.9061, -0.9135, -0.9213, -0.9311, -0.9414, -0.8069, -0.8181, -0.8282, -0.8325, -0.8363, -0.8403,
1:         -0.8471], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.4671, -0.4740, -0.4817, -0.4899, -0.4996, -0.5080, -0.5159, -0.5218, -0.5250, -0.5290, -0.5305, -0.5336,
1:         -0.5378, -0.5416, -0.5440, -0.5437, -0.5389, -0.5322, -0.4871, -0.4932, -0.4987, -0.5069, -0.5149, -0.5219,
1:         -0.5283], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.0772, 0.0928, 0.0903, 0.1010, 0.1027, 0.0962, 0.0890, 0.0787, 0.0757, 0.0890, 0.1053, 0.1117, 0.1178, 0.1102,
1:         0.0857, 0.0903, 0.1015, 0.0990, 0.0953, 0.1079, 0.1058, 0.1102, 0.1093, 0.1195, 0.1245], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.6175, 0.6123, 0.6065, 0.5989, 0.5917, 0.5848, 0.5766, 0.5686, 0.5602, 0.5531, 0.5496, 0.5495, 0.5498, 0.5484,
1:         0.5463, 0.5425, 0.5383, 0.5349, 0.5310, 0.5283, 0.5250, 0.5250, 0.5259, 0.5281, 0.5303], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.1671, -0.1689, -0.1731, -0.1749, -0.1708, -0.1767, -0.1754, -0.1763, -0.1701, -0.1713, -0.1680, -0.1718,
1:         -0.1738, -0.1747, -0.1786, -0.1728, -0.1744, -0.1743, -0.1642, -0.1644, -0.1642, -0.1686, -0.1729, -0.1767,
1:         -0.1718], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-2.5533e-04,  2.3402e-02,  8.5684e-03, -1.3863e-02, -4.9564e-03,  8.1032e-03,  1.8878e-03, -5.3508e-02,
1:         -2.1325e-02, -1.8607e-02,  1.8864e-02, -5.7636e-03,  1.7277e-02,  3.4452e-03,  9.8270e-03, -1.0104e-02,
1:         -8.9633e-05,  6.7765e-03,  8.6782e-03,  5.5522e-03,  5.6708e-03,  1.9996e-02,  3.4369e-02,  3.7586e-03,
1:         -2.1818e-04], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 15, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6385, -0.6362, -0.6337, -0.6313, -0.6290, -0.6265, -0.6241, -0.6218, -0.6194, -0.6169, -0.6146, -0.6122,
0:         -0.6099, -0.6076, -0.6052, -0.6027, -0.6004, -0.5980, -0.5801, -0.5778, -0.5754, -0.5732, -0.5709, -0.5686,
0:         -0.5664], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.3706, 0.3702, 0.3698, 0.3694, 0.3690, 0.3686, 0.3681, 0.3677, 0.3671, 0.3665, 0.3661, 0.3655, 0.3649, 0.3643,
0:         0.3635, 0.3629, 0.3621, 0.3614, 0.4073, 0.4067, 0.4063, 0.4057, 0.4051, 0.4043, 0.4037], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.0759, 0.0737, 0.0737, 0.0737, 0.0737, 0.0714, 0.0714, 0.0714, 0.0692, 0.0692, 0.0692, 0.0670, 0.0670, 0.0647,
0:         0.0647, 0.0625, 0.0625, 0.0602, 0.0490, 0.0490, 0.0513, 0.0513, 0.0535, 0.0535, 0.0535], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2377, -0.2377, -0.2365, -0.2365, -0.2365, -0.2365, -0.2365, -0.2365, -0.2365, -0.2377, -0.2377, -0.2377,
0:         -0.2377, -0.2365, -0.2365, -0.2365, -0.2365, -0.2365, -0.2253, -0.2253, -0.2253, -0.2253, -0.2253, -0.2253,
0:         -0.2253], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 15, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan, 1.0984,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 15, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([1.1245, 1.1118, 1.0962, 1.0813, 1.0667, 1.0557, 1.0444, 1.0319, 1.0209, 1.0077, 0.9954, 0.9829, 0.9683, 0.9550,
0:         0.9414, 0.9303, 0.9207, 0.9133, 1.0851, 1.0748, 1.0606, 1.0466, 1.0344, 1.0228, 1.0105], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.7076, 0.6945, 0.6812, 0.6702, 0.6623, 0.6588, 0.6555, 0.6512, 0.6442, 0.6372, 0.6274, 0.6180, 0.6100, 0.6026,
0:         0.5953, 0.5877, 0.5841, 0.5832, 0.8113, 0.7982, 0.7865, 0.7763, 0.7704, 0.7652, 0.7607], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.5167, -0.5191, -0.5169, -0.5157, -0.5149, -0.5138, -0.5130, -0.5122, -0.5117, -0.5110, -0.5110, -0.5119,
0:         -0.5137, -0.5159, -0.5167, -0.5136, -0.5092, -0.5024, -0.4850, -0.4856, -0.4848, -0.4846, -0.4839, -0.4835,
0:         -0.4831], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.4278, -0.4079, -0.4062, -0.4077, -0.4071, -0.4202, -0.4306, -0.4383, -0.4443, -0.4472, -0.4531, -0.4507,
0:         -0.4513, -0.4638, -0.4769, -0.4980, -0.5083, -0.4980, -0.4474, -0.4314, -0.4439, -0.4495, -0.4477, -0.4575,
0:         -0.4579], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.5852, 0.5748, 0.5668, 0.5614, 0.5568, 0.5533, 0.5485, 0.5440, 0.5372, 0.5293, 0.5218, 0.5137, 0.5052, 0.4986,
0:         0.4933, 0.4880, 0.4807, 0.4739, 0.4645, 0.4547, 0.4434, 0.4340, 0.4272, 0.4226, 0.4177], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2363, -0.2367, -0.2363, -0.2407, -0.2405, -0.2436, -0.2394, -0.2388, -0.2356, -0.2399, -0.2381, -0.2359,
0:         -0.2402, -0.2380, -0.2390, -0.2374, -0.2385, -0.2422, -0.2374, -0.2354, -0.2334, -0.2377, -0.2368, -0.2390,
0:         -0.2402], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0027,  0.0295, -0.0037, -0.0113, -0.0104, -0.0107, -0.0161, -0.0430, -0.0126, -0.0196,  0.0115, -0.0105,
0:          0.0198,  0.0154,  0.0007, -0.0055, -0.0339, -0.0244,  0.0182,  0.0180,  0.0114,  0.0138,  0.0150, -0.0112,
0:         -0.0007], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 15 [1/5 (20%)]	Loss: 0.27853 : 0.22430 :: 0.02423 (1.93 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 15 [2/5 (40%)]	Loss: 0.25161 : 0.19041 :: 0.02418 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 15 [3/5 (60%)]	Loss: 0.28911 : 0.20417 :: 0.02340 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 15 [4/5 (80%)]	Loss: 0.25892 : 0.19781 :: 0.02480 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 15 : 0.20185084640979767
0: validation loss for velocity_u : 0.003834967967122793
0: validation loss for velocity_v : 0.005141112022101879
0: validation loss for specific_humidity : 0.006127779372036457
0: validation loss for velocity_z : 0.1139422357082367
0: validation loss for temperature : 0.01788201928138733
0: validation loss for total_precip : 0.263566792011261
0: validation loss for t2m : 1.0024610757827759
1: 16 : 01:45:52 :: batch_size = 96, lr = 1.4154543915199217e-05
0: 16 : 01:45:52 :: batch_size = 96, lr = 1.4154543915199217e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 16, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.4300, -0.4475, -0.4657, -0.4848, -0.5033, -0.5189, -0.5306, -0.5387, -0.5451, -0.5515, -0.5594, -0.5699,
0:         -0.5837, -0.6012, -0.6228, -0.6480, -0.6762, -0.7056, -0.4330, -0.4518, -0.4713, -0.4912, -0.5096, -0.5245,
0:         -0.5356], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.5271, -1.5508, -1.5721, -1.5910, -1.6083, -1.6248, -1.6389, -1.6483, -1.6509, -1.6439, -1.6255, -1.5940,
0:         -1.5536, -1.5133, -1.4824, -1.4666, -1.4649, -1.4720, -1.5680, -1.5907, -1.6098, -1.6257, -1.6402, -1.6548,
0:         -1.6674], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.3967,  0.4325,  0.4586,  0.4369,  0.3870,  0.3501,  0.3295,  0.3089,  0.2904,  0.2850,  0.2806,  0.2394,
0:          0.1461,  0.0387, -0.0264, -0.0243,  0.0246,  0.0940,  0.4651,  0.5400,  0.5736,  0.5204,  0.4293,  0.3696,
0:          0.3501], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2434, -0.2434, -0.2411, -0.2456, -0.2456, -0.2456,
0:         -0.2456, -0.2456, -0.2456, -0.2434, -0.2434, -0.2411, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456,
0:         -0.2434], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 16, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 2.1581,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 16, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.7745, -0.7477, -0.6967, -0.6226, -0.5376, -0.4537, -0.3770, -0.3157, -0.2713, -0.2445, -0.2363, -0.2423,
0:         -0.2637, -0.2919, -0.3202, -0.3407, -0.3553, -0.3554, -0.7087, -0.7008, -0.6711, -0.6180, -0.5491, -0.4708,
0:         -0.3901], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-1.7541, -1.6809, -1.5904, -1.4895, -1.3896, -1.2888, -1.1902, -1.0905, -0.9824, -0.8705, -0.7551, -0.6441,
0:         -0.5441, -0.4599, -0.4005, -0.3609, -0.3416, -0.3315, -1.8251, -1.7494, -1.6571, -1.5598, -1.4635, -1.3725,
0:         -1.2828], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.0095,  0.0348,  0.0697,  0.1007,  0.1221,  0.1378,  0.1454,  0.1504,  0.1521,  0.1525,  0.1514,  0.1513,
0:          0.1438,  0.1329,  0.1194,  0.1029,  0.0909,  0.0847, -0.0374,  0.0144,  0.0615,  0.0996,  0.1282,  0.1455,
0:          0.1542], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 1.2650e-01,  1.2768e-01,  1.3263e-01,  1.3337e-01,  1.5038e-01,  1.5254e-01,  1.4504e-01,  1.3204e-01,
0:          1.0420e-01,  7.6493e-02,  4.1412e-02, -1.0317e-04, -3.2279e-02, -7.5550e-02, -1.3350e-01, -1.7664e-01,
0:         -2.2558e-01, -2.6903e-01,  1.8910e-01,  1.9437e-01,  2.0297e-01,  1.9809e-01,  1.9948e-01,  1.8431e-01,
0:          1.7423e-01], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.7128, -0.6573, -0.5939, -0.5313, -0.4747, -0.4262, -0.3864, -0.3508, -0.3182, -0.2869, -0.2578, -0.2338,
0:         -0.2135, -0.1935, -0.1709, -0.1453, -0.1197, -0.0926, -0.0676, -0.0433, -0.0209,  0.0027,  0.0259,  0.0487,
0:          0.0695], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1222, -0.1250, -0.1292, -0.1397, -0.1433, -0.1535, -0.1635, -0.1728, -0.1727, -0.0842, -0.0844, -0.0925,
0:         -0.1046, -0.1135, -0.1283, -0.1425, -0.1561, -0.1661, -0.0353, -0.0404, -0.0491, -0.0647, -0.0782, -0.1001,
0:         -0.1165], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0065,  0.0145, -0.0128,  0.0047, -0.0147,  0.0047, -0.0201, -0.0220, -0.0272, -0.0242,  0.0174, -0.0214,
0:         -0.0096, -0.0010,  0.0154, -0.0026, -0.0307, -0.0239,  0.0081,  0.0458,  0.0172,  0.0144,  0.0094,  0.0034,
0:          0.0039], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 16, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.4300, -0.4475, -0.4657, -0.4848, -0.5033, -0.5189, -0.5306, -0.5387, -0.5451, -0.5515, -0.5594, -0.5699,
1:         -0.5837, -0.6012, -0.6228, -0.6480, -0.6762, -0.7056, -0.4330, -0.4518, -0.4713, -0.4912, -0.5096, -0.5245,
1:         -0.5356], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0202,  0.0337, -0.0510, -0.0980,  0.1670, -0.1677,  0.0341,  0.0693, -0.0669, -0.0606,  0.1105, -0.1724,
1:         -0.1421, -0.1664, -0.1453,  0.0327, -0.0731,  0.0380,  0.1868, -0.0970,  0.0423, -0.0401,  0.2037, -0.0060,
1:          0.0514], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.2876, -0.2886, -0.2930, -0.2976, -0.3000, -0.3029, -0.3091, -0.3127, -0.3145, -0.3171, -0.3171, -0.3141,
1:         -0.3073, -0.2892, -0.2733, -0.2282, -0.1825, -0.1421, -0.3010, -0.2994, -0.3010, -0.3045, -0.3073, -0.3107,
1:         -0.3182], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.6323, -0.6768, -0.7240, -0.7741, -0.8275, -0.8862, -0.9489, -1.0131, -1.0763, -1.1363, -1.1936, -1.2479,
1:         -1.2991, -1.3473, -1.3912, -1.4303, -1.4617, -1.4826, -1.4931, -1.4949, -1.4940, -1.4964, -1.5066, -1.5267,
1:         -1.5533], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2434, -0.2434, -0.2411, -0.2456, -0.2456, -0.2456,
1:         -0.2456, -0.2456, -0.2456, -0.2434, -0.2434, -0.2411, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456, -0.2456,
1:         -0.2434], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 16, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan, -0.4558,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 16, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.7616, -0.7696, -0.7723, -0.7706, -0.7670, -0.7657, -0.7659, -0.7687, -0.7747, -0.7819, -0.7915, -0.7998,
1:         -0.8080, -0.8157, -0.8216, -0.8294, -0.8418, -0.8557, -0.7059, -0.7110, -0.7100, -0.7031, -0.6988, -0.6967,
1:         -0.6975], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-1.9828, -1.9733, -1.9630, -1.9485, -1.9259, -1.9014, -1.8689, -1.8328, -1.7898, -1.7371, -1.6719, -1.5944,
1:         -1.5060, -1.4088, -1.3024, -1.1901, -1.0742, -0.9538, -1.9024, -1.8904, -1.8738, -1.8545, -1.8295, -1.8000,
1:         -1.7675], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.3108, -0.3205, -0.3273, -0.3373, -0.3539, -0.3769, -0.4092, -0.4455, -0.4831, -0.5184, -0.5505, -0.5773,
1:         -0.5996, -0.6187, -0.6318, -0.6353, -0.6312, -0.6163, -0.2882, -0.2972, -0.3056, -0.3213, -0.3403, -0.3699,
1:         -0.4041], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.2928, 0.2839, 0.2591, 0.3174, 0.3726, 0.4097, 0.4678, 0.4663, 0.4239, 0.4024, 0.4423, 0.5395, 0.6316, 0.6794,
1:         0.7650, 0.8210, 0.6845, 0.5540, 0.1855, 0.1069, 0.0463, 0.0960, 0.1517, 0.2010, 0.2688], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.1879, -1.1580, -1.1326, -1.1144, -1.1025, -1.0893, -1.0729, -1.0545, -1.0381, -1.0286, -1.0227, -1.0183,
1:         -1.0107, -0.9985, -0.9829, -0.9730, -0.9744, -0.9884, -1.0142, -1.0479, -1.0834, -1.1110, -1.1247, -1.1203,
1:         -1.1000], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.1862, -0.1870, -0.1899, -0.1862, -0.1771, -0.1774, -0.1640, -0.1572, -0.1448, -0.2047, -0.2077, -0.1976,
1:         -0.1911, -0.1841, -0.1775, -0.1674, -0.1590, -0.1477, -0.2037, -0.2052, -0.2012, -0.1930, -0.1841, -0.1727,
1:         -0.1601], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-6.1026e-04,  2.2120e-02, -6.1414e-03, -1.7106e-02, -2.2460e-02, -7.5832e-05, -1.3360e-02, -3.3778e-02,
1:         -1.1586e-02, -1.7583e-02,  1.6930e-02, -2.0096e-02,  1.7616e-02,  8.8841e-03, -3.7563e-03,  1.5939e-02,
1:         -8.2807e-03,  1.2655e-02,  7.1535e-03,  1.8125e-02,  1.0090e-02,  5.7984e-02,  1.7951e-02,  4.6343e-03,
1:         -1.7407e-02], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 16 [1/5 (20%)]	Loss: 0.26712 : 0.19904 :: 0.02446 (1.68 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 16 [2/5 (40%)]	Loss: 0.28177 : 0.21080 :: 0.02539 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 16 [3/5 (60%)]	Loss: 0.22948 : 0.18713 :: 0.02523 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 16 [4/5 (80%)]	Loss: 0.29378 : 0.21891 :: 0.02306 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 16 : 0.19992972910404205
0: validation loss for velocity_u : 0.0037520083133131266
0: validation loss for velocity_v : 0.005295811221003532
0: validation loss for specific_humidity : 0.006456227973103523
0: validation loss for velocity_z : 0.11319434642791748
0: validation loss for temperature : 0.019023369997739792
0: validation loss for total_precip : 0.29104965925216675
0: validation loss for t2m : 0.9607366919517517
1: 17 : 01:52:00 :: batch_size = 96, lr = 1.3809311136779726e-05
0: 17 : 01:52:01 :: batch_size = 96, lr = 1.3809311136779726e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 17, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.1375, -1.0636, -0.9968, -0.9372, -0.8840, -0.8373, -0.7954, -0.7542, -0.7131, -0.6772, -0.6494, -0.6295,
1:         -0.6173, -0.6122, -0.6096, -0.6026, -0.5887, -0.5695, -1.1186, -1.0545, -0.9971, -0.9463, -0.9015, -0.8614,
1:         -0.8226], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0932, -0.1449,  0.1760, -0.0407, -0.0088, -0.0572,  0.1821,  0.1122,  0.1825, -0.1025,  0.0351, -0.0591,
1:         -0.1203, -0.1372,  0.1366,  0.1061, -0.1500, -0.0613, -0.0105, -0.0324, -0.0681, -0.0100,  0.0675,  0.1959,
1:          0.1036], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.2501, -0.2588, -0.2707, -0.3027, -0.3401, -0.3802, -0.4173, -0.4464, -0.4671, -0.4862, -0.5027, -0.5198,
1:         -0.5320, -0.5481, -0.5661, -0.5833, -0.6035, -0.6069, -0.2343, -0.2284, -0.2364, -0.2653, -0.2962, -0.3400,
1:         -0.3777], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.8625, 0.8720, 0.8774, 0.8856, 0.8968, 0.9075, 0.9159, 0.9227, 0.9268, 0.9294, 0.9346, 0.9454, 0.9608, 0.9798,
1:         1.0027, 1.0285, 1.0559, 1.0835, 1.1109, 1.1366, 1.1589, 1.1786, 1.1969, 1.2155, 1.2368], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([ 0.0198, -0.0135, -0.0324, -0.0813, -0.1291, -0.0791, -0.0636,  0.0598,  0.1065, -0.1736, -0.1647, -0.1669,
1:         -0.1758, -0.2180, -0.2225, -0.2158, -0.2136, -0.1058, -0.0647, -0.0524, -0.0380, -0.0791, -0.1347, -0.1847,
1:         -0.2036], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 17, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([-0.3395,     nan,     nan,     nan,     nan,     nan, -0.7958, -0.9396,     nan, -1.1354,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -1.3072,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 17, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([ 0.0530,  0.0539,  0.0558,  0.0583,  0.0600,  0.0582,  0.0562,  0.0566,  0.0585,  0.0625,  0.0673,  0.0737,
1:          0.0792,  0.0815,  0.0875,  0.0960,  0.1040,  0.1120, -0.0043, -0.0040, -0.0049, -0.0041, -0.0040, -0.0044,
1:         -0.0058], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([2.1177, 2.1306, 2.1338, 2.1314, 2.1163, 2.0883, 2.0412, 1.9716, 1.8860, 1.7904, 1.6919, 1.6024, 1.5203, 1.4519,
1:         1.3983, 1.3563, 1.3321, 1.3164, 2.0469, 2.0560, 2.0531, 2.0401, 2.0193, 1.9871, 1.9446], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.0401, -0.0642, -0.0969, -0.1348, -0.1757, -0.2160, -0.2505, -0.2733, -0.2913, -0.3100, -0.3392, -0.3828,
1:         -0.4376, -0.4966, -0.5486, -0.5858, -0.6053, -0.6080, -0.0300, -0.0616, -0.0992, -0.1458, -0.2006, -0.2502,
1:         -0.2911], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.3673,  0.4216,  0.4109,  0.4291,  0.4896,  0.4930,  0.4684,  0.4761,  0.5101,  0.4891,  0.3435,  0.2044,
1:          0.1902,  0.1678, -0.0678, -0.3009, -0.1151,  0.2079,  0.3764,  0.4363,  0.4010,  0.3463,  0.3327,  0.3084,
1:          0.3021], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.1457, 0.0822, 0.0446, 0.0435, 0.0804, 0.1506, 0.2381, 0.3300, 0.4206, 0.5084, 0.5941, 0.6780, 0.7631, 0.8513,
1:         0.9496, 1.0547, 1.1574, 1.2394, 1.2908, 1.3088, 1.3024, 1.2914, 1.2843, 1.2806, 1.2761], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2275, -0.2273, -0.2245, -0.2251, -0.2268, -0.2322, -0.2337, -0.2371, -0.2373, -0.2356, -0.2347, -0.2329,
1:         -0.2318, -0.2318, -0.2364, -0.2364, -0.2382, -0.2428, -0.2404, -0.2411, -0.2394, -0.2374, -0.2357, -0.2335,
1:         -0.2364], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0024,  0.0332, -0.0044, -0.0231, -0.0108,  0.0348, -0.0101, -0.0614, -0.0143, -0.0070,  0.0397, -0.0150,
1:          0.0209,  0.0095, -0.0097,  0.0021, -0.0109,  0.0009, -0.0098,  0.0090, -0.0059,  0.0513,  0.0098,  0.0003,
1:         -0.0062], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 17, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.1375, -1.0636, -0.9968, -0.9372, -0.8840, -0.8373, -0.7954, -0.7542, -0.7131, -0.6772, -0.6494, -0.6295,
0:         -0.6173, -0.6122, -0.6096, -0.6026, -0.5887, -0.5695, -1.1186, -1.0545, -0.9971, -0.9463, -0.9015, -0.8614,
0:         -0.8226], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.6298, 1.6430, 1.6550, 1.6649, 1.6723, 1.6775, 1.6793, 1.6781, 1.6755, 1.6739, 1.6743, 1.6759, 1.6793, 1.6843,
0:         1.6895, 1.6941, 1.6981, 1.7001, 1.6775, 1.6869, 1.6967, 1.7063, 1.7157, 1.7256, 1.7338], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.4209, -0.4752, -0.4709, -0.3862, -0.2712, -0.1800, -0.1366, -0.1344, -0.1431, -0.1149,  0.0023,  0.1999,
0:          0.3735,  0.4082,  0.3236,  0.2563,  0.2541,  0.2541, -0.1366, -0.1323, -0.1084, -0.0324,  0.0414,  0.0501,
0:         -0.0042], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([ 0.0198, -0.0135, -0.0324, -0.0813, -0.1291, -0.0791, -0.0636,  0.0598,  0.1065, -0.1736, -0.1647, -0.1669,
0:         -0.1758, -0.2180, -0.2225, -0.2158, -0.2136, -0.1058, -0.0647, -0.0524, -0.0380, -0.0791, -0.1347, -0.1847,
0:         -0.2036], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 17, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan, -0.2488,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 17, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-1.1209, -1.1001, -1.0785, -1.0573, -1.0402, -1.0353, -1.0405, -1.0581, -1.0832, -1.1165, -1.1519, -1.1834,
0:         -1.2066, -1.2247, -1.2392, -1.2460, -1.2495, -1.2458, -1.1325, -1.1176, -1.1068, -1.0990, -1.1015, -1.1075,
0:         -1.1197], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.5021, 0.5612, 0.6199, 0.6882, 0.7724, 0.8767, 0.9972, 1.1261, 1.2516, 1.3570, 1.4419, 1.5015, 1.5346, 1.5484,
0:         1.5506, 1.5565, 1.5753, 1.6035, 0.4681, 0.5232, 0.5785, 0.6420, 0.7228, 0.8247, 0.9478], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.4894, -0.4686, -0.4295, -0.3842, -0.3485, -0.3434, -0.3875, -0.4758, -0.5770, -0.6644, -0.7112, -0.7209,
0:         -0.7017, -0.6684, -0.6416, -0.6204, -0.6067, -0.5985, -0.4878, -0.4580, -0.4077, -0.3428, -0.2914, -0.2808,
0:         -0.3307], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.0112, -0.0612, -0.1555, -0.1993, -0.2280, -0.1473,  0.0094,  0.0801,  0.0782,  0.0318, -0.0255, -0.0362,
0:         -0.0271,  0.0088,  0.0731,  0.1262,  0.1472,  0.1170, -0.0028,  0.0137, -0.0173, -0.0213, -0.0559, -0.0313,
0:          0.0258], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.9461, 0.9501, 0.9390, 0.9187, 0.8969, 0.8798, 0.8611, 0.8398, 0.8165, 0.7895, 0.7594, 0.7249, 0.6897, 0.6604,
0:         0.6411, 0.6274, 0.6205, 0.6152, 0.6122, 0.6111, 0.6114, 0.6184, 0.6323, 0.6577, 0.6950], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([ 1.2898,  1.2078,  1.0054,  0.7383,  0.4367,  0.1693,  0.0023, -0.0771, -0.0626,  1.2892,  1.1974,  0.9744,
0:          0.6771,  0.3584,  0.0934, -0.0518, -0.1089, -0.1046,  1.1258,  1.0202,  0.7937,  0.5265,  0.2391,  0.0045,
0:         -0.1247], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0043,  0.0051,  0.0013, -0.0246, -0.0299, -0.0001, -0.0109, -0.0410, -0.0200, -0.0228,  0.0118, -0.0019,
0:         -0.0063, -0.0132,  0.0046, -0.0057, -0.0211, -0.0409, -0.0079,  0.0240, -0.0016,  0.0161, -0.0181, -0.0175,
0:         -0.0144], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 17 [1/5 (20%)]	Loss: 0.27619 : 0.22246 :: 0.02599 (1.73 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 17 [2/5 (40%)]	Loss: 0.25185 : 0.18478 :: 0.02518 (8.46 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 17 [3/5 (60%)]	Loss: 0.24777 : 0.20089 :: 0.02659 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 17 [4/5 (80%)]	Loss: 0.25576 : 0.20538 :: 0.02437 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 17 : 0.2019130438566208
0: validation loss for velocity_u : 0.0036761704832315445
0: validation loss for velocity_v : 0.004968782886862755
0: validation loss for specific_humidity : 0.0060242158360779285
0: validation loss for velocity_z : 0.10925769805908203
0: validation loss for temperature : 0.016977984458208084
0: validation loss for total_precip : 0.2320336103439331
0: validation loss for t2m : 1.0404527187347412
1: 18 : 01:57:57 :: batch_size = 96, lr = 1.3472498670029002e-05
0: 18 : 01:57:57 :: batch_size = 96, lr = 1.3472498670029002e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 18, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.5049, 1.4590, 1.4161, 1.3788, 1.3487, 1.3264, 1.3118, 1.3032, 1.2989, 1.2970, 1.2958, 1.2942, 1.2908, 1.2850,
0:         1.2770, 1.2673, 1.2565, 1.2451, 1.3706, 1.3324, 1.3015, 1.2788, 1.2644, 1.2573, 1.2556], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.9423, 0.9268, 0.9118, 0.9012, 0.8973, 0.9020, 0.9161, 0.9396, 0.9715, 1.0089, 1.0496, 1.0909, 1.1301, 1.1655,
0:         1.1942, 1.2148, 1.2272, 1.2318, 0.8114, 0.7981, 0.7919, 0.7946, 0.8068, 0.8281, 0.8576], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.4918, 0.5625, 0.6265, 0.6871, 0.7421, 0.7792, 0.7915, 0.7758, 0.7410, 0.6894, 0.6209, 0.5356, 0.4391, 0.3459,
0:         0.2640, 0.1978, 0.1473, 0.1080, 0.5524, 0.6074, 0.6467, 0.6737, 0.6927, 0.7017, 0.6995], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1740, -0.1692, -0.1644, -0.1571, -0.1511, -0.1426, -0.1330, -0.1282, -0.1354, -0.1873, -0.1825, -0.1777,
0:         -0.1740, -0.1668, -0.1583, -0.1571, -0.1571, -0.1559, -0.1656, -0.1656, -0.1656, -0.1644, -0.1632, -0.1608,
0:         -0.1583], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 18, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 18, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan, 0.3982,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:         0.5505, 0.5622,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.3416])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 18, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.9660, -0.9786, -0.9867, -0.9861, -0.9777, -0.9620, -0.9408, -0.9181, -0.8912, -0.8654, -0.8352, -0.8057,
0:         -0.7779, -0.7536, -0.7331, -0.7126, -0.6898, -0.6642, -1.0999, -1.1048, -1.1009, -1.0871, -1.0644, -1.0411,
0:         -1.0144], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.5797, -0.5687, -0.5567, -0.5460, -0.5353, -0.5254, -0.5150, -0.5053, -0.4972, -0.4901, -0.4850, -0.4787,
0:         -0.4714, -0.4628, -0.4550, -0.4478, -0.4383, -0.4256, -0.5673, -0.5544, -0.5369, -0.5241, -0.5115, -0.4996,
0:         -0.4876], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.4869, -0.4822, -0.4785, -0.4760, -0.4746, -0.4733, -0.4718, -0.4705, -0.4690, -0.4682, -0.4686, -0.4683,
0:         -0.4679, -0.4674, -0.4662, -0.4641, -0.4618, -0.4584, -0.4964, -0.4899, -0.4848, -0.4798, -0.4767, -0.4716,
0:         -0.4679], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([1.1474, 1.1604, 1.1630, 1.1532, 1.1726, 1.2013, 1.2131, 1.2171, 1.2314, 1.2454, 1.2614, 1.2824, 1.2925, 1.3075,
0:         1.3461, 1.3866, 1.4325, 1.4854, 1.5745, 1.5973, 1.6001, 1.5885, 1.5999, 1.6043, 1.5814], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([ 0.2569,  0.2567,  0.2438,  0.2229,  0.1964,  0.1673,  0.1362,  0.1039,  0.0727,  0.0445,  0.0198, -0.0028,
0:         -0.0232, -0.0414, -0.0566, -0.0689, -0.0776, -0.0838, -0.0905, -0.0978, -0.1047, -0.1097, -0.1113, -0.1121,
0:         -0.1133], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2546, -0.2546, -0.2471, -0.2466, -0.2478, -0.2523, -0.2548, -0.2569, -0.2564, -0.2550, -0.2539, -0.2491,
0:         -0.2514, -0.2507, -0.2528, -0.2536, -0.2577, -0.2597, -0.2548, -0.2542, -0.2526, -0.2491, -0.2487, -0.2489,
0:         -0.2552], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0095, -0.0042, -0.0215, -0.0154, -0.0276, -0.0004, -0.0201, -0.0281, -0.0226, -0.0171,  0.0303, -0.0205,
0:         -0.0016, -0.0203, -0.0083, -0.0244, -0.0186, -0.0576, -0.0240,  0.0131,  0.0148, -0.0083, -0.0127, -0.0154,
0:          0.0014], device='cuda:0', grad_fn=<SliceBackward0>)
1:      first 25 values: tensor([1.5049, 1.4590, 1.4161, 1.3788, 1.3487, 1.3264, 1.3118, 1.3032, 1.2989, 1.2970, 1.2958, 1.2942, 1.2908, 1.2850,
1:         1.2770, 1.2673, 1.2565, 1.2451, 1.3706, 1.3324, 1.3015, 1.2788, 1.2644, 1.2573, 1.2556], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0575,  0.0840, -0.1189, -0.0725, -0.0536, -0.0234,  0.0282, -0.0465, -0.1899,  0.0360,  0.1161,  0.0909,
1:         -0.1305,  0.0284, -0.0240, -0.0632, -0.0656, -0.0155,  0.1652,  0.1336, -0.0162, -0.0606, -0.0737,  0.1208,
1:         -0.1265], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6711, -0.6641, -0.6546, -0.6397, -0.6247, -0.6074, -0.5902, -0.5744, -0.5612, -0.5482, -0.5412, -0.5345,
1:         -0.5308, -0.5289, -0.5272, -0.5265, -0.5256, -0.5248, -0.6592, -0.6446, -0.6299, -0.6132, -0.5954, -0.5777,
1:         -0.5637], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., 0., 0., 0., 0., -0., 0., 0., -0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.5797, -0.6399, -0.6965, -0.7477, -0.7929, -0.8315, -0.8642, -0.8919, -0.9158, -0.9374, -0.9579, -0.9787,
1:         -1.0005, -1.0230, -1.0461, -1.0692, -1.0918, -1.1143, -1.1363, -1.1581, -1.1795, -1.2003, -1.2210, -1.2413,
1:         -1.2613], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1740, -0.1692, -0.1644, -0.1571, -0.1511, -0.1426, -0.1330, -0.1282, -0.1354, -0.1873, -0.1825, -0.1777,
1:         -0.1740, -0.1668, -0.1583, -0.1571, -0.1571, -0.1559, -0.1656, -0.1656, -0.1656, -0.1644, -0.1632, -0.1608,
1:         -0.1583], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 18, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan, -0.6285,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 18, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([1.0715, 1.0726, 1.0746, 1.0713, 1.0656, 1.0584, 1.0512, 1.0439, 1.0368, 1.0312, 1.0275, 1.0212, 1.0172, 1.0095,
1:         0.9994, 0.9892, 0.9733, 0.9630, 1.0112, 1.0066, 1.0039, 0.9998, 0.9961, 0.9918, 0.9893], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.3026, 0.2949, 0.2776, 0.2622, 0.2472, 0.2346, 0.2254, 0.2209, 0.2179, 0.2152, 0.2102, 0.2017, 0.1895, 0.1762,
1:         0.1633, 0.1489, 0.1304, 0.1087, 0.2941, 0.2821, 0.2674, 0.2513, 0.2371, 0.2238, 0.2125], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.4708, -0.4659, -0.4629, -0.4588, -0.4551, -0.4506, -0.4457, -0.4395, -0.4341, -0.4286, -0.4244, -0.4209,
1:         -0.4201, -0.4196, -0.4200, -0.4218, -0.4232, -0.4261, -0.5059, -0.5016, -0.4981, -0.4926, -0.4892, -0.4837,
1:         -0.4787], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.1092,  0.0633,  0.0443,  0.0429,  0.0546,  0.0657,  0.0173, -0.0043, -0.0096, -0.1055, -0.1838, -0.1994,
1:         -0.2234, -0.2630, -0.2932, -0.3086, -0.3461, -0.3769,  0.0639,  0.0616,  0.0696,  0.0792,  0.0885,  0.1220,
1:          0.0957], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.0807, -0.0508, -0.0222,  0.0045,  0.0293,  0.0548,  0.0824,  0.1124,  0.1423,  0.1705,  0.1942,  0.2120,
1:          0.2231,  0.2282,  0.2298,  0.2273,  0.2213,  0.2114,  0.1956,  0.1772,  0.1584,  0.1441,  0.1370,  0.1347,
1:          0.1349], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([ 0.0096, -0.0128, -0.0390, -0.0715, -0.0877, -0.1112, -0.1330, -0.1397, -0.1317, -0.0567, -0.0669, -0.0861,
1:         -0.1044, -0.1166, -0.1294, -0.1408, -0.1470, -0.1462, -0.1096, -0.1133, -0.1197, -0.1191, -0.1222, -0.1241,
1:         -0.1266], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0111, -0.0042, -0.0245, -0.0093, -0.0329,  0.0292, -0.0281, -0.0446, -0.0112, -0.0011,  0.0184,  0.0020,
1:          0.0258, -0.0077, -0.0203, -0.0264,  0.0001, -0.0218, -0.0235, -0.0056,  0.0011,  0.0257, -0.0063, -0.0133,
1:          0.0098], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 18 [1/5 (20%)]	Loss: 0.29420 : 0.21876 :: 0.02433 (1.89 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 18 [2/5 (40%)]	Loss: 0.23814 : 0.17917 :: 0.02499 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 18 [3/5 (60%)]	Loss: 0.27072 : 0.19265 :: 0.02440 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 18 [4/5 (80%)]	Loss: 0.29807 : 0.23111 :: 0.02467 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 18 : 0.2013760805130005
0: validation loss for velocity_u : 0.0034705414436757565
0: validation loss for velocity_v : 0.00498240627348423
0: validation loss for specific_humidity : 0.006756027694791555
0: validation loss for velocity_z : 0.10736793279647827
0: validation loss for temperature : 0.020271487534046173
0: validation loss for total_precip : 0.28110355138778687
0: validation loss for t2m : 0.9856804609298706
1: 19 : 02:03:53 :: batch_size = 96, lr = 1.3143901141491711e-05
0: 19 : 02:03:53 :: batch_size = 96, lr = 1.3143901141491711e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 19, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.2016, -0.2114, -0.2130, -0.2213, -0.2287, -0.2304, -0.2352, -0.2565, -0.2940, -0.3304, -0.3559, -0.3721,
1:         -0.4005, -0.4360, -0.4785, -0.5296, -0.5424, -0.5247, -0.2420, -0.2530, -0.2610, -0.2710, -0.2718, -0.2675,
1:         -0.2655], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0175,  0.0179,  0.0136,  0.1255, -0.0393,  0.1718,  0.0456,  0.0264,  0.1055,  0.2063,  0.0133,  0.0752,
1:          0.1036,  0.0295, -0.1420,  0.0485,  0.1353, -0.0455, -0.0096,  0.0475, -0.1263,  0.0169,  0.1911, -0.0762,
1:          0.0330], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([2.2368, 2.2651, 2.2650, 2.2136, 2.0789, 1.9057, 1.8271, 1.8068, 1.8378, 1.8436, 1.7575, 1.7199, 1.7302, 1.7566,
1:         1.7321, 1.7615, 1.7705, 1.9288, 2.1254, 2.1339, 2.1056, 2.0372, 1.9173, 1.8904, 1.8228], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.3047, -1.2590, -1.2483, -1.2354, -1.2870, -1.3304, -1.3147, -1.2421, -1.2293, -1.2828, -1.2911, -1.2924,
1:         -1.2502, -1.1898, -1.1349, -1.0947, -1.0721, -1.1093, -1.0718, -0.9722, -0.9543, -0.9360, -0.9464, -0.9196,
1:         -0.8920], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504,
1:         -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504,
1:         -0.2504], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 19, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.9746,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 19, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.3200, -0.3270, -0.3362, -0.3382, -0.3270, -0.3020, -0.2623, -0.2133, -0.1644, -0.1251, -0.0973, -0.0853,
1:         -0.0846, -0.0902, -0.0995, -0.1054, -0.1026, -0.0939, -0.3053, -0.3201, -0.3351, -0.3441, -0.3375, -0.3153,
1:         -0.2737], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.1114,  0.1328,  0.1585,  0.1806,  0.1913,  0.1821,  0.1537,  0.1098,  0.0593,  0.0104, -0.0300, -0.0565,
1:         -0.0705, -0.0763, -0.0788, -0.0857, -0.1018, -0.1269,  0.1274,  0.1466,  0.1699,  0.1865,  0.1916,  0.1838,
1:          0.1597], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([1.8398, 1.9161, 1.9974, 2.0722, 2.1180, 2.1407, 2.1304, 2.1075, 2.0749, 2.0591, 2.0545, 2.0579, 2.0526, 2.0197,
1:         1.9500, 1.8396, 1.7179, 1.6110, 1.6593, 1.6981, 1.7540, 1.7970, 1.8072, 1.7892, 1.7508], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.4382,  0.5629,  0.5896,  0.5155,  0.4516,  0.3068,  0.0781, -0.1089, -0.2665, -0.2959, -0.1936, -0.1361,
1:         -0.0530,  0.0721,  0.1922,  0.3342,  0.4139,  0.4135,  0.5625,  0.7742,  0.8853,  0.8344,  0.7489,  0.6055,
1:          0.3497], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.2545, -0.1314,  0.0383,  0.2191,  0.3643,  0.4575,  0.4839,  0.4622,  0.4109,  0.3517,  0.3062,  0.2934,
1:          0.3209,  0.3941,  0.5002,  0.6255,  0.7494,  0.8534,  0.9229,  0.9561,  0.9635,  0.9530,  0.9396,  0.9379,
1:          0.9491], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2429, -0.2451, -0.2452, -0.2492, -0.2505, -0.2523, -0.2563, -0.2544, -0.2547, -0.2410, -0.2465, -0.2457,
1:         -0.2521, -0.2542, -0.2558, -0.2600, -0.2589, -0.2574, -0.2410, -0.2444, -0.2492, -0.2554, -0.2553, -0.2550,
1:         -0.2592], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0039, -0.0283,  0.0016, -0.0101, -0.0305,  0.0070, -0.0110, -0.0279, -0.0353,  0.0022,  0.0243, -0.0078,
1:          0.0026, -0.0298, -0.0454, -0.0336, -0.0047, -0.0119, -0.0221, -0.0234,  0.0033,  0.0221, -0.0016, -0.0072,
1:         -0.0049], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 19, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2016, -0.2114, -0.2130, -0.2213, -0.2287, -0.2304, -0.2352, -0.2565, -0.2940, -0.3304, -0.3559, -0.3721,
0:         -0.4005, -0.4360, -0.4785, -0.5296, -0.5424, -0.5247, -0.2420, -0.2530, -0.2610, -0.2710, -0.2718, -0.2675,
0:         -0.2655], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2145, -0.2200, -0.2428, -0.2951, -0.3583, -0.3947, -0.4135, -0.4212, -0.4173, -0.4012, -0.3893, -0.3990,
0:         -0.4018, -0.3577, -0.2788, -0.2513, -0.2969, -0.3171, -0.2107, -0.2040, -0.2214, -0.2765, -0.3448, -0.3858,
0:         -0.4194], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.7313,  0.7619,  0.5584,  0.4314,  0.2147, -0.0097, -0.1257, -0.2953, -0.1060, -0.1519, -0.1695, -0.1147,
0:         -0.3336, -0.2428, -0.6707, -0.8732, -0.2811, -0.3883,  1.0925,  1.0191,  0.7948,  0.6820,  0.4062,  0.1961,
0:         -0.0830], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504,
0:         -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504, -0.2504,
0:         -0.2504], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 19, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([-1.3448, -1.3532,     nan,     nan,     nan,     nan,     nan, -0.0069,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.2353,     nan,     nan, -0.3648,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 19, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([ 0.0029, -0.0259, -0.0544, -0.0801, -0.1028, -0.1203, -0.1339, -0.1427, -0.1484, -0.1502, -0.1514, -0.1545,
0:         -0.1631, -0.1736, -0.1879, -0.2054, -0.2256, -0.2456,  0.0057, -0.0172, -0.0396, -0.0606, -0.0805, -0.0977,
0:         -0.1130], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.2826, -0.2865, -0.3040, -0.3335, -0.3567, -0.3575, -0.3290, -0.2789, -0.2273, -0.1943, -0.1790, -0.1786,
0:         -0.1841, -0.1920, -0.2152, -0.2633, -0.3411, -0.4134, -0.2828, -0.2866, -0.3070, -0.3430, -0.3729, -0.3777,
0:         -0.3512], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([2.1395, 2.1613, 2.1887, 2.2186, 2.2443, 2.2524, 2.2374, 2.1982, 2.1519, 2.1174, 2.1223, 2.1760, 2.2784, 2.4264,
0:         2.5981, 2.7769, 2.9420, 3.0773, 2.1096, 2.1081, 2.1186, 2.1470, 2.1812, 2.2056, 2.2130], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-8.7154e-01, -4.9684e-01, -2.1700e-01,  2.0484e-02,  5.3842e-02, -1.3916e-01, -3.4690e-01, -7.7270e-01,
0:         -1.1773e+00, -1.3625e+00, -1.4135e+00, -1.1963e+00, -1.1316e+00, -9.7737e-01, -4.4161e-01, -6.0336e-04,
0:          3.9420e-01,  5.9633e-01, -5.5386e-01, -2.0250e-01,  1.2231e-01,  3.1339e-01,  2.9001e-01,  6.4890e-02,
0:         -1.3709e-01], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.6955, 0.6317, 0.6357, 0.7343, 0.9238, 1.1832, 1.4550, 1.6973, 1.8577, 1.9180, 1.8765, 1.7544, 1.5871, 1.4074,
0:         1.2490, 1.1143, 0.9982, 0.8930, 0.7908, 0.6903, 0.6015, 0.5256, 0.4586, 0.4014, 0.3526], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2356, -0.2394, -0.2440, -0.2395, -0.2434, -0.2429, -0.2430, -0.2410, -0.2299, -0.2409, -0.2461, -0.2484,
0:         -0.2518, -0.2508, -0.2533, -0.2484, -0.2482, -0.2378, -0.2407, -0.2478, -0.2485, -0.2513, -0.2514, -0.2522,
0:         -0.2541], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-8.5803e-03, -8.8540e-03, -6.7828e-03, -3.0174e-03, -2.1572e-02, -1.3889e-02, -3.9832e-02, -2.4938e-02,
0:         -1.9675e-02, -9.8810e-03, -6.4977e-03, -1.7446e-02, -1.7122e-02, -1.9302e-02, -6.7706e-03, -1.8924e-02,
0:         -1.4331e-02, -3.9595e-02, -4.8690e-02,  8.7557e-05, -1.0725e-02,  2.8674e-03, -2.2887e-02, -9.7293e-03,
0:          5.1203e-03], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 19 [1/5 (20%)]	Loss: 0.27689 : 0.23969 :: 0.02469 (1.82 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 19 [2/5 (40%)]	Loss: 0.23222 : 0.20229 :: 0.02399 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 19 [3/5 (60%)]	Loss: 0.24190 : 0.17671 :: 0.02384 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 19 [4/5 (80%)]	Loss: 0.34685 : 0.26423 :: 0.02286 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 19 : 0.19247660040855408
0: validation loss for velocity_u : 0.0036208280362188816
0: validation loss for velocity_v : 0.005193783901631832
0: validation loss for specific_humidity : 0.005602972581982613
0: validation loss for velocity_z : 0.10634401440620422
0: validation loss for temperature : 0.014894776977598667
0: validation loss for total_precip : 0.19746756553649902
0: validation loss for t2m : 1.0142123699188232
1: 20 : 02:10:11 :: batch_size = 96, lr = 1.2823318186821183e-05
0: 20 : 02:10:24 :: batch_size = 96, lr = 1.2823318186821183e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 20, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0478,  0.0081, -0.0148, -0.1054, -0.2057, -0.2546, -0.2514, -0.2549, -0.2175, -0.1168, -0.0878, -0.1457,
1:         -0.1773, -0.1819, -0.2141, -0.2822, -0.3651, -0.4319,  0.0397,  0.0987,  0.0699, -0.0611, -0.2224, -0.3005,
1:         -0.2808], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.2056, -0.0174,  0.2182,  0.0231, -0.0339,  0.0499,  0.0544,  0.1161,  0.0078,  0.0102,  0.0560, -0.0218,
1:          0.0037,  0.0441, -0.0603, -0.0460,  0.0312,  0.1059, -0.1523,  0.0096,  0.0795,  0.1695,  0.0169,  0.1582,
1:         -0.0880], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([2.1006, 2.0467, 2.0746, 1.9915, 1.9146, 1.8371, 1.8189, 1.8466, 1.9081, 2.0654, 2.0454, 2.0151, 1.9077, 1.6631,
1:         1.3583, 1.0991, 0.9396, 0.8646, 2.0565, 2.0396, 1.9947, 1.9568, 1.8543, 1.7767, 1.7741], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.0988, -0.1000, -0.1727, -0.2046, -0.1359, -0.0792, -0.0779, -0.0801, -0.1148, -0.2011, -0.2031, -0.0800,
1:          0.0117,  0.0232,  0.0037, -0.0496, -0.1272, -0.2248, -0.3293, -0.3907, -0.3963, -0.3574, -0.3000, -0.2707,
1:         -0.2771], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([ 1.7650,  1.8484,  0.1131,  0.8269,  0.3199,  0.3025,  0.3847,  0.4158,  0.2314,  1.8111,  1.5046, -0.0264,
1:          0.5117,  0.1966,  0.1779,  0.3162,  0.3049,  0.0969,  1.2430,  0.2452, -0.0401, -0.1983, -0.1946, -0.1697,
1:         -0.0837], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 20, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan, 1.4430,    nan,    nan, 0.6303,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 20, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.5829, -0.6047, -0.6249, -0.6453, -0.6634, -0.6813, -0.7033, -0.7286, -0.7556, -0.7872, -0.8175, -0.8467,
1:         -0.8746, -0.9024, -0.9300, -0.9583, -0.9888, -1.0144, -0.5774, -0.5961, -0.6083, -0.6182, -0.6249, -0.6376,
1:         -0.6529], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.5026, -0.4926, -0.4813, -0.4690, -0.4602, -0.4514, -0.4438, -0.4323, -0.4126, -0.3867, -0.3562, -0.3254,
1:         -0.3010, -0.2869, -0.2866, -0.2968, -0.3169, -0.3413, -0.5258, -0.5208, -0.5135, -0.5039, -0.4967, -0.4885,
1:         -0.4773], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([0.9791, 1.0043, 1.0075, 0.9841, 0.9482, 0.9060, 0.8746, 0.8636, 0.8740, 0.9053, 0.9571, 1.0321, 1.1274, 1.2336,
1:         1.3285, 1.4043, 1.4460, 1.4506, 0.9184, 0.9349, 0.9178, 0.8769, 0.8172, 0.7616, 0.7268], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.3507, -0.3557, -0.3119, -0.2615, -0.1659, -0.0340,  0.0901,  0.1970,  0.2307,  0.1815,  0.0918, -0.0451,
1:         -0.1482, -0.1918, -0.2199, -0.2226, -0.2622, -0.2955, -0.3889, -0.4047, -0.3906, -0.3444, -0.2434, -0.1270,
1:         -0.0193], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.0303, -1.0741, -1.0799, -1.0469, -0.9835, -0.9063, -0.8364, -0.7875, -0.7672, -0.7703, -0.7859, -0.8018,
1:         -0.8076, -0.7997, -0.7805, -0.7594, -0.7442, -0.7422, -0.7527, -0.7712, -0.7877, -0.7925, -0.7835, -0.7623,
1:         -0.7328], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.0621, -0.0485, -0.0436, -0.0470, -0.0468, -0.0643, -0.0850, -0.1006, -0.1114, -0.0894, -0.0743, -0.0568,
1:         -0.0355, -0.0307, -0.0352, -0.0507, -0.0687, -0.0763, -0.1447, -0.1263, -0.0925, -0.0639, -0.0420, -0.0404,
1:         -0.0359], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0212, -0.0199, -0.0110, -0.0086, -0.0427, -0.0093, -0.0190, -0.0229, -0.0488, -0.0004,  0.0039, -0.0187,
1:          0.0041, -0.0322, -0.0306,  0.0006, -0.0101, -0.0182, -0.0220,  0.0058, -0.0085,  0.0127,  0.0046, -0.0266,
1:         -0.0116], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 20, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0158,  0.0066,  0.0087, -0.0121, -0.0533, -0.1075, -0.1638, -0.2147, -0.2597, -0.3025, -0.3449, -0.3852,
0:         -0.4189, -0.4385, -0.4369, -0.4156, -0.3894, -0.3766, -0.0029,  0.0160,  0.0174, -0.0038, -0.0519, -0.1195,
0:         -0.1878], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.0920, 1.1088, 1.1284, 1.1371, 1.1104, 1.0375, 0.9321, 0.8200, 0.7176, 0.6277, 0.5479, 0.4819, 0.4395, 0.4292,
0:         0.4512, 0.4989, 0.5591, 0.6132, 1.0981, 1.0839, 1.0843, 1.0894, 1.0633, 0.9870, 0.8771], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.7698,  1.0687,  1.5117,  1.9197,  2.0659,  1.7408,  1.0033,  0.2526, -0.1118, -0.1074, -0.0747, -0.2121,
0:         -0.4107, -0.5133, -0.5285, -0.4893, -0.3692, -0.1881,  1.2433,  1.4659,  1.7888,  2.0899,  2.1597,  1.7997,
0:          1.0796], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2054, -0.2054, -0.2460, -0.1434, -0.2460, -0.2460, -0.2460,
0:         -0.1792, -0.1530, -0.2365, -0.2365, -0.1363, -0.0743, -0.2460, -0.2388, -0.2174, -0.1864, -0.1577, -0.2198,
0:         -0.1792], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 20, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan, -0.4447,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.3505, -0.3620,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 20, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-2.9988, -3.0220, -3.0566, -3.0962, -3.1365, -3.1835, -3.2367, -3.2849, -3.3379, -3.3792, -3.4044, -3.4147,
0:         -3.4148, -3.3917, -3.3491, -3.2797, -3.1932, -3.1056, -3.0749, -3.0875, -3.1101, -3.1345, -3.1626, -3.2045,
0:         -3.2497], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-1.0780, -1.0943, -1.1090, -1.1199, -1.1336, -1.1531, -1.1859, -1.2365, -1.3041, -1.3845, -1.4763, -1.5703,
0:         -1.6638, -1.7576, -1.8490, -1.9437, -2.0386, -2.1256, -1.1667, -1.1812, -1.1874, -1.1907, -1.1920, -1.2024,
0:         -1.2279], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6245, -0.6457, -0.6577, -0.6492, -0.6233, -0.5772, -0.5149, -0.4385, -0.3583, -0.2836, -0.2245, -0.1953,
0:         -0.1977, -0.2326, -0.2885, -0.3524, -0.4099, -0.4503, -0.6512, -0.6673, -0.6698, -0.6549, -0.6244, -0.5798,
0:         -0.5210], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.5314, -0.5718, -0.5425, -0.5035, -0.4324, -0.3152, -0.2206, -0.1328, -0.1069, -0.1632, -0.2216, -0.2860,
0:         -0.2994, -0.2583, -0.2173, -0.0819,  0.1475,  0.3022, -0.5934, -0.6272, -0.5265, -0.4044, -0.2929, -0.1622,
0:         -0.0811], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.5385, 0.5017, 0.4516, 0.3953, 0.3405, 0.2970, 0.2688, 0.2582, 0.2652, 0.2841, 0.3083, 0.3370, 0.3703, 0.4060,
0:         0.4514, 0.5027, 0.5645, 0.6352, 0.7141, 0.7957, 0.8758, 0.9485, 1.0099, 1.0608, 1.1032], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2344, -0.2296, -0.2483, -0.2615, -0.2633, -0.2629, -0.2702, -0.2635, -0.2488, -0.2241, -0.2361, -0.2487,
0:         -0.2543, -0.2631, -0.2669, -0.2620, -0.2689, -0.2539, -0.2052, -0.2129, -0.2360, -0.2394, -0.2432, -0.2607,
0:         -0.2634], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0053, -0.0180,  0.0065,  0.0056, -0.0382, -0.0048, -0.0252, -0.0141, -0.0240, -0.0094,  0.0128, -0.0232,
0:         -0.0059, -0.0401, -0.0190, -0.0277, -0.0311, -0.0327, -0.0298,  0.0136,  0.0020, -0.0096, -0.0073, -0.0102,
0:         -0.0049], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 20 [1/5 (20%)]	Loss: 0.32957 : 0.24260 :: 0.02327 (1.64 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 20 [2/5 (40%)]	Loss: 0.23360 : 0.18866 :: 0.02213 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 20 [3/5 (60%)]	Loss: 0.30016 : 0.22711 :: 0.02511 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 20 [4/5 (80%)]	Loss: 0.27996 : 0.18905 :: 0.02365 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 20 : 0.20944377779960632
0: validation loss for velocity_u : 0.0035856631584465504
0: validation loss for velocity_v : 0.0051677776500582695
0: validation loss for specific_humidity : 0.006208586506545544
0: validation loss for velocity_z : 0.11234870553016663
0: validation loss for temperature : 0.0182225089520216
0: validation loss for total_precip : 0.321471244096756
0: validation loss for t2m : 0.9991016387939453
1: 21 : 02:16:30 :: batch_size = 96, lr = 1.2510554328606033e-05
0: 21 : 02:16:30 :: batch_size = 96, lr = 1.2510554328606033e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 21, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.4456,  0.4008,  0.3487,  0.2988,  0.2412,  0.1797,  0.1389,  0.0775,  0.0170, -0.0381, -0.1179, -0.0453,
0:          0.2228,  0.4653,  0.6131,  0.6843,  0.6751,  0.6329,  0.3944,  0.3510,  0.2976,  0.2448,  0.1802,  0.1163,
0:          0.0786], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2031, 0.2234, 0.2415, 0.2539, 0.2726, 0.3076, 0.3615, 0.4355, 0.5116, 0.5800, 0.6880, 0.8562, 0.9826, 0.9675,
0:         0.8281, 0.6375, 0.4700, 0.3485, 0.1997, 0.2208, 0.2402, 0.2492, 0.2598, 0.2852, 0.3300], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 5.5415e-01,  3.4442e-01,  2.2617e-01, -7.7275e-02, -1.2571e-02,  1.1461e-01,  1.9270e-01,  5.9208e-01,
0:          4.3208e-02,  2.8195e-01,  5.5415e-01, -3.9774e+00, -7.9444e+00, -5.6597e+00, -3.0157e+00, -3.0068e+00,
0:         -3.0157e+00, -2.4803e+00,  4.2474e-01,  2.6186e-01,  1.8824e-01, -1.1967e-01, -5.9426e-02,  8.1599e-04,
0:          1.0345e-01], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2434, -0.2434, -0.2387, -0.2306, -0.2364, -0.2260, -0.2190, -0.1273,  0.1326, -0.2434, -0.2434, -0.2387,
0:         -0.2132, -0.2376, -0.2213, -0.1737, -0.0739,  0.1477, -0.2434, -0.2434, -0.2434, -0.2120, -0.2352, -0.1877,
0:         -0.1494], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 21, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,  0.0125,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2704, -0.3765,
0:             nan,     nan,     nan,     nan, -0.7309,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 21, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.1442, -0.1877, -0.2373, -0.2867, -0.3344, -0.3721, -0.4025, -0.4219, -0.4301, -0.4335, -0.4344, -0.4395,
0:         -0.4503, -0.4705, -0.4935, -0.5162, -0.5346, -0.5466, -0.1092, -0.1563, -0.2056, -0.2565, -0.3053, -0.3469,
0:         -0.3781], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.6490, 0.6401, 0.6258, 0.6102, 0.5953, 0.5826, 0.5762, 0.5730, 0.5703, 0.5666, 0.5604, 0.5490, 0.5328, 0.5121,
0:         0.4861, 0.4569, 0.4254, 0.3962, 0.6186, 0.6124, 0.6012, 0.5878, 0.5726, 0.5624, 0.5564], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.3623, -0.3719, -0.3843, -0.3962, -0.4029, -0.4038, -0.3971, -0.3895, -0.3791, -0.3721, -0.3707, -0.3807,
0:         -0.4001, -0.4278, -0.4606, -0.4918, -0.5202, -0.5376, -0.3702, -0.3806, -0.3964, -0.4105, -0.4214, -0.4270,
0:         -0.4272], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.1325, -0.0845, -0.0597, -0.0620, -0.0672, -0.0531, -0.0326, -0.0020,  0.0422,  0.0636,  0.0705,  0.0458,
0:         -0.0295, -0.0870, -0.1124, -0.1377, -0.1205, -0.0959, -0.0289,  0.0045,  0.0090, -0.0021, -0.0075,  0.0085,
0:          0.0391], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([ 0.1651,  0.2465,  0.3224,  0.3694,  0.3765,  0.3668,  0.3742,  0.4225,  0.4927,  0.5374,  0.4977,  0.3331,
0:          0.0435, -0.3275, -0.7320, -1.1269, -1.4804, -1.7709, -2.0030, -2.1909, -2.3500, -2.4982, -2.6386, -2.7518,
0:         -2.8134], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.0616, -0.0621, -0.0586, -0.0467, -0.0388, -0.0350, -0.0289, -0.0323, -0.0301, -0.0804, -0.0811, -0.0707,
0:         -0.0554, -0.0475, -0.0401, -0.0390, -0.0438, -0.0455, -0.0986, -0.0960, -0.0920, -0.0767, -0.0709, -0.0684,
0:         -0.0618], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0040, -0.0045, -0.0043,  0.0104, -0.0232, -0.0169, -0.0158, -0.0085, -0.0236,  0.0115,  0.0087, -0.0320,
0:         -0.0234, -0.0165,  0.0027, -0.0073, -0.0069, -0.0298, -0.0227,  0.0194,  0.0092, -0.0044, -0.0215, -0.0207,
0:          0.0097], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 21, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.4456,  0.4008,  0.3487,  0.2988,  0.2412,  0.1797,  0.1389,  0.0775,  0.0170, -0.0381, -0.1179, -0.0453,
1:          0.2228,  0.4653,  0.6131,  0.6843,  0.6751,  0.6329,  0.3944,  0.3510,  0.2976,  0.2448,  0.1802,  0.1163,
1:          0.0786], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0222, -0.2464, -0.0165,  0.0495,  0.0027, -0.0648,  0.1465, -0.1219,  0.0255,  0.0502,  0.0527, -0.0254,
1:         -0.0324,  0.0322, -0.0221,  0.0756, -0.0300, -0.1091, -0.0035, -0.0466,  0.0502,  0.0371,  0.0390, -0.0277,
1:          0.0768], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.2962, -0.3511, -0.3924, -0.4020, -0.4202, -0.4326, -0.4706, -0.5490, -0.5913, -0.2823,  1.5499,  3.0421,
1:          3.6015,  3.8641,  3.8698,  3.8571,  3.7992,  3.6790, -0.2827, -0.3601, -0.4052, -0.4143, -0.4339, -0.4436,
1:         -0.4836], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([ 0.1915,  0.2389,  0.2578,  0.2336,  0.1782,  0.1241,  0.1030,  0.1296,  0.1533,  0.1268,  0.0526,  0.0444,
1:          0.2047,  0.3404,  0.3318,  0.3204,  0.2892,  0.2232,  0.1895,  0.1526,  0.1408,  0.1117, -0.0209, -0.1302,
1:         -0.1286], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2434, -0.2434, -0.2387, -0.2306, -0.2364, -0.2260, -0.2190, -0.1273,  0.1326, -0.2434, -0.2434, -0.2387,
1:         -0.2132, -0.2376, -0.2213, -0.1737, -0.0739,  0.1477, -0.2434, -0.2434, -0.2434, -0.2120, -0.2352, -0.1877,
1:         -0.1494], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 21, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan, 0.4922,    nan,    nan, 0.4366,    nan, 0.4140,    nan,    nan, 0.3389,    nan,    nan,
1:            nan,    nan,    nan,    nan, 0.3024,    nan,    nan,    nan, 0.2803,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 21, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([ 0.0492,  0.0349,  0.0150, -0.0022, -0.0168, -0.0295, -0.0412, -0.0504, -0.0605, -0.0702, -0.0772, -0.0818,
1:         -0.0878, -0.0972, -0.1029, -0.1107, -0.1213, -0.1276,  0.0042, -0.0101, -0.0265, -0.0413, -0.0537, -0.0641,
1:         -0.0721], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.1382,  0.1145,  0.0920,  0.0695,  0.0458,  0.0249,  0.0049, -0.0106, -0.0210, -0.0290, -0.0314, -0.0305,
1:         -0.0305, -0.0333, -0.0433, -0.0562, -0.0738, -0.0901,  0.1458,  0.1256,  0.1030,  0.0816,  0.0574,  0.0342,
1:          0.0135], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.5144, -0.5182, -0.5099, -0.4996, -0.4831, -0.4658, -0.4575, -0.4561, -0.4614, -0.4738, -0.4865, -0.4996,
1:         -0.5061, -0.5130, -0.5163, -0.5203, -0.5276, -0.5355, -0.4944, -0.5009, -0.4997, -0.4901, -0.4763, -0.4635,
1:         -0.4568], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.8375, 0.7119, 0.6219, 0.6338, 0.6856, 0.8418, 1.1614, 1.4110, 1.5341, 1.4838, 1.2099, 0.8494, 0.6392, 0.7186,
1:         0.9092, 0.9326, 0.6886, 0.3303, 1.2247, 1.1848, 1.1007, 1.0329, 0.9883, 1.0816, 1.3978], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.6400, 0.6598, 0.6840, 0.7085, 0.7360, 0.7638, 0.7904, 0.8110, 0.8223, 0.8216, 0.8115, 0.7950, 0.7784, 0.7631,
1:         0.7563, 0.7559, 0.7641, 0.7784, 0.7967, 0.8139, 0.8318, 0.8502, 0.8676, 0.8818, 0.8840], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2255, -0.2307, -0.2378, -0.2435, -0.2445, -0.2432, -0.2381, -0.2364, -0.2301, -0.2304, -0.2381, -0.2405,
1:         -0.2461, -0.2435, -0.2444, -0.2382, -0.2366, -0.2316, -0.2392, -0.2419, -0.2446, -0.2434, -0.2436, -0.2425,
1:         -0.2363], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0155,  0.0002,  0.0061,  0.0143, -0.0341,  0.0039,  0.0129, -0.0362, -0.0405, -0.0080,  0.0289, -0.0166,
1:          0.0096,  0.0049, -0.0146, -0.0002, -0.0109,  0.0011, -0.0162, -0.0117,  0.0024,  0.0049,  0.0283, -0.0168,
1:         -0.0047], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 21 [1/5 (20%)]	Loss: 0.25542 : 0.19630 :: 0.02437 (1.74 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 21 [2/5 (40%)]	Loss: 0.27084 : 0.20035 :: 0.02417 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 21 [3/5 (60%)]	Loss: 0.20299 : 0.15165 :: 0.02395 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 21 [4/5 (80%)]	Loss: 0.27532 : 0.20044 :: 0.02331 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 21 : 0.19633397459983826
0: validation loss for velocity_u : 0.003913209307938814
0: validation loss for velocity_v : 0.005435164086520672
0: validation loss for specific_humidity : 0.006330837029963732
0: validation loss for velocity_z : 0.11748623102903366
0: validation loss for temperature : 0.01782672479748726
0: validation loss for total_precip : 0.21414852142333984
0: validation loss for t2m : 1.0091972351074219
1: 22 : 02:22:31 :: batch_size = 96, lr = 1.2205418857176618e-05
0: 22 : 02:22:31 :: batch_size = 96, lr = 1.2205418857176618e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 22, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 22, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.5428, 0.4608, 0.3820, 0.3130, 0.2591, 0.2235, 0.2062, 0.2052, 0.2185, 0.2423, 0.2698, 0.2924, 0.3045, 0.3042,
0:         0.2905, 0.2644, 0.2282, 0.1878, 0.5155, 0.4367, 0.3617, 0.2979, 0.2513, 0.2245, 0.2159], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.9032, 1.8285, 1.7620, 1.7039, 1.6535, 1.6090, 1.5675, 1.5253, 1.4798, 1.4287, 1.3722, 1.3138, 1.2589, 1.2134,
0:         1.1823, 1.1706, 1.1827, 1.2194, 1.8060, 1.7396, 1.6802, 1.6286, 1.5850, 1.5464, 1.5089], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6609, -0.5309, -0.4435, -0.3919, -0.4278, -0.5690, -0.7461, -0.8470, -0.8156, -0.6766, -0.4906, -0.3292,
0:         -0.2485, -0.2821, -0.4099, -0.5668, -0.6879, -0.7506, -0.6654, -0.6184, -0.5623, -0.5063, -0.5309, -0.6565,
0:         -0.7865], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([ 0.1969,  0.1077, -0.0681, -0.1597, -0.1845, -0.1969, -0.2440, -0.2588, -0.2588, -0.1127, -0.1969, -0.2217,
0:         -0.2539, -0.2563, -0.2588, -0.2588, -0.2588, -0.2588, -0.2142, -0.2588, -0.2588, -0.2588, -0.2588, -0.2588,
0:         -0.2588], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 22, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.6171,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,  0.0133,     nan,     nan,     nan,  0.3537,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 22, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.5176, -0.5543, -0.5980, -0.6425, -0.6852, -0.7223, -0.7525, -0.7723, -0.7801, -0.7815, -0.7775, -0.7728,
0:         -0.7728, -0.7792, -0.7936, -0.8184, -0.8489, -0.8804, -0.6126, -0.6535, -0.6975, -0.7372, -0.7709, -0.7966,
0:         -0.8143], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.4856, -0.3688, -0.2126, -0.0175,  0.1942,  0.3952,  0.5586,  0.6654,  0.7098,  0.6949,  0.6535,  0.6125,
0:          0.6085,  0.6632,  0.7802,  0.9389,  1.1079,  1.2652, -0.5791, -0.4778, -0.3258, -0.1279,  0.0946,  0.3163,
0:          0.5023], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.1130, -0.1512, -0.2158, -0.3053, -0.4062, -0.4955, -0.5488, -0.5416, -0.4655, -0.3171, -0.1132,  0.1005,
0:          0.2892,  0.4214,  0.4873,  0.4932,  0.4680,  0.4381, -0.0990, -0.1325, -0.1979, -0.2855, -0.3866, -0.4825,
0:         -0.5449], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.6121, -1.0069, -1.3556, -1.5980, -1.6307, -1.5048, -1.2791, -1.0674, -0.9874, -1.0645, -1.1371, -1.0976,
0:         -0.9660, -0.8483, -0.7496, -0.6314, -0.4830, -0.3454, -0.7419, -0.9696, -1.2275, -1.4900, -1.6128, -1.5703,
0:         -1.3924], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([ 0.0053, -0.0244, -0.0580, -0.0995, -0.1537, -0.2259, -0.3156, -0.4227, -0.5332, -0.6365, -0.7212, -0.7816,
0:         -0.8196, -0.8412, -0.8502, -0.8466, -0.8250, -0.7768, -0.7005, -0.5989, -0.4762, -0.3422, -0.2059, -0.0765,
0:          0.0330], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2577, -0.2692, -0.2733, -0.2705, -0.2655, -0.2383, -0.1982, -0.1497, -0.1042, -0.2594, -0.2723, -0.2735,
0:         -0.2704, -0.2607, -0.2334, -0.1846, -0.1362, -0.0832, -0.2589, -0.2645, -0.2688, -0.2643, -0.2522, -0.2206,
0:         -0.1766], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0067,  0.0109,  0.0040,  0.0057, -0.0179, -0.0076, -0.0081, -0.0151, -0.0210, -0.0006, -0.0010, -0.0234,
0:         -0.0069, -0.0005,  0.0034, -0.0018, -0.0120, -0.0348, -0.0287,  0.0382,  0.0050, -0.0122,  0.0003, -0.0116,
0:          0.0011], device='cuda:0', grad_fn=<SliceBackward0>)
1:      first 25 values: tensor([0.5428, 0.4608, 0.3820, 0.3130, 0.2591, 0.2235, 0.2062, 0.2052, 0.2185, 0.2423, 0.2698, 0.2924, 0.3045, 0.3042,
1:         0.2905, 0.2644, 0.2282, 0.1878, 0.5155, 0.4367, 0.3617, 0.2979, 0.2513, 0.2245, 0.2159], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.1180,  0.1305,  0.1647, -0.1012,  0.0421,  0.1044, -0.0126, -0.0266, -0.0655,  0.0071, -0.0255,  0.0389,
1:         -0.0401, -0.0306, -0.0479, -0.1487, -0.1443, -0.0848, -0.0195, -0.0748,  0.0915,  0.0138, -0.0237,  0.0924,
1:          0.0112], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.3142, 0.3169, 0.3369, 0.3420, 0.3341, 0.3136, 0.2955, 0.2910, 0.3139, 0.3445, 0.3787, 0.4455, 0.5046, 0.5533,
1:         0.5749, 0.5942, 0.6054, 0.6191, 0.2034, 0.1982, 0.2000, 0.1966, 0.1903, 0.1704, 0.1728], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.1951, -0.1617, -0.1374, -0.1210, -0.1084, -0.0954, -0.0797, -0.0613, -0.0402, -0.0171,  0.0058,  0.0253,
1:          0.0414,  0.0560,  0.0699,  0.0812,  0.0875,  0.0888,  0.0879,  0.0889,  0.0915,  0.0922,  0.0896,  0.0859,
1:          0.0866], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([ 0.1969,  0.1077, -0.0681, -0.1597, -0.1845, -0.1969, -0.2440, -0.2588, -0.2588, -0.1127, -0.1969, -0.2217,
1:         -0.2539, -0.2563, -0.2588, -0.2588, -0.2588, -0.2588, -0.2142, -0.2588, -0.2588, -0.2588, -0.2588, -0.2588,
1:         -0.2588], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 22, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -1.6231,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 22, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.4768, -0.5039, -0.5331, -0.5603, -0.5937, -0.6324, -0.6772, -0.7264, -0.7844, -0.8417, -0.8962, -0.9458,
1:         -0.9875, -1.0288, -1.0629, -1.0987, -1.1399, -1.1732, -0.5284, -0.5538, -0.5842, -0.6121, -0.6446, -0.6831,
1:         -0.7305], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.6063, -0.6200, -0.6554, -0.7102, -0.7906, -0.8892, -0.9971, -1.1115, -1.2199, -1.3244, -1.3997, -1.4409,
1:         -1.4351, -1.3705, -1.2433, -1.0739, -0.8822, -0.6981, -0.6276, -0.6404, -0.6739, -0.7353, -0.8211, -0.9210,
1:         -1.0300], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.5734, -0.4833, -0.3768, -0.2726, -0.1814, -0.1244, -0.1076, -0.1277, -0.1674, -0.2137, -0.2454, -0.2600,
1:         -0.2514, -0.2321, -0.2036, -0.1745, -0.1470, -0.1259, -0.5793, -0.4925, -0.3882, -0.2829, -0.1920, -0.1328,
1:         -0.1149], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.3308, -0.2847, -0.0603,  0.1078,  0.2232,  0.2232,  0.1211,  0.1479,  0.1627,  0.0246, -0.1689, -0.5646,
1:         -0.9874, -1.0939, -1.0061, -0.8562, -0.7196, -0.7338, -0.3689, -0.2727, -0.0221,  0.1125,  0.1537,  0.1056,
1:         -0.0337], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([ 0.0633,  0.0172, -0.0255, -0.0551, -0.0681, -0.0711, -0.0739, -0.0852, -0.0995, -0.1006, -0.0734, -0.0123,
1:          0.0701,  0.1578,  0.2194,  0.2468,  0.2373,  0.2065,  0.1731,  0.1509,  0.1486,  0.1655,  0.1912,  0.2098,
1:          0.2124], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2601, -0.2554, -0.2502, -0.2429, -0.2395, -0.2406, -0.2452, -0.2477, -0.2489, -0.2635, -0.2608, -0.2519,
1:         -0.2492, -0.2386, -0.2423, -0.2456, -0.2489, -0.2562, -0.2652, -0.2607, -0.2549, -0.2448, -0.2406, -0.2410,
1:         -0.2428], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0004,  0.0031, -0.0053,  0.0205, -0.0130,  0.0139, -0.0012, -0.0190, -0.0195, -0.0153,  0.0331, -0.0035,
1:         -0.0139,  0.0057,  0.0061,  0.0046,  0.0285,  0.0014, -0.0298,  0.0191, -0.0101,  0.0168,  0.0136, -0.0107,
1:          0.0123], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 22 [1/5 (20%)]	Loss: 0.24769 : 0.17652 :: 0.02175 (1.88 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 22 [2/5 (40%)]	Loss: 0.28813 : 0.20808 :: 0.02329 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 22 [3/5 (60%)]	Loss: 0.29490 : 0.21732 :: 0.02410 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 22 [4/5 (80%)]	Loss: 0.22246 : 0.18597 :: 0.02394 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 22 : 0.20205312967300415
0: validation loss for velocity_u : 0.003567580133676529
0: validation loss for velocity_v : 0.004967524204403162
0: validation loss for specific_humidity : 0.006279592867940664
0: validation loss for velocity_z : 0.11337760090827942
0: validation loss for temperature : 0.019070502370595932
0: validation loss for total_precip : 0.2406843900680542
0: validation loss for t2m : 1.0264246463775635
1: 23 : 02:28:45 :: batch_size = 96, lr = 1.1907725714318652e-05
0: 23 : 02:28:45 :: batch_size = 96, lr = 1.1907725714318652e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 23, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 23, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.5078, -1.5053, -1.5014, -1.4965, -1.4906, -1.4842, -1.4775, -1.4705, -1.4633, -1.4560, -1.4481, -1.4403,
1:         -1.4325, -1.4247, -1.4170, -1.4095, -1.4022, -1.3955, -1.5171, -1.5121, -1.5070, -1.5021, -1.4975, -1.4935,
1:         -1.4900], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.1152,  0.0950, -0.0628, -0.0882,  0.0048,  0.1054, -0.0635, -0.1043,  0.0827,  0.0018,  0.0867, -0.0447,
1:         -0.0456, -0.0541, -0.0249, -0.0243,  0.1303,  0.2001,  0.0089, -0.0754,  0.0162, -0.1197, -0.0015, -0.0610,
1:          0.2261], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.5962, -0.5892, -0.5858, -0.5844, -0.5777, -0.5708, -0.5636, -0.5603, -0.5607, -0.5563, -0.5504, -0.5474,
1:         -0.5455, -0.5477, -0.5499, -0.5510, -0.5545, -0.5595, -0.5923, -0.5893, -0.5862, -0.5853, -0.5845, -0.5883,
1:         -0.5892], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., 0., 0., 0., -0., -0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0., 0., 0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.5878, -0.6156, -0.6431, -0.6706, -0.6978, -0.7246, -0.7511, -0.7776, -0.8031, -0.8277, -0.8509, -0.8731,
1:         -0.8942, -0.9144, -0.9335, -0.9517, -0.9686, -0.9848, -1.0001, -1.0150, -1.0292, -1.0422, -1.0536, -1.0632,
1:         -1.0707], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.0411, -0.0080,  0.0079, -0.0068,  0.0214,  0.0398,  0.0349,  0.0141, -0.0105,  0.0202,  0.0337,  0.0472,
1:          0.0300,  0.0128, -0.0141, -0.0436, -0.0755, -0.1000,  0.0496,  0.0239, -0.0031, -0.0215, -0.0509, -0.0779,
1:         -0.1012], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 23, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan, 0.3296,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.3112,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 23, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-1.3582, -1.3515, -1.3468, -1.3417, -1.3363, -1.3323, -1.3218, -1.3113, -1.2958, -1.2784, -1.2579, -1.2426,
1:         -1.2290, -1.2164, -1.2061, -1.1980, -1.1942, -1.1904, -1.4749, -1.4657, -1.4538, -1.4411, -1.4271, -1.4167,
1:         -1.4000], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-1.6155, -1.6004, -1.5971, -1.6020, -1.6131, -1.6306, -1.6425, -1.6562, -1.6663, -1.6745, -1.6804, -1.6824,
1:         -1.6831, -1.6820, -1.6776, -1.6719, -1.6651, -1.6547, -1.6317, -1.6176, -1.6108, -1.6113, -1.6154, -1.6236,
1:         -1.6317], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6025, -0.5998, -0.5964, -0.5934, -0.5901, -0.5866, -0.5834, -0.5809, -0.5792, -0.5781, -0.5774, -0.5770,
1:         -0.5763, -0.5770, -0.5765, -0.5761, -0.5760, -0.5743, -0.6066, -0.6052, -0.6019, -0.5987, -0.5952, -0.5915,
1:         -0.5865], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.2855, -0.2548, -0.2140, -0.1799, -0.1306, -0.0919, -0.0376,  0.0341,  0.0697,  0.0859,  0.1047,  0.1257,
1:          0.1364,  0.1473,  0.1724,  0.1902,  0.1842,  0.1469, -0.0815, -0.0299,  0.0061,  0.0053,  0.0123,  0.0100,
1:          0.0203], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.4594, 0.4628, 0.4708, 0.4775, 0.4833, 0.4866, 0.4882, 0.4880, 0.4872, 0.4868, 0.4876, 0.4908, 0.4977, 0.5061,
1:         0.5142, 0.5218, 0.5261, 0.5290, 0.5321, 0.5353, 0.5401, 0.5480, 0.5564, 0.5665, 0.5763], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([0.5882, 0.6008, 0.6269, 0.6253, 0.6248, 0.6242, 0.6111, 0.5995, 0.5789, 0.6826, 0.6893, 0.6871, 0.6727, 0.6540,
1:         0.6363, 0.6369, 0.6245, 0.6168, 0.7027, 0.7033, 0.6775, 0.6583, 0.6403, 0.6255, 0.6126], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0130,  0.0118,  0.0042,  0.0222,  0.0004,  0.0198,  0.0120, -0.0066, -0.0119,  0.0106,  0.0318,  0.0201,
1:         -0.0107, -0.0057,  0.0029, -0.0037,  0.0312,  0.0013, -0.0082,  0.0256,  0.0162,  0.0139,  0.0282,  0.0040,
1:          0.0197], device='cuda:0', grad_fn=<SliceBackward0>)
0:      first 25 values: tensor([-1.5078, -1.5053, -1.5014, -1.4965, -1.4906, -1.4842, -1.4775, -1.4705, -1.4633, -1.4560, -1.4481, -1.4403,
0:         -1.4325, -1.4247, -1.4170, -1.4095, -1.4022, -1.3955, -1.5171, -1.5121, -1.5070, -1.5021, -1.4975, -1.4935,
0:         -1.4900], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.3430, -0.3545, -0.3689, -0.3864, -0.4068, -0.4298, -0.4555, -0.4831, -0.5126, -0.5433, -0.5742, -0.6045,
0:         -0.6338, -0.6618, -0.6887, -0.7139, -0.7380, -0.7602, -0.3475, -0.3517, -0.3604, -0.3735, -0.3913, -0.4131,
0:         -0.4385], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.4676,  0.4342,  0.3976,  0.3654,  0.3332,  0.2965,  0.2477,  0.1910,  0.1388,  0.0999,  0.0733,  0.0500,
0:          0.0233, -0.0056, -0.0267, -0.0311, -0.0222, -0.0089,  0.3265,  0.2876,  0.2510,  0.2243,  0.2055,  0.1844,
0:          0.1555], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.0411, -0.0080,  0.0079, -0.0068,  0.0214,  0.0398,  0.0349,  0.0141, -0.0105,  0.0202,  0.0337,  0.0472,
0:          0.0300,  0.0128, -0.0141, -0.0436, -0.0755, -0.1000,  0.0496,  0.0239, -0.0031, -0.0215, -0.0509, -0.0779,
0:         -0.1012], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 23, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan, 1.0502,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 1.0124,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 23, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-1.0959, -1.0748, -1.0513, -1.0277, -0.9970, -0.9617, -0.9238, -0.8847, -0.8438, -0.8044, -0.7646, -0.7229,
0:         -0.6827, -0.6397, -0.5981, -0.5583, -0.5196, -0.4903, -1.0138, -0.9865, -0.9575, -0.9280, -0.8943, -0.8587,
0:         -0.8195], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([ 0.0202,  0.0238,  0.0290,  0.0372,  0.0434,  0.0509,  0.0548,  0.0574,  0.0615,  0.0670,  0.0724,  0.0779,
0:          0.0785,  0.0785,  0.0769,  0.0769,  0.0773,  0.0770, -0.0301, -0.0243, -0.0177, -0.0106, -0.0028,  0.0018,
0:          0.0036], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.2306, -0.2299, -0.2281, -0.2265, -0.2230, -0.2205, -0.2187, -0.2164, -0.2160, -0.2156, -0.2155, -0.2156,
0:         -0.2164, -0.2180, -0.2189, -0.2216, -0.2220, -0.2224, -0.2613, -0.2611, -0.2600, -0.2579, -0.2558, -0.2533,
0:         -0.2522], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.3152, -0.3225, -0.3501, -0.3635, -0.3474, -0.3302, -0.3040, -0.2710, -0.2671, -0.2755, -0.2653, -0.2674,
0:         -0.2964, -0.3201, -0.3335, -0.3540, -0.3500, -0.3357, -0.4010, -0.4032, -0.4173, -0.4100, -0.3685, -0.3391,
0:         -0.3028], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.6030, 0.6158, 0.6319, 0.6470, 0.6583, 0.6655, 0.6702, 0.6733, 0.6749, 0.6759, 0.6765, 0.6760, 0.6749, 0.6716,
0:         0.6652, 0.6558, 0.6442, 0.6331, 0.6217, 0.6095, 0.5948, 0.5795, 0.5619, 0.5439, 0.5257], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2522, -0.2551, -0.2528, -0.2567, -0.2598, -0.2599, -0.2602, -0.2587, -0.2531, -0.2511, -0.2552, -0.2545,
0:         -0.2590, -0.2591, -0.2611, -0.2606, -0.2600, -0.2602, -0.2515, -0.2547, -0.2560, -0.2580, -0.2596, -0.2587,
0:         -0.2612], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0204, -0.0096,  0.0041,  0.0159, -0.0115, -0.0029,  0.0144,  0.0154, -0.0208,  0.0038,  0.0189, -0.0058,
0:          0.0177,  0.0181,  0.0377,  0.0125, -0.0094, -0.0153, -0.0077,  0.0439,  0.0051,  0.0168,  0.0168,  0.0122,
0:          0.0239], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 23 [1/5 (20%)]	Loss: 0.27393 : 0.19410 :: 0.02480 (1.93 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 23 [2/5 (40%)]	Loss: 0.26494 : 0.22277 :: 0.02378 (8.46 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 23 [3/5 (60%)]	Loss: 0.27337 : 0.20054 :: 0.02532 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 23 [4/5 (80%)]	Loss: 0.24982 : 0.19224 :: 0.02235 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 23 : 0.2127038836479187
0: validation loss for velocity_u : 0.003845399245619774
0: validation loss for velocity_v : 0.005351527594029903
0: validation loss for specific_humidity : 0.006583008915185928
0: validation loss for velocity_z : 0.12253693491220474
0: validation loss for temperature : 0.02035655453801155
0: validation loss for total_precip : 0.33441007137298584
0: validation loss for t2m : 0.9958438873291016
1: 24 : 02:34:41 :: batch_size = 96, lr = 1.1617293379823076e-05
0: 24 : 02:34:41 :: batch_size = 96, lr = 1.1617293379823076e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 24, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([2.8915, 2.8525, 2.8253, 2.8104, 2.8062, 2.8091, 2.8154, 2.8207, 2.8220, 2.8175, 2.8065, 2.7884, 2.7635, 2.7325,
1:         2.6966, 2.6560, 2.6099, 2.5581, 2.9146, 2.8971, 2.8864, 2.8818, 2.8815, 2.8835, 2.8856], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.2289,  0.2576,  0.0234,  0.0784, -0.1510, -0.2144, -0.0227, -0.0461, -0.0192,  0.0789, -0.0357, -0.0518,
1:          0.0527, -0.0066, -0.1900, -0.1304,  0.1217,  0.0456,  0.1038, -0.0296,  0.0841, -0.0764,  0.0176, -0.0966,
1:          0.1609], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.7760, 0.7564, 0.7440, 0.7341, 0.7244, 0.7233, 0.7230, 0.7253, 0.7275, 0.7253, 0.7203, 0.7103, 0.7009, 0.6937,
1:         0.6913, 0.6836, 0.6907, 0.7020, 0.7357, 0.7315, 0.7271, 0.7172, 0.7081, 0.7072, 0.7045], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([2.5129, 2.5289, 2.5475, 2.5655, 2.5809, 2.5928, 2.6018, 2.6106, 2.6226, 2.6394, 2.6598, 2.6812, 2.7007, 2.7174,
1:         2.7320, 2.7445, 2.7544, 2.7610, 2.7645, 2.7639, 2.7580, 2.7455, 2.7268, 2.7054, 2.6853], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([0.6292, 0.6358, 0.6625, 0.7048, 0.7337, 0.7581, 0.7848, 0.7826, 0.7826, 0.7826, 0.8315, 0.8805, 0.9361, 0.9894,
1:         1.0295, 1.0606, 1.0539, 1.0361, 0.8627, 0.9027, 0.9427, 0.9983, 1.0539, 1.1140, 1.1762], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 24, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan, -1.9998, -2.0157,     nan,     nan,     nan,     nan,
1:         -1.9834,     nan,     nan,     nan,     nan, -1.8360,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 24, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([2.1173, 2.0509, 1.9831, 1.9164, 1.8599, 1.8118, 1.7755, 1.7493, 1.7164, 1.6788, 1.6397, 1.5946, 1.5546, 1.5223,
1:         1.4983, 1.4785, 1.4550, 1.4315, 2.1514, 2.0742, 2.0014, 1.9301, 1.8703, 1.8191, 1.7841], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.2438,  0.2544,  0.2647,  0.2747,  0.2776,  0.2726,  0.2555,  0.2283,  0.1935,  0.1557,  0.1163,  0.0792,
1:          0.0442,  0.0149, -0.0090, -0.0227, -0.0293, -0.0252,  0.2237,  0.2315,  0.2395,  0.2436,  0.2453,  0.2364,
1:          0.2176], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6061, -0.6068, -0.6049, -0.6050, -0.6049, -0.6035, -0.6031, -0.6018, -0.6005, -0.5977, -0.5943, -0.5908,
1:         -0.5878, -0.5876, -0.5880, -0.5898, -0.5902, -0.5906, -0.5951, -0.5961, -0.5961, -0.5958, -0.5953, -0.5928,
1:         -0.5921], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 2.0364e-01,  1.7290e-01,  1.0538e-01,  7.4740e-02,  5.7002e-02,  3.4769e-02, -1.4158e-04, -4.1547e-02,
1:         -7.2463e-02, -1.4268e-01, -2.3815e-01, -3.2091e-01, -4.0000e-01, -4.9436e-01, -6.1346e-01, -7.2111e-01,
1:         -8.2688e-01, -9.1288e-01,  2.0255e-01,  1.7914e-01,  1.3596e-01,  1.1259e-01,  9.4086e-02,  8.4308e-02,
1:          5.1071e-02], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.8756, -0.8542, -0.8335, -0.8167, -0.8034, -0.7902, -0.7746, -0.7572, -0.7389, -0.7196, -0.7003, -0.6831,
1:         -0.6684, -0.6576, -0.6471, -0.6381, -0.6303, -0.6225, -0.6139, -0.6071, -0.6012, -0.5929, -0.5837, -0.5727,
1:         -0.5599], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([0.7788, 0.8127, 0.8695, 0.8838, 0.8987, 0.9081, 0.9202, 0.9510, 0.9650, 0.9025, 0.9361, 0.9775, 1.0123, 1.0412,
1:         1.0756, 1.1272, 1.1586, 1.1733, 1.0443, 1.0932, 1.1507, 1.1900, 1.2362, 1.2945, 1.3519], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([0.0316, 0.0190, 0.0248, 0.0332, 0.0187, 0.0320, 0.0433, 0.0166, 0.0135, 0.0093, 0.0495, 0.0247, 0.0476, 0.0330,
1:         0.0368, 0.0168, 0.0438, 0.0222, 0.0137, 0.0403, 0.0246, 0.0215, 0.0469, 0.0378, 0.0311], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 24, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.3334,  0.2379,  0.1631,  0.1281,  0.1276,  0.1679,  0.2699,  0.3844,  0.4247,  0.3804,  0.2992,  0.2199,
0:          0.1522,  0.0869,  0.0275, -0.0271, -0.0854, -0.1067,  0.3222,  0.2173,  0.1387,  0.0932,  0.0826,  0.1132,
0:          0.2133], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.1290, 0.1496, 0.1642, 0.1668, 0.1957, 0.2635, 0.3413, 0.3977, 0.4244, 0.4733, 0.5749, 0.6408, 0.6070, 0.5377,
0:         0.5020, 0.5314, 0.6349, 0.7777, 0.0018, 0.0120, 0.0365, 0.0620, 0.0977, 0.1715, 0.2807], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0434,  0.0230,  0.1115,  0.1911,  0.4079,  0.9411,  1.3614,  1.7397,  1.8924,  1.3481,  0.6933, -0.2690,
0:         -1.6826, -2.2070, -2.0477, -1.7180, -0.7911, -0.0832, -0.3420, -0.3155, -0.2026,  0.0142,  0.0628,  0.4101,
0:          1.0296], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489,
0:         -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489, -0.2489,
0:         -0.2489], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 24, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan, -0.9288,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.9827, -0.8406,     nan,     nan,     nan,     nan,     nan, -0.2746,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 24, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.5063, -0.5335, -0.5534, -0.5656, -0.5700, -0.5798, -0.5939, -0.6167, -0.6436, -0.6694, -0.6852, -0.6845,
0:         -0.6673, -0.6362, -0.5989, -0.5588, -0.5207, -0.4849, -0.6270, -0.6593, -0.6774, -0.6841, -0.6831, -0.6845,
0:         -0.6902], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.0161, -0.0547, -0.1128, -0.1838, -0.2559, -0.3160, -0.3498, -0.3587, -0.3443, -0.3170, -0.2867, -0.2640,
0:         -0.2500, -0.2450, -0.2416, -0.2308, -0.2082, -0.1735, -0.0629, -0.1021, -0.1667, -0.2456, -0.3233, -0.3838,
0:         -0.4142], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6406, -0.6222, -0.6023, -0.5845, -0.5689, -0.5598, -0.5575, -0.5625, -0.5746, -0.5885, -0.6032, -0.6159,
0:         -0.6240, -0.6275, -0.6242, -0.6148, -0.6006, -0.5812, -0.6826, -0.6760, -0.6696, -0.6633, -0.6559, -0.6505,
0:         -0.6458], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.4359,  0.3017,  0.2564,  0.2117,  0.6735,  0.8286,  0.1720, -0.2296,  0.0097,  0.2112,  0.1674,  0.1325,
0:          0.1654,  0.5586,  0.8370,  0.6067,  0.4830,  0.3652,  0.5211,  0.6451,  0.5818,  0.5756,  1.0697,  1.0417,
0:          0.3721], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-1.0235, -1.0791, -1.1337, -1.1865, -1.2342, -1.2651, -1.2789, -1.2816, -1.2816, -1.2893, -1.3097, -1.3397,
0:         -1.3706, -1.3980, -1.4110, -1.4048, -1.3793, -1.3359, -1.2859, -1.2402, -1.2003, -1.1634, -1.1288, -1.0916,
0:         -1.0516], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2579, -0.2590, -0.2564, -0.2585, -0.2633, -0.2629, -0.2626, -0.2629, -0.2623, -0.2543, -0.2596, -0.2579,
0:         -0.2613, -0.2574, -0.2615, -0.2630, -0.2616, -0.2639, -0.2543, -0.2566, -0.2548, -0.2589, -0.2555, -0.2567,
0:         -0.2586], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([0.0102, 0.0231, 0.0346, 0.0296, 0.0295, 0.0315, 0.0196, 0.0148, 0.0121, 0.0263, 0.0356, 0.0103, 0.0300, 0.0005,
0:         0.0382, 0.0313, 0.0141, 0.0051, 0.0193, 0.0711, 0.0253, 0.0343, 0.0330, 0.0262, 0.0379], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 24 [1/5 (20%)]	Loss: 0.25915 : 0.21322 :: 0.02329 (1.69 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 24 [2/5 (40%)]	Loss: 0.29424 : 0.21733 :: 0.02297 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 24 [3/5 (60%)]	Loss: 0.26819 : 0.22825 :: 0.02395 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 24 [4/5 (80%)]	Loss: 0.25961 : 0.19642 :: 0.02328 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 24 : 0.20241032540798187
0: validation loss for velocity_u : 0.0036672288551926613
0: validation loss for velocity_v : 0.005214575678110123
0: validation loss for specific_humidity : 0.005839681252837181
0: validation loss for velocity_z : 0.11243601143360138
0: validation loss for temperature : 0.018028734251856804
0: validation loss for total_precip : 0.23726122081279755
0: validation loss for t2m : 1.034424901008606
1: 25 : 02:40:47 :: batch_size = 96, lr = 1.1333944760803001e-05
0: 25 : 02:40:47 :: batch_size = 96, lr = 1.1333944760803001e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 25, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1: Created sparse mask for t2m with 10.0% data retained
0:      first 25 values: tensor([0.2971, 0.2883, 0.2873, 0.2863, 0.2594, 0.2193, 0.2019, 0.2093, 0.2218, 0.2345, 0.2504, 0.2673, 0.2821, 0.2963,
0:         0.3115, 0.3274, 0.3419, 0.3533, 0.2102, 0.1919, 0.1828, 0.1801, 0.1589, 0.1295, 0.1230], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.5164, 1.4233, 1.3356, 1.2553, 1.1824, 1.1124, 1.0456, 0.9853, 0.9306, 0.8791, 0.8293, 0.7786, 0.7312, 0.6879,
0:         0.6418, 0.5923, 0.5466, 0.5069, 1.5095, 1.4201, 1.3359, 1.2691, 1.2165, 1.1598, 1.0965], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.1061, -0.9343, -0.4947, -0.5207, -1.0044, -1.1366, -0.9558, -0.9976, -0.8880, -0.3308,  0.1088,  0.2659,
0:          0.3654,  0.2422, -0.0110, -0.0076,  0.1371,  0.2173, -1.2915, -1.1762, -0.6992, -0.5975, -0.9343, -0.9852,
0:         -0.7162], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1950, -0.1573, -0.1444, -0.2044, -0.2480, -0.2468, -0.2468, -0.2480, -0.2433, -0.1844, -0.1514, -0.1620,
0:         -0.2209, -0.2468, -0.2457, -0.2468, -0.2480, -0.2433, -0.1679, -0.1361, -0.1927, -0.2174, -0.2433, -0.2468,
0:         -0.2480], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 25, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan, -1.1770,     nan,     nan,     nan,     nan,     nan, -1.1430,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -1.0622,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 25, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.1976, 0.2158, 0.2318, 0.2492, 0.2662, 0.2839, 0.3023, 0.3225, 0.3449, 0.3709, 0.4024, 0.4403, 0.4825, 0.5238,
0:         0.5641, 0.5949, 0.6198, 0.6390, 0.1484, 0.1625, 0.1724, 0.1848, 0.1994, 0.2174, 0.2352], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.4285, -0.3898, -0.3393, -0.2806, -0.2127, -0.1373, -0.0570,  0.0262,  0.1091,  0.1881,  0.2594,  0.3242,
0:          0.3823,  0.4376,  0.4883,  0.5395,  0.5873,  0.6318, -0.3731, -0.3260, -0.2675, -0.2008, -0.1257, -0.0485,
0:          0.0346], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([0.1344, 0.1803, 0.2283, 0.2755, 0.3238, 0.3822, 0.4512, 0.5217, 0.5904, 0.6550, 0.7032, 0.7368, 0.7539, 0.7561,
0:         0.7464, 0.7301, 0.7151, 0.7088, 0.1478, 0.2032, 0.2580, 0.3065, 0.3570, 0.4128, 0.4749], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.1916,  0.1966,  0.2680,  0.2798,  0.0984, -0.3618, -0.7747, -0.8187, -0.6631, -0.5656, -0.5436, -0.4987,
0:         -0.4788, -0.4566, -0.3819, -0.3062, -0.1877, -0.0670,  0.5347,  0.3422,  0.2114,  0.1500,  0.0371, -0.3424,
0:         -0.7434], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.4215, 1.5196, 1.6268, 1.7277, 1.8085, 1.8679, 1.9031, 1.9217, 1.9366, 1.9544, 1.9803, 2.0142, 2.0537, 2.0893,
0:         2.1223, 2.1464, 2.1627, 2.1681, 2.1626, 2.1436, 2.1132, 2.0734, 2.0283, 1.9917, 1.9643], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2581, -0.2572, -0.2559, -0.2566, -0.2562, -0.2555, -0.2568, -0.2554, -0.2517, -0.2567, -0.2573, -0.2557,
0:         -0.2550, -0.2491, -0.2539, -0.2557, -0.2562, -0.2598, -0.2521, -0.2536, -0.2537, -0.2525, -0.2497, -0.2510,
0:         -0.2549], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0348,  0.0155,  0.0409,  0.0444,  0.0207,  0.0366,  0.0283,  0.0290,  0.0295,  0.0291,  0.0401,  0.0265,
0:          0.0225,  0.0228,  0.0312,  0.0328,  0.0060,  0.0004, -0.0066,  0.0616,  0.0307,  0.0119,  0.0157,  0.0214,
0:          0.0321], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 25, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.2971, 0.2883, 0.2873, 0.2863, 0.2594, 0.2193, 0.2019, 0.2093, 0.2218, 0.2345, 0.2504, 0.2673, 0.2821, 0.2963,
1:         0.3115, 0.3274, 0.3419, 0.3533, 0.2102, 0.1919, 0.1828, 0.1801, 0.1589, 0.1295, 0.1230], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.1856,  0.0095, -0.1428, -0.0262, -0.0297, -0.0246, -0.0380,  0.1195,  0.0346, -0.0075,  0.0727, -0.0096,
1:         -0.0316,  0.0099,  0.0840, -0.0968,  0.1570, -0.1077,  0.1822,  0.1120, -0.1577,  0.3294, -0.1795,  0.1615,
1:          0.0430], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.7985, 1.7379, 1.7024, 1.6882, 1.6744, 1.6447, 1.5803, 1.5189, 1.4157, 1.3223, 1.2154, 1.1537, 1.1100, 1.0440,
1:         0.9933, 0.9558, 0.9303, 0.9114, 1.8398, 1.7677, 1.7191, 1.6801, 1.6153, 1.5739, 1.4675], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.7320, 0.7514, 0.7559, 0.7587, 0.7596, 0.7476, 0.7334, 0.7297, 0.7195, 0.6973, 0.6850, 0.6857, 0.6879, 0.6949,
1:         0.7031, 0.7055, 0.7161, 0.7433, 0.7814, 0.8289, 0.8820, 0.9306, 0.9767, 1.0227, 1.0658], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1950, -0.1573, -0.1444, -0.2044, -0.2480, -0.2468, -0.2468, -0.2480, -0.2433, -0.1844, -0.1514, -0.1620,
1:         -0.2209, -0.2468, -0.2457, -0.2468, -0.2480, -0.2433, -0.1679, -0.1361, -0.1927, -0.2174, -0.2433, -0.2468,
1:         -0.2480], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 25, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan, -0.2021,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:         -0.5103,     nan,     nan,     nan,     nan, -0.0929,     nan,     nan,     nan, -0.2520, -0.3640,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 25, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.4296, 0.4332, 0.4329, 0.4283, 0.4233, 0.4172, 0.4108, 0.4040, 0.3942, 0.3842, 0.3767, 0.3741, 0.3748, 0.3763,
1:         0.3778, 0.3769, 0.3745, 0.3773, 0.3495, 0.3595, 0.3619, 0.3588, 0.3530, 0.3468, 0.3392], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.9693, 0.9687, 0.9587, 0.9447, 0.9314, 0.9248, 0.9262, 0.9363, 0.9561, 0.9714, 0.9805, 0.9734, 0.9499, 0.9159,
1:         0.8755, 0.8403, 0.8117, 0.7979, 0.9847, 0.9886, 0.9849, 0.9761, 0.9688, 0.9599, 0.9575], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([0.9198, 0.9341, 0.9411, 0.9453, 0.9559, 0.9783, 0.9939, 1.0092, 1.0069, 0.9885, 0.9496, 0.8911, 0.8144, 0.7128,
1:         0.5904, 0.4488, 0.3046, 0.1836, 0.9704, 0.9833, 0.9914, 0.9988, 1.0078, 1.0229, 1.0291], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.7551, 0.7336, 0.6281, 0.5033, 0.3532, 0.2074, 0.1605, 0.1887, 0.2737, 0.4149, 0.5234, 0.5887, 0.6566, 0.6843,
1:         0.6453, 0.6280, 0.6273, 0.5506, 0.7887, 0.7905, 0.7290, 0.6144, 0.4709, 0.3279, 0.2429], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.5171, -0.4158, -0.3228, -0.2522, -0.2029, -0.1666, -0.1391, -0.1168, -0.0945, -0.0687, -0.0291,  0.0320,
1:          0.1131,  0.2008,  0.2836,  0.3486,  0.3905,  0.4173,  0.4449,  0.4780,  0.5288,  0.5995,  0.6908,  0.8025,
1:          0.9284], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2428, -0.2457, -0.2453, -0.2464, -0.2449, -0.2436, -0.2453, -0.2429, -0.2386, -0.2469, -0.2495, -0.2509,
1:         -0.2489, -0.2476, -0.2459, -0.2466, -0.2455, -0.2487, -0.2519, -0.2517, -0.2528, -0.2524, -0.2491, -0.2496,
1:         -0.2492], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([0.0423, 0.0261, 0.0157, 0.0436, 0.0419, 0.0541, 0.0508, 0.0167, 0.0224, 0.0153, 0.0424, 0.0203, 0.0358, 0.0210,
1:         0.0380, 0.0165, 0.0589, 0.0296, 0.0106, 0.0338, 0.0248, 0.0529, 0.0294, 0.0324, 0.0204], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 25 [1/5 (20%)]	Loss: 0.24186 : 0.18013 :: 0.02352 (1.86 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 25 [2/5 (40%)]	Loss: 0.20930 : 0.16711 :: 0.02410 (8.46 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 25 [3/5 (60%)]	Loss: 0.29025 : 0.22046 :: 0.02391 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 25 [4/5 (80%)]	Loss: 0.25500 : 0.19488 :: 0.02338 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 25 : 0.20026928186416626
0: validation loss for velocity_u : 0.003321954282000661
0: validation loss for velocity_v : 0.004577961750328541
0: validation loss for specific_humidity : 0.006150002591311932
0: validation loss for velocity_z : 0.09789703041315079
0: validation loss for temperature : 0.01952361688017845
0: validation loss for total_precip : 0.2335388958454132
0: validation loss for t2m : 1.0368753671646118
1: 26 : 02:46:45 :: batch_size = 96, lr = 1.1057507083710246e-05
0: 26 : 02:46:45 :: batch_size = 96, lr = 1.1057507083710246e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 26, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 26, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.2420,  0.2233,  0.1976,  0.1635,  0.1208,  0.0710,  0.0155, -0.0445, -0.1062, -0.1665, -0.2220, -0.2706,
0:         -0.3130, -0.3508, -0.3854, -0.4165, -0.4431, -0.4634,  0.3295,  0.3166,  0.2979,  0.2715,  0.2369,  0.1949,
0:          0.1470], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.0278,  0.1210,  0.2151,  0.3093,  0.4021,  0.4913,  0.5761,  0.6562,  0.7322,  0.8060,  0.8800,  0.9558,
0:          1.0340,  1.1133,  1.1913,  1.2653,  1.3322,  1.3911, -0.0704,  0.0199,  0.1120,  0.2054,  0.2990,  0.3917,
0:          0.4827], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.5864,  0.3689,  0.1492, -0.0017, -0.0350,  0.0604,  0.2424,  0.4421,  0.5930,  0.6596,  0.6507,  0.5975,
0:          0.5309,  0.4710,  0.4443,  0.4687,  0.5331,  0.6108,  0.7905,  0.5975,  0.3644,  0.1581,  0.0382,  0.0360,
0:          0.1381], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2427, -0.2427, -0.2449, -0.2427, -0.2393, -0.2236, -0.2112, -0.2011, -0.1944, -0.2427, -0.2427, -0.2438,
0:         -0.2427, -0.2427, -0.2337, -0.2213, -0.2112, -0.2011, -0.2393, -0.2393, -0.2393, -0.2427, -0.2415, -0.2337,
0:         -0.2292], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 26, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.0919,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 26, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.5967, 0.5661, 0.5381, 0.5126, 0.4910, 0.4782, 0.4717, 0.4708, 0.4730, 0.4817, 0.4923, 0.5043, 0.5198, 0.5332,
0:         0.5469, 0.5598, 0.5705, 0.5774, 0.6642, 0.6332, 0.6030, 0.5783, 0.5585, 0.5437, 0.5344], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-2.2594, -2.2184, -2.1775, -2.1358, -2.0940, -2.0530, -2.0125, -1.9681, -1.9167, -1.8578, -1.7935, -1.7247,
0:         -1.6555, -1.5866, -1.5199, -1.4494, -1.3767, -1.3008, -2.2851, -2.2352, -2.1841, -2.1322, -2.0822, -2.0363,
0:         -1.9910], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.4915, -0.4946, -0.4957, -0.4965, -0.4997, -0.5021, -0.5028, -0.5036, -0.5034, -0.5031, -0.5040, -0.5058,
0:         -0.5059, -0.5086, -0.5089, -0.5106, -0.5131, -0.5160, -0.5013, -0.5026, -0.5036, -0.5047, -0.5073, -0.5085,
0:         -0.5123], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.5377,  0.4866,  0.3647,  0.1827,  0.0191, -0.1148, -0.2003, -0.2432, -0.2745, -0.2913, -0.2954, -0.2889,
0:         -0.2859, -0.2766, -0.2887, -0.3390, -0.3726, -0.3895,  0.6495,  0.5503,  0.3733,  0.1555, -0.0208, -0.1654,
0:         -0.2706], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.9246, 1.9363, 1.9518, 1.9661, 1.9747, 1.9777, 1.9766, 1.9741, 1.9711, 1.9669, 1.9615, 1.9550, 1.9500, 1.9441,
0:         1.9421, 1.9411, 1.9449, 1.9487, 1.9519, 1.9548, 1.9545, 1.9547, 1.9502, 1.9429, 1.9382], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2492, -0.2529, -0.2489, -0.2480, -0.2472, -0.2448, -0.2420, -0.2368, -0.2333, -0.2526, -0.2542, -0.2510,
0:         -0.2515, -0.2439, -0.2441, -0.2419, -0.2392, -0.2400, -0.2551, -0.2548, -0.2565, -0.2511, -0.2495, -0.2465,
0:         -0.2442], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0301,  0.0311,  0.0385,  0.0336,  0.0358,  0.0259,  0.0375,  0.0195,  0.0341,  0.0291,  0.0379,  0.0164,
0:          0.0214,  0.0030,  0.0311,  0.0399,  0.0250, -0.0120, -0.0079,  0.0453,  0.0513,  0.0083,  0.0194,  0.0211,
0:          0.0270], device='cuda:0', grad_fn=<SliceBackward0>)
1:      first 25 values: tensor([ 0.2420,  0.2233,  0.1976,  0.1635,  0.1208,  0.0710,  0.0155, -0.0445, -0.1062, -0.1665, -0.2220, -0.2706,
1:         -0.3130, -0.3508, -0.3854, -0.4165, -0.4431, -0.4634,  0.3295,  0.3166,  0.2979,  0.2715,  0.2369,  0.1949,
1:          0.1470], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0395,  0.0660,  0.0177,  0.1886, -0.0803,  0.2189,  0.0688, -0.0413, -0.2008,  0.1478, -0.0512, -0.0314,
1:          0.1012,  0.0246, -0.0397, -0.0279,  0.1043, -0.0224, -0.1460,  0.0800, -0.0085,  0.0815, -0.1442,  0.0968,
1:         -0.0815], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.8046, -0.8082, -0.8113, -0.8160, -0.8200, -0.8233, -0.8273, -0.8300, -0.8321, -0.8330, -0.8343, -0.8347,
1:         -0.8348, -0.8337, -0.8331, -0.8310, -0.8281, -0.8238, -0.7998, -0.8017, -0.8048, -0.8095, -0.8140, -0.8189,
1:         -0.8229], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.9469, 1.9580, 1.9691, 1.9798, 1.9893, 1.9975, 2.0037, 2.0077, 2.0097, 2.0094, 2.0076, 2.0050, 2.0028, 2.0019,
1:         2.0027, 2.0046, 2.0071, 2.0095, 2.0113, 2.0118, 2.0107, 2.0073, 2.0020, 1.9942, 1.9843], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2427, -0.2427, -0.2449, -0.2427, -0.2393, -0.2236, -0.2112, -0.2011, -0.1944, -0.2427, -0.2427, -0.2438,
1:         -0.2427, -0.2427, -0.2337, -0.2213, -0.2112, -0.2011, -0.2393, -0.2393, -0.2393, -0.2427, -0.2415, -0.2337,
1:         -0.2292], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 26, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 26, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.5134, -0.5270, -0.5403, -0.5527, -0.5637, -0.5763, -0.5914, -0.6107, -0.6375, -0.6638, -0.6909, -0.7139,
1:         -0.7320, -0.7468, -0.7553, -0.7640, -0.7769, -0.7919, -0.4538, -0.4665, -0.4806, -0.4941, -0.5063, -0.5205,
1:         -0.5371], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.8246, -0.8016, -0.7885, -0.7819, -0.7717, -0.7581, -0.7384, -0.7107, -0.6782, -0.6424, -0.6035, -0.5588,
1:         -0.5112, -0.4600, -0.4013, -0.3398, -0.2736, -0.1992, -0.8579, -0.8371, -0.8217, -0.8109, -0.7971, -0.7801,
1:         -0.7594], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.8684, -0.8674, -0.8612, -0.8564, -0.8536, -0.8509, -0.8499, -0.8470, -0.8418, -0.8355, -0.8310, -0.8279,
1:         -0.8257, -0.8239, -0.8214, -0.8172, -0.8099, -0.8013, -0.8607, -0.8619, -0.8581, -0.8530, -0.8482, -0.8476,
1:         -0.8488], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.1313, -0.2410, -0.3028, -0.3145, -0.2106, -0.0326,  0.1690,  0.3751,  0.5010,  0.5618,  0.5929,  0.5563,
1:          0.4772,  0.3803,  0.2831,  0.2005,  0.1147,  0.0480, -0.0712, -0.1824, -0.2515, -0.2631, -0.1589,  0.0065,
1:          0.1814], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.8159, 1.8212, 1.8240, 1.8238, 1.8214, 1.8204, 1.8212, 1.8240, 1.8264, 1.8271, 1.8258, 1.8245, 1.8275, 1.8314,
1:         1.8375, 1.8397, 1.8391, 1.8342, 1.8294, 1.8242, 1.8205, 1.8205, 1.8194, 1.8201, 1.8275], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2391, -0.2406, -0.2377, -0.2382, -0.2342, -0.2335, -0.2343, -0.2276, -0.2248, -0.2424, -0.2451, -0.2416,
1:         -0.2422, -0.2376, -0.2365, -0.2371, -0.2348, -0.2358, -0.2450, -0.2438, -0.2484, -0.2472, -0.2450, -0.2441,
1:         -0.2403], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([0.0422, 0.0199, 0.0352, 0.0344, 0.0307, 0.0554, 0.0537, 0.0232, 0.0458, 0.0144, 0.0266, 0.0304, 0.0316, 0.0174,
1:         0.0240, 0.0272, 0.0157, 0.0205, 0.0014, 0.0160, 0.0239, 0.0472, 0.0337, 0.0291, 0.0167], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 26 [1/5 (20%)]	Loss: 0.23662 : 0.20139 :: 0.02217 (1.83 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 26 [2/5 (40%)]	Loss: 0.27815 : 0.26928 :: 0.02365 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 26 [3/5 (60%)]	Loss: 0.30885 : 0.21576 :: 0.02290 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 26 [4/5 (80%)]	Loss: 0.26089 : 0.21616 :: 0.02381 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 26 : 0.207730233669281
0: validation loss for velocity_u : 0.003501706290990114
0: validation loss for velocity_v : 0.004918589256703854
0: validation loss for specific_humidity : 0.006537767127156258
0: validation loss for velocity_z : 0.1043236032128334
0: validation loss for temperature : 0.02130584791302681
0: validation loss for total_precip : 0.23999077081680298
0: validation loss for t2m : 1.073533058166504
0: 27 : 02:52:49 :: batch_size = 96, lr = 1.0787811788985607e-05
1: 27 : 02:52:49 :: batch_size = 96, lr = 1.0787811788985607e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 27, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.1794, 1.1675, 1.1556, 1.1436, 1.1319, 1.1200, 1.1076, 1.0950, 1.0823, 1.0700, 1.0586, 1.0484, 1.0396, 1.0319,
0:         1.0261, 1.0219, 1.0194, 1.0188, 1.1836, 1.1726, 1.1617, 1.1507, 1.1398, 1.1288, 1.1176], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.1588, 1.1654, 1.1737, 1.1834, 1.1945, 1.2064, 1.2191, 1.2323, 1.2455, 1.2591, 1.2737, 1.2899, 1.3081, 1.3285,
0:         1.3511, 1.3751, 1.3982, 1.4180, 1.1263, 1.1323, 1.1410, 1.1522, 1.1654, 1.1800, 1.1960], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2874, 0.3273, 0.3628, 0.4094, 0.4649, 0.5115, 0.5403, 0.5603, 0.5802, 0.5913, 0.5802, 0.5581, 0.5492, 0.5581,
0:         0.5669, 0.5581, 0.5514, 0.5802, 0.2696, 0.3118, 0.3473, 0.3783, 0.4138, 0.4516, 0.4871], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2291, -0.2050, -0.1843, -0.1717, -0.1590, -0.1303, -0.1062, -0.0499,  0.0167, -0.2211, -0.1855, -0.1384,
0:         -0.1372, -0.1315, -0.1085, -0.0901,  0.0132,  0.1005, -0.2096, -0.1809, -0.1407, -0.1407, -0.1441, -0.0292,
0:          0.0201], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 27, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([ 1.3233,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,  0.2861,     nan,     nan,     nan,     nan,     nan, -0.0246,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 27, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.2990, -0.2797, -0.2638, -0.2509, -0.2421, -0.2362, -0.2335, -0.2334, -0.2327, -0.2330, -0.2331, -0.2317,
0:         -0.2305, -0.2307, -0.2339, -0.2389, -0.2466, -0.2554, -0.3536, -0.3373, -0.3238, -0.3121, -0.3014, -0.2918,
0:         -0.2864], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([2.0761, 2.0799, 2.0763, 2.0672, 2.0571, 2.0457, 2.0347, 2.0220, 2.0089, 1.9934, 1.9723, 1.9477, 1.9173, 1.8859,
0:         1.8553, 1.8266, 1.7974, 1.7660, 2.0963, 2.0926, 2.0829, 2.0721, 2.0598, 2.0451, 2.0336], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6634, -0.6631, -0.6618, -0.6616, -0.6605, -0.6576, -0.6541, -0.6515, -0.6497, -0.6478, -0.6461, -0.6449,
0:         -0.6441, -0.6442, -0.6433, -0.6421, -0.6406, -0.6390, -0.6590, -0.6574, -0.6561, -0.6548, -0.6534, -0.6497,
0:         -0.6472], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.1270,  0.0829,  0.0253, -0.0213, -0.0585, -0.0798, -0.0896, -0.1126, -0.1143, -0.1029, -0.0996, -0.0891,
0:         -0.0674, -0.0446, -0.0193,  0.0134,  0.0526,  0.0763,  0.0958,  0.0469, -0.0129, -0.0529, -0.0911, -0.1170,
0:         -0.1203], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.8811, -0.8580, -0.8376, -0.8200, -0.8034, -0.7855, -0.7656, -0.7442, -0.7236, -0.7030, -0.6821, -0.6608,
0:         -0.6387, -0.6154, -0.5916, -0.5702, -0.5497, -0.5302, -0.5098, -0.4904, -0.4718, -0.4521, -0.4295, -0.4053,
0:         -0.3805], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2376, -0.2385, -0.2382, -0.2394, -0.2394, -0.2388, -0.2386, -0.2355, -0.2320, -0.2345, -0.2369, -0.2363,
0:         -0.2376, -0.2371, -0.2402, -0.2367, -0.2369, -0.2379, -0.2358, -0.2355, -0.2387, -0.2369, -0.2374, -0.2386,
0:         -0.2400], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0178,  0.0159,  0.0216,  0.0188,  0.0466,  0.0381,  0.0473,  0.0225,  0.0338,  0.0125,  0.0137,  0.0163,
0:          0.0084,  0.0147,  0.0455,  0.0284,  0.0236, -0.0042, -0.0173,  0.0298,  0.0238,  0.0002, -0.0033,  0.0334,
0:          0.0076], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 27, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.1794, 1.1675, 1.1556, 1.1436, 1.1319, 1.1200, 1.1076, 1.0950, 1.0823, 1.0700, 1.0586, 1.0484, 1.0396, 1.0319,
1:         1.0261, 1.0219, 1.0194, 1.0188, 1.1836, 1.1726, 1.1617, 1.1507, 1.1398, 1.1288, 1.1176], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.2530, -0.1196, -0.1083, -0.0713, -0.1002,  0.0748, -0.0907, -0.0180, -0.0944, -0.0332, -0.0401,  0.0378,
1:          0.0180, -0.0594,  0.2860,  0.0097,  0.1245, -0.1170,  0.0174,  0.0034,  0.0060,  0.2077,  0.0771, -0.0925,
1:          0.0743], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6779, -0.6791, -0.6800, -0.6796, -0.6795, -0.6783, -0.6770, -0.6752, -0.6733, -0.6716, -0.6701, -0.6690,
1:         -0.6676, -0.6671, -0.6667, -0.6673, -0.6680, -0.6703, -0.6707, -0.6727, -0.6754, -0.6763, -0.6767, -0.6760,
1:         -0.6754], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.3048, -1.3295, -1.3540, -1.3781, -1.4006, -1.4208, -1.4386, -1.4552, -1.4706, -1.4842, -1.4959, -1.5054,
1:         -1.5129, -1.5183, -1.5204, -1.5192, -1.5160, -1.5106, -1.5030, -1.4925, -1.4792, -1.4640, -1.4471, -1.4290,
1:         -1.4099], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2291, -0.2050, -0.1843, -0.1717, -0.1590, -0.1303, -0.1062, -0.0499,  0.0167, -0.2211, -0.1855, -0.1384,
1:         -0.1372, -0.1315, -0.1085, -0.0901,  0.0132,  0.1005, -0.2096, -0.1809, -0.1407, -0.1407, -0.1441, -0.0292,
1:          0.0201], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 27, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([-0.6188,     nan,     nan,     nan, -0.6573,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.6175, -0.6397,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 27, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.9757, 0.9727, 0.9692, 0.9663, 0.9624, 0.9557, 0.9511, 0.9448, 0.9348, 0.9233, 0.9103, 0.8987, 0.8885, 0.8767,
1:         0.8702, 0.8642, 0.8570, 0.8500, 0.8752, 0.8724, 0.8686, 0.8644, 0.8605, 0.8541, 0.8473], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.1814,  0.1795,  0.1775,  0.1711,  0.1593,  0.1425,  0.1208,  0.1014,  0.0821,  0.0644,  0.0482,  0.0350,
1:          0.0216,  0.0090, -0.0018, -0.0128, -0.0187, -0.0210,  0.1436,  0.1386,  0.1320,  0.1219,  0.1072,  0.0909,
1:          0.0706], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6159, -0.6187, -0.6217, -0.6257, -0.6296, -0.6316, -0.6320, -0.6321, -0.6311, -0.6298, -0.6289, -0.6289,
1:         -0.6297, -0.6318, -0.6332, -0.6355, -0.6361, -0.6365, -0.6149, -0.6175, -0.6206, -0.6242, -0.6271, -0.6280,
1:         -0.6285], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.3562, -0.3472, -0.3571, -0.3776, -0.4100, -0.4331, -0.4658, -0.5211, -0.5850, -0.6588, -0.7091, -0.7442,
1:         -0.7375, -0.6874, -0.6616, -0.6498, -0.6593, -0.6893, -0.3928, -0.3722, -0.3862, -0.4189, -0.4688, -0.4880,
1:         -0.5254], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.1765, -1.1793, -1.1800, -1.1798, -1.1834, -1.1920, -1.2070, -1.2232, -1.2417, -1.2593, -1.2742, -1.2851,
1:         -1.2896, -1.2867, -1.2756, -1.2612, -1.2463, -1.2311, -1.2151, -1.1983, -1.1817, -1.1638, -1.1458, -1.1256,
1:         -1.1008], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.0100,  0.0055,  0.0565,  0.1233,  0.2231,  0.3625,  0.4951,  0.6307,  0.7248,  0.0441,  0.0835,  0.1537,
1:          0.2560,  0.4078,  0.5695,  0.7471,  0.9008,  1.0082,  0.1223,  0.1887,  0.2966,  0.4280,  0.6091,  0.8164,
1:          1.0303], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0403,  0.0267,  0.0207,  0.0159,  0.0421,  0.0371,  0.0110,  0.0017,  0.0321,  0.0151,  0.0231,  0.0132,
1:          0.0251,  0.0214,  0.0344,  0.0039,  0.0380,  0.0269, -0.0091,  0.0143,  0.0136,  0.0250,  0.0338,  0.0277,
1:          0.0136], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 27 [1/5 (20%)]	Loss: 0.29481 : 0.24082 :: 0.02262 (1.81 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 27 [2/5 (40%)]	Loss: 0.26858 : 0.20821 :: 0.02339 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 27 [3/5 (60%)]	Loss: 0.22474 : 0.20605 :: 0.02473 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 27 [4/5 (80%)]	Loss: 0.32847 : 0.23558 :: 0.02311 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 27 : 0.21216681599617004
0: validation loss for velocity_u : 0.0033777018543332815
0: validation loss for velocity_v : 0.004782015923410654
0: validation loss for specific_humidity : 0.0061730435118079185
0: validation loss for velocity_z : 0.1015135794878006
0: validation loss for temperature : 0.019206194207072258
0: validation loss for total_precip : 0.301643431186676
0: validation loss for t2m : 1.0484720468521118
0: 28 : 02:58:57 :: batch_size = 96, lr = 1.0524694428278642e-05
1: 28 : 02:58:57 :: batch_size = 96, lr = 1.0524694428278642e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 28, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.1204, -1.3265, -1.4948, -1.6044, -1.6399, -1.6374, -1.6363, -1.6445, -1.6573, -1.6556, -1.6426, -1.6239,
0:         -1.6201, -1.6396, -1.6498, -1.6505, -1.6502, -1.6401, -1.0410, -1.2773, -1.4632, -1.5660, -1.6000, -1.5986,
0:         -1.6024], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.4126, -0.3889, -0.2717, -0.2205, -0.2365, -0.2473, -0.2514, -0.2551, -0.2594, -0.2623, -0.2608, -0.2451,
0:         -0.2389, -0.2725, -0.3166, -0.3364, -0.3536, -0.3850, -0.3793, -0.3956, -0.3215, -0.2678, -0.2686, -0.2692,
0:         -0.2676], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0363,  0.1877,  0.1203,  0.0942, -0.1211, -0.4190, -0.4559, -0.3929, -0.1232, -0.3755, -0.1211,  0.6814,
0:          0.1769, -0.0710,  0.1399,  0.0138,  0.2269,  0.3508, -0.2015,  0.1899,  0.2508,  0.2291, -0.1819, -0.7386,
0:         -0.2972], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430,
0:         -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430,
0:         -0.2430], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 28, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.5081,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.1646,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 28, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.1288, 0.1301, 0.1308, 0.1347, 0.1390, 0.1466, 0.1579, 0.1743, 0.1945, 0.2160, 0.2359, 0.2530, 0.2647, 0.2737,
0:         0.2822, 0.2889, 0.2983, 0.3057, 0.0645, 0.0664, 0.0683, 0.0727, 0.0812, 0.0916, 0.1046], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.2920, -0.4306, -0.5756, -0.6971, -0.7842, -0.8396, -0.8727, -0.8902, -0.8970, -0.8911, -0.8745, -0.8534,
0:         -0.8310, -0.8125, -0.8007, -0.7905, -0.7791, -0.7648, -0.2453, -0.3931, -0.5478, -0.6703, -0.7568, -0.8133,
0:         -0.8535], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.2085, -0.2157, -0.2251, -0.2388, -0.2515, -0.2591, -0.2641, -0.2596, -0.2456, -0.2224, -0.1973, -0.1684,
0:         -0.1419, -0.1178, -0.0989, -0.0875, -0.0738, -0.0580, -0.1950, -0.2057, -0.2188, -0.2285, -0.2364, -0.2393,
0:         -0.2359], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 3.7936e-02,  3.4382e-02,  1.0186e-01,  2.2025e-01,  2.4007e-01,  1.7022e-01,  5.3778e-02,  1.1031e-03,
0:         -2.8543e-02, -1.0756e-01, -1.1207e-01, -1.1671e-01, -1.5187e-01, -1.2366e-01, -5.9144e-02, -2.4101e-04,
0:          8.1812e-02,  1.8044e-01,  1.6733e-01,  1.7124e-01,  1.9050e-01,  2.4813e-01,  2.5391e-01,  1.9713e-01,
0:          9.1362e-02], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([2.2512, 2.3027, 2.3113, 2.2809, 2.2351, 2.1880, 2.1406, 2.0944, 2.0519, 2.0288, 2.0370, 2.0767, 2.1400, 2.2027,
0:         2.2463, 2.2643, 2.2631, 2.2519, 2.2382, 2.2206, 2.1987, 2.1753, 2.1549, 2.1423, 2.1331], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1613, -0.2064, -0.2255, -0.2304, -0.2162, -0.1465, -0.0515,  0.0441,  0.1233, -0.0855, -0.1292, -0.1794,
0:         -0.1960, -0.1850, -0.1379, -0.0500,  0.0406,  0.1414,  0.0065, -0.0503, -0.0876, -0.1105, -0.1162, -0.1001,
0:         -0.0319], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0217,  0.0300,  0.0332,  0.0349,  0.0461,  0.0211,  0.0137,  0.0167,  0.0190,  0.0026,  0.0205,  0.0112,
0:          0.0207,  0.0167,  0.0360,  0.0183, -0.0071,  0.0046,  0.0006,  0.0350,  0.0269,  0.0065, -0.0029,  0.0180,
0:          0.0181], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 28, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.1204, -1.3265, -1.4948, -1.6044, -1.6399, -1.6374, -1.6363, -1.6445, -1.6573, -1.6556, -1.6426, -1.6239,
1:         -1.6201, -1.6396, -1.6498, -1.6505, -1.6502, -1.6401, -1.0410, -1.2773, -1.4632, -1.5660, -1.6000, -1.5986,
1:         -1.6024], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0665, -0.0668, -0.0293,  0.0105, -0.1020,  0.1358, -0.0050, -0.0496, -0.0482,  0.0031, -0.0607,  0.0049,
1:          0.1042,  0.0087, -0.0138,  0.0805, -0.0169, -0.0031,  0.0465,  0.0136, -0.1294,  0.0588,  0.1511,  0.1614,
1:         -0.2381], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.4887, -0.4996, -0.4487, -0.3704, -0.3532, -0.3614, -0.3742, -0.3672, -0.3542, -0.3562, -0.3679, -0.3866,
1:         -0.4015, -0.3768, -0.3494, -0.3455, -0.3553, -0.3746, -0.4253, -0.4411, -0.3912, -0.3743, -0.4051, -0.3958,
1:         -0.3910], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.3132, -0.2350,  0.8831,  1.2756,  1.1911,  1.1432,  1.2578,  1.3759,  1.4307,  1.4507,  1.4945,  1.4133,
1:          1.3402,  1.5470,  1.6570,  1.6236,  1.5551,  1.4830,  1.4042,  1.3445,  1.3310,  1.3183,  1.3201,  1.3066,
1:          1.2859], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430,
1:         -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430, -0.2430,
1:         -0.2430], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 28, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan, -0.2042,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 28, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.7355, -0.7259, -0.7103, -0.6922, -0.6717, -0.6512, -0.6306, -0.6084, -0.5850, -0.5608, -0.5376, -0.5158,
1:         -0.4930, -0.4696, -0.4428, -0.4153, -0.3939, -0.3767, -0.7310, -0.7166, -0.6927, -0.6613, -0.6297, -0.5986,
1:         -0.5666], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.0856, -0.0760, -0.0681, -0.0616, -0.0596, -0.0615, -0.0666, -0.0697, -0.0707, -0.0706, -0.0665, -0.0603,
1:         -0.0539, -0.0438, -0.0318, -0.0193, -0.0049,  0.0087, -0.0611, -0.0534, -0.0489, -0.0452, -0.0463, -0.0498,
1:         -0.0545], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.0245, -0.0627, -0.0994, -0.1347, -0.1604, -0.1802, -0.2022, -0.2284, -0.2607, -0.2939, -0.3298, -0.3644,
1:         -0.3986, -0.4295, -0.4588, -0.4819, -0.4953, -0.5026, -0.1016, -0.1391, -0.1750, -0.2047, -0.2312, -0.2485,
1:         -0.2642], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.0466,  0.0680,  0.0721, -0.0391, -0.2239, -0.2441, -0.1943, -0.1643, -0.1912, -0.2498, -0.1359,  0.0380,
1:          0.0406,  0.0623,  0.2547,  0.3541,  0.3630,  0.4987, -0.0538,  0.1212,  0.2023,  0.0917, -0.0626, -0.0139,
1:          0.0183], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.1235, 1.1251, 1.1040, 1.0615, 1.0056, 0.9432, 0.8850, 0.8427, 0.8228, 0.8258, 0.8461, 0.8779, 0.9144, 0.9497,
1:         0.9735, 0.9650, 0.9038, 0.7791, 0.6032, 0.4048, 0.2232, 0.0983, 0.0513, 0.0927, 0.2200], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2034, -0.2153, -0.2183, -0.2122, -0.2101, -0.2057, -0.2093, -0.1993, -0.1907, -0.2143, -0.2209, -0.2225,
1:         -0.2232, -0.2213, -0.2198, -0.2076, -0.2045, -0.1972, -0.2185, -0.2263, -0.2263, -0.2267, -0.2256, -0.2201,
1:         -0.2128], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0272,  0.0291,  0.0260,  0.0151,  0.0322,  0.0265,  0.0263, -0.0059,  0.0307,  0.0118,  0.0170,  0.0103,
1:          0.0144,  0.0254,  0.0217,  0.0132,  0.0200,  0.0250, -0.0080,  0.0222,  0.0255,  0.0242, -0.0021,  0.0183,
1:          0.0164], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 28 [1/5 (20%)]	Loss: 0.24372 : 0.20317 :: 0.02432 (1.68 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 28 [2/5 (40%)]	Loss: 0.29334 : 0.22322 :: 0.02261 (8.25 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 28 [3/5 (60%)]	Loss: 0.29213 : 0.22717 :: 0.02423 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 28 [4/5 (80%)]	Loss: 0.25019 : 0.19659 :: 0.02340 (8.46 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 28 : 0.20065999031066895
0: validation loss for velocity_u : 0.0037992075085639954
0: validation loss for velocity_v : 0.005093451589345932
0: validation loss for specific_humidity : 0.006335707381367683
0: validation loss for velocity_z : 0.11635471880435944
0: validation loss for temperature : 0.01791117712855339
0: validation loss for total_precip : 0.2318187952041626
0: validation loss for t2m : 1.0233066082000732
1: 29 : 03:05:15 :: batch_size = 96, lr = 1.0267994564174285e-05
0: 29 : 03:05:15 :: batch_size = 96, lr = 1.0267994564174285e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 29, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.1770, -0.1900, -0.2148, -0.2441, -0.2718, -0.2950, -0.3123, -0.3249, -0.3350, -0.3456, -0.3583, -0.3731,
1:         -0.3893, -0.4069, -0.4272, -0.4499, -0.4723, -0.4903, -0.1485, -0.1599, -0.1802, -0.2051, -0.2301, -0.2523,
1:         -0.2696], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0745, -0.1078, -0.1717, -0.0027,  0.1121,  0.1590, -0.0479, -0.0563,  0.0091,  0.1517, -0.0466,  0.0380,
1:         -0.2137, -0.0264, -0.1227, -0.0168, -0.0823, -0.0289, -0.0222,  0.0819, -0.0080, -0.0720, -0.0668,  0.0590,
1:          0.0213], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.5247, -0.5447, -0.5613, -0.5722, -0.5737, -0.5756, -0.5838, -0.5947, -0.6111, -0.6299, -0.6424, -0.6474,
1:         -0.6480, -0.6440, -0.6389, -0.6429, -0.6492, -0.6676, -0.5164, -0.5426, -0.5606, -0.5709, -0.5743, -0.5753,
1:         -0.5790], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., -0., -0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.3962, -0.3746, -0.3482, -0.3175, -0.2824, -0.2420, -0.1963, -0.1461, -0.0924, -0.0372,  0.0162,  0.0652,
1:          0.1085,  0.1485,  0.1901,  0.2392,  0.2984,  0.3647,  0.4308,  0.4905,  0.5396,  0.5765,  0.6006,  0.6148,
1:          0.6245], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488,
1:         -0.2397, -0.2363, -0.2420, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2454, -0.2329, -0.2294, -0.2329,
1:         -0.2454], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 29, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 29, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.3262, -0.3252, -0.3222, -0.3176, -0.3114, -0.3067, -0.2966, -0.2869, -0.2771, -0.2673, -0.2563, -0.2471,
1:         -0.2338, -0.2217, -0.2106, -0.1980, -0.1886, -0.1782, -0.3359, -0.3342, -0.3298, -0.3233, -0.3160, -0.3083,
1:         -0.2995], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.7692, 0.8533, 0.9436, 1.0362, 1.1255, 1.2144, 1.2924, 1.3562, 1.4028, 1.4289, 1.4453, 1.4548, 1.4594, 1.4617,
1:         1.4611, 1.4619, 1.4706, 1.4963, 0.7516, 0.8377, 0.9280, 1.0180, 1.1082, 1.1934, 1.2735], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.3883, -0.4233, -0.4472, -0.4135, -0.3009, -0.0987,  0.1978,  0.5496,  0.9049,  1.2094,  1.4197,  1.5341,
1:          1.5760,  1.5832,  1.5716,  1.5686,  1.5668,  1.5653, -0.3430, -0.3837, -0.4206, -0.4143, -0.3409, -0.1685,
1:          0.1080], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.1979,  0.2379,  0.2517,  0.2605,  0.2599,  0.2287,  0.2046,  0.2076,  0.1938,  0.1526,  0.1266,  0.1145,
1:          0.0945,  0.0636,  0.0141, -0.0069, -0.0235, -0.0984,  0.2481,  0.2640,  0.2700,  0.2785,  0.2725,  0.2481,
1:          0.2262], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.2448, 1.2521, 1.2562, 1.2550, 1.2532, 1.2522, 1.2547, 1.2633, 1.2796, 1.3025, 1.3283, 1.3548, 1.3803, 1.3987,
1:         1.4110, 1.4117, 1.4015, 1.3818, 1.3606, 1.3414, 1.3275, 1.3193, 1.3129, 1.3076, 1.3040], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2036, -0.2028, -0.1961, -0.1894, -0.1775, -0.1729, -0.1714, -0.1707, -0.1617, -0.2138, -0.2108, -0.2052,
1:         -0.1957, -0.1911, -0.1913, -0.1800, -0.1807, -0.1781, -0.2149, -0.2155, -0.2104, -0.2004, -0.1970, -0.1951,
1:         -0.1916], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0143,  0.0224,  0.0147,  0.0310,  0.0166,  0.0209,  0.0128, -0.0079,  0.0095,  0.0124,  0.0039,  0.0062,
1:          0.0253,  0.0272,  0.0271,  0.0125,  0.0271,  0.0241, -0.0025,  0.0155,  0.0104,  0.0288,  0.0044,  0.0020,
1:          0.0004], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 29, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1770, -0.1900, -0.2148, -0.2441, -0.2718, -0.2950, -0.3123, -0.3249, -0.3350, -0.3456, -0.3583, -0.3731,
0:         -0.3893, -0.4069, -0.4272, -0.4499, -0.4723, -0.4903, -0.1485, -0.1599, -0.1802, -0.2051, -0.2301, -0.2523,
0:         -0.2696], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([2.3408, 2.3201, 2.3177, 2.3268, 2.3441, 2.3691, 2.4031, 2.4472, 2.5011, 2.5588, 2.6096, 2.6406, 2.6416, 2.6086,
0:         2.5439, 2.4574, 2.3663, 2.2911, 2.2900, 2.2610, 2.2480, 2.2461, 2.2532, 2.2697, 2.2965], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2559, -0.2101, -0.1991, -0.1817, -0.1009,  0.0802,  0.3465,  0.6368,  0.8682,  0.9620,  0.8791,  0.6455,
0:          0.3552,  0.1152, -0.0027, -0.0114,  0.0344,  0.0890, -0.5265, -0.6859, -0.7819, -0.8168, -0.7601, -0.5658,
0:         -0.2406], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488,
0:         -0.2397, -0.2363, -0.2420, -0.2488, -0.2488, -0.2488, -0.2488, -0.2488, -0.2454, -0.2329, -0.2294, -0.2329,
0:         -0.2454], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 29, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([-1.4314,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -1.3486,     nan,     nan,     nan,     nan,     nan, -1.0763,     nan,
0:         -1.0047])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 29, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.6504, -0.6461, -0.6453, -0.6460, -0.6485, -0.6541, -0.6601, -0.6695, -0.6779, -0.6872, -0.6957, -0.7026,
0:         -0.7051, -0.7068, -0.7056, -0.7036, -0.6990, -0.6929, -0.6618, -0.6579, -0.6546, -0.6508, -0.6522, -0.6551,
0:         -0.6623], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.7430, 0.6290, 0.5065, 0.3828, 0.2683, 0.1721, 0.1032, 0.0668, 0.0699, 0.1101, 0.1852, 0.2865, 0.4067, 0.5360,
0:         0.6698, 0.7994, 0.9236, 1.0409, 0.7779, 0.6500, 0.5127, 0.3807, 0.2591, 0.1582, 0.0872], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([ 1.2022,  1.0853,  0.8899,  0.6251,  0.3243,  0.0515, -0.1521, -0.2555, -0.2874, -0.2792, -0.2716, -0.2962,
0:         -0.3365, -0.3932, -0.4416, -0.4738, -0.4926, -0.4937,  1.2798,  1.1890,  1.0152,  0.7365,  0.4018,  0.0815,
0:         -0.1574], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.6957, -0.6884, -0.6478, -0.5936, -0.5113, -0.4171, -0.3391, -0.2756, -0.2411, -0.2319, -0.2353, -0.2285,
0:         -0.2114, -0.1659, -0.1052, -0.0798, -0.0606, -0.0671, -0.7401, -0.7450, -0.6822, -0.6098, -0.4997, -0.3822,
0:         -0.2899], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.2511, 1.2523, 1.2434, 1.2279, 1.2107, 1.1936, 1.1783, 1.1646, 1.1517, 1.1399, 1.1259, 1.1100, 1.0942, 1.0799,
0:         1.0683, 1.0580, 1.0488, 1.0374, 1.0236, 1.0063, 0.9838, 0.9589, 0.9326, 0.9051, 0.8807], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2506, -0.2623, -0.2680, -0.2670, -0.2621, -0.2587, -0.2523, -0.2536, -0.2408, -0.2147, -0.2308, -0.2466,
0:         -0.2546, -0.2584, -0.2564, -0.2571, -0.2621, -0.2515, -0.1375, -0.1788, -0.2116, -0.2256, -0.2397, -0.2536,
0:         -0.2572], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0252,  0.0353,  0.0216,  0.0353,  0.0179,  0.0111,  0.0115,  0.0081,  0.0020,  0.0056,  0.0174,  0.0145,
0:          0.0202,  0.0044,  0.0375,  0.0215,  0.0175, -0.0026, -0.0070,  0.0145,  0.0248,  0.0039, -0.0003,  0.0206,
0:          0.0080], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 29 [1/5 (20%)]	Loss: 0.28712 : 0.21607 :: 0.02267 (1.67 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 29 [2/5 (40%)]	Loss: 0.25060 : 0.20924 :: 0.02259 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 29 [3/5 (60%)]	Loss: 0.24040 : 0.17933 :: 0.02368 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 29 [4/5 (80%)]	Loss: 0.25282 : 0.19299 :: 0.02214 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 29 : 0.1986289620399475
0: validation loss for velocity_u : 0.003376880194991827
0: validation loss for velocity_v : 0.0046701193787157536
0: validation loss for specific_humidity : 0.006310451775789261
0: validation loss for velocity_z : 0.10329663753509521
0: validation loss for temperature : 0.019544312730431557
0: validation loss for total_precip : 0.28373295068740845
0: validation loss for t2m : 0.9694713950157166
1: 30 : 03:11:15 :: batch_size = 96, lr = 1.0017555672365157e-05
0: 30 : 03:11:15 :: batch_size = 96, lr = 1.0017555672365157e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 30, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.1912, -0.1928, -0.1943, -0.1959, -0.1974, -0.1991, -0.2008, -0.2026, -0.2044, -0.2061, -0.2080, -0.2099,
1:         -0.2117, -0.2137, -0.2156, -0.2176, -0.2197, -0.2217, -0.1524, -0.1536, -0.1549, -0.1562, -0.1576, -0.1592,
1:         -0.1608], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.4790e-01, -8.4879e-02, -9.8738e-03, -1.1597e-02,  2.7071e-02,  5.9454e-02, -2.2227e-01,  3.5959e-02,
1:         -3.2046e-04,  1.4730e-01,  3.2544e-02,  1.1509e-01,  6.7186e-02,  7.2071e-02, -2.3299e-02,  1.7440e-01,
1:         -9.5064e-02, -5.2176e-03,  3.3720e-01, -2.4757e-02,  1.5756e-02, -4.6545e-02,  1.2955e-01, -1.2074e-01,
1:          2.4640e-01], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6826, -0.6824, -0.6807, -0.6788, -0.6770, -0.6752, -0.6734, -0.6716, -0.6698, -0.6678, -0.6660, -0.6642,
1:         -0.6623, -0.6605, -0.6585, -0.6567, -0.6556, -0.6544, -0.6914, -0.6913, -0.6911, -0.6909, -0.6908, -0.6907,
1:         -0.6908], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.5319, -0.5343, -0.5368, -0.5388, -0.5412, -0.5433, -0.5457, -0.5481, -0.5504, -0.5524, -0.5547, -0.5571,
1:         -0.5594, -0.5617, -0.5640, -0.5663, -0.5686, -0.5708, -0.5730, -0.5756, -0.5779, -0.5802, -0.5824, -0.5849,
1:         -0.5872], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2372, -0.2372, -0.2372,
1:         -0.2372, -0.2372, -0.2372, -0.2372, -0.2372, -0.2384, -0.2361, -0.2361, -0.2361, -0.2361, -0.2361, -0.2361,
1:         -0.2372], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 30, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.1177,    nan,    nan,
1:            nan,    nan, 0.0751,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 30, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.2284, -0.2300, -0.2318, -0.2332, -0.2347, -0.2372, -0.2383, -0.2385, -0.2380, -0.2399, -0.2429, -0.2473,
1:         -0.2510, -0.2583, -0.2649, -0.2743, -0.2850, -0.2945, -0.2111, -0.2126, -0.2137, -0.2153, -0.2178, -0.2185,
1:         -0.2200], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.9135, -0.9139, -0.9103, -0.9042, -0.8973, -0.8883, -0.8824, -0.8761, -0.8696, -0.8638, -0.8587, -0.8537,
1:         -0.8528, -0.8487, -0.8448, -0.8370, -0.8287, -0.8173, -0.9198, -0.9231, -0.9220, -0.9172, -0.9103, -0.9029,
1:         -0.8967], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6406, -0.6385, -0.6351, -0.6342, -0.6336, -0.6337, -0.6343, -0.6362, -0.6370, -0.6377, -0.6385, -0.6394,
1:         -0.6381, -0.6371, -0.6353, -0.6324, -0.6302, -0.6278, -0.6547, -0.6527, -0.6505, -0.6498, -0.6500, -0.6487,
1:         -0.6476], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.1359, -0.1257, -0.1174, -0.0864, -0.0645, -0.0517, -0.0221,  0.0085,  0.0256,  0.0316,  0.0382,  0.0569,
1:          0.0774,  0.0988,  0.1315,  0.1467,  0.1611,  0.1840, -0.0048, -0.0039, -0.0053,  0.0180,  0.0348,  0.0663,
1:          0.1118], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.1448, -1.1466, -1.1500, -1.1530, -1.1553, -1.1556, -1.1560, -1.1574, -1.1593, -1.1616, -1.1641, -1.1653,
1:         -1.1651, -1.1641, -1.1614, -1.1574, -1.1531, -1.1485, -1.1416, -1.1357, -1.1298, -1.1242, -1.1195, -1.1171,
1:         -1.1171], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2387, -0.2403, -0.2378, -0.2411, -0.2451, -0.2477, -0.2481, -0.2486, -0.2456, -0.2445, -0.2432, -0.2441,
1:         -0.2444, -0.2442, -0.2447, -0.2464, -0.2494, -0.2459, -0.2442, -0.2438, -0.2455, -0.2415, -0.2378, -0.2387,
1:         -0.2378], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0315,  0.0133,  0.0118,  0.0157,  0.0075,  0.0179,  0.0047, -0.0040, -0.0113,  0.0152,  0.0096, -0.0093,
1:          0.0182,  0.0111,  0.0038,  0.0124,  0.0181,  0.0202,  0.0094,  0.0061,  0.0174,  0.0166,  0.0180, -0.0004,
1:         -0.0054], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 30, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1912, -0.1928, -0.1943, -0.1959, -0.1974, -0.1991, -0.2008, -0.2026, -0.2044, -0.2061, -0.2080, -0.2099,
0:         -0.2117, -0.2137, -0.2156, -0.2176, -0.2197, -0.2217, -0.1524, -0.1536, -0.1549, -0.1562, -0.1576, -0.1592,
0:         -0.1608], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.3356, -0.3399, -0.3443, -0.3484, -0.3525, -0.3566, -0.3607, -0.3646, -0.3685, -0.3724, -0.3763, -0.3800,
0:         -0.3836, -0.3873, -0.3908, -0.3943, -0.3978, -0.4013, -0.3114, -0.3180, -0.3244, -0.3307, -0.3371, -0.3432,
0:         -0.3494], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.5084, -0.5107, -0.5129, -0.5140, -0.5162, -0.5173, -0.5184, -0.5195, -0.5206, -0.5206, -0.5206, -0.5206,
0:         -0.5206, -0.5206, -0.5195, -0.5184, -0.5173, -0.5162, -0.4741, -0.4796, -0.4863, -0.4918, -0.4962, -0.5018,
0:         -0.5062], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2384, -0.2372, -0.2372, -0.2372,
0:         -0.2372, -0.2372, -0.2372, -0.2372, -0.2372, -0.2384, -0.2361, -0.2361, -0.2361, -0.2361, -0.2361, -0.2361,
0:         -0.2372], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 30, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.1626,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 30, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.6272, -0.6280, -0.6278, -0.6271, -0.6275, -0.6279, -0.6305, -0.6330, -0.6358, -0.6386, -0.6419, -0.6450,
0:         -0.6492, -0.6521, -0.6553, -0.6580, -0.6605, -0.6638, -0.6246, -0.6272, -0.6287, -0.6308, -0.6342, -0.6381,
0:         -0.6433], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.0934, 0.0918, 0.0904, 0.0874, 0.0837, 0.0793, 0.0767, 0.0752, 0.0767, 0.0793, 0.0838, 0.0900, 0.0927, 0.0948,
0:         0.0910, 0.0881, 0.0860, 0.0889, 0.0810, 0.0789, 0.0764, 0.0717, 0.0707, 0.0687, 0.0683], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6340, -0.6288, -0.6227, -0.6150, -0.6107, -0.6065, -0.6060, -0.6057, -0.6071, -0.6087, -0.6111, -0.6114,
0:         -0.6125, -0.6138, -0.6142, -0.6169, -0.6199, -0.6232, -0.6332, -0.6270, -0.6205, -0.6146, -0.6099, -0.6063,
0:         -0.6044], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.1131, 0.1267, 0.1300, 0.1287, 0.1394, 0.1428, 0.1539, 0.1703, 0.1661, 0.1523, 0.1470, 0.1553, 0.1716, 0.1804,
0:         0.1854, 0.1853, 0.1873, 0.1873, 0.1112, 0.1138, 0.1152, 0.1176, 0.1261, 0.1203, 0.1265], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-1.1872, -1.1799, -1.1769, -1.1772, -1.1774, -1.1778, -1.1786, -1.1791, -1.1808, -1.1806, -1.1806, -1.1813,
0:         -1.1838, -1.1861, -1.1887, -1.1880, -1.1869, -1.1839, -1.1799, -1.1754, -1.1725, -1.1685, -1.1651, -1.1644,
0:         -1.1642], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1877, -0.1833, -0.1759, -0.1717, -0.1653, -0.1596, -0.1559, -0.1555, -0.1511, -0.1950, -0.1937, -0.1852,
0:         -0.1754, -0.1692, -0.1646, -0.1644, -0.1640, -0.1579, -0.1985, -0.2009, -0.1933, -0.1793, -0.1712, -0.1665,
0:         -0.1650], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0126,  0.0171,  0.0081,  0.0297,  0.0231, -0.0101,  0.0039,  0.0018,  0.0053,  0.0166,  0.0199,  0.0089,
0:          0.0106,  0.0242,  0.0335,  0.0089,  0.0028, -0.0144, -0.0066,  0.0206,  0.0369,  0.0088, -0.0069, -0.0144,
0:          0.0112], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 30 [1/5 (20%)]	Loss: 0.29998 : 0.22371 :: 0.02318 (1.67 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 30 [2/5 (40%)]	Loss: 0.24838 : 0.20591 :: 0.02341 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 30 [3/5 (60%)]	Loss: 0.24469 : 0.19230 :: 0.02341 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 30 [4/5 (80%)]	Loss: 0.24969 : 0.19761 :: 0.02345 (8.46 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 30 : 0.1891961693763733
0: validation loss for velocity_u : 0.0035883819218724966
0: validation loss for velocity_v : 0.005069397389888763
0: validation loss for specific_humidity : 0.0059548006393015385
0: validation loss for velocity_z : 0.10968168079853058
0: validation loss for temperature : 0.017356015741825104
0: validation loss for total_precip : 0.23309867084026337
0: validation loss for t2m : 0.9496244788169861
0: 31 : 03:17:35 :: batch_size = 96, lr = 1e-05
1: 31 : 03:17:44 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 31, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.8110, -0.8346, -0.8481, -0.8451, -0.8272, -0.8002, -0.7669, -0.7362, -0.7182, -0.7190, -0.7399, -0.7718,
0:         -0.8026, -0.8279, -0.8486, -0.8597, -0.8530, -0.8319, -0.8555, -0.8749, -0.8852, -0.8769, -0.8525, -0.8203,
0:         -0.7874], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1236, -0.1405, -0.1542, -0.1573, -0.1482, -0.1331, -0.1163, -0.1014, -0.0998, -0.1143, -0.1381, -0.1502,
0:         -0.1383, -0.1147, -0.0899, -0.0641, -0.0320,  0.0036, -0.1065, -0.1214, -0.1369, -0.1462, -0.1423, -0.1272,
0:         -0.1123], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 1.1637,  1.1911,  1.1469,  1.1196,  0.9154,  0.5893,  0.3683,  0.1074, -0.1619, -0.3198, -0.3303, -0.1535,
0:          0.1179,  0.4104,  0.5409,  0.4693,  0.3536,  0.1221,  0.9175,  0.8271,  0.7282,  0.6714,  0.5030,  0.3641,
0:          0.2800], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438,
0:         -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438, -0.2438,
0:         -0.2438], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 31, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,  0.0146,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:          0.0072,     nan,     nan,     nan,     nan, -0.0773,     nan,     nan, -0.6846,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 31, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.6582, -0.6687, -0.6679, -0.6560, -0.6399, -0.6264, -0.6215, -0.6278, -0.6382, -0.6489, -0.6479, -0.6362,
0:         -0.6163, -0.5985, -0.5920, -0.6041, -0.6308, -0.6598, -0.6747, -0.6829, -0.6796, -0.6655, -0.6459, -0.6298,
0:         -0.6209], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.1038, -0.0525,  0.0119,  0.0765,  0.1290,  0.1636,  0.1748,  0.1672,  0.1437,  0.1026,  0.0496, -0.0134,
0:         -0.0800, -0.1387, -0.1839, -0.2104, -0.2230, -0.2243, -0.1356, -0.0840, -0.0169,  0.0551,  0.1177,  0.1618,
0:          0.1833], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([0.4368, 0.6608, 0.9080, 1.1459, 1.3369, 1.4747, 1.5498, 1.5737, 1.5562, 1.5160, 1.4770, 1.4585, 1.4757, 1.5319,
0:         1.6118, 1.6970, 1.7730, 1.8216, 0.8171, 1.0731, 1.3351, 1.5613, 1.7226, 1.8209, 1.8669], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.5798,  0.4357,  0.2310,  0.0980,  0.1022,  0.1489,  0.1241,  0.0563, -0.0458, -0.0999, -0.0920, -0.1153,
0:         -0.0382,  0.1043,  0.1701,  0.2022,  0.1936,  0.1869,  0.5192,  0.3801,  0.1860,  0.0536,  0.0136,  0.0089,
0:         -0.0664], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.0486, 0.0559, 0.0979, 0.1712, 0.2695, 0.3931, 0.5228, 0.6357, 0.7136, 0.7441, 0.7274, 0.6825, 0.6345, 0.5980,
0:         0.5779, 0.5671, 0.5525, 0.5269, 0.4946, 0.4715, 0.4871, 0.5532, 0.6696, 0.8156, 0.9571], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1863, -0.3501, -0.5251, -0.4676, -0.3366,  0.0914,  0.6876,  1.2578,  1.8440, -0.0552, -0.4092, -0.6379,
0:         -0.8921, -0.8951, -0.5331,  0.0423,  0.8503,  1.5421,  0.1421, -0.2621, -0.5785, -0.8889, -1.0733, -0.7480,
0:         -0.1301], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0239,  0.0174,  0.0078,  0.0285, -0.0024,  0.0152,  0.0278, -0.0003,  0.0229, -0.0023,  0.0040, -0.0018,
0:          0.0098,  0.0253,  0.0310,  0.0094,  0.0014,  0.0013, -0.0113,  0.0087,  0.0308, -0.0050, -0.0074, -0.0019,
0:          0.0066], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 31, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3328, -0.2840, -0.2423, -0.2298, -0.2441, -0.2716, -0.2975, -0.3196, -0.3473, -0.3918, -0.4604, -0.5304,
1:         -0.5652, -0.5729, -0.5848, -0.6015, -0.6219, -0.6489, -0.2716, -0.2312, -0.1758, -0.1499, -0.1666, -0.1994,
1:         -0.2232], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0797, -0.0173, -0.0168,  0.0034,  0.0822, -0.1000, -0.0075, -0.0743,  0.1051,  0.0376, -0.0453, -0.1223,
1:         -0.1503, -0.1095, -0.0584,  0.0370,  0.0613, -0.1165,  0.0546,  0.1088, -0.0753,  0.0293,  0.1370,  0.1227,
1:         -0.0891], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.4873, -0.4525, -0.4354, -0.4267, -0.4382, -0.4630, -0.5033, -0.5302, -0.5411, -0.5318, -0.5027, -0.4737,
1:         -0.4485, -0.4228, -0.3944, -0.3498, -0.3046, -0.2701, -0.5116, -0.4747, -0.4417, -0.4202, -0.4330, -0.4529,
1:         -0.4888], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., 0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-2.1446, -2.1373, -2.1268, -2.1267, -2.1362, -2.1429, -2.1378, -2.1193, -2.0911, -2.0630, -2.0333, -1.9897,
1:         -1.9370, -1.8970, -1.8812, -1.8756, -1.8539, -1.8003, -1.7128, -1.6079, -1.5338, -1.5275, -1.5577, -1.5760,
1:         -1.5810], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2342, -0.2353, -0.2401, -0.2424, -0.2436, -0.2436, -0.2424, -0.2436, -0.2436,  0.2333,  0.2333, -0.0630,
1:         -0.2318, -0.2330, -0.2106, -0.1999, -0.2023, -0.2424,  0.7632,  1.0383,  0.7857, -0.0311, -0.2259, -0.2318,
1:         -0.1279], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 31, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([-0.9238,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 31, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.1221, -0.1155, -0.1099, -0.1001, -0.0870, -0.0715, -0.0563, -0.0459, -0.0399, -0.0426, -0.0470, -0.0545,
1:         -0.0563, -0.0477, -0.0263,  0.0090,  0.0504,  0.0987, -0.1340, -0.1261, -0.1172, -0.1035, -0.0857, -0.0645,
1:         -0.0486], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-1.0116, -0.9855, -0.9522, -0.9090, -0.8564, -0.7933, -0.7192, -0.6352, -0.5393, -0.4365, -0.3303, -0.2234,
1:         -0.1232, -0.0282,  0.0641,  0.1565,  0.2503,  0.3437, -0.9352, -0.9053, -0.8651, -0.8173, -0.7592, -0.6959,
1:         -0.6241], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.7029, -0.7027, -0.7021, -0.7014, -0.7005, -0.7002, -0.7001, -0.6984, -0.6979, -0.6984, -0.7002, -0.7041,
1:         -0.7076, -0.7118, -0.7118, -0.7081, -0.6994, -0.6881, -0.7038, -0.7030, -0.7031, -0.7032, -0.7019, -0.7028,
1:         -0.7019], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-1.9474, -1.6165, -1.1686, -1.0695, -1.3347, -1.4875, -1.5093, -1.6817, -1.8360, -1.7215, -1.4886, -1.3754,
1:         -1.3325, -1.0318, -0.6197, -0.5156, -0.3653, -0.0243, -1.9302, -1.8059, -1.3294, -0.9593, -1.0358, -1.1715,
1:         -1.1829], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.5058, -0.4701, -0.4250, -0.3689, -0.3093, -0.2449, -0.1804, -0.1142, -0.0430,  0.0345,  0.1120,  0.1791,
1:          0.2192,  0.2170,  0.1669,  0.0731, -0.0504, -0.1827, -0.3059, -0.4109, -0.4945, -0.5504, -0.5745, -0.5613,
1:         -0.5072], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2306, -0.2334, -0.2350, -0.2378, -0.2400, -0.2419, -0.2504, -0.2515, -0.2511, -0.2331, -0.2355, -0.2382,
1:         -0.2368, -0.2388, -0.2426, -0.2475, -0.2510, -0.2525, -0.2356, -0.2346, -0.2364, -0.2382, -0.2368, -0.2410,
1:         -0.2444], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0126,  0.0289,  0.0068,  0.0122, -0.0068,  0.0164,  0.0099, -0.0012,  0.0027, -0.0047,  0.0065, -0.0085,
1:          0.0059,  0.0323,  0.0192,  0.0070,  0.0169,  0.0177,  0.0103,  0.0023,  0.0238,  0.0092,  0.0134,  0.0071,
1:          0.0010], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 31 [1/5 (20%)]	Loss: 0.26499 : 0.20047 :: 0.02233 (1.56 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 31 [2/5 (40%)]	Loss: 0.31667 : 0.25358 :: 0.02267 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 31 [3/5 (60%)]	Loss: 0.28321 : 0.22217 :: 0.02265 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 31 [4/5 (80%)]	Loss: 0.25949 : 0.19127 :: 0.02263 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 31 : 0.20978456735610962
0: validation loss for velocity_u : 0.0034775100648403168
0: validation loss for velocity_v : 0.004847987554967403
0: validation loss for specific_humidity : 0.0066275992430746555
0: validation loss for velocity_z : 0.11296724528074265
0: validation loss for temperature : 0.020564235746860504
0: validation loss for total_precip : 0.29389727115631104
0: validation loss for t2m : 1.0261099338531494
1: 32 : 03:23:47 :: batch_size = 96, lr = 1e-05
0: 32 : 03:23:47 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 32, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.8148, 0.8604, 0.9040, 0.9449, 0.9830, 1.0170, 1.0461, 1.0708, 1.0907, 1.1046, 1.1125, 1.1138, 1.1082, 1.0959,
0:         1.0780, 1.0547, 1.0264, 0.9952, 0.9050, 0.9472, 0.9868, 1.0234, 1.0565, 1.0847, 1.1069], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.1041, -1.1367, -1.1684, -1.1978, -1.2234, -1.2444, -1.2604, -1.2714, -1.2769, -1.2782, -1.2754, -1.2678,
0:         -1.2549, -1.2384, -1.2211, -1.2065, -1.1989, -1.2040, -1.0420, -1.0703, -1.0986, -1.1270, -1.1532, -1.1763,
0:         -1.1963], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.0640,  0.0769,  0.0813,  0.0640,  0.0423,  0.0250, -0.0117, -0.0722, -0.1263, -0.1587, -0.1868, -0.1998,
0:         -0.1825, -0.1479, -0.1068, -0.0420,  0.0640,  0.1764,  0.2629,  0.2737,  0.2888,  0.2737,  0.2456,  0.2261,
0:          0.1958], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2145, -0.2044, -0.1830, -0.1628, -0.1650, -0.1707, -0.1875, -0.1774, -0.1605, -0.2022, -0.1920, -0.1819,
0:         -0.1695, -0.1763, -0.1740, -0.1617, -0.1572, -0.1560, -0.1965, -0.1819, -0.1763, -0.1740, -0.1583, -0.1448,
0:         -0.1335], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 32, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  0.2442,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0910,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 32, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.9090, 0.9559, 0.9960, 1.0216, 1.0313, 1.0298, 1.0163, 1.0012, 0.9822, 0.9602, 0.9445, 0.9332, 0.9335, 0.9387,
0:         0.9543, 0.9713, 0.9908, 1.0061, 0.9176, 0.9569, 0.9898, 1.0116, 1.0224, 1.0241, 1.0223], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([ 0.7807,  0.8500,  0.8865,  0.8898,  0.8597,  0.7852,  0.6738,  0.5280,  0.3498,  0.1606, -0.0237, -0.1940,
0:         -0.3220, -0.4075, -0.4418, -0.4389, -0.4129, -0.3949,  0.8188,  0.8710,  0.8897,  0.8637,  0.7992,  0.7010,
0:          0.5575], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6028, -0.6307, -0.6530, -0.6722, -0.6888, -0.7010, -0.7062, -0.6991, -0.6724, -0.6238, -0.5535, -0.4666,
0:         -0.3701, -0.2714, -0.1823, -0.1038, -0.0424, -0.0010, -0.5984, -0.6203, -0.6368, -0.6511, -0.6695, -0.6885,
0:         -0.7083], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.1838, -0.4611, -0.8962, -1.2080, -1.1785, -0.9179, -0.6696, -0.5764, -0.7887, -1.2859, -1.8071, -2.0376,
0:         -1.8639, -1.3441, -0.7053, -0.2442, -0.1558, -0.3688, -0.2712, -0.5053, -0.9260, -1.2458, -1.2660, -1.0697,
0:         -0.8749], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.8491, 0.8541, 0.8570, 0.8585, 0.8608, 0.8702, 0.8834, 0.8987, 0.9152, 0.9328, 0.9557, 0.9847, 1.0218, 1.0624,
0:         1.1079, 1.1580, 1.2132, 1.2755, 1.3405, 1.4040, 1.4632, 1.5168, 1.5668, 1.6166, 1.6654], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([0.3364, 0.2956, 0.2499, 0.2027, 0.1532, 0.1038, 0.0746, 0.0570, 0.0523, 0.3679, 0.3373, 0.2973, 0.2391, 0.1967,
0:         0.1595, 0.1217, 0.1016, 0.0871, 0.3783, 0.3608, 0.3344, 0.2987, 0.2611, 0.2251, 0.1778], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0078,  0.0062,  0.0062,  0.0043, -0.0013, -0.0173,  0.0074,  0.0032, -0.0010, -0.0123, -0.0249, -0.0271,
0:         -0.0150,  0.0268,  0.0008,  0.0015, -0.0141, -0.0036, -0.0302,  0.0234,  0.0154,  0.0033, -0.0144, -0.0319,
0:          0.0189], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 32, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0487, -0.0845, -0.1117, -0.1307, -0.1429, -0.1513, -0.1592, -0.1685, -0.1789, -0.1887, -0.1965, -0.2017,
1:         -0.2040, -0.2032, -0.1997, -0.1938, -0.1861, -0.1774,  0.0410,  0.0057, -0.0234, -0.0454, -0.0607, -0.0726,
1:         -0.0852], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0562, -0.0547,  0.0916, -0.1106,  0.1642,  0.0687, -0.0449,  0.1268,  0.0707, -0.1671,  0.0985,  0.0730,
1:         -0.0927,  0.1461, -0.1822,  0.1701, -0.1161, -0.0719,  0.1280,  0.0756,  0.0625,  0.0612, -0.0641,  0.1457,
1:         -0.0716], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.5503, -0.5524, -0.5531, -0.5528, -0.5524, -0.5533, -0.5557, -0.5574, -0.5591, -0.5618, -0.5648, -0.5678,
1:         -0.5731, -0.5787, -0.5879, -0.5986, -0.6136, -0.6302, -0.5272, -0.5308, -0.5314, -0.5326, -0.5345, -0.5361,
1:         -0.5385], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.0926, 1.0868, 1.0797, 1.0713, 1.0613, 1.0479, 1.0301, 1.0086, 0.9844, 0.9588, 0.9328, 0.9078, 0.8844, 0.8630,
1:         0.8434, 0.8260, 0.8107, 0.7967, 0.7839, 0.7744, 0.7697, 0.7698, 0.7750, 0.7858, 0.8018], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460,
1:         -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460, -0.2460,
1:         -0.2460], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 32, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,  0.2272,     nan,     nan,     nan,     nan,     nan,     nan, -0.0490,
1:             nan,     nan,     nan,     nan, -0.0164,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:         -0.2466])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 32, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.3861, -0.3935, -0.3990, -0.4046, -0.4085, -0.4117, -0.4072, -0.3892, -0.3663, -0.3311, -0.2910, -0.2473,
1:         -0.2002, -0.1633, -0.1192, -0.0799, -0.0453, -0.0116, -0.3579, -0.3652, -0.3725, -0.3792, -0.3852, -0.3879,
1:         -0.3870], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.8018, 0.8346, 0.8664, 0.8960, 0.9279, 0.9614, 1.0015, 1.0446, 1.0952, 1.1505, 1.2129, 1.2813, 1.3548, 1.4333,
1:         1.5131, 1.5850, 1.6446, 1.6944, 0.8144, 0.8431, 0.8765, 0.9090, 0.9453, 0.9852, 1.0335], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.3081, -0.3160, -0.3239, -0.3366, -0.3503, -0.3658, -0.3840, -0.3999, -0.4139, -0.4264, -0.4374, -0.4494,
1:         -0.4599, -0.4727, -0.4837, -0.4934, -0.5007, -0.5082, -0.3284, -0.3370, -0.3463, -0.3596, -0.3742, -0.3903,
1:         -0.4094], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.3805, -0.0664,  0.2684,  0.5679,  0.8055,  0.9969,  1.1508,  1.2010,  1.1956,  1.1298,  0.9691,  0.8092,
1:          0.6953,  0.5913,  0.4743,  0.3739,  0.3016,  0.2485, -0.2568,  0.0360,  0.3233,  0.5441,  0.6987,  0.8123,
1:          0.9071], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.3774, -0.3441, -0.3173, -0.2964, -0.2771, -0.2579, -0.2346, -0.2076, -0.1797, -0.1557, -0.1366, -0.1252,
1:         -0.1207, -0.1206, -0.1240, -0.1298, -0.1383, -0.1484, -0.1565, -0.1617, -0.1646, -0.1673, -0.1745, -0.1864,
1:         -0.2037], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2081, -0.2036, -0.1928, -0.1832, -0.1761, -0.1671, -0.1656, -0.1624, -0.1589, -0.2089, -0.2037, -0.1989,
1:         -0.1901, -0.1862, -0.1852, -0.1777, -0.1735, -0.1721, -0.2085, -0.2026, -0.2028, -0.2017, -0.1968, -0.1970,
1:         -0.1901], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-7.0337e-04,  1.8064e-02,  2.2343e-02,  7.3585e-03,  3.2864e-03, -4.1114e-03, -1.4620e-02, -4.8596e-03,
1:         -9.0439e-03, -8.1897e-03, -6.4364e-03, -2.6881e-03, -4.6243e-03,  1.8972e-02,  4.0078e-03,  1.0438e-02,
1:         -1.0725e-02,  5.8383e-03, -1.4754e-02, -8.2260e-05,  1.6927e-03,  9.2704e-03, -8.3108e-03, -4.8532e-03,
1:          1.4417e-03], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 32 [1/5 (20%)]	Loss: 0.25819 : 0.20836 :: 0.02346 (1.88 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 32 [2/5 (40%)]	Loss: 0.23918 : 0.18928 :: 0.02195 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 32 [3/5 (60%)]	Loss: 0.24875 : 0.19355 :: 0.02258 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 32 [4/5 (80%)]	Loss: 0.19635 : 0.16255 :: 0.02299 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 32 : 0.21130025386810303
0: validation loss for velocity_u : 0.0038015996105968952
0: validation loss for velocity_v : 0.005101720802485943
0: validation loss for specific_humidity : 0.005930408835411072
0: validation loss for velocity_z : 0.11845520883798599
0: validation loss for temperature : 0.017354102805256844
0: validation loss for total_precip : 0.28242942690849304
0: validation loss for t2m : 1.046029806137085
1: 33 : 03:29:47 :: batch_size = 96, lr = 1e-05
0: 33 : 03:29:47 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 33, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.5215, 0.4965, 0.4783, 0.4778, 0.4783, 0.4374, 0.3632, 0.3053, 0.2734, 0.2362, 0.2257, 0.2818, 0.3167, 0.2916,
0:         0.2566, 0.2063, 0.1475, 0.1056, 0.4868, 0.4573, 0.4381, 0.4347, 0.4227, 0.3819, 0.3236], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.9915, 1.0819, 1.1617, 1.2101, 1.2161, 1.1649, 1.0493, 0.8940, 0.8157, 0.9272, 1.0471, 0.9834, 0.8753, 0.8147,
0:         0.7451, 0.6774, 0.6421, 0.6413, 1.0696, 1.1414, 1.1916, 1.1972, 1.1669, 1.0871, 0.9420], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.4050, -0.1510,  0.0653,  0.3655,  0.9036,  0.7077,  0.5474,  0.5280, -1.5016, -4.8895, -5.3135, -2.1990,
0:         -0.1833, -0.0316,  0.0663,  0.3418,  0.6712,  0.5420, -0.5180, -0.1478,  0.2622,  0.4785,  0.8799,  0.6550,
0:          0.5226], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2039, -0.0705, -0.2483, -0.2483, -0.2483,
0:         -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483,
0:         -0.2483], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 33, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 1.2632,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 33, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.4057, -0.3713, -0.3367, -0.3080, -0.2868, -0.2725, -0.2596, -0.2502, -0.2421, -0.2350, -0.2293, -0.2244,
0:         -0.2212, -0.2191, -0.2160, -0.2132, -0.2100, -0.2092, -0.4138, -0.3734, -0.3397, -0.3172, -0.3051, -0.3006,
0:         -0.2979], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.3170, -0.3227, -0.3349, -0.3496, -0.3635, -0.3758, -0.3771, -0.3688, -0.3446, -0.3045, -0.2473, -0.1749,
0:         -0.0912, -0.0026,  0.0829,  0.1643,  0.2285,  0.2757, -0.3537, -0.3596, -0.3697, -0.3798, -0.3888, -0.3925,
0:         -0.3852], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([2.7372, 2.9245, 3.1022, 3.2490, 3.3573, 3.4230, 3.4602, 3.4838, 3.5103, 3.5335, 3.5551, 3.5602, 3.5296, 3.4612,
0:         3.3523, 3.2196, 3.0834, 2.9777, 2.8242, 2.9949, 3.1413, 3.2512, 3.3163, 3.3531, 3.3592], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-1.2598, -1.3416, -1.0098, -0.5566, -0.6881, -1.0666, -0.9313, -0.8944, -1.0903, -0.9602, -0.8127, -0.7964,
0:         -0.7507, -0.6028, -0.5525, -0.8995, -1.1563, -1.0249, -1.0836, -0.7207, -0.3480, -0.1340, -0.3437, -0.6771,
0:         -0.5359], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.7673, -0.6824, -0.5813, -0.4778, -0.3930, -0.3401, -0.3184, -0.3022, -0.2605, -0.1777, -0.0677,  0.0425,
0:          0.1146,  0.1153,  0.0542, -0.0479, -0.1394, -0.1702, -0.1095,  0.0298,  0.2089,  0.3720,  0.4757,  0.5089,
0:          0.4847], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2115, -0.2282, -0.2391, -0.2462, -0.2546, -0.2545, -0.2542, -0.2527, -0.2469, -0.1982, -0.2182, -0.2314,
0:         -0.2432, -0.2479, -0.2552, -0.2497, -0.2524, -0.2478, -0.1873, -0.2051, -0.2213, -0.2335, -0.2443, -0.2489,
0:         -0.2502], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0090,  0.0120,  0.0115,  0.0057, -0.0044, -0.0207, -0.0101, -0.0193, -0.0041, -0.0195,  0.0060, -0.0055,
0:          0.0005,  0.0212,  0.0056,  0.0089, -0.0121, -0.0134, -0.0142,  0.0263,  0.0102, -0.0133, -0.0291, -0.0247,
0:          0.0050], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 33, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.5215, 0.4965, 0.4783, 0.4778, 0.4783, 0.4374, 0.3632, 0.3053, 0.2734, 0.2362, 0.2257, 0.2818, 0.3167, 0.2916,
1:         0.2566, 0.2063, 0.1475, 0.1056, 0.4868, 0.4573, 0.4381, 0.4347, 0.4227, 0.3819, 0.3236], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0097, -0.0044,  0.0928,  0.0445, -0.0110,  0.0932,  0.0817,  0.1135,  0.0625,  0.1865, -0.1055,  0.1192,
1:          0.0697, -0.0204, -0.0628,  0.1299,  0.0020,  0.0537,  0.0286,  0.2090,  0.0663, -0.0427,  0.0247,  0.1464,
1:          0.0153], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3913, -0.0280,  0.4501,  0.8742,  1.2925,  1.8088,  2.4001,  2.9060,  3.1595,  2.9452,  3.0065,  2.9992,
1:          2.9785,  2.8220,  2.6823,  2.7174,  2.8917,  3.0770, -0.0930,  0.5686,  0.9994,  1.2817,  1.6292,  2.0962,
1:          2.6361], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., 0., 0., -0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.3154, -0.3336, -0.2806, -0.1486, -0.0255,  0.0235, -0.0064, -0.0407,  0.0596,  0.2224,  0.2494,  0.1315,
1:         -0.0448, -0.1504, -0.1196, -0.1116, -0.1891, -0.2823, -0.3452, -0.3097, -0.1966, -0.0525,  0.0527,  0.0727,
1:          0.0577], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2039, -0.0705, -0.2483, -0.2483, -0.2483,
1:         -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483,
1:         -0.2483], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 33, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,  0.7662,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.6514,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 33, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.3571, -0.3562, -0.3576, -0.3636, -0.3614, -0.3531, -0.3328, -0.3132, -0.2989, -0.2933, -0.2926, -0.2927,
1:         -0.2867, -0.2791, -0.2698, -0.2610, -0.2595, -0.2629, -0.3829, -0.3739, -0.3737, -0.3821, -0.3909, -0.3932,
1:         -0.3869], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-7.0544e-01, -6.7253e-01, -6.1098e-01, -5.2927e-01, -4.5342e-01, -3.9789e-01, -3.6345e-01, -3.3324e-01,
1:         -2.9415e-01, -2.3544e-01, -1.5923e-01, -7.5428e-02, -2.9222e-04,  7.4191e-02,  1.5099e-01,  2.3604e-01,
1:          3.3218e-01,  4.3880e-01, -6.0085e-01, -5.3961e-01, -4.4821e-01, -3.5283e-01, -2.7677e-01, -2.4361e-01,
1:         -2.3954e-01], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([4.0836, 4.0168, 3.9482, 3.8864, 3.8406, 3.8125, 3.8025, 3.8030, 3.8137, 3.8156, 3.8059, 3.7893, 3.7686, 3.7594,
1:         3.7751, 3.8025, 3.8404, 3.8603, 4.0389, 3.9802, 3.9157, 3.8633, 3.8206, 3.7972, 3.7756], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.1841,  1.4771,  1.3819, -1.0431, -0.9135,  0.8249,  0.2232, -0.4775, -0.1299,  0.2217,  0.8791,  1.4797,
1:          1.2016, -0.0533, -0.6739,  0.1999,  0.8961,  0.7411,  0.6507,  1.2435,  0.7487, -1.5888, -0.8905,  1.2962,
1:          0.3280], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-2.5703, -2.6427, -2.6075, -2.4100, -2.0634, -1.6231, -1.1854, -0.8202, -0.5746, -0.4403, -0.3717, -0.3162,
1:         -0.2255, -0.0679,  0.1609,  0.4332,  0.6969,  0.8972,  0.9981,  0.9889,  0.8840,  0.7297,  0.5533,  0.3888,
1:          0.2524], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2496, -0.2554, -0.2516, -0.2529, -0.2467, -0.2484, -0.2461, -0.2415, -0.2393, -0.2531, -0.2579, -0.2551,
1:         -0.2585, -0.2539, -0.2565, -0.2532, -0.2500, -0.2489, -0.2563, -0.2579, -0.2599, -0.2604, -0.2590, -0.2583,
1:         -0.2576], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-2.4585e-04,  1.6060e-02,  1.1341e-03,  6.7218e-03, -3.2619e-03, -5.2069e-03, -6.3131e-03, -1.6032e-02,
1:         -1.3669e-02, -1.8817e-02, -1.0857e-02, -4.6952e-03,  1.1126e-02,  3.1407e-02,  6.3877e-03, -1.7244e-02,
1:          5.9031e-03,  1.8181e-02, -7.1376e-05, -4.1596e-03, -3.8761e-03,  9.1663e-03, -1.1223e-02, -2.5249e-02,
1:         -4.9459e-03], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 33 [1/5 (20%)]	Loss: 0.28041 : 0.21547 :: 0.02405 (1.85 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 33 [2/5 (40%)]	Loss: 0.29867 : 0.23880 :: 0.02325 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 33 [3/5 (60%)]	Loss: 0.22329 : 0.17767 :: 0.02246 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 33 [4/5 (80%)]	Loss: 0.22284 : 0.17732 :: 0.02297 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 33 : 0.19117289781570435
0: validation loss for velocity_u : 0.003834775649011135
0: validation loss for velocity_v : 0.005448261275887489
0: validation loss for specific_humidity : 0.006291085388511419
0: validation loss for velocity_z : 0.11469119787216187
0: validation loss for temperature : 0.018675491213798523
0: validation loss for total_precip : 0.24207670986652374
0: validation loss for t2m : 0.9471927285194397
1: 34 : 03:36:00 :: batch_size = 96, lr = 1e-05
0: 34 : 03:36:00 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 34, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.0423, -1.0452, -1.0464, -1.0459, -1.0439, -1.0408, -1.0363, -1.0300, -1.0212, -1.0102, -0.9973, -0.9836,
0:         -0.9696, -0.9556, -0.9417, -0.9271, -0.9115, -0.8953, -1.1197, -1.1186, -1.1152, -1.1095, -1.1015, -1.0916,
0:         -1.0804], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6539, -0.6634, -0.6738, -0.6852, -0.6974, -0.7107, -0.7246, -0.7400, -0.7565, -0.7746, -0.7945, -0.8158,
0:         -0.8381, -0.8612, -0.8842, -0.9063, -0.9272, -0.9475, -0.6379, -0.6432, -0.6497, -0.6573, -0.6660, -0.6757,
0:         -0.6864], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2950, 0.3441, 0.4244, 0.4824, 0.4801, 0.4333, 0.3842, 0.3641, 0.3864, 0.4400, 0.5024, 0.5582, 0.5917, 0.6006,
0:         0.5983, 0.6006, 0.6162, 0.6407, 0.0786, 0.1166, 0.1768, 0.2258, 0.2392, 0.2303, 0.2236], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1041, -0.1482, -0.1889, -0.2144, -0.2318, -0.2423, -0.2446, -0.2458, -0.2469, -0.0147, -0.1110, -0.2156,
0:         -0.2225, -0.2318, -0.2400, -0.2423, -0.2446, -0.2446,  0.0841, -0.0495, -0.2040, -0.2109, -0.2179, -0.2214,
0:         -0.2225], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 34, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan, -0.4497,     nan,     nan, -0.4670,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.2657,     nan,
0:         -0.1676])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 34, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([1.6192, 1.6353, 1.6387, 1.6433, 1.6442, 1.6462, 1.6465, 1.6436, 1.6381, 1.6334, 1.6308, 1.6252, 1.6187, 1.6092,
0:         1.5967, 1.5885, 1.5905, 1.6024, 1.7325, 1.7577, 1.7740, 1.7849, 1.7962, 1.8050, 1.8099], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.4396, 0.4267, 0.4192, 0.4101, 0.3983, 0.3812, 0.3624, 0.3404, 0.3158, 0.2872, 0.2543, 0.2177, 0.1790, 0.1388,
0:         0.0979, 0.0637, 0.0355, 0.0131, 0.5486, 0.5371, 0.5296, 0.5197, 0.5045, 0.4883, 0.4674], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.0359, -0.0035,  0.0272,  0.0533,  0.0641,  0.0584,  0.0321, -0.0131, -0.0793, -0.1575, -0.2486, -0.3435,
0:         -0.4377, -0.5219, -0.5922, -0.6468, -0.6860, -0.7108, -0.0086,  0.0074,  0.0234,  0.0343,  0.0373,  0.0271,
0:          0.0053], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.2282, -0.2487, -0.2528, -0.2537, -0.2253, -0.2016, -0.1960, -0.1823, -0.1658, -0.1577, -0.1501, -0.1116,
0:         -0.0799, -0.0741, -0.0741, -0.0845, -0.0893, -0.0964, -0.1844, -0.2060, -0.2091, -0.2342, -0.2247, -0.1961,
0:         -0.1760], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.0130, 1.0220, 1.0312, 1.0408, 1.0521, 1.0645, 1.0753, 1.0829, 1.0873, 1.0902, 1.0919, 1.0973, 1.1075, 1.1227,
0:         1.1420, 1.1607, 1.1777, 1.1925, 1.2065, 1.2212, 1.2379, 1.2555, 1.2727, 1.2885, 1.3025], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.0500, -0.0484, -0.0481, -0.0487, -0.0588, -0.0747, -0.0981, -0.1211, -0.1201, -0.0931, -0.0810, -0.0749,
0:         -0.0737, -0.0672, -0.0746, -0.0796, -0.0986, -0.1138, -0.1440, -0.1388, -0.1278, -0.1019, -0.0895, -0.0693,
0:         -0.0698], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-6.6995e-03, -1.3517e-02, -1.7232e-03,  1.0346e-02,  9.6951e-04, -3.1866e-02, -1.0626e-02, -8.4876e-03,
0:         -1.8418e-02, -3.7770e-02, -2.4594e-02, -2.0224e-02, -2.6327e-03,  8.9391e-05,  9.5193e-03,  6.0890e-04,
0:         -1.9380e-02,  6.0715e-03, -2.5973e-02,  3.5129e-03,  1.2596e-02, -1.1412e-03, -2.7528e-02, -4.0404e-02,
0:         -9.3208e-03], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 34, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.2616, 0.2659, 0.2685, 0.2703, 0.2729, 0.2772, 0.2830, 0.2913, 0.3014, 0.3103, 0.3161, 0.3196, 0.3223, 0.3266,
1:         0.3331, 0.3419, 0.3522, 0.3615, 0.3078, 0.3145, 0.3210, 0.3275, 0.3344, 0.3419, 0.3511], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0269,  0.1298,  0.0432,  0.1404, -0.0335, -0.0051,  0.0195, -0.1069,  0.1538,  0.0540, -0.1558,  0.1048,
1:          0.0518,  0.1896,  0.0192, -0.0441, -0.0378, -0.0348,  0.0916, -0.1924,  0.0152, -0.0117, -0.0901, -0.0376,
1:         -0.1018], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3256, -0.3227, -0.3120, -0.2989, -0.2764, -0.2470, -0.2180, -0.1924, -0.1690, -0.1495, -0.1413, -0.1310,
1:         -0.1305, -0.1352, -0.1446, -0.1631, -0.1821, -0.2034, -0.3253, -0.3224, -0.3176, -0.3073, -0.2896, -0.2690,
1:         -0.2400], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.7938, 1.7717, 1.7491, 1.7244, 1.6976, 1.6729, 1.6538, 1.6379, 1.6251, 1.6148, 1.5977, 1.5670, 1.5212, 1.4665,
1:         1.4093, 1.3487, 1.2840, 1.2215, 1.1616, 1.1084, 1.0616, 1.0127, 0.9600, 0.9090, 0.8625], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2396, -0.2396, -0.2075, -0.1961, -0.1755,  0.0463,  0.1903,  0.0486, -0.0383, -0.2418, -0.2418, -0.2418,
1:         -0.2396, -0.2304, -0.2281, -0.0841,  0.0806,  0.0691, -0.2418, -0.2418, -0.2396, -0.2418, -0.2418, -0.2373,
1:         -0.2373], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 34, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan, 0.7367,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.6439,    nan,    nan,
1:            nan, 0.5740, 0.5623,    nan,    nan, 0.5288,    nan,    nan,    nan,    nan, 0.4458])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 34, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.3612, 0.3587, 0.3513, 0.3411, 0.3290, 0.3177, 0.3088, 0.3007, 0.2948, 0.2865, 0.2776, 0.2723, 0.2655, 0.2593,
1:         0.2574, 0.2549, 0.2537, 0.2519, 0.4112, 0.4067, 0.3980, 0.3875, 0.3751, 0.3644, 0.3570], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.0504,  0.0108, -0.0342, -0.0732, -0.0981, -0.1083, -0.0953, -0.0653, -0.0240,  0.0132,  0.0377,  0.0353,
1:          0.0093, -0.0434, -0.1032, -0.1664, -0.2259, -0.2785,  0.0073, -0.0444, -0.0926, -0.1289, -0.1505, -0.1598,
1:         -0.1475], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([1.8150, 1.8388, 1.8499, 1.8479, 1.8293, 1.8049, 1.7622, 1.7178, 1.6645, 1.6118, 1.5667, 1.5321, 1.5159, 1.5152,
1:         1.5210, 1.5327, 1.5392, 1.5344, 1.8011, 1.8281, 1.8472, 1.8510, 1.8461, 1.8303, 1.7984], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.1755,  0.2440,  0.3316,  0.3861,  0.4024,  0.4054,  0.3337,  0.1631,  0.0130, -0.0808, -0.1519, -0.1814,
1:         -0.1677, -0.0810,  0.0484,  0.1565,  0.2442,  0.2688,  0.0491,  0.0667,  0.1187,  0.1587,  0.1974,  0.2513,
1:          0.2493], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.8595, 0.8653, 0.8650, 0.8560, 0.8448, 0.8328, 0.8241, 0.8198, 0.8195, 0.8222, 0.8280, 0.8380, 0.8553, 0.8783,
1:         0.9077, 0.9357, 0.9622, 0.9867, 1.0136, 1.0435, 1.0725, 1.1026, 1.1293, 1.1556, 1.1848], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2268, -0.2294, -0.2275, -0.2232, -0.2149, -0.2091, -0.2041, -0.1955, -0.1937, -0.2353, -0.2377, -0.2367,
1:         -0.2360, -0.2274, -0.2261, -0.2185, -0.2138, -0.2119, -0.2400, -0.2400, -0.2434, -0.2436, -0.2412, -0.2342,
1:         -0.2339], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0039, -0.0029, -0.0110,  0.0063, -0.0087, -0.0133, -0.0149, -0.0129, -0.0163, -0.0280, -0.0264, -0.0144,
1:         -0.0073,  0.0044, -0.0090, -0.0261, -0.0037,  0.0229, -0.0024, -0.0001, -0.0170, -0.0058, -0.0033, -0.0336,
1:         -0.0011], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 34 [1/5 (20%)]	Loss: 0.24352 : 0.21743 :: 0.02343 (1.64 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 34 [2/5 (40%)]	Loss: 0.31184 : 0.23334 :: 0.02148 (8.46 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 34 [3/5 (60%)]	Loss: 0.31121 : 0.22487 :: 0.02267 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 34 [4/5 (80%)]	Loss: 0.28918 : 0.21340 :: 0.02253 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 34 : 0.19941163063049316
0: validation loss for velocity_u : 0.003415151499211788
0: validation loss for velocity_v : 0.0047420309856534
0: validation loss for specific_humidity : 0.00630228454247117
0: validation loss for velocity_z : 0.10354258120059967
0: validation loss for temperature : 0.018869727849960327
0: validation loss for total_precip : 0.2527247369289398
0: validation loss for t2m : 1.0062849521636963
1: 35 : 03:41:58 :: batch_size = 96, lr = 1e-05
0: 35 : 03:41:58 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 35, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.7342, -0.7400, -0.7456, -0.7508, -0.7558, -0.7605, -0.7648, -0.7687, -0.7724, -0.7758, -0.7789, -0.7818,
1:         -0.7847, -0.7873, -0.7896, -0.7919, -0.7939, -0.7956, -0.6954, -0.7027, -0.7098, -0.7165, -0.7230, -0.7293,
1:         -0.7353], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.1147,  0.0533,  0.0214,  0.1515,  0.0084,  0.0010,  0.0650, -0.0897,  0.0447, -0.1092,  0.1017, -0.0178,
1:         -0.0394, -0.0434,  0.0982, -0.0927, -0.1631,  0.0124, -0.1881,  0.0611, -0.0239, -0.1070, -0.0908, -0.1057,
1:         -0.1733], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.5456, -0.5470, -0.5485, -0.5465, -0.5443, -0.5423, -0.5401, -0.5367, -0.5332, -0.5298, -0.5264, -0.5242,
1:         -0.5220, -0.5197, -0.5177, -0.5160, -0.5144, -0.5127, -0.5493, -0.5524, -0.5533, -0.5522, -0.5512, -0.5500,
1:         -0.5487], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.3236, 1.3117, 1.3011, 1.2914, 1.2830, 1.2753, 1.2685, 1.2628, 1.2577, 1.2536, 1.2498, 1.2464, 1.2434, 1.2405,
1:         1.2379, 1.2354, 1.2331, 1.2310, 1.2289, 1.2268, 1.2246, 1.2223, 1.2193, 1.2163, 1.2127], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2201, -0.2189, -0.2178, -0.2167, -0.2144, -0.2133, -0.2111, -0.2111, -0.2111, -0.2234, -0.2223, -0.2212,
1:         -0.2201, -0.2201, -0.2189, -0.2178, -0.2167, -0.2156, -0.2268, -0.2245, -0.2234, -0.2223, -0.2201, -0.2201,
1:         -0.2189], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 35, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan, -0.8323,     nan,     nan,     nan, -0.9464,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 35, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.7334, -0.7350, -0.7382, -0.7424, -0.7431, -0.7405, -0.7326, -0.7226, -0.7099, -0.7003, -0.6910, -0.6827,
1:         -0.6723, -0.6620, -0.6516, -0.6404, -0.6265, -0.6109, -0.7136, -0.7133, -0.7142, -0.7133, -0.7128, -0.7064,
1:         -0.6946], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-1.8658, -1.8569, -1.8527, -1.8540, -1.8552, -1.8618, -1.8659, -1.8747, -1.8813, -1.8903, -1.8983, -1.9044,
1:         -1.9088, -1.9141, -1.9200, -1.9268, -1.9331, -1.9347, -1.9021, -1.8955, -1.8885, -1.8856, -1.8822, -1.8804,
1:         -1.8781], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6529, -0.6552, -0.6568, -0.6566, -0.6559, -0.6560, -0.6551, -0.6545, -0.6546, -0.6539, -0.6543, -0.6537,
1:         -0.6535, -0.6532, -0.6527, -0.6518, -0.6500, -0.6483, -0.6564, -0.6587, -0.6594, -0.6591, -0.6590, -0.6590,
1:         -0.6587], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.2130, 0.1661, 0.1438, 0.1440, 0.1344, 0.1495, 0.1784, 0.1703, 0.1720, 0.1712, 0.1723, 0.2282, 0.2803, 0.3200,
1:         0.3686, 0.3956, 0.4160, 0.4225, 0.2220, 0.1654, 0.1470, 0.1538, 0.1476, 0.1696, 0.1773], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.0360, 1.0562, 1.0787, 1.1014, 1.1262, 1.1514, 1.1750, 1.1961, 1.2140, 1.2289, 1.2426, 1.2547, 1.2673, 1.2807,
1:         1.2950, 1.3089, 1.3211, 1.3306, 1.3420, 1.3538, 1.3675, 1.3813, 1.3932, 1.4019, 1.4075], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2335, -0.2372, -0.2375, -0.2386, -0.2409, -0.2402, -0.2377, -0.2381, -0.2313, -0.2395, -0.2396, -0.2377,
1:         -0.2434, -0.2389, -0.2428, -0.2343, -0.2338, -0.2269, -0.2391, -0.2397, -0.2357, -0.2334, -0.2299, -0.2276,
1:         -0.2220], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0182, -0.0184, -0.0103, -0.0094, -0.0199, -0.0233, -0.0247, -0.0366, -0.0364, -0.0290, -0.0440, -0.0290,
1:         -0.0119, -0.0006, -0.0189, -0.0133, -0.0186, -0.0067, -0.0191, -0.0256, -0.0264, -0.0198, -0.0174, -0.0495,
1:         -0.0283], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 35, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.7342, -0.7400, -0.7456, -0.7508, -0.7558, -0.7605, -0.7648, -0.7687, -0.7724, -0.7758, -0.7789, -0.7818,
0:         -0.7847, -0.7873, -0.7896, -0.7919, -0.7939, -0.7956, -0.6954, -0.7027, -0.7098, -0.7165, -0.7230, -0.7293,
0:         -0.7353], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6394, -0.6417, -0.6451, -0.6502, -0.6563, -0.6632, -0.6708, -0.6785, -0.6860, -0.6928, -0.6989, -0.7037,
0:         -0.7078, -0.7105, -0.7121, -0.7127, -0.7119, -0.7101, -0.6710, -0.6681, -0.6665, -0.6663, -0.6673, -0.6698,
0:         -0.6734], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2602, -0.2450, -0.2321, -0.2191, -0.2104, -0.1996, -0.1910, -0.1801, -0.1693, -0.1563, -0.1434, -0.1282,
0:         -0.1152, -0.1066, -0.0979, -0.0958, -0.0936, -0.0914, -0.2342, -0.2212, -0.2061, -0.1910, -0.1715, -0.1498,
0:         -0.1260], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2201, -0.2189, -0.2178, -0.2167, -0.2144, -0.2133, -0.2111, -0.2111, -0.2111, -0.2234, -0.2223, -0.2212,
0:         -0.2201, -0.2201, -0.2189, -0.2178, -0.2167, -0.2156, -0.2268, -0.2245, -0.2234, -0.2223, -0.2201, -0.2201,
0:         -0.2189], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 35, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([0.3846,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 35, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([ 0.0853,  0.0804,  0.0756,  0.0707,  0.0621,  0.0519,  0.0437,  0.0363,  0.0285,  0.0224,  0.0137,  0.0045,
0:         -0.0075, -0.0183, -0.0302, -0.0408, -0.0515, -0.0644,  0.1572,  0.1534,  0.1486,  0.1404,  0.1296,  0.1167,
0:          0.1055], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.6258, -0.6300, -0.6327, -0.6333, -0.6319, -0.6295, -0.6231, -0.6168, -0.6066, -0.5964, -0.5845, -0.5744,
0:         -0.5651, -0.5571, -0.5488, -0.5403, -0.5275, -0.5102, -0.5780, -0.5789, -0.5744, -0.5696, -0.5631, -0.5575,
0:         -0.5486], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6158, -0.6150, -0.6148, -0.6139, -0.6112, -0.6098, -0.6083, -0.6062, -0.6043, -0.6028, -0.6010, -0.6003,
0:         -0.5996, -0.6000, -0.6004, -0.5996, -0.5989, -0.5964, -0.6074, -0.6066, -0.6076, -0.6073, -0.6068, -0.6066,
0:         -0.6069], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.3180, 0.2933, 0.3611, 0.4425, 0.5310, 0.6288, 0.6714, 0.6875, 0.7659, 0.8523, 0.8931, 0.9305, 0.9579, 0.9497,
0:         0.9621, 1.0083, 1.0379, 1.0691, 0.2135, 0.1787, 0.2285, 0.2943, 0.3799, 0.5027, 0.5692], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.5675, 1.5853, 1.6003, 1.6117, 1.6217, 1.6319, 1.6422, 1.6521, 1.6617, 1.6694, 1.6762, 1.6802, 1.6834, 1.6860,
0:         1.6883, 1.6895, 1.6910, 1.6940, 1.6996, 1.7066, 1.7128, 1.7158, 1.7158, 1.7150, 1.7146], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2319, -0.2324, -0.2311, -0.2314, -0.2329, -0.2340, -0.2338, -0.2351, -0.2279, -0.2306, -0.2298, -0.2247,
0:         -0.2293, -0.2253, -0.2286, -0.2291, -0.2305, -0.2316, -0.2280, -0.2260, -0.2228, -0.2214, -0.2207, -0.2210,
0:         -0.2247], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0261, -0.0057, -0.0219, -0.0174, -0.0278, -0.0556, -0.0222, -0.0247, -0.0231, -0.0205, -0.0454, -0.0170,
0:         -0.0226, -0.0195, -0.0185, -0.0284, -0.0377, -0.0268, -0.0241,  0.0057,  0.0010, -0.0393, -0.0366, -0.0453,
0:         -0.0065], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 35 [1/5 (20%)]	Loss: 0.26693 : 0.20703 :: 0.02425 (1.80 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 35 [2/5 (40%)]	Loss: 0.30993 : 0.23201 :: 0.02156 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 35 [3/5 (60%)]	Loss: 0.27035 : 0.20738 :: 0.02166 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 35 [4/5 (80%)]	Loss: 0.24630 : 0.18790 :: 0.02490 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 35 : 0.2181723713874817
0: validation loss for velocity_u : 0.0033757872879505157
0: validation loss for velocity_v : 0.004749141167849302
0: validation loss for specific_humidity : 0.006516872905194759
0: validation loss for velocity_z : 0.10853105783462524
0: validation loss for temperature : 0.020832736045122147
0: validation loss for total_precip : 0.31523457169532776
0: validation loss for t2m : 1.0679662227630615
1: 36 : 03:48:12 :: batch_size = 96, lr = 1e-05
0: 36 : 03:48:12 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 36, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.4487, 1.4127, 1.3841, 1.3742, 1.3800, 1.4023, 1.4375, 1.4778, 1.5223, 1.5574, 1.5757, 1.5868, 1.5933, 1.5974,
1:         1.6032, 1.6096, 1.6148, 1.5986, 1.4833, 1.4539, 1.4471, 1.4633, 1.4909, 1.5244, 1.5645], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0460, -0.0636, -0.0711,  0.3150,  0.0414, -0.1524,  0.0293,  0.1634, -0.0089,  0.0797,  0.0428,  0.0034,
1:         -0.0338, -0.0862, -0.0263,  0.0352, -0.1758, -0.1057, -0.0033,  0.0175, -0.1074,  0.0299,  0.0215,  0.0916,
1:         -0.0163], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.6938, 1.7363, 1.7804, 1.8244, 1.8699, 1.9121, 1.9583, 2.0027, 2.0517, 2.0975, 2.1392, 2.1712, 2.1981, 2.2229,
1:         2.2617, 2.2908, 2.3115, 2.3067, 1.8103, 1.8631, 1.9109, 1.9538, 1.9942, 2.0483, 2.0837], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.2515, 1.2603, 1.2592, 1.2634, 1.2824, 1.3202, 1.3603, 1.3871, 1.4068, 1.4285, 1.4491, 1.4654, 1.4815, 1.5003,
1:         1.5173, 1.5265, 1.5191, 1.4850, 1.4213, 1.3480, 1.2961, 1.2689, 1.2640, 1.2858, 1.3244], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495,
1:         -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495,
1:         -0.2495], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 36, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan, -0.2225,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 36, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.7484, 0.7245, 0.7019, 0.6828, 0.6686, 0.6622, 0.6699, 0.6876, 0.7172, 0.7575, 0.8048, 0.8569, 0.9080, 0.9475,
1:         0.9802, 1.0051, 1.0227, 1.0367, 0.7835, 0.7674, 0.7499, 0.7314, 0.7122, 0.6987, 0.6953], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([1.0661, 1.0934, 1.1178, 1.1338, 1.1386, 1.1307, 1.1039, 1.0651, 1.0182, 0.9613, 0.9042, 0.8518, 0.8002, 0.7549,
1:         0.7113, 0.6674, 0.6258, 0.5809, 1.0834, 1.1116, 1.1307, 1.1382, 1.1339, 1.1162, 1.0860], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.5039, -0.5039, -0.4915, -0.4692, -0.4419, -0.4147, -0.3902, -0.3689, -0.3505, -0.3344, -0.3184, -0.3028,
1:         -0.2855, -0.2688, -0.2517, -0.2352, -0.2194, -0.2055, -0.5066, -0.5090, -0.5023, -0.4855, -0.4640, -0.4426,
1:         -0.4217], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.6039, 0.5820, 0.5887, 0.6520, 0.7447, 0.7513, 0.7395, 0.8047, 0.8834, 0.9642, 1.0254, 1.0366, 0.9852, 0.9670,
1:         1.0360, 1.1486, 1.3238, 1.4303, 0.5467, 0.5534, 0.5963, 0.6168, 0.6770, 0.6898, 0.6672], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.1546, 1.1839, 1.2136, 1.2438, 1.2763, 1.3102, 1.3475, 1.3879, 1.4337, 1.4828, 1.5324, 1.5794, 1.6179, 1.6489,
1:         1.6714, 1.6873, 1.6985, 1.7091, 1.7250, 1.7439, 1.7667, 1.7934, 1.8222, 1.8536, 1.8886], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2459, -0.2438, -0.2394, -0.2387, -0.2398, -0.2425, -0.2458, -0.2462, -0.2437, -0.2503, -0.2460, -0.2402,
1:         -0.2398, -0.2404, -0.2431, -0.2474, -0.2487, -0.2488, -0.2502, -0.2453, -0.2434, -0.2393, -0.2404, -0.2411,
1:         -0.2445], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0324, -0.0266, -0.0359, -0.0286, -0.0279, -0.0309, -0.0091, -0.0519, -0.0236, -0.0473, -0.0366, -0.0394,
1:         -0.0100, -0.0219, -0.0391, -0.0323, -0.0138, -0.0069, -0.0189, -0.0232, -0.0266, -0.0250, -0.0111, -0.0525,
1:         -0.0185], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 36, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.4487, 1.4127, 1.3841, 1.3742, 1.3800, 1.4023, 1.4375, 1.4778, 1.5223, 1.5574, 1.5757, 1.5868, 1.5933, 1.5974,
0:         1.6032, 1.6096, 1.6148, 1.5986, 1.4833, 1.4539, 1.4471, 1.4633, 1.4909, 1.5244, 1.5645], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.8935, 1.8663, 1.8022, 1.7155, 1.6235, 1.5355, 1.4517, 1.3671, 1.2849, 1.2128, 1.1489, 1.0888, 1.0283, 0.9555,
0:         0.8721, 0.7859, 0.6992, 0.6185, 2.0372, 2.0237, 1.9779, 1.9095, 1.8330, 1.7566, 1.6759], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-3.1261, -2.9687, -2.8711, -2.7070, -2.6050, -2.6250, -2.5606, -2.4054, -2.2214, -2.0019, -1.7446, -1.4896,
0:         -1.2169, -0.7867, -0.4031, -0.4785, -0.9308, -1.5074, -3.5031, -3.7492, -3.8312, -3.6827, -3.2924, -2.8489,
0:         -2.4365], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495,
0:         -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495, -0.2495,
0:         -0.2495], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 36, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:         0.6990,    nan,    nan, 0.9942,    nan,    nan,    nan,    nan,    nan, 1.0555,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 36, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([1.8298, 1.8999, 1.9820, 2.0741, 2.1729, 2.2717, 2.3665, 2.4521, 2.5194, 2.5746, 2.6137, 2.6423, 2.6568, 2.6625,
0:         2.6588, 2.6477, 2.6336, 2.6170, 1.7431, 1.8083, 1.8798, 1.9616, 2.0495, 2.1428, 2.2338], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-2.2403e-01, -1.1961e-01, -2.0346e-03,  1.2994e-01,  2.6376e-01,  3.8951e-01,  5.0380e-01,  6.0339e-01,
0:          6.8607e-01,  7.7253e-01,  8.7580e-01,  1.0046e+00,  1.1691e+00,  1.3626e+00,  1.5740e+00,  1.7816e+00,
0:          1.9728e+00,  2.1327e+00, -3.2035e-01, -2.0573e-01, -6.5598e-02,  8.2367e-02,  2.2791e-01,  3.6809e-01,
0:          4.8641e-01], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([0.9899, 1.1597, 1.2721, 1.3277, 1.3236, 1.2760, 1.2120, 1.1539, 1.1138, 1.1058, 1.1239, 1.1607, 1.2104, 1.2678,
0:         1.3245, 1.3684, 1.4079, 1.4329, 1.2061, 1.3942, 1.5200, 1.5775, 1.5610, 1.4991, 1.4247], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.4891, -1.5752, -1.6185, -1.5769, -1.2910, -0.5952, -0.2576, -0.1345,  0.0919,  0.3475,  0.5777,  0.6339,
0:          0.4971,  0.4567,  0.4279,  0.3070,  0.2326,  0.0859, -0.4090, -1.3448, -1.3195, -1.4185, -1.3079, -0.7578,
0:         -0.4545], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.9843, 2.0164, 2.0660, 2.1265, 2.1871, 2.2364, 2.2668, 2.2783, 2.2718, 2.2507, 2.2158, 2.1684, 2.1106, 2.0494,
0:         1.9941, 1.9444, 1.9012, 1.8602, 1.8208, 1.7839, 1.7505, 1.7265, 1.7083, 1.6970, 1.6925], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2413, -0.2400, -0.2356, -0.2340, -0.2355, -0.2393, -0.2429, -0.2486, -0.2458, -0.2401, -0.2368, -0.2310,
0:         -0.2305, -0.2294, -0.2350, -0.2415, -0.2440, -0.2502, -0.2404, -0.2382, -0.2334, -0.2284, -0.2289, -0.2321,
0:         -0.2384], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0219, -0.0097, -0.0349, -0.0239, -0.0320, -0.0498, -0.0305, -0.0271, -0.0204, -0.0432, -0.0503, -0.0333,
0:         -0.0272, -0.0295, -0.0203, -0.0274, -0.0424, -0.0128, -0.0254, -0.0081, -0.0159, -0.0393, -0.0280, -0.0428,
0:         -0.0173], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 36 [1/5 (20%)]	Loss: 0.27156 : 0.23286 :: 0.02274 (1.76 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 36 [2/5 (40%)]	Loss: 0.28430 : 0.19746 :: 0.02229 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 36 [3/5 (60%)]	Loss: 0.24771 : 0.19575 :: 0.02328 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 36 [4/5 (80%)]	Loss: 0.26286 : 0.20599 :: 0.02174 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 36 : 0.2072131335735321
0: validation loss for velocity_u : 0.003693720791488886
0: validation loss for velocity_v : 0.0051030730828642845
0: validation loss for specific_humidity : 0.006931565701961517
0: validation loss for velocity_z : 0.11062681674957275
0: validation loss for temperature : 0.020457934588193893
0: validation loss for total_precip : 0.3078051805496216
0: validation loss for t2m : 0.9958735704421997
1: 37 : 03:54:20 :: batch_size = 96, lr = 1e-05
0: 37 : 03:54:20 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 37, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.5335, 1.5443, 1.5509, 1.5536, 1.5529, 1.5496, 1.5452, 1.5423, 1.5410, 1.5393, 1.5366, 1.5325, 1.5270, 1.5192,
0:         1.5091, 1.4954, 1.4765, 1.4515, 1.5477, 1.5607, 1.5710, 1.5794, 1.5865, 1.5917, 1.5965], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1341, -0.1312, -0.1146, -0.0830, -0.0368,  0.0221,  0.0925,  0.1730,  0.2625,  0.3602,  0.4651,  0.5754,
0:          0.6884,  0.8018,  0.9121,  1.0160,  1.1104,  1.1938, -0.0909, -0.0895, -0.0771, -0.0526, -0.0150,  0.0359,
0:          0.1001], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2032, 0.2806, 0.3591, 0.4443, 0.5240, 0.5494, 0.5018, 0.4067, 0.3005, 0.2043, 0.1445, 0.1368, 0.1722, 0.2275,
0:         0.2850, 0.3370, 0.3934, 0.4742, 0.1611, 0.2596, 0.3470, 0.4111, 0.4609, 0.4797, 0.4487], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2480, -0.2491, -0.2503, -0.2503, -0.2526, -0.2526, -0.2514, -0.2468, -0.2422, -0.2526, -0.2537, -0.2526,
0:         -0.2526, -0.2503, -0.2491, -0.2491, -0.2457, -0.2410, -0.2514, -0.2491, -0.2480, -0.2468, -0.2468, -0.2457,
0:         -0.2457], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 37, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 37, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([1.2939, 1.2659, 1.2463, 1.2393, 1.2415, 1.2454, 1.2503, 1.2486, 1.2464, 1.2385, 1.2285, 1.2161, 1.2037, 1.1835,
0:         1.1623, 1.1377, 1.1091, 1.0849, 1.2597, 1.2332, 1.2133, 1.2091, 1.2114, 1.2166, 1.2208], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-1.5285, -1.4617, -1.3926, -1.3265, -1.2624, -1.2045, -1.1486, -1.0965, -1.0484, -1.0054, -0.9646, -0.9323,
0:         -0.9043, -0.8828, -0.8679, -0.8544, -0.8426, -0.8245, -1.5044, -1.4303, -1.3540, -1.2865, -1.2233, -1.1679,
0:         -1.1166], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.4424, -0.4470, -0.4425, -0.4338, -0.4202, -0.4029, -0.3816, -0.3593, -0.3369, -0.3167, -0.2962, -0.2768,
0:         -0.2570, -0.2343, -0.2113, -0.1897, -0.1693, -0.1550, -0.3932, -0.3857, -0.3739, -0.3612, -0.3445, -0.3253,
0:         -0.3080], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.1140,  0.1521,  0.1618,  0.1673,  0.0969, -0.0004,  0.0236,  0.0694,  0.1198,  0.1684,  0.1347,  0.1778,
0:          0.2713,  0.2891,  0.3029,  0.3242,  0.3125,  0.2539,  0.0469,  0.0858,  0.0997,  0.1009,  0.0478, -0.0277,
0:          0.0507], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([ 0.2147,  0.2210,  0.2275,  0.2279,  0.2236,  0.2099,  0.1934,  0.1805,  0.1754,  0.1774,  0.1808,  0.1796,
0:          0.1728,  0.1590,  0.1436,  0.1261,  0.1041,  0.0780,  0.0509,  0.0229, -0.0066, -0.0360, -0.0659, -0.0985,
0:         -0.1356], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1415, -0.1408, -0.1414, -0.1405, -0.1391, -0.1414, -0.1402, -0.1374, -0.1322, -0.1602, -0.1579, -0.1544,
0:         -0.1565, -0.1547, -0.1557, -0.1511, -0.1491, -0.1458, -0.1766, -0.1780, -0.1757, -0.1714, -0.1702, -0.1714,
0:         -0.1698], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0284, -0.0296, -0.0280, -0.0100, -0.0305, -0.0407, -0.0370, -0.0447, -0.0174, -0.0313, -0.0269, -0.0380,
0:         -0.0274, -0.0350, -0.0157, -0.0400, -0.0399, -0.0385, -0.0065, -0.0131, -0.0282, -0.0611, -0.0228, -0.0385,
0:         -0.0152], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 37, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.5335, 1.5443, 1.5509, 1.5536, 1.5529, 1.5496, 1.5452, 1.5423, 1.5410, 1.5393, 1.5366, 1.5325, 1.5270, 1.5192,
1:         1.5091, 1.4954, 1.4765, 1.4515, 1.5477, 1.5607, 1.5710, 1.5794, 1.5865, 1.5917, 1.5965], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0321,  0.1559, -0.0364, -0.0128,  0.0312,  0.0025,  0.0092, -0.0027, -0.0546, -0.1071, -0.0072, -0.0619,
1:         -0.1519,  0.0829, -0.0157, -0.0446,  0.0621, -0.0024, -0.1661,  0.0293, -0.0288,  0.0173, -0.0493, -0.0411,
1:         -0.0053], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.8297, -0.8319, -0.8331, -0.8337, -0.8337, -0.8337, -0.8334, -0.8332, -0.8331, -0.8333, -0.8338, -0.8347,
1:         -0.8360, -0.8377, -0.8397, -0.8415, -0.8432, -0.8439, -0.8285, -0.8311, -0.8328, -0.8342, -0.8345, -0.8348,
1:         -0.8349], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.8287, 0.8483, 0.8665, 0.8829, 0.8996, 0.9169, 0.9330, 0.9459, 0.9552, 0.9611, 0.9639, 0.9655, 0.9672, 0.9692,
1:         0.9705, 0.9713, 0.9713, 0.9695, 0.9658, 0.9607, 0.9548, 0.9490, 0.9449, 0.9427, 0.9410], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2480, -0.2491, -0.2503, -0.2503, -0.2526, -0.2526, -0.2514, -0.2468, -0.2422, -0.2526, -0.2537, -0.2526,
1:         -0.2526, -0.2503, -0.2491, -0.2491, -0.2457, -0.2410, -0.2514, -0.2491, -0.2480, -0.2468, -0.2468, -0.2457,
1:         -0.2457], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 37, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.6735,     nan,
1:             nan, -0.7940, -0.8514, -0.9146,     nan, -1.0340,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 37, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([1.1287, 1.1134, 1.0996, 1.0872, 1.0777, 1.0658, 1.0549, 1.0395, 1.0215, 0.9953, 0.9680, 0.9398, 0.9130, 0.8881,
1:         0.8700, 0.8511, 0.8288, 0.8067, 1.1691, 1.1532, 1.1388, 1.1306, 1.1233, 1.1168, 1.1085], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.7675, 0.7815, 0.7925, 0.7992, 0.8087, 0.8238, 0.8413, 0.8575, 0.8697, 0.8790, 0.8842, 0.8905, 0.8986, 0.9079,
1:         0.9190, 0.9290, 0.9394, 0.9448, 0.6567, 0.6588, 0.6622, 0.6620, 0.6696, 0.6797, 0.6906], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.8315, -0.8335, -0.8349, -0.8362, -0.8362, -0.8365, -0.8366, -0.8364, -0.8354, -0.8350, -0.8360, -0.8369,
1:         -0.8383, -0.8419, -0.8451, -0.8475, -0.8484, -0.8475, -0.8365, -0.8384, -0.8400, -0.8402, -0.8401, -0.8395,
1:         -0.8387], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.7027, -0.5743, -0.5490, -0.5479, -0.4827, -0.6118, -0.9146, -1.1133, -1.2050, -1.2372, -1.2013, -1.1693,
1:         -1.0731, -0.9003, -0.7653, -0.7303, -0.7697, -0.7879, -0.7659, -0.7145, -0.6577, -0.6066, -0.5827, -0.7109,
1:         -0.9203], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.9640, 0.9531, 0.9392, 0.9168, 0.8897, 0.8589, 0.8256, 0.7929, 0.7591, 0.7268, 0.6996, 0.6767, 0.6582, 0.6425,
1:         0.6284, 0.6133, 0.5976, 0.5812, 0.5668, 0.5514, 0.5352, 0.5204, 0.5051, 0.4893, 0.4761], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2326, -0.2354, -0.2409, -0.2399, -0.2253, -0.2150, -0.2084, -0.1945, -0.1783, -0.2305, -0.2405, -0.2330,
1:         -0.2303, -0.2270, -0.2149, -0.2077, -0.1928, -0.1759, -0.2230, -0.2236, -0.2301, -0.2280, -0.2210, -0.2132,
1:         -0.1961], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0208, -0.0267, -0.0351, -0.0113, -0.0364, -0.0202, -0.0194, -0.0475, -0.0282, -0.0325, -0.0101, -0.0285,
1:         -0.0130, -0.0140, -0.0284, -0.0442, -0.0378, -0.0072, -0.0076, -0.0316, -0.0277, -0.0209, -0.0169, -0.0336,
1:         -0.0130], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 37 [1/5 (20%)]	Loss: 0.28202 : 0.22977 :: 0.02265 (1.63 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 37 [2/5 (40%)]	Loss: 0.30749 : 0.22652 :: 0.02203 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 37 [3/5 (60%)]	Loss: 0.27486 : 0.19382 :: 0.02151 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 37 [4/5 (80%)]	Loss: 0.27957 : 0.21650 :: 0.02280 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 37 : 0.19967082142829895
0: validation loss for velocity_u : 0.003648498561233282
0: validation loss for velocity_v : 0.005198530852794647
0: validation loss for specific_humidity : 0.00542089669033885
0: validation loss for velocity_z : 0.11268480122089386
0: validation loss for temperature : 0.01789054647088051
0: validation loss for total_precip : 0.2555944323539734
0: validation loss for t2m : 0.9972579479217529
1: 38 : 04:00:39 :: batch_size = 96, lr = 1e-05
0: 38 : 04:00:39 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 38, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.1343, -0.1602, -0.1779, -0.1860, -0.1897, -0.1899, -0.1862, -0.1805, -0.1734, -0.1628, -0.1484, -0.1346,
1:         -0.1285, -0.1277, -0.1189, -0.0938, -0.0579, -0.0172, -0.1641, -0.1837, -0.2024, -0.2141, -0.2209, -0.2247,
1:         -0.2252], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0435,  0.1986,  0.0460, -0.0426, -0.0134,  0.0162, -0.1414, -0.0930,  0.1987,  0.0937, -0.0894, -0.2129,
1:         -0.0371, -0.0935,  0.1773,  0.0665,  0.1380,  0.0974,  0.0331, -0.0817,  0.0603, -0.0400,  0.1580, -0.1249,
1:         -0.0037], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6319, -0.5951, -0.5719, -0.5589, -0.5573, -0.5551, -0.5525, -0.5548, -0.5398, -0.5198, -0.4930, -0.4708,
1:         -0.4332, -0.3822, -0.3371, -0.2913, -0.2498, -0.2057, -0.6687, -0.6506, -0.6298, -0.6131, -0.6016, -0.5666,
1:         -0.5470], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.0718, 1.0071, 0.9662, 0.9146, 0.8455, 0.7860, 0.7421, 0.6994, 0.6646, 0.6528, 0.6591, 0.6668, 0.6602, 0.6340,
1:         0.5968, 0.5503, 0.4875, 0.4337, 0.4242, 0.4332, 0.4079, 0.3581, 0.3282, 0.3196, 0.3069], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2347, -0.2347, -0.2233, -0.2233, -0.2347, -0.2347, -0.2347, -0.2347, -0.2347, -0.2324, -0.2301, -0.2324,
1:         -0.2335, -0.2347, -0.2347, -0.2347, -0.2347, -0.2347, -0.1938, -0.0734, -0.1620, -0.1904, -0.2188, -0.2313,
1:         -0.2335], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 38, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0572,     nan,
1:             nan,     nan,     nan,  0.5433,  0.5574,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 38, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([ 0.0198,  0.0250,  0.0301,  0.0364,  0.0456,  0.0562,  0.0685,  0.0811,  0.0921,  0.1024,  0.1113,  0.1163,
1:          0.1224,  0.1228,  0.1279,  0.1345,  0.1447,  0.1607, -0.0537, -0.0502, -0.0475, -0.0383, -0.0272, -0.0137,
1:          0.0040], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-2.6608, -2.4316, -2.1371, -1.8220, -1.5306, -1.3128, -1.1950, -1.1702, -1.1996, -1.2520, -1.2811, -1.2591,
1:         -1.1883, -1.0835, -0.9661, -0.8638, -0.7827, -0.7176, -2.8662, -2.6597, -2.3780, -2.0568, -1.7413, -1.4885,
1:         -1.3293], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.2301, -0.2115, -0.1929, -0.1863, -0.1885, -0.1965, -0.2101, -0.2231, -0.2381, -0.2538, -0.2738, -0.2971,
1:         -0.3169, -0.3290, -0.3355, -0.3330, -0.3264, -0.3190, -0.2377, -0.2136, -0.1907, -0.1827, -0.1853, -0.1971,
1:         -0.2101], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.8760,  1.4788,  1.4788,  0.9323, -0.3922, -2.0503, -2.8805, -2.3158, -1.4223, -1.9245, -3.2989, -3.6524,
1:         -2.2401, -0.1686,  0.9418,  0.8731,  0.6621,  0.5996,  0.9954,  1.3560,  1.1691,  0.4865, -0.7252, -1.7935,
1:         -2.1386], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.4693, 0.4172, 0.3879, 0.3812, 0.3920, 0.4050, 0.4156, 0.4243, 0.4380, 0.4655, 0.5121, 0.5747, 0.6474, 0.7262,
1:         0.8025, 0.8777, 0.9497, 1.0212, 1.0980, 1.1735, 1.2449, 1.3084, 1.3621, 1.4060, 1.4463], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2299, -0.2356, -0.2361, -0.2398, -0.2427, -0.2433, -0.2443, -0.2429, -0.2396, -0.2313, -0.2334, -0.2368,
1:         -0.2398, -0.2419, -0.2452, -0.2464, -0.2443, -0.2434, -0.2294, -0.2330, -0.2376, -0.2418, -0.2450, -0.2467,
1:         -0.2488], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0161, -0.0140, -0.0209,  0.0085, -0.0337, -0.0089, -0.0034, -0.0325, -0.0264, -0.0160, -0.0196,  0.0090,
1:         -0.0067, -0.0170, -0.0153, -0.0162, -0.0088,  0.0059,  0.0169, -0.0125, -0.0315, -0.0171,  0.0140, -0.0072,
1:         -0.0205], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 38, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1343, -0.1602, -0.1779, -0.1860, -0.1897, -0.1899, -0.1862, -0.1805, -0.1734, -0.1628, -0.1484, -0.1346,
0:         -0.1285, -0.1277, -0.1189, -0.0938, -0.0579, -0.0172, -0.1641, -0.1837, -0.2024, -0.2141, -0.2209, -0.2247,
0:         -0.2252], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.8353, -0.7647, -0.6904, -0.6329, -0.5933, -0.5619, -0.5259, -0.4725, -0.3978, -0.3107, -0.2324, -0.1811,
0:         -0.1558, -0.1420, -0.1335, -0.1285, -0.1212, -0.1109, -1.0222, -0.9612, -0.8702, -0.7737, -0.6814, -0.6010,
0:         -0.5312], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.7018, 1.7265, 1.6670, 1.4029, 1.1277, 1.1322, 1.4175, 1.5715, 1.3850, 1.2299, 1.2614, 1.1333, 0.9074, 0.9108,
0:         0.8906, 0.7120, 0.8501, 1.1962, 1.4973, 1.9816, 2.2242, 1.9613, 1.3917, 1.0277, 1.0827], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2347, -0.2347, -0.2233, -0.2233, -0.2347, -0.2347, -0.2347, -0.2347, -0.2347, -0.2324, -0.2301, -0.2324,
0:         -0.2335, -0.2347, -0.2347, -0.2347, -0.2347, -0.2347, -0.1938, -0.0734, -0.1620, -0.1904, -0.2188, -0.2313,
0:         -0.2335], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 38, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.7489])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 38, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.5596, 0.5278, 0.4921, 0.4591, 0.4319, 0.4135, 0.3993, 0.3886, 0.3859, 0.3898, 0.4021, 0.4218, 0.4438, 0.4661,
0:         0.4899, 0.5138, 0.5411, 0.5722, 0.6498, 0.6152, 0.5729, 0.5335, 0.5032, 0.4799, 0.4600], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.9575, 0.8712, 0.7876, 0.7210, 0.6750, 0.6436, 0.6275, 0.6131, 0.5956, 0.5697, 0.5349, 0.4928, 0.4470, 0.4004,
0:         0.3553, 0.3254, 0.3026, 0.2872, 0.9913, 0.9056, 0.8181, 0.7427, 0.6833, 0.6362, 0.6026], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([ 0.0049, -0.1239, -0.2585, -0.3925, -0.5096, -0.6029, -0.6701, -0.7062, -0.7198, -0.7181, -0.7096, -0.6998,
0:         -0.6846, -0.6677, -0.6440, -0.6112, -0.5692, -0.5262, -0.0518, -0.1813, -0.3166, -0.4436, -0.5491, -0.6267,
0:         -0.6766], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.3945, -0.4465, -0.5354, -0.6781, -0.7170, -0.5623, -0.3606, -0.1791, -0.0602, -0.0250, -0.0475, -0.0718,
0:         -0.0810, -0.0983, -0.0894, -0.0857, -0.1154, -0.0829, -0.3002, -0.3495, -0.3874, -0.4917, -0.5092, -0.3454,
0:         -0.1724], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.3246, 1.3282, 1.3242, 1.3151, 1.3104, 1.3128, 1.3206, 1.3292, 1.3315, 1.3262, 1.3160, 1.3033, 1.2923, 1.2799,
0:         1.2647, 1.2421, 1.2141, 1.1851, 1.1602, 1.1434, 1.1325, 1.1279, 1.1255, 1.1245, 1.1256], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2204, -0.2270, -0.2295, -0.2300, -0.2346, -0.2382, -0.2377, -0.2366, -0.2348, -0.2181, -0.2223, -0.2248,
0:         -0.2295, -0.2304, -0.2368, -0.2369, -0.2399, -0.2385, -0.2179, -0.2204, -0.2239, -0.2296, -0.2335, -0.2354,
0:         -0.2411], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0195, -0.0140, -0.0263,  0.0038, -0.0243, -0.0207, -0.0281, -0.0318, -0.0224, -0.0060, -0.0127, -0.0015,
0:         -0.0076, -0.0338, -0.0161, -0.0201, -0.0256, -0.0154, -0.0002,  0.0120, -0.0337, -0.0306, -0.0106, -0.0231,
0:         -0.0129], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 38 [1/5 (20%)]	Loss: 0.23585 : 0.18389 :: 0.02339 (1.71 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 38 [2/5 (40%)]	Loss: 0.29297 : 0.22165 :: 0.02260 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 38 [3/5 (60%)]	Loss: 0.28152 : 0.20891 :: 0.02245 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 38 [4/5 (80%)]	Loss: 0.27751 : 0.22135 :: 0.02284 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 38 : 0.19803711771965027
0: validation loss for velocity_u : 0.003777476027607918
0: validation loss for velocity_v : 0.00520641403272748
0: validation loss for specific_humidity : 0.0060763913206756115
0: validation loss for velocity_z : 0.11066160351037979
0: validation loss for temperature : 0.015618642792105675
0: validation loss for total_precip : 0.2663632333278656
0: validation loss for t2m : 0.9785561561584473
1: 39 : 04:06:38 :: batch_size = 96, lr = 1e-05
0: 39 : 04:06:38 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 39, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.3076, 0.3143, 0.3212, 0.3276, 0.3329, 0.3386, 0.3462, 0.3561, 0.3671, 0.3757, 0.3806, 0.3811, 0.3826, 0.3919,
1:         0.4121, 0.4411, 0.4667, 0.4832, 0.4124, 0.4218, 0.4306, 0.4395, 0.4485, 0.4569, 0.4670], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0666,  0.0426, -0.2038,  0.0982,  0.1600,  0.0371,  0.1338,  0.1832,  0.0115,  0.0433,  0.0469,  0.0068,
1:         -0.0367, -0.0466, -0.2034, -0.0664,  0.0863,  0.0096,  0.1631,  0.0250, -0.0972,  0.1723, -0.3219,  0.0966,
1:          0.1372], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.8981, 0.9296, 0.9519, 0.9708, 0.9854, 0.9999, 1.0119, 1.0173, 1.0055, 0.9738, 0.9292, 0.8654, 0.7971, 0.7151,
1:         0.6186, 0.5068, 0.3908, 0.2700, 1.0342, 1.0573, 1.0791, 1.0950, 1.1094, 1.1246, 1.1389], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.4238, 0.4643, 0.5032, 0.5391, 0.5645, 0.5764, 0.5827, 0.5863, 0.5899, 0.6021, 0.6192, 0.6394, 0.6508, 0.6398,
1:         0.6126, 0.5854, 0.5794, 0.5869, 0.6024, 0.6282, 0.6523, 0.6844, 0.7162, 0.7368, 0.7541], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2483, -0.2483, -0.2483, -0.2471, -0.2471, -0.1863, -0.1313, -0.1091, -0.1875, -0.2483, -0.2483, -0.2483,
1:         -0.2483, -0.2483, -0.2483, -0.2191, -0.1816, -0.1851, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483,
1:         -0.2436], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 39, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([1.7718, 1.7474,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 39, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.4222, 0.4101, 0.3913, 0.3707, 0.3465, 0.3214, 0.3000, 0.2756, 0.2535, 0.2315, 0.2078, 0.1854, 0.1649, 0.1481,
1:         0.1339, 0.1242, 0.1149, 0.1043, 0.5100, 0.4978, 0.4792, 0.4575, 0.4318, 0.4059, 0.3819], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.0805,  0.0433,  0.0046, -0.0301, -0.0634, -0.0909, -0.1156, -0.1351, -0.1504, -0.1593, -0.1651, -0.1632,
1:         -0.1560, -0.1424, -0.1235, -0.1019, -0.0793, -0.0531,  0.0732,  0.0363, -0.0012, -0.0391, -0.0740, -0.1073,
1:         -0.1351], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6988, -0.6851, -0.6683, -0.6500, -0.6320, -0.6164, -0.6044, -0.5963, -0.5925, -0.5909, -0.5910, -0.5915,
1:         -0.5934, -0.5974, -0.6023, -0.6096, -0.6178, -0.6238, -0.6816, -0.6662, -0.6503, -0.6332, -0.6179, -0.6042,
1:         -0.5952], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-1.0654, -1.1096, -0.9909, -0.6446, -0.3968, -0.4613, -0.4928, -0.2767, -0.1262, -0.1335, -0.0925, -0.0641,
1:         -0.0157,  0.0639, -0.1281, -0.4011, -0.5462, -0.7342, -0.8174, -0.7607, -0.6882, -0.5201, -0.3917, -0.4574,
1:         -0.5124], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.2880, -1.3111, -1.3525, -1.4058, -1.4639, -1.5185, -1.5672, -1.6112, -1.6582, -1.7134, -1.7769, -1.8427,
1:         -1.8991, -1.9355, -1.9482, -1.9402, -1.9197, -1.8917, -1.8603, -1.8274, -1.7946, -1.7614, -1.7328, -1.7138,
1:         -1.7014], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2327, -0.2339, -0.2326, -0.2298, -0.2343, -0.2321, -0.2338, -0.2300, -0.2280, -0.2402, -0.2375, -0.2350,
1:         -0.2359, -0.2350, -0.2381, -0.2374, -0.2381, -0.2395, -0.2393, -0.2399, -0.2394, -0.2420, -0.2424, -0.2440,
1:         -0.2437], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0162, -0.0170, -0.0118, -0.0066, -0.0281, -0.0103, -0.0011, -0.0173, -0.0318, -0.0159, -0.0094, -0.0030,
1:          0.0036, -0.0163, -0.0126, -0.0181, -0.0031,  0.0109,  0.0062, -0.0217, -0.0310, -0.0070, -0.0024, -0.0127,
1:         -0.0023], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 39, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.3076, 0.3143, 0.3212, 0.3276, 0.3329, 0.3386, 0.3462, 0.3561, 0.3671, 0.3757, 0.3806, 0.3811, 0.3826, 0.3919,
0:         0.4121, 0.4411, 0.4667, 0.4832, 0.4124, 0.4218, 0.4306, 0.4395, 0.4485, 0.4569, 0.4670], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.5999, 0.6324, 0.6664, 0.7011, 0.7361, 0.7741, 0.8161, 0.8599, 0.9031, 0.9440, 0.9830, 1.0188, 1.0533, 1.0799,
0:         1.0893, 1.0793, 1.0519, 1.0192, 0.6073, 0.6451, 0.6828, 0.7212, 0.7586, 0.7984, 0.8424], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.6221, 0.5790, 0.5683, 0.5403, 0.4542, 0.2885, 0.2024, 0.1852, 0.2002, 0.2562, 0.3143, 0.3423, 0.2928, 0.1959,
0:         0.1830, 0.2949, 0.3832, 0.4241, 0.6694, 0.6070, 0.5769, 0.5704, 0.4994, 0.3466, 0.2024], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2483, -0.2483, -0.2483, -0.2471, -0.2471, -0.1863, -0.1313, -0.1091, -0.1875, -0.2483, -0.2483, -0.2483,
0:         -0.2483, -0.2483, -0.2483, -0.2191, -0.1816, -0.1851, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483, -0.2483,
0:         -0.2436], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 39, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 1.2873,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.9532,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 39, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.9576, 0.9747, 0.9859, 0.9938, 0.9998, 1.0057, 1.0064, 1.0062, 1.0089, 1.0148, 1.0229, 1.0336, 1.0411, 1.0477,
0:         1.0494, 1.0504, 1.0531, 1.0526, 0.8918, 0.9131, 0.9335, 0.9502, 0.9677, 0.9785, 0.9867], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.1437, -0.1302, -0.1215, -0.1124, -0.1051, -0.0969, -0.0879, -0.0733, -0.0563, -0.0370, -0.0140,  0.0099,
0:          0.0333,  0.0580,  0.0830,  0.1105,  0.1402,  0.1733, -0.2092, -0.1946, -0.1845, -0.1726, -0.1615, -0.1491,
0:         -0.1347], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.5491, -0.5868, -0.6110, -0.6190, -0.6002, -0.5468, -0.4639, -0.3601, -0.2473, -0.1393, -0.0500,  0.0188,
0:          0.0781,  0.1424,  0.2276,  0.3424,  0.4797,  0.6104, -0.6591, -0.6905, -0.7102, -0.7055, -0.6708, -0.6018,
0:         -0.5029], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.1744, -0.2175, -0.2559, -0.2170, -0.0602,  0.0908,  0.0969,  0.0263,  0.0100, -0.0110, -0.0640, -0.0215,
0:          0.0304, -0.0216, -0.0614, -0.0195, -0.0255, -0.0607,  0.0635, -0.0457, -0.1711, -0.2151, -0.0882,  0.0592,
0:          0.0809], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-1.6317, -1.6361, -1.6382, -1.6354, -1.6226, -1.5987, -1.5681, -1.5357, -1.5054, -1.4789, -1.4569, -1.4390,
0:         -1.4238, -1.4109, -1.4021, -1.3968, -1.3946, -1.3901, -1.3802, -1.3635, -1.3382, -1.3073, -1.2765, -1.2486,
0:         -1.2228], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2415, -0.2424, -0.2425, -0.2422, -0.2458, -0.2463, -0.2468, -0.2440, -0.2412, -0.2423, -0.2435, -0.2428,
0:         -0.2442, -0.2428, -0.2472, -0.2469, -0.2460, -0.2473, -0.2434, -0.2445, -0.2444, -0.2453, -0.2463, -0.2453,
0:         -0.2479], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0365, -0.0192, -0.0025,  0.0031, -0.0154, -0.0075, -0.0069, -0.0145, -0.0100, -0.0074, -0.0245,  0.0077,
0:         -0.0165, -0.0234, -0.0204, -0.0322, -0.0180, -0.0025, -0.0045,  0.0047, -0.0184, -0.0272, -0.0185, -0.0227,
0:         -0.0016], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 39 [1/5 (20%)]	Loss: 0.24513 : 0.19817 :: 0.02202 (1.64 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 39 [2/5 (40%)]	Loss: 0.26882 : 0.20744 :: 0.02355 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 39 [3/5 (60%)]	Loss: 0.23216 : 0.18502 :: 0.02165 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 39 [4/5 (80%)]	Loss: 0.21928 : 0.18961 :: 0.02269 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 39 : 0.19884225726127625
0: validation loss for velocity_u : 0.0034548374824225903
0: validation loss for velocity_v : 0.004772965796291828
0: validation loss for specific_humidity : 0.006539741065353155
0: validation loss for velocity_z : 0.10213598608970642
0: validation loss for temperature : 0.020061813294887543
0: validation loss for total_precip : 0.2917673587799072
0: validation loss for t2m : 0.9631631374359131
1: 40 : 04:12:39 :: batch_size = 96, lr = 1e-05
0: 40 : 04:12:39 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 40, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.1105, -1.1147, -1.1169, -1.1157, -1.1111, -1.1044, -1.0958, -1.0879, -1.0812, -1.0779, -1.0781, -1.0814,
0:         -1.0875, -1.0945, -1.1003, -1.1044, -1.1083, -1.1141, -1.1316, -1.1336, -1.1344, -1.1333, -1.1293, -1.1228,
0:         -1.1136], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.3149, -0.3297, -0.3372, -0.3398, -0.3390, -0.3370, -0.3366, -0.3380, -0.3411, -0.3447, -0.3481, -0.3484,
0:         -0.3463, -0.3388, -0.3255, -0.3066, -0.2809, -0.2519, -0.3291, -0.3358, -0.3390, -0.3415, -0.3439, -0.3469,
0:         -0.3510], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.3246,  0.2938,  0.2433,  0.0951, -0.0267, -0.1354, -0.1463, -0.0882,  0.0227,  0.1621,  0.2521,  0.2763,
0:          0.2411,  0.2104,  0.1819,  0.2466,  0.3707,  0.5013,  0.3476,  0.2818,  0.1896,  0.0161, -0.1145, -0.2023,
0:         -0.2243], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2003, -0.1978, -0.2090, -0.2426, -0.2551, -0.2414, -0.2252, -0.2327, -0.2402, -0.2215, -0.2065, -0.2426,
0:         -0.2514, -0.2364, -0.2364, -0.2215, -0.2152, -0.2314, -0.2576, -0.2551, -0.2526, -0.2564, -0.2551, -0.2402,
0:         -0.2364], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 40, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan, 0.0743,    nan,    nan,    nan,    nan,    nan,    nan, 0.0705])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 40, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.9108, -0.8858, -0.8612, -0.8379, -0.8200, -0.8046, -0.7949, -0.7944, -0.7992, -0.8118, -0.8280, -0.8418,
0:         -0.8490, -0.8502, -0.8466, -0.8415, -0.8348, -0.8285, -0.9211, -0.9014, -0.8822, -0.8648, -0.8471, -0.8312,
0:         -0.8185], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.0255, -0.0277, -0.0281, -0.0242, -0.0190, -0.0075,  0.0066,  0.0281,  0.0553,  0.0877,  0.1246,  0.1637,
0:          0.2029,  0.2435,  0.2836,  0.3226,  0.3612,  0.4000, -0.0254, -0.0246, -0.0222, -0.0136, -0.0037,  0.0101,
0:          0.0281], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([0.3102, 0.3202, 0.3272, 0.3311, 0.3337, 0.3275, 0.3194, 0.3037, 0.2910, 0.2829, 0.2740, 0.2762, 0.2791, 0.2830,
0:         0.2900, 0.3028, 0.3201, 0.3458, 0.3378, 0.3484, 0.3589, 0.3648, 0.3656, 0.3588, 0.3461], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.0227,  0.0630,  0.1622,  0.2182,  0.2197,  0.1905,  0.1602,  0.1417,  0.1232,  0.1022,  0.1301,  0.1771,
0:          0.2022,  0.2655,  0.2998,  0.3271,  0.3567,  0.3283,  0.0798,  0.1719,  0.2693,  0.2821,  0.2305,  0.1619,
0:          0.1038], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([ 0.2747,  0.3353,  0.3790,  0.4015,  0.4047,  0.3939,  0.3684,  0.3250,  0.2588,  0.1636,  0.0411, -0.0989,
0:         -0.2388, -0.3619, -0.4530, -0.5159, -0.5515, -0.5667, -0.5715, -0.5776, -0.5967, -0.6348, -0.6976, -0.7769,
0:         -0.8573], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.3266, -0.3655, -0.4514, -0.6917, -0.6226, -0.6477, -0.6943, -0.5569, -0.3149, -0.8471, -0.7467, -0.6364,
0:         -0.5466, -0.4380, -0.3284, -0.3004, -0.2562, -0.0651, -1.2889, -0.9542, -0.4546,  0.1821,  0.5946,  0.9125,
0:          1.0210], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0131, -0.0049, -0.0097, -0.0057, -0.0277, -0.0036, -0.0019, -0.0067, -0.0259,  0.0087,  0.0091,  0.0167,
0:          0.0080, -0.0249, -0.0365, -0.0111,  0.0076, -0.0148, -0.0126, -0.0150, -0.0145, -0.0395, -0.0037, -0.0101,
0:         -0.0009], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 40, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.1105, -1.1147, -1.1169, -1.1157, -1.1111, -1.1044, -1.0958, -1.0879, -1.0812, -1.0779, -1.0781, -1.0814,
1:         -1.0875, -1.0945, -1.1003, -1.1044, -1.1083, -1.1141, -1.1316, -1.1336, -1.1344, -1.1333, -1.1293, -1.1228,
1:         -1.1136], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0017, -0.0048, -0.2688, -0.0038, -0.0637,  0.0035,  0.0413, -0.1649, -0.0374,  0.0585, -0.0613,  0.0386,
1:          0.0927, -0.0043, -0.0254,  0.0279,  0.0082,  0.0037, -0.1371,  0.0018, -0.0422, -0.0295, -0.0659,  0.0076,
1:          0.0102], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.0780, 0.0497, 0.0221, 0.0087, 0.0013, 0.0144, 0.0343, 0.0520, 0.0707, 0.0912, 0.1087, 0.1237, 0.1307, 0.1337,
1:         0.1345, 0.1418, 0.1546, 0.1869, 0.0356, 0.0138, 0.0053, 0.0091, 0.0298, 0.0558, 0.0764], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.5977, 0.5736, 0.5453, 0.5377, 0.5479, 0.5790, 0.6262, 0.6752, 0.7252, 0.7602, 0.7888, 0.8082, 0.8205, 0.8330,
1:         0.8427, 0.8523, 0.8516, 0.8381, 0.8008, 0.7461, 0.6946, 0.6725, 0.6851, 0.7247, 0.7802], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2003, -0.1978, -0.2090, -0.2426, -0.2551, -0.2414, -0.2252, -0.2327, -0.2402, -0.2215, -0.2065, -0.2426,
1:         -0.2514, -0.2364, -0.2364, -0.2215, -0.2152, -0.2314, -0.2576, -0.2551, -0.2526, -0.2564, -0.2551, -0.2402,
1:         -0.2364], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 40, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([-0.9254,     nan,     nan,     nan,     nan, -0.2264,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:          0.7730])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 40, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-1.1072, -1.0870, -1.0661, -1.0442, -1.0205, -0.9947, -0.9646, -0.9346, -0.9029, -0.8743, -0.8489, -0.8249,
1:         -0.8038, -0.7847, -0.7681, -0.7531, -0.7408, -0.7310, -1.1222, -1.1028, -1.0825, -1.0614, -1.0390, -1.0136,
1:         -0.9856], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.1595, -0.1391, -0.1121, -0.0832, -0.0569, -0.0352, -0.0115,  0.0177,  0.0517,  0.0936,  0.1398,  0.1898,
1:          0.2373,  0.2821,  0.3214,  0.3564,  0.3890,  0.4185, -0.1189, -0.0986, -0.0729, -0.0479, -0.0249, -0.0036,
1:          0.0195], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([1.3642, 1.3357, 1.2853, 1.2116, 1.1221, 1.0289, 0.9421, 0.8791, 0.8440, 0.8318, 0.8310, 0.8255, 0.8087, 0.7869,
1:         0.7646, 0.7568, 0.7679, 0.7941, 1.3522, 1.3347, 1.2884, 1.2191, 1.1265, 1.0220, 0.9220], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.4353, -0.2310,  0.2892,  0.0274, -0.6525, -1.0158, -0.9787, -0.5134, -0.4209, -0.6645, -0.6460, -0.5386,
1:         -0.3330, -0.2824, -0.5461, -0.7621, -1.0014, -1.1292, -0.4419, -0.5855, -0.2803, -0.3232, -0.4356, -0.3983,
1:         -0.4195], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.5117, -0.5352, -0.5558, -0.5774, -0.5963, -0.6101, -0.6199, -0.6294, -0.6426, -0.6626, -0.6866, -0.7082,
1:         -0.7213, -0.7256, -0.7201, -0.7099, -0.6946, -0.6718, -0.6386, -0.5987, -0.5541, -0.5088, -0.4684, -0.4369,
1:         -0.4220], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([1.3935, 1.3567, 1.3057, 1.2741, 1.2807, 1.2656, 1.1906, 1.1149, 0.9848, 1.4815, 1.5049, 1.5178, 1.5234, 1.5229,
1:         1.4923, 1.3833, 1.2621, 1.0796, 1.4408, 1.5075, 1.6018, 1.6547, 1.6821, 1.6370, 1.5074], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0152, -0.0028, -0.0064, -0.0237, -0.0131,  0.0121, -0.0026, -0.0302, -0.0381,  0.0001, -0.0068,  0.0102,
1:          0.0033, -0.0087, -0.0263, -0.0171, -0.0012,  0.0095,  0.0014, -0.0021, -0.0187, -0.0184,  0.0151, -0.0117,
1:         -0.0115], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 40 [1/5 (20%)]	Loss: 0.23019 : 0.18634 :: 0.02230 (1.66 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 40 [2/5 (40%)]	Loss: 0.27320 : 0.21718 :: 0.02217 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 40 [3/5 (60%)]	Loss: 0.26415 : 0.20463 :: 0.02189 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 40 [4/5 (80%)]	Loss: 0.24282 : 0.18026 :: 0.02131 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 40 : 0.19712740182876587
0: validation loss for velocity_u : 0.0035987631417810917
0: validation loss for velocity_v : 0.0050276825204491615
0: validation loss for specific_humidity : 0.007021244615316391
0: validation loss for velocity_z : 0.11093182116746902
0: validation loss for temperature : 0.021149737760424614
0: validation loss for total_precip : 0.31432491540908813
0: validation loss for t2m : 0.9178375601768494
1: 41 : 04:18:55 :: batch_size = 96, lr = 1e-05
0: 41 : 04:18:55 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 41, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.2043, -1.2176, -1.2465, -1.2887, -1.3380, -1.3882, -1.4349, -1.4699, -1.4931, -1.5050, -1.5085, -1.5073,
1:         -1.4987, -1.4827, -1.4597, -1.4362, -1.4163, -1.4041, -1.1042, -1.1071, -1.1230, -1.1531, -1.1927, -1.2342,
1:         -1.2727], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.2443,  0.0255,  0.0039,  0.0361, -0.0428,  0.0394, -0.0058,  0.0798, -0.0129, -0.0992,  0.0706, -0.0193,
1:         -0.1622, -0.0459,  0.0312,  0.1477, -0.0757, -0.0633,  0.0586,  0.0148,  0.0310,  0.0180,  0.0177,  0.0042,
1:          0.1231], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3754, -0.3933, -0.4154, -0.4384, -0.4572, -0.4700, -0.4781, -0.4817, -0.4840, -0.4914, -0.4944, -0.4883,
1:         -0.4763, -0.4555, -0.4330, -0.4142, -0.3999, -0.3895, -0.3642, -0.3652, -0.3805, -0.3899, -0.3982, -0.4007,
1:         -0.4031], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([ 0.8977,  0.8430,  0.8034,  0.7512,  0.6824,  0.5775,  0.4340,  0.2709,  0.0993, -0.0582, -0.2065, -0.3581,
1:         -0.5130, -0.6861, -0.8713, -1.0343, -1.1410, -1.1972, -1.2243, -1.2037, -1.1397, -1.0253, -0.8787, -0.7375,
1:         -0.6131], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1698, -0.1007, -0.2116, -0.2467, -0.2467, -0.2467, -0.2467, -0.2456, -0.2467, -0.0136, -0.0476, -0.1947,
1:         -0.2444, -0.2467, -0.2467, -0.2444, -0.2433, -0.2467,  0.0339,  0.1109, -0.1856, -0.2422, -0.2467, -0.2467,
1:         -0.2433], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 41, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.4480,    nan, 0.3606, 0.4088,    nan,    nan,
1:            nan,    nan,    nan,    nan, 0.3906,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 41, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.9419, -0.9127, -0.8801, -0.8419, -0.8020, -0.7651, -0.7329, -0.7069, -0.6897, -0.6775, -0.6761, -0.6824,
1:         -0.6941, -0.7178, -0.7450, -0.7732, -0.8024, -0.8319, -0.8879, -0.8676, -0.8407, -0.8073, -0.7711, -0.7367,
1:         -0.7078], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.7059, -0.7024, -0.7025, -0.7087, -0.7204, -0.7397, -0.7625, -0.7862, -0.8109, -0.8413, -0.8758, -0.9180,
1:         -0.9665, -1.0165, -1.0626, -1.0960, -1.1138, -1.1137, -0.6784, -0.6736, -0.6735, -0.6800, -0.6944, -0.7148,
1:         -0.7385], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([0.4695, 0.4523, 0.4343, 0.4081, 0.3772, 0.3496, 0.3322, 0.3337, 0.3664, 0.4312, 0.5294, 0.6576, 0.8033, 0.9645,
1:         1.1323, 1.2939, 1.4434, 1.5611, 0.5352, 0.5195, 0.4941, 0.4589, 0.4174, 0.3754, 0.3482], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.8389,  0.2908,  0.0209, -0.0053,  0.0737,  0.0025, -0.0884, -0.0312, -0.0215,  0.0959, -0.2317, -1.1571,
1:         -1.9108, -2.0056, -1.3650, -0.2864,  0.7088,  1.1785,  1.3139,  0.7438,  0.3961,  0.2437,  0.2009,  0.0256,
1:          0.1105], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([ 0.1256,  0.0873,  0.0340, -0.0560, -0.1609, -0.2492, -0.2670, -0.1911, -0.0222,  0.2144,  0.4781,  0.7392,
1:          0.9811,  1.1934,  1.3550,  1.4565,  1.4675,  1.3805,  1.2140,  0.9945,  0.7801,  0.6252,  0.5534,  0.5482,
1:          0.5819], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([11.3657, 11.3501, 10.6931,  9.5216,  8.2716,  7.2863,  6.6037,  6.2962,  6.1691, 11.4349, 11.2654, 10.4423,
1:          9.2467,  8.1111,  7.3540,  6.9905,  6.8972,  6.8375, 10.7014, 10.3953,  9.4968,  8.4333,  7.5587,  7.1140,
1:          7.1158], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0271, -0.0181, -0.0014, -0.0170, -0.0194,  0.0213, -0.0027, -0.0158, -0.0198, -0.0063,  0.0029,  0.0136,
1:         -0.0108, -0.0198, -0.0205, -0.0075, -0.0154,  0.0184, -0.0171, -0.0253, -0.0227, -0.0230, -0.0056, -0.0175,
1:         -0.0124], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 41, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.2043, -1.2176, -1.2465, -1.2887, -1.3380, -1.3882, -1.4349, -1.4699, -1.4931, -1.5050, -1.5085, -1.5073,
0:         -1.4987, -1.4827, -1.4597, -1.4362, -1.4163, -1.4041, -1.1042, -1.1071, -1.1230, -1.1531, -1.1927, -1.2342,
0:         -1.2727], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.3087, -0.3171, -0.3334, -0.3548, -0.3829, -0.4156, -0.4524, -0.4932, -0.5356, -0.5757, -0.6105, -0.6408,
0:         -0.6607, -0.6674, -0.6622, -0.6438, -0.6200, -0.5947, -0.3280, -0.3340, -0.3463, -0.3643, -0.3913, -0.4244,
0:         -0.4619], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.4008,  0.3399,  0.3279,  0.3432,  0.4225,  0.5813,  0.7172,  0.7792,  0.8074,  0.7705,  0.7335,  0.7552,
0:          0.6835,  0.5650,  0.3519,  0.1018, -0.0450, -0.1178,  0.3008,  0.2616,  0.2692,  0.3312,  0.4345,  0.4976,
0:          0.5715], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1698, -0.1007, -0.2116, -0.2467, -0.2467, -0.2467, -0.2467, -0.2456, -0.2467, -0.0136, -0.0476, -0.1947,
0:         -0.2444, -0.2467, -0.2467, -0.2444, -0.2433, -0.2467,  0.0339,  0.1109, -0.1856, -0.2422, -0.2467, -0.2467,
0:         -0.2433], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 41, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([-0.0811,     nan,     nan,     nan,     nan,  0.2983,     nan,  0.3640,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,  0.5473,  0.3549,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 41, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.4373, -0.4622, -0.4861, -0.5156, -0.5569, -0.6104, -0.6733, -0.7428, -0.8092, -0.8713, -0.9225, -0.9626,
0:         -0.9879, -1.0000, -0.9987, -0.9864, -0.9674, -0.9436, -0.4174, -0.4491, -0.4809, -0.5164, -0.5614, -0.6155,
0:         -0.6765], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.1215, -0.1137, -0.1172, -0.1236, -0.1295, -0.1263, -0.1155, -0.0967, -0.0708, -0.0411, -0.0071,  0.0327,
0:          0.0727,  0.1132,  0.1542,  0.1976,  0.2448,  0.2976, -0.1133, -0.1062, -0.1090, -0.1195, -0.1279, -0.1286,
0:         -0.1188], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([1.4962, 1.3366, 1.1908, 1.0933, 1.0560, 1.0785, 1.1674, 1.3000, 1.4658, 1.6371, 1.8167, 1.9868, 2.1525, 2.3033,
0:         2.4256, 2.5301, 2.6136, 2.6605, 1.4192, 1.2845, 1.1839, 1.1322, 1.1335, 1.2054, 1.3259], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.0978, -0.1219, -0.0423,  0.0568,  0.1425,  0.2205,  0.2355,  0.1996,  0.1845,  0.1718,  0.1047,  0.0471,
0:          0.0266, -0.0080, -0.0233, -0.0161, -0.0370, -0.1087, -0.4280, -0.4306, -0.2694, -0.1053,  0.0135,  0.1150,
0:          0.1354], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([ 3.1986e-01,  2.8879e-01,  2.7687e-01,  2.4957e-01,  1.9154e-01,  1.0576e-01,  1.6569e-02, -4.3314e-02,
0:         -6.0957e-02, -4.1424e-02,  4.8450e-04,  5.6268e-02,  1.3657e-01,  2.4880e-01,  3.8913e-01,  5.3214e-01,
0:          6.3291e-01,  6.5322e-01,  5.8812e-01,  4.7190e-01,  3.6627e-01,  3.4060e-01,  4.1514e-01,  5.6697e-01,
0:          7.4650e-01], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([ 0.0359,  0.0604,  0.0635,  0.1443,  0.2714,  0.4500,  0.6613,  0.8299,  0.9391, -0.0667, -0.1034, -0.1160,
0:         -0.1390, -0.0804,  0.0619,  0.2194,  0.4287,  0.5870, -0.1095, -0.1688, -0.2344, -0.3174, -0.3324, -0.2680,
0:         -0.1513], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0158, -0.0187, -0.0031, -0.0132, -0.0163, -0.0174, -0.0064, -0.0106, -0.0199, -0.0079, -0.0132,  0.0007,
0:         -0.0082, -0.0306, -0.0162, -0.0097, -0.0241, -0.0084, -0.0145, -0.0042, -0.0153, -0.0404, -0.0141, -0.0229,
0:         -0.0006], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 41 [1/5 (20%)]	Loss: 0.26328 : 0.20834 :: 0.02419 (1.72 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 41 [2/5 (40%)]	Loss: 0.23816 : 0.17856 :: 0.02344 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 41 [3/5 (60%)]	Loss: 0.30256 : 0.21033 :: 0.02170 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 41 [4/5 (80%)]	Loss: 0.27879 : 0.21447 :: 0.02275 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 41 : 0.2066662311553955
0: validation loss for velocity_u : 0.0036278599873185158
0: validation loss for velocity_v : 0.005268596578389406
0: validation loss for specific_humidity : 0.006030399352312088
0: validation loss for velocity_z : 0.1123598963022232
0: validation loss for temperature : 0.017595017328858376
0: validation loss for total_precip : 0.2998623251914978
0: validation loss for t2m : 1.0019196271896362
1: 42 : 04:24:59 :: batch_size = 96, lr = 1e-05
0: 42 : 04:24:59 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 42, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1738, -0.1689, -0.1655, -0.1670, -0.1725, -0.1836, -0.1986, -0.2149, -0.2345, -0.2573, -0.2824, -0.3078,
0:         -0.3282, -0.3441, -0.3561, -0.3638, -0.3708, -0.3808, -0.1573, -0.1520, -0.1463, -0.1440, -0.1458, -0.1523,
0:         -0.1630], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.1855, 0.1926, 0.1986, 0.2059, 0.2166, 0.2293, 0.2439, 0.2602, 0.2750, 0.2861, 0.2928, 0.2979, 0.3059, 0.3179,
0:         0.3301, 0.3381, 0.3381, 0.3273, 0.1561, 0.1600, 0.1647, 0.1739, 0.1879, 0.2042, 0.2220], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.4070, 0.3710, 0.3845, 0.3216, 0.2744, 0.2643, 0.2396, 0.3227, 0.3272, 0.2733, 0.2789, 0.2576, 0.3194, 0.3856,
0:         0.4047, 0.4463, 0.4328, 0.4104, 0.4823, 0.4946, 0.4632, 0.4126, 0.3452, 0.3194, 0.2710], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2233, -0.2120,  0.1037, -0.0961, -0.2074, -0.2301, -0.2347, -0.2324, -0.2301, -0.2211, -0.2233, -0.1779,
0:         -0.0030,  0.0288, -0.0734, -0.2324, -0.2347, -0.2324, -0.2256, -0.2279, -0.2029, -0.0757,  0.0401,  0.0106,
0:         -0.2347], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 42, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan, -0.7703,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan, -0.6701,     nan,     nan,     nan, -0.7812, -0.6938,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 42, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.2772, 0.2848, 0.2877, 0.2932, 0.3006, 0.3102, 0.3230, 0.3354, 0.3491, 0.3652, 0.3822, 0.4021, 0.4202, 0.4394,
0:         0.4541, 0.4652, 0.4723, 0.4703, 0.2534, 0.2584, 0.2647, 0.2755, 0.2868, 0.3017, 0.3181], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.6000, 0.5933, 0.5887, 0.5875, 0.5862, 0.5889, 0.5867, 0.5833, 0.5776, 0.5717, 0.5643, 0.5602, 0.5535, 0.5505,
0:         0.5451, 0.5370, 0.5284, 0.5189, 0.6246, 0.6200, 0.6150, 0.6127, 0.6121, 0.6110, 0.6108], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.5521, -0.5529, -0.5438, -0.5262, -0.5003, -0.4650, -0.4197, -0.3671, -0.3076, -0.2451, -0.1828, -0.1286,
0:         -0.0839, -0.0587, -0.0411, -0.0328, -0.0261,  0.0018, -0.5153, -0.5234, -0.5240, -0.5245, -0.5125, -0.4895,
0:         -0.4504], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.3171, 0.2946, 0.2442, 0.1763, 0.1514, 0.1208, 0.0728, 0.0694, 0.0823, 0.0995, 0.1399, 0.1920, 0.2017, 0.2327,
0:         0.3170, 0.3546, 0.3712, 0.3931, 0.2254, 0.2538, 0.2442, 0.1984, 0.1884, 0.1808, 0.1413], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.1931, -0.1686, -0.1394, -0.1025, -0.0585, -0.0035,  0.0582,  0.1241,  0.1848,  0.2373,  0.2835,  0.3262,
0:          0.3687,  0.4109,  0.4504,  0.4828,  0.5093,  0.5334,  0.5620,  0.6006,  0.6482,  0.7029,  0.7602,  0.8180,
0:          0.8747], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([0.2383, 0.2867, 0.3387, 0.3685, 0.3631, 0.3365, 0.3071, 0.2768, 0.2630, 0.2226, 0.2796, 0.3172, 0.3542, 0.3436,
0:         0.3331, 0.3253, 0.3192, 0.3322, 0.2291, 0.2537, 0.2680, 0.2754, 0.3067, 0.3097, 0.3131], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0166, -0.0196, -0.0259, -0.0365, -0.0261, -0.0122, -0.0410, -0.0262, -0.0122, -0.0146, -0.0273, -0.0032,
0:         -0.0249, -0.0426, -0.0117, -0.0078, -0.0244, -0.0268, -0.0655, -0.0197, -0.0144, -0.0540, -0.0306, -0.0321,
0:         -0.0127], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 42, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.5053, 1.5351, 1.5637, 1.5904, 1.6134, 1.6314, 1.6443, 1.6524, 1.6583, 1.6678, 1.6816, 1.6982, 1.7201, 1.7521,
1:         1.7975, 1.8569, 1.9233, 1.9866, 1.5230, 1.5512, 1.5775, 1.5985, 1.6123, 1.6202, 1.6244], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0771,  0.0055, -0.0240, -0.1172, -0.2412,  0.0733, -0.0145,  0.0188, -0.0519,  0.0298, -0.0122,  0.1706,
1:          0.0231,  0.0684,  0.1291,  0.0287,  0.0269,  0.1076, -0.1567,  0.1012,  0.0620, -0.1035,  0.1636, -0.1665,
1:         -0.0336], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0211, -0.0207, -0.0246, -0.0427, -0.0709, -0.1089, -0.1553, -0.2078, -0.2590, -0.3079, -0.3544, -0.3973,
1:         -0.4406, -0.4876, -0.5352, -0.5906, -0.6470, -0.6990, -0.0304, -0.0304, -0.0341, -0.0532, -0.0835, -0.1225,
1:         -0.1699], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., -0., -0., -0., 0., 0., 0., 0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.3667, -0.3456, -0.3203, -0.2907, -0.2596, -0.2280, -0.1951, -0.1612, -0.1244, -0.0831, -0.0357,  0.0160,
1:          0.0667,  0.1153,  0.1635,  0.2096,  0.2467,  0.2674,  0.2612,  0.2217,  0.1447,  0.0235, -0.1425, -0.3502,
1:         -0.6076], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2480, -0.2366, -0.1909, -0.0926,  0.0034,  0.0583,  0.0972,  0.0491, -0.0057, -0.1566, -0.2023, -0.1977,
1:         -0.2023, -0.1429, -0.0629, -0.0400,  0.0103, -0.0240, -0.1520, -0.1840, -0.1771, -0.1497, -0.1154, -0.1406,
1:         -0.2023], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 42, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan, -0.0394,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 42, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([1.1482, 1.1631, 1.1764, 1.1889, 1.2009, 1.2103, 1.2235, 1.2416, 1.2592, 1.2796, 1.2999, 1.3184, 1.3376, 1.3565,
1:         1.3787, 1.4051, 1.4267, 1.4419, 1.0366, 1.0651, 1.0955, 1.1181, 1.1355, 1.1488, 1.1650], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 1.7439,  1.5790,  1.3312,  1.0164,  0.6463,  0.2627, -0.0958, -0.3956, -0.5986, -0.6960, -0.6897, -0.6025,
1:         -0.4724, -0.3270, -0.1961, -0.0897, -0.0162,  0.0308,  1.6582,  1.4555,  1.1723,  0.8119,  0.4132,  0.0099,
1:         -0.3450], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.4663, -0.4318, -0.4101, -0.4034, -0.4078, -0.4199, -0.4387, -0.4615, -0.4895, -0.5219, -0.5583, -0.5933,
1:         -0.6205, -0.6368, -0.6403, -0.6322, -0.6173, -0.5984, -0.4339, -0.4047, -0.3913, -0.3929, -0.4062, -0.4255,
1:         -0.4445], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.7368, 0.7790, 0.9292, 1.0764, 1.1801, 1.2183, 1.1967, 1.1434, 1.1059, 1.2277, 1.4740, 1.6748, 1.8336, 1.8320,
1:         1.6991, 1.6496, 1.6659, 1.6615, 0.5022, 0.5549, 0.8289, 1.1120, 1.2981, 1.3912, 1.3945], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.9764, -1.8248, -1.6652, -1.5211, -1.4066, -1.3192, -1.2599, -1.2146, -1.1833, -1.1649, -1.1612, -1.1750,
1:         -1.2066, -1.2419, -1.2731, -1.2949, -1.3028, -1.2994, -1.2857, -1.2702, -1.2605, -1.2663, -1.2933, -1.3403,
1:         -1.4039], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([ 0.4658,  0.4132,  0.3107,  0.1985,  0.1255,  0.0602,  0.0299, -0.0169, -0.0077,  0.4117,  0.3623,  0.3198,
1:          0.2680,  0.1850,  0.0765,  0.0030, -0.0765, -0.0928,  0.2595,  0.3020,  0.3785,  0.3779,  0.3117,  0.1893,
1:          0.0587], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0277, -0.0203, -0.0135, -0.0368, -0.0219, -0.0045, -0.0261, -0.0380, -0.0147, -0.0158, -0.0248,  0.0011,
1:         -0.0137, -0.0258, -0.0174, -0.0109, -0.0163, -0.0083, -0.0400, -0.0431, -0.0162, -0.0370, -0.0280, -0.0375,
1:         -0.0091], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 42 [1/5 (20%)]	Loss: 0.28137 : 0.21525 :: 0.02439 (1.60 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 42 [2/5 (40%)]	Loss: 0.26652 : 0.22633 :: 0.02266 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 42 [3/5 (60%)]	Loss: 0.28130 : 0.22464 :: 0.02219 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 42 [4/5 (80%)]	Loss: 0.28851 : 0.21355 :: 0.02178 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 42 : 0.20013907551765442
0: validation loss for velocity_u : 0.0035644620656967163
0: validation loss for velocity_v : 0.00515583623200655
0: validation loss for specific_humidity : 0.006035495549440384
0: validation loss for velocity_z : 0.11306397616863251
0: validation loss for temperature : 0.017335765063762665
0: validation loss for total_precip : 0.3093017637729645
0: validation loss for t2m : 0.9465158581733704
1: 43 : 04:31:18 :: batch_size = 96, lr = 1e-05
0: 43 : 04:31:18 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 43, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.0951, 1.0668, 1.0389, 1.0115, 0.9849, 0.9591, 0.9344, 0.9106, 0.8878, 0.8661, 0.8452, 0.8250, 0.8055, 0.7867,
0:         0.7682, 0.7499, 0.7311, 0.7114, 1.0314, 1.0044, 0.9784, 0.9534, 0.9294, 0.9063, 0.8840], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.8441, 1.8330, 1.8209, 1.8079, 1.7946, 1.7812, 1.7681, 1.7554, 1.7430, 1.7311, 1.7196, 1.7085, 1.6978, 1.6876,
0:         1.6777, 1.6683, 1.6588, 1.6494, 1.7605, 1.7488, 1.7369, 1.7252, 1.7141, 1.7034, 1.6935], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.8597, 0.8762, 0.8828, 0.8784, 0.8652, 0.8444, 0.8225, 0.8016, 0.7830, 0.7632, 0.7402, 0.7117, 0.6777, 0.6415,
0:         0.6086, 0.5790, 0.5538, 0.5318, 0.8268, 0.8433, 0.8499, 0.8488, 0.8389, 0.8236, 0.8049], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2234, -0.2211, -0.2211, -0.2211, -0.2188, -0.2164, -0.2118, -0.2047, -0.1966, -0.2281, -0.2258, -0.2234,
0:         -0.2199, -0.2153, -0.2106, -0.2071, -0.2012, -0.1966, -0.2304, -0.2269, -0.2223, -0.2176, -0.2129, -0.2094,
0:         -0.2059], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 43, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([1.2538,    nan,    nan, 1.2296,    nan,    nan,    nan,    nan,    nan,    nan, 1.3024,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 43, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.5633, -0.5856, -0.6104, -0.6359, -0.6627, -0.6879, -0.7128, -0.7361, -0.7605, -0.7847, -0.8083, -0.8313,
0:         -0.8525, -0.8672, -0.8799, -0.8879, -0.8918, -0.8963, -0.5657, -0.5883, -0.6085, -0.6318, -0.6552, -0.6781,
0:         -0.7013], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.9360, -0.9131, -0.8837, -0.8511, -0.8133, -0.7749, -0.7362, -0.6963, -0.6517, -0.6047, -0.5531, -0.4968,
0:         -0.4373, -0.3761, -0.3166, -0.2563, -0.1971, -0.1392, -0.9083, -0.8779, -0.8422, -0.8037, -0.7634, -0.7240,
0:         -0.6801], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6500, -0.6627, -0.6730, -0.6828, -0.6905, -0.6969, -0.7013, -0.7054, -0.7076, -0.7098, -0.7118, -0.7143,
0:         -0.7152, -0.7166, -0.7161, -0.7147, -0.7129, -0.7074, -0.6867, -0.6963, -0.7043, -0.7107, -0.7144, -0.7167,
0:         -0.7167], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.6878, 0.6803, 0.6599, 0.6314, 0.6000, 0.5755, 0.5451, 0.5108, 0.4874, 0.4768, 0.4583, 0.4287, 0.4078, 0.4008,
0:         0.3985, 0.3830, 0.3642, 0.3373, 0.6527, 0.6426, 0.6222, 0.5969, 0.5614, 0.5419, 0.5281], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.2909, 0.3261, 0.3623, 0.3988, 0.4353, 0.4741, 0.5120, 0.5488, 0.5804, 0.6069, 0.6288, 0.6479, 0.6650, 0.6779,
0:         0.6916, 0.7036, 0.7151, 0.7262, 0.7362, 0.7443, 0.7531, 0.7626, 0.7707, 0.7767, 0.7759], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2455, -0.2509, -0.2499, -0.2547, -0.2560, -0.2603, -0.2618, -0.2629, -0.2579, -0.2408, -0.2455, -0.2461,
0:         -0.2501, -0.2502, -0.2535, -0.2559, -0.2577, -0.2582, -0.2409, -0.2422, -0.2460, -0.2463, -0.2475, -0.2478,
0:         -0.2503], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0272, -0.0418, -0.0123, -0.0328, -0.0121, -0.0480, -0.0314, -0.0300, -0.0293, -0.0294, -0.0354, -0.0123,
0:         -0.0251, -0.0303, -0.0230, -0.0227, -0.0285, -0.0205, -0.0545, -0.0193, -0.0142, -0.0572, -0.0403, -0.0361,
0:         -0.0163], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 43, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.0951, 1.0668, 1.0389, 1.0115, 0.9849, 0.9591, 0.9344, 0.9106, 0.8878, 0.8661, 0.8452, 0.8250, 0.8055, 0.7867,
1:         0.7682, 0.7499, 0.7311, 0.7114, 1.0314, 1.0044, 0.9784, 0.9534, 0.9294, 0.9063, 0.8840], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.1005,  0.0131, -0.1290,  0.1825, -0.0097,  0.2045,  0.1324,  0.0493, -0.0761, -0.0800,  0.1246, -0.0270,
1:          0.0253, -0.1156, -0.0073, -0.2077, -0.0504, -0.0551,  0.1453, -0.0308,  0.0542, -0.0096,  0.1726,  0.0247,
1:         -0.0908], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6766, -0.6766, -0.6765, -0.6766, -0.6768, -0.6772, -0.6774, -0.6775, -0.6777, -0.6777, -0.6777, -0.6776,
1:         -0.6777, -0.6778, -0.6777, -0.6780, -0.6785, -0.6800, -0.6745, -0.6745, -0.6746, -0.6748, -0.6750, -0.6753,
1:         -0.6754], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([ 0.2988,  0.2705,  0.2425,  0.2149,  0.1879,  0.1613,  0.1356,  0.1108,  0.0866,  0.0632,  0.0404,  0.0179,
1:         -0.0043, -0.0263, -0.0484, -0.0705, -0.0926, -0.1153, -0.1381, -0.1614, -0.1851, -0.2091, -0.2333, -0.2576,
1:         -0.2819], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2234, -0.2211, -0.2211, -0.2211, -0.2188, -0.2164, -0.2118, -0.2047, -0.1966, -0.2281, -0.2258, -0.2234,
1:         -0.2199, -0.2153, -0.2106, -0.2071, -0.2012, -0.1966, -0.2304, -0.2269, -0.2223, -0.2176, -0.2129, -0.2094,
1:         -0.2059], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 43, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.8071,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.7892,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 43, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([ 0.1911,  0.1706,  0.1469,  0.1231,  0.0985,  0.0742,  0.0537,  0.0345,  0.0168,  0.0006, -0.0163, -0.0333,
1:         -0.0518, -0.0737, -0.0958, -0.1157, -0.1353, -0.1496,  0.1288,  0.1091,  0.0882,  0.0642,  0.0406,  0.0181,
1:         -0.0034], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([1.0255, 1.0363, 1.0380, 1.0336, 1.0233, 1.0131, 1.0031, 0.9917, 0.9816, 0.9717, 0.9623, 0.9534, 0.9444, 0.9360,
1:         0.9261, 0.9164, 0.9050, 0.8947, 0.9619, 0.9640, 0.9626, 0.9563, 0.9520, 0.9442, 0.9360], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.7136, -0.7133, -0.7138, -0.7159, -0.7174, -0.7183, -0.7186, -0.7182, -0.7181, -0.7165, -0.7151, -0.7136,
1:         -0.7112, -0.7100, -0.7087, -0.7078, -0.7076, -0.7064, -0.7105, -0.7091, -0.7091, -0.7106, -0.7118, -0.7118,
1:         -0.7114], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.1685,  0.1959,  0.1915,  0.1921,  0.2051,  0.2050,  0.1581,  0.1246,  0.1119,  0.0552,  0.0278,  0.0692,
1:          0.1012,  0.1352,  0.2122,  0.2867,  0.3159,  0.3075, -0.1541, -0.2251, -0.2770, -0.2672, -0.2196, -0.1278,
1:         -0.0348], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.0821, -0.0721, -0.0585, -0.0405, -0.0207, -0.0013,  0.0158,  0.0321,  0.0476,  0.0643,  0.0828,  0.1022,
1:          0.1218,  0.1395,  0.1572,  0.1728,  0.1874,  0.2003,  0.2141,  0.2299,  0.2485,  0.2705,  0.2938,  0.3184,
1:          0.3431], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2278, -0.2331, -0.2351, -0.2372, -0.2380, -0.2393, -0.2394, -0.2385, -0.2332, -0.2265, -0.2345, -0.2358,
1:         -0.2409, -0.2395, -0.2431, -0.2416, -0.2426, -0.2428, -0.2288, -0.2347, -0.2379, -0.2410, -0.2427, -0.2449,
1:         -0.2442], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0265, -0.0263, -0.0210, -0.0355, -0.0335, -0.0045, -0.0314, -0.0458, -0.0258, -0.0340, -0.0316, -0.0143,
1:         -0.0146, -0.0314, -0.0371, -0.0156, -0.0037, -0.0077, -0.0587, -0.0352, -0.0330, -0.0390, -0.0167, -0.0429,
1:         -0.0187], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 43 [1/5 (20%)]	Loss: 0.23382 : 0.18091 :: 0.02161 (1.71 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 43 [2/5 (40%)]	Loss: 0.29864 : 0.26125 :: 0.02490 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 43 [3/5 (60%)]	Loss: 0.26730 : 0.19916 :: 0.02169 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 43 [4/5 (80%)]	Loss: 0.24476 : 0.20453 :: 0.02271 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 43 : 0.21147450804710388
0: validation loss for velocity_u : 0.0035736304707825184
0: validation loss for velocity_v : 0.005172405857592821
0: validation loss for specific_humidity : 0.006516417488455772
0: validation loss for velocity_z : 0.11745317280292511
0: validation loss for temperature : 0.02135138399899006
0: validation loss for total_precip : 0.33884188532829285
0: validation loss for t2m : 0.9874126315116882
1: 44 : 04:37:21 :: batch_size = 96, lr = 1e-05
0: 44 : 04:37:21 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 44, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.8020, 0.7918, 0.7875, 0.7889, 0.7955, 0.8067, 0.8215, 0.8388, 0.8573, 0.8757, 0.8925, 0.9066, 0.9169, 0.9228,
0:         0.9243, 0.9214, 0.9146, 0.9043, 0.7971, 0.7905, 0.7889, 0.7921, 0.7996, 0.8105, 0.8241], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.7574, 0.8267, 0.8992, 0.9751, 1.0539, 1.1350, 1.2179, 1.3022, 1.3874, 1.4729, 1.5590, 1.6451, 1.7314, 1.8173,
0:         1.9032, 1.9884, 2.0733, 2.1573, 0.8069, 0.8821, 0.9609, 1.0428, 1.1272, 1.2133, 1.3003], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.4841, 0.4169, 0.3531, 0.3112, 0.3024, 0.3376, 0.4180, 0.5446, 0.7131, 0.9179, 1.1513, 1.3990, 1.6456, 1.8714,
0:         2.0629, 2.2083, 2.3096, 2.3745, 0.4599, 0.3586, 0.2826, 0.2529, 0.2826, 0.3784, 0.5358], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2492, -0.2480, -0.2480, -0.2469, -0.2469, -0.2469, -0.2469, -0.2469, -0.2480, -0.2492, -0.2492, -0.2492,
0:         -0.2492, -0.2492, -0.2480, -0.2480, -0.2469, -0.2469, -0.2480, -0.2480, -0.2480, -0.2480, -0.2480, -0.2492,
0:         -0.2492], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 44, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan, -1.1721, -1.1644,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 44, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.3769, -0.4002, -0.4222, -0.4438, -0.4645, -0.4842, -0.5018, -0.5204, -0.5395, -0.5588, -0.5787, -0.5976,
0:         -0.6171, -0.6328, -0.6486, -0.6638, -0.6826, -0.7044, -0.3642, -0.3870, -0.4072, -0.4288, -0.4506, -0.4713,
0:         -0.4901], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.7337, 0.7653, 0.7986, 0.8312, 0.8665, 0.9036, 0.9433, 0.9859, 1.0317, 1.0750, 1.1180, 1.1582, 1.1969, 1.2375,
0:         1.2761, 1.3209, 1.3660, 1.4138, 0.7193, 0.7551, 0.7946, 0.8314, 0.8715, 0.9094, 0.9482], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.7409, -0.7416, -0.7418, -0.7423, -0.7429, -0.7433, -0.7442, -0.7444, -0.7433, -0.7427, -0.7422, -0.7413,
0:         -0.7414, -0.7427, -0.7436, -0.7444, -0.7443, -0.7417, -0.7429, -0.7430, -0.7439, -0.7452, -0.7461, -0.7459,
0:         -0.7455], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([2.3720, 2.4152, 2.4207, 2.4114, 2.3884, 2.3754, 2.3912, 2.4168, 2.4316, 2.4058, 2.3704, 2.3321, 2.2731, 2.2447,
0:         2.2093, 2.1538, 2.1190, 2.0569, 2.4935, 2.5039, 2.5013, 2.4792, 2.4261, 2.3621, 2.3141], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.6486, 1.6185, 1.5858, 1.5544, 1.5217, 1.4920, 1.4616, 1.4309, 1.3976, 1.3612, 1.3209, 1.2811, 1.2440, 1.2073,
0:         1.1736, 1.1399, 1.1048, 1.0693, 1.0327, 0.9929, 0.9519, 0.9106, 0.8681, 0.8239, 0.7783], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1709, -0.1706, -0.1691, -0.1669, -0.1621, -0.1637, -0.1623, -0.1650, -0.1619, -0.1707, -0.1677, -0.1694,
0:         -0.1690, -0.1654, -0.1651, -0.1597, -0.1614, -0.1636, -0.1684, -0.1720, -0.1732, -0.1676, -0.1654, -0.1662,
0:         -0.1605], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0210, -0.0306, -0.0229, -0.0226, -0.0180, -0.0176, -0.0229, -0.0342, -0.0080, -0.0105, -0.0243, -0.0164,
0:         -0.0177, -0.0114, -0.0038, -0.0194, -0.0036, -0.0243, -0.0510,  0.0004, -0.0058, -0.0315, -0.0150, -0.0129,
0:         -0.0076], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 44, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.8020, 0.7918, 0.7875, 0.7889, 0.7955, 0.8067, 0.8215, 0.8388, 0.8573, 0.8757, 0.8925, 0.9066, 0.9169, 0.9228,
1:         0.9243, 0.9214, 0.9146, 0.9043, 0.7971, 0.7905, 0.7889, 0.7921, 0.7996, 0.8105, 0.8241], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0999,  0.1463,  0.0237, -0.1065, -0.2187, -0.0979, -0.1374,  0.0488,  0.0150, -0.0055, -0.0014, -0.1047,
1:         -0.2167, -0.0507, -0.0806,  0.0702, -0.0286,  0.0821, -0.0534, -0.0572, -0.0864, -0.1172, -0.1019, -0.0793,
1:         -0.1380], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6881, -0.6884, -0.6889, -0.6893, -0.6899, -0.6907, -0.6913, -0.6922, -0.6934, -0.6947, -0.6960, -0.6975,
1:         -0.6997, -0.7019, -0.7040, -0.7065, -0.7092, -0.7120, -0.6924, -0.6926, -0.6927, -0.6930, -0.6935, -0.6934,
1:         -0.6933], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.7085, 1.7225, 1.7338, 1.7423, 1.7482, 1.7520, 1.7544, 1.7572, 1.7616, 1.7680, 1.7780, 1.7913, 1.8077, 1.8265,
1:         1.8463, 1.8662, 1.8849, 1.9011, 1.9153, 1.9269, 1.9365, 1.9444, 1.9505, 1.9555, 1.9591], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2492, -0.2480, -0.2480, -0.2469, -0.2469, -0.2469, -0.2469, -0.2469, -0.2480, -0.2492, -0.2492, -0.2492,
1:         -0.2492, -0.2492, -0.2480, -0.2480, -0.2469, -0.2469, -0.2480, -0.2480, -0.2480, -0.2480, -0.2480, -0.2492,
1:         -0.2492], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 44, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([-0.9042,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan, -1.1842,     nan,     nan, -1.2467,     nan,     nan,     nan, -1.3491, -1.3750,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 44, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([ 0.5193,  0.4943,  0.4611,  0.4250,  0.3869,  0.3471,  0.3079,  0.2686,  0.2273,  0.1869,  0.1465,  0.1102,
1:          0.0782,  0.0474,  0.0184, -0.0063, -0.0336, -0.0602,  0.5021,  0.4727,  0.4402,  0.4042,  0.3673,  0.3298,
1:          0.2918], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.0293, 0.0450, 0.0589, 0.0719, 0.0866, 0.1038, 0.1193, 0.1332, 0.1500, 0.1652, 0.1790, 0.1948, 0.2055, 0.2152,
1:         0.2211, 0.2271, 0.2320, 0.2397, 0.0303, 0.0451, 0.0599, 0.0734, 0.0898, 0.1043, 0.1199], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.7350, -0.7350, -0.7345, -0.7348, -0.7342, -0.7345, -0.7347, -0.7344, -0.7337, -0.7324, -0.7315, -0.7313,
1:         -0.7313, -0.7322, -0.7328, -0.7331, -0.7330, -0.7309, -0.7341, -0.7336, -0.7336, -0.7336, -0.7340, -0.7342,
1:         -0.7340], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.4493, 0.4867, 0.4938, 0.4883, 0.4960, 0.5014, 0.4874, 0.4823, 0.4747, 0.4512, 0.4362, 0.4158, 0.3831, 0.3642,
1:         0.3582, 0.3614, 0.3608, 0.3347, 0.3769, 0.3944, 0.4021, 0.4053, 0.4132, 0.4229, 0.4211], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.5232, 0.5416, 0.5508, 0.5548, 0.5582, 0.5641, 0.5720, 0.5804, 0.5860, 0.5886, 0.5899, 0.5896, 0.5905, 0.5959,
1:         0.6025, 0.6135, 0.6255, 0.6378, 0.6513, 0.6648, 0.6798, 0.6972, 0.7162, 0.7343, 0.7497], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2532, -0.2528, -0.2469, -0.2467, -0.2474, -0.2491, -0.2481, -0.2506, -0.2485, -0.2536, -0.2520, -0.2496,
1:         -0.2472, -0.2447, -0.2465, -0.2447, -0.2484, -0.2505, -0.2538, -0.2508, -0.2495, -0.2440, -0.2436, -0.2406,
1:         -0.2426], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0188, -0.0199, -0.0052, -0.0238, -0.0137, -0.0187, -0.0164, -0.0296, -0.0253, -0.0007, -0.0224, -0.0084,
1:         -0.0055, -0.0109, -0.0174, -0.0257, -0.0030,  0.0087, -0.0359, -0.0134, -0.0126, -0.0215,  0.0071, -0.0085,
1:         -0.0151], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 44 [1/5 (20%)]	Loss: 0.29450 : 0.24703 :: 0.02369 (1.91 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 44 [2/5 (40%)]	Loss: 0.25998 : 0.20764 :: 0.02274 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 44 [3/5 (60%)]	Loss: 0.24327 : 0.20068 :: 0.02188 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 44 [4/5 (80%)]	Loss: 0.25025 : 0.22110 :: 0.02271 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 44 : 0.20813167095184326
0: validation loss for velocity_u : 0.0034871851094067097
0: validation loss for velocity_v : 0.004821860697120428
0: validation loss for specific_humidity : 0.00767254363745451
0: validation loss for velocity_z : 0.11928609758615494
0: validation loss for temperature : 0.025152554735541344
0: validation loss for total_precip : 0.35134580731391907
0: validation loss for t2m : 0.9451556205749512
1: 45 : 04:43:27 :: batch_size = 96, lr = 1e-05
0: 45 : 04:43:27 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 45, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.4373, 0.4725, 0.5006, 0.5186, 0.5305, 0.5381, 0.5495, 0.5662, 0.5733, 0.5651, 0.5414, 0.5027, 0.4698, 0.4561,
1:         0.4629, 0.4988, 0.5561, 0.6245, 0.4347, 0.4628, 0.4801, 0.4873, 0.4915, 0.4941, 0.4970], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0645, -0.0517,  0.0179, -0.0427,  0.0459,  0.1668,  0.0337, -0.1031, -0.0389, -0.1075, -0.0002,  0.0355,
1:         -0.0549,  0.0397,  0.0592,  0.1149,  0.0573, -0.1913, -0.1667, -0.0537, -0.0499, -0.1264,  0.1025, -0.1350,
1:          0.1008], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3739, -0.3663, -0.3637, -0.3610, -0.3641, -0.3982, -0.4445, -0.5369, -0.6296, -0.7098, -0.7559, -0.7667,
1:         -0.7755, -0.7635, -0.7491, -0.7260, -0.7002, -0.6779, -0.3498, -0.3475, -0.3476, -0.3519, -0.3782, -0.4297,
1:         -0.5217], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.6418, -1.6637, -1.6794, -1.6927, -1.7035, -1.7112, -1.7090, -1.6889, -1.6611, -1.6455, -1.6558, -1.6915,
1:         -1.7431, -1.8061, -1.8742, -1.9287, -1.9632, -1.9829, -1.9856, -1.9809, -1.9725, -1.9450, -1.8976, -1.8550,
1:         -1.8403], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1121, -0.1212, -0.0828,  0.0414,  0.1047,  0.1905,  0.2198, -0.0263, -0.1754, -0.1279, -0.2025, -0.0737,
1:         -0.0670,  0.0550,  0.2334,  0.3915,  0.1024, -0.0625, -0.1686, -0.0986,  0.0008,  0.0053,  0.1543,  0.2898,
1:          0.2018], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 45, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.4470,    nan,    nan,    nan,    nan,    nan,
1:            nan, 0.2295,    nan, 0.1819,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 45, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([ 0.4287,  0.3644,  0.2997,  0.2309,  0.1704,  0.1180,  0.0765,  0.0408,  0.0034, -0.0372, -0.0723, -0.1071,
1:         -0.1369, -0.1682, -0.1996, -0.2248, -0.2448, -0.2582,  0.2910,  0.2286,  0.1599,  0.0906,  0.0296, -0.0211,
1:         -0.0598], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.6545,  0.5581,  0.4279,  0.2834,  0.1515,  0.0616,  0.0215,  0.0347,  0.0746,  0.1088,  0.1119,  0.0701,
1:         -0.0126, -0.1050, -0.1886, -0.2380, -0.2484, -0.2267,  0.6502,  0.5706,  0.4557,  0.3163,  0.1764,  0.0600,
1:         -0.0131], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.0791, -0.0586, -0.0478, -0.0426, -0.0414, -0.0502, -0.0618, -0.0799, -0.0989, -0.1155, -0.1288, -0.1386,
1:         -0.1414, -0.1351, -0.1265, -0.1139, -0.0996, -0.0821, -0.1260, -0.0895, -0.0628, -0.0485, -0.0432, -0.0458,
1:         -0.0555], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.5153, 0.5083, 0.4422, 0.3654, 0.2611, 0.1735, 0.1314, 0.1482, 0.1894, 0.1723, 0.1287, 0.1057, 0.0795, 0.0599,
1:         0.0630, 0.1256, 0.2299, 0.2691, 0.4209, 0.3867, 0.3206, 0.2585, 0.2006, 0.1900, 0.1998], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.4536, -1.4654, -1.4795, -1.4949, -1.5090, -1.5194, -1.5264, -1.5305, -1.5377, -1.5472, -1.5580, -1.5664,
1:         -1.5737, -1.5805, -1.5857, -1.5913, -1.5936, -1.5898, -1.5777, -1.5551, -1.5244, -1.4823, -1.4326, -1.3767,
1:         -1.3168], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([ 0.2740,  0.2729,  0.2414,  0.1658,  0.0680, -0.0357, -0.1413, -0.2167, -0.2486,  0.4582,  0.4642,  0.3801,
1:          0.2774,  0.1324,  0.0115, -0.1243, -0.2254, -0.2744,  0.5940,  0.5630,  0.4809,  0.3423,  0.1674,  0.0161,
1:         -0.1233], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0148, -0.0222, -0.0243, -0.0195,  0.0041, -0.0027, -0.0013, -0.0220, -0.0094, -0.0190, -0.0356, -0.0282,
1:         -0.0138, -0.0041, -0.0239, -0.0253,  0.0074,  0.0098, -0.0353, -0.0124, -0.0248, -0.0152, -0.0089, -0.0051,
1:         -0.0038], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 45, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.4373, 0.4725, 0.5006, 0.5186, 0.5305, 0.5381, 0.5495, 0.5662, 0.5733, 0.5651, 0.5414, 0.5027, 0.4698, 0.4561,
0:         0.4629, 0.4988, 0.5561, 0.6245, 0.4347, 0.4628, 0.4801, 0.4873, 0.4915, 0.4941, 0.4970], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.3552, 1.4440, 1.5353, 1.6153, 1.6760, 1.7222, 1.7693, 1.8189, 1.8474, 1.8438, 1.8223, 1.8028, 1.8004, 1.8208,
0:         1.8571, 1.9006, 1.9504, 2.0083, 1.4111, 1.5038, 1.5877, 1.6512, 1.7001, 1.7494, 1.8041], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.4168, 1.3694, 1.3780, 1.2637, 1.0824, 0.9508, 0.7545, 0.8128, 1.2054, 1.4319, 1.5851, 1.8008, 1.6757, 1.4686,
0:         1.6736, 2.0382, 2.3812, 2.7997, 1.2356, 1.2205, 1.2313, 1.0695, 0.9077, 0.7610, 0.4719], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1121, -0.1212, -0.0828,  0.0414,  0.1047,  0.1905,  0.2198, -0.0263, -0.1754, -0.1279, -0.2025, -0.0737,
0:         -0.0670,  0.0550,  0.2334,  0.3915,  0.1024, -0.0625, -0.1686, -0.0986,  0.0008,  0.0053,  0.1543,  0.2898,
0:          0.2018], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 45, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan, -1.5493,     nan, -1.4982,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 45, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.6459, -0.6460, -0.6405, -0.6298, -0.6198, -0.6128, -0.6087, -0.6087, -0.6082, -0.6060, -0.5991, -0.5898,
0:         -0.5778, -0.5650, -0.5553, -0.5488, -0.5436, -0.5402, -0.6854, -0.6813, -0.6728, -0.6594, -0.6470, -0.6361,
0:         -0.6287], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([1.1495, 1.1387, 1.1336, 1.1367, 1.1482, 1.1748, 1.2104, 1.2559, 1.3048, 1.3437, 1.3632, 1.3492, 1.3049, 1.2371,
0:         1.1572, 1.0819, 1.0219, 0.9815, 1.1706, 1.1700, 1.1710, 1.1741, 1.1811, 1.1950, 1.2145], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.3932, -0.3970, -0.4002, -0.3985, -0.3896, -0.3731, -0.3536, -0.3329, -0.3138, -0.2967, -0.2822, -0.2682,
0:         -0.2556, -0.2445, -0.2345, -0.2249, -0.2155, -0.2056, -0.3782, -0.3808, -0.3848, -0.3867, -0.3802, -0.3665,
0:         -0.3492], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.6516, -0.5273, -0.4652, -0.4419, -0.4458, -0.5567, -0.7656, -1.0837, -1.3861, -1.4900, -1.3674, -1.0501,
0:         -0.7439, -0.4961, -0.3232, -0.3834, -0.5432, -0.7015, -0.5134, -0.4356, -0.4076, -0.3703, -0.3622, -0.5193,
0:         -0.8516], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-1.3061, -1.2698, -1.2355, -1.2073, -1.1860, -1.1696, -1.1564, -1.1456, -1.1374, -1.1305, -1.1240, -1.1178,
0:         -1.1116, -1.1039, -1.0950, -1.0851, -1.0753, -1.0653, -1.0573, -1.0534, -1.0556, -1.0650, -1.0808, -1.1009,
0:         -1.1248], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2417, -0.2351, -0.2359, -0.2259, -0.2245, -0.2219, -0.2248, -0.2298, -0.2244, -0.2413, -0.2381, -0.2320,
0:         -0.2211, -0.2156, -0.2181, -0.2185, -0.2238, -0.2267, -0.2273, -0.2269, -0.2236, -0.2157, -0.2091, -0.2055,
0:         -0.2092], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0215, -0.0334, -0.0165, -0.0222,  0.0019, -0.0158, -0.0088, -0.0221,  0.0034,  0.0020, -0.0204, -0.0240,
0:         -0.0154, -0.0190, -0.0067, -0.0231, -0.0015, -0.0009, -0.0438,  0.0023, -0.0116, -0.0255,  0.0005, -0.0038,
0:         -0.0117], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 45 [1/5 (20%)]	Loss: 0.22605 : 0.17565 :: 0.02179 (1.69 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 45 [2/5 (40%)]	Loss: 0.31713 : 0.23327 :: 0.02122 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 45 [3/5 (60%)]	Loss: 0.26779 : 0.21019 :: 0.02161 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 45 [4/5 (80%)]	Loss: 0.26847 : 0.21640 :: 0.02209 (8.43 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 45 : 0.20153260231018066
0: validation loss for velocity_u : 0.0036280278582125902
0: validation loss for velocity_v : 0.0049711111932992935
0: validation loss for specific_humidity : 0.006422762759029865
0: validation loss for velocity_z : 0.10980328917503357
0: validation loss for temperature : 0.01786990649998188
0: validation loss for total_precip : 0.22924715280532837
0: validation loss for t2m : 1.0387859344482422
1: 46 : 04:49:34 :: batch_size = 96, lr = 1e-05
0: 46 : 04:49:34 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 46, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.7666, 0.7348, 0.6598, 0.5890, 0.5432, 0.4924, 0.4193, 0.3998, 0.4486, 0.4937, 0.5180, 0.5095, 0.4578, 0.3736,
1:         0.2336, 0.0923, 0.0375, 0.0205, 0.6694, 0.6371, 0.5613, 0.5001, 0.4631, 0.4003, 0.3175], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0556, -0.0407,  0.1535, -0.1280,  0.0786,  0.1037,  0.2614, -0.1868,  0.0261, -0.0329,  0.0501, -0.0783,
1:         -0.1062, -0.0562,  0.0215,  0.0072, -0.0400,  0.0154, -0.0179,  0.0453,  0.0034,  0.0683,  0.0723,  0.0700,
1:         -0.1214], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.5740, 0.7821, 0.8721, 0.6582, 0.4886, 0.4658, 0.6179, 0.5993, 0.5391, 0.7476, 1.0092, 1.2493, 1.2886, 1.3346,
1:         1.7123, 2.1475, 2.3181, 2.2691, 0.7077, 0.8278, 0.7340, 0.5194, 0.4229, 0.5192, 0.7255], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.9048, 1.9059, 1.8412, 1.7580, 1.6951, 1.6399, 1.5718, 1.5232, 1.4705, 1.3873, 1.3651, 1.4423, 1.5293, 1.5734,
1:         1.5595, 1.5069, 1.5131, 1.5708, 1.6128, 1.6359, 1.6433, 1.6576, 1.6895, 1.7155, 1.7400], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([ 1.3741,  5.4048,  4.1688,  2.0499,  0.3163,  1.0095,  1.1611,  0.0316, -0.1478,  1.4146,  3.8425,  2.6621,
1:          0.5373, -0.0367,  0.7329,  0.0906, -0.1813, -0.2056,  0.5373,  0.2642,  0.2584,  0.2874,  0.1277,  0.5860,
1:          0.5593], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 46, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 46, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.1077, -0.0873, -0.0699, -0.0537, -0.0370, -0.0204,  0.0009,  0.0238,  0.0462,  0.0658,  0.0854,  0.1093,
1:          0.1373,  0.1681,  0.2037,  0.2367,  0.2669,  0.2927, -0.1236, -0.0994, -0.0768, -0.0538, -0.0318, -0.0085,
1:          0.0175], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.0021,  0.0261,  0.0409,  0.0403,  0.0255,  0.0007, -0.0343, -0.0711, -0.1058, -0.1376, -0.1627, -0.1787,
1:         -0.1933, -0.2024, -0.2104, -0.2148, -0.2141, -0.2124, -0.0229, -0.0002,  0.0155,  0.0197,  0.0146, -0.0019,
1:         -0.0275], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([2.2156, 2.0794, 1.9436, 1.8492, 1.8307, 1.8804, 1.9742, 2.0645, 2.1118, 2.0931, 2.0062, 1.8628, 1.6916, 1.5257,
1:         1.3997, 1.3190, 1.2959, 1.3072, 2.2442, 2.1384, 2.0204, 1.9403, 1.9185, 1.9549, 2.0168], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.0956,  0.0063, -0.0695, -0.1059, -0.1750, -0.2017, -0.1888, -0.1759, -0.1269, -0.0631,  0.0073,  0.0600,
1:          0.0340, -0.0208, -0.0279, -0.0090,  0.0408,  0.1311, -0.1578, -0.2293, -0.2539, -0.2081, -0.1879, -0.1199,
1:         -0.0391], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([2.5835, 2.5619, 2.5554, 2.5573, 2.5502, 2.5218, 2.4652, 2.3880, 2.2951, 2.1887, 2.0756, 1.9682, 1.8749, 1.8112,
1:         1.7905, 1.8045, 1.8393, 1.8747, 1.8984, 1.9033, 1.8934, 1.8772, 1.8561, 1.8336, 1.8132], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([ 1.6361,  1.5059,  1.2854,  1.0316,  0.7841,  0.6008,  0.3218,  0.0212, -0.1435,  2.5158,  2.5759,  2.6451,
1:          2.5551,  2.4137,  2.2506,  1.8528,  1.3867,  0.9854,  3.6478,  3.9439,  4.2699,  4.4642,  4.5695,  4.2409,
1:          3.6362], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0146, -0.0231, -0.0011, -0.0360, -0.0042,  0.0086, -0.0254, -0.0091, -0.0291, -0.0142, -0.0144, -0.0143,
1:          0.0040,  0.0036, -0.0135, -0.0138,  0.0014,  0.0203, -0.0336, -0.0087,  0.0045, -0.0069,  0.0092, -0.0018,
1:          0.0078], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 46, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.7616, -0.7652, -0.7685, -0.7715, -0.7740, -0.7762, -0.7780, -0.7796, -0.7810, -0.7820, -0.7828, -0.7833,
0:         -0.7834, -0.7830, -0.7823, -0.7811, -0.7800, -0.7785, -0.8005, -0.8036, -0.8063, -0.8088, -0.8111, -0.8132,
0:         -0.8151], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.8054, 0.8009, 0.7966, 0.7926, 0.7887, 0.7851, 0.7814, 0.7780, 0.7749, 0.7719, 0.7690, 0.7664, 0.7637, 0.7611,
0:         0.7587, 0.7562, 0.7540, 0.7522, 0.8066, 0.8029, 0.7991, 0.7954, 0.7914, 0.7875, 0.7832], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1442, -0.1571, -0.1721, -0.1893, -0.2065, -0.2259, -0.2452, -0.2668, -0.2861, -0.3033, -0.3184, -0.3313,
0:         -0.3377, -0.3399, -0.3377, -0.3313, -0.3205, -0.3098, -0.2130, -0.2323, -0.2539, -0.2754, -0.2969, -0.3205,
0:         -0.3442], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2182, -0.2182, -0.2182, -0.2160, -0.2160, -0.2182, -0.2182, -0.2182, -0.2182, -0.2182, -0.2182, -0.2182,
0:         -0.2160, -0.2138, -0.2116, -0.2094, -0.2116, -0.2116, -0.2050, -0.2072, -0.2094, -0.2094, -0.2116, -0.2116,
0:         -0.2116], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 46, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan, -0.5472, -0.6489,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 46, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.2878, 0.2957, 0.3014, 0.3039, 0.3052, 0.3075, 0.3110, 0.3176, 0.3238, 0.3299, 0.3363, 0.3443, 0.3509, 0.3550,
0:         0.3603, 0.3650, 0.3704, 0.3773, 0.2728, 0.2790, 0.2802, 0.2786, 0.2773, 0.2773, 0.2794], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.4328, -0.4650, -0.5025, -0.5400, -0.5756, -0.6054, -0.6274, -0.6440, -0.6595, -0.6728, -0.6888, -0.7065,
0:         -0.7237, -0.7426, -0.7609, -0.7781, -0.7893, -0.7980, -0.4168, -0.4449, -0.4807, -0.5203, -0.5580, -0.5904,
0:         -0.6187], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.5483, -0.5506, -0.5432, -0.5331, -0.5231, -0.5092, -0.4948, -0.4767, -0.4601, -0.4435, -0.4323, -0.4249,
0:         -0.4209, -0.4215, -0.4214, -0.4218, -0.4217, -0.4222, -0.5568, -0.5647, -0.5658, -0.5634, -0.5602, -0.5569,
0:         -0.5492], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.7368, 0.7257, 0.7090, 0.7003, 0.6771, 0.6575, 0.6692, 0.6674, 0.6579, 0.6729, 0.6835, 0.6987, 0.7082, 0.7102,
0:         0.7123, 0.7186, 0.7351, 0.7588, 0.7448, 0.7251, 0.7099, 0.6819, 0.6575, 0.6428, 0.6519], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.5612, 1.5734, 1.5829, 1.5888, 1.5939, 1.5978, 1.6015, 1.6049, 1.6077, 1.6097, 1.6113, 1.6129, 1.6115, 1.6082,
0:         1.6029, 1.5971, 1.5927, 1.5892, 1.5847, 1.5786, 1.5706, 1.5637, 1.5576, 1.5536, 1.5503], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2333, -0.2316, -0.2345, -0.2315, -0.2333, -0.2362, -0.2416, -0.2399, -0.2392, -0.2294, -0.2293, -0.2307,
0:         -0.2305, -0.2269, -0.2310, -0.2335, -0.2377, -0.2394, -0.2282, -0.2289, -0.2262, -0.2250, -0.2263, -0.2256,
0:         -0.2282], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0222, -0.0252,  0.0084, -0.0092, -0.0125, -0.0182, -0.0170, -0.0102, -0.0119, -0.0108, -0.0279, -0.0155,
0:         -0.0091,  0.0074, -0.0029, -0.0111, -0.0007, -0.0035, -0.0311,  0.0107,  0.0028, -0.0274, -0.0044, -0.0006,
0:          0.0113], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 46 [1/5 (20%)]	Loss: 0.24019 : 0.19253 :: 0.02225 (1.73 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 46 [2/5 (40%)]	Loss: 0.25653 : 0.20488 :: 0.02375 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 46 [3/5 (60%)]	Loss: 0.25187 : 0.19791 :: 0.02124 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 46 [4/5 (80%)]	Loss: 0.29187 : 0.24417 :: 0.02211 (8.45 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 46 : 0.20772844552993774
0: validation loss for velocity_u : 0.00367537559941411
0: validation loss for velocity_v : 0.005009305663406849
0: validation loss for specific_humidity : 0.0072065903805196285
0: validation loss for velocity_z : 0.11534906923770905
0: validation loss for temperature : 0.020829416811466217
0: validation loss for total_precip : 0.29762792587280273
0: validation loss for t2m : 1.004401683807373
1: 47 : 04:55:42 :: batch_size = 96, lr = 1e-05
0: 47 : 04:55:42 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 47, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.3975, -1.3858, -1.3728, -1.3651, -1.3680, -1.3868, -1.4148, -1.4421, -1.4586, -1.4609, -1.4513, -1.4339,
1:         -1.4166, -1.4003, -1.3850, -1.3693, -1.3530, -1.3418, -1.4551, -1.4408, -1.4233, -1.4090, -1.4083, -1.4264,
1:         -1.4524], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0639,  0.1115,  0.1364,  0.1474,  0.0856,  0.0434, -0.1939,  0.0240, -0.1765, -0.0190,  0.2470,  0.0121,
1:          0.0693,  0.1850, -0.1929,  0.1010, -0.1472, -0.0066,  0.1207,  0.1064,  0.0135, -0.2102,  0.1036,  0.1070,
1:         -0.0296], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.1882, 0.1728, 0.1538, 0.1328, 0.1230, 0.1209, 0.1311, 0.1439, 0.1593, 0.1668, 0.1728, 0.1758, 0.1751, 0.1773,
1:         0.1805, 0.1848, 0.1858, 0.1835, 0.2358, 0.2260, 0.2117, 0.1901, 0.1722, 0.1681, 0.1717], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.6163, 0.6230, 0.6341, 0.6549, 0.6709, 0.6419, 0.5369, 0.4021, 0.2793, 0.1981, 0.1734, 0.1763, 0.2068, 0.2379,
1:         0.2566, 0.2691, 0.2793, 0.2996, 0.3038, 0.3077, 0.3095, 0.2897, 0.2546, 0.1908, 0.1186], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2346, -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2369, -0.2392, -0.2392,
1:         -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2277, -0.2369, -0.2369, -0.2392, -0.2392, -0.2392,
1:         -0.2392], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 47, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan, 1.4867,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan, 0.6042,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 47, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-1.4305, -1.4188, -1.4069, -1.3955, -1.3815, -1.3698, -1.3538, -1.3360, -1.3192, -1.3002, -1.2808, -1.2612,
1:         -1.2444, -1.2288, -1.2183, -1.2052, -1.1905, -1.1716, -1.4410, -1.4295, -1.4160, -1.4046, -1.3917, -1.3783,
1:         -1.3626], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.1289,  0.1002,  0.0687,  0.0494,  0.0464,  0.0586,  0.0819,  0.1063,  0.1198,  0.1142,  0.0860,  0.0323,
1:         -0.0401, -0.1187, -0.1962, -0.2557, -0.2949, -0.3145,  0.1302,  0.1097,  0.0829,  0.0642,  0.0574,  0.0637,
1:          0.0745], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([3.8540, 3.9394, 4.0547, 4.1798, 4.2684, 4.2346, 4.0397, 3.6622, 3.1479, 2.5790, 2.0149, 1.5185, 1.1180, 0.8088,
1:         0.6037, 0.4876, 0.4603, 0.4926, 3.7643, 3.8468, 3.9531, 4.0627, 4.1099, 4.0225, 3.7658], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.4990, 0.6134, 0.7684, 0.6232, 0.5988, 0.8610, 0.9910, 0.9021, 0.6673, 0.3632, 0.3277, 0.3146, 0.1245, 0.1112,
1:         0.1964, 0.3133, 0.4544, 0.6654, 0.7617, 0.9884, 1.1599, 1.1084, 1.0006, 1.2547, 1.3908], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.1909, -1.4200, -1.5624, -1.5895, -1.4900, -1.2793, -1.0134, -0.7515, -0.5495, -0.4385, -0.4048, -0.4065,
1:         -0.3864, -0.3085, -0.1716, -0.0179,  0.0934,  0.1154,  0.0453, -0.0936, -0.2449, -0.3653, -0.4423, -0.4896,
1:         -0.5341], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2043, -0.2042, -0.2078, -0.2150, -0.2154, -0.2221, -0.2312, -0.2279, -0.2191, -0.2072, -0.2124, -0.2155,
1:         -0.2170, -0.2227, -0.2209, -0.2256, -0.2265, -0.2205, -0.2031, -0.2067, -0.2185, -0.2201, -0.2268, -0.2259,
1:         -0.2223], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0050, -0.0111, -0.0097, -0.0121, -0.0005,  0.0037,  0.0049, -0.0232, -0.0134, -0.0156, -0.0046, -0.0057,
1:          0.0145, -0.0041,  0.0176, -0.0147,  0.0259,  0.0074, -0.0218,  0.0064,  0.0095,  0.0017,  0.0095, -0.0014,
1:          0.0058], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 47, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.3975, -1.3858, -1.3728, -1.3651, -1.3680, -1.3868, -1.4148, -1.4421, -1.4586, -1.4609, -1.4513, -1.4339,
0:         -1.4166, -1.4003, -1.3850, -1.3693, -1.3530, -1.3418, -1.4551, -1.4408, -1.4233, -1.4090, -1.4083, -1.4264,
0:         -1.4524], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2327, 0.2193, 0.1993, 0.1762, 0.1557, 0.1440, 0.1392, 0.1346, 0.1267, 0.1150, 0.1017, 0.0898, 0.0798, 0.0720,
0:         0.0656, 0.0589, 0.0531, 0.0485, 0.2421, 0.2340, 0.2202, 0.2010, 0.1828, 0.1718, 0.1626], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.3061, 0.1801, 0.0888, 0.0106, 0.2213, 0.5690, 0.9471, 0.9840, 0.7320, 0.5060, 0.1735, 0.0388, 0.0519, 0.1257,
0:         0.2105, 0.2539, 0.2822, 0.2844, 0.4691, 0.3278, 0.2605, 0.2235, 0.5234, 0.8384, 1.0188], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2346, -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2369, -0.2392, -0.2392,
0:         -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2392, -0.2277, -0.2369, -0.2369, -0.2392, -0.2392, -0.2392,
0:         -0.2392], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 47, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan, -0.2464,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -0.4366,     nan,     nan,     nan, -0.1857,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 47, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.5531, -0.5448, -0.5373, -0.5274, -0.5155, -0.5029, -0.4899, -0.4800, -0.4697, -0.4606, -0.4481, -0.4322,
0:         -0.4167, -0.4088, -0.4141, -0.4323, -0.4584, -0.4843, -0.5435, -0.5363, -0.5305, -0.5250, -0.5153, -0.5021,
0:         -0.4883], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.0307, -0.0424, -0.0549, -0.0669, -0.0784, -0.0925, -0.1051, -0.1166, -0.1280, -0.1385, -0.1496, -0.1604,
0:         -0.1708, -0.1814, -0.1935, -0.2050, -0.2189, -0.2351, -0.0553, -0.0665, -0.0815, -0.0948, -0.1081, -0.1213,
0:         -0.1349], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([0.0801, 0.0287, 0.0300, 0.0830, 0.1704, 0.2634, 0.3512, 0.4233, 0.4722, 0.5095, 0.5290, 0.5344, 0.5303, 0.5015,
0:         0.4465, 0.3895, 0.3395, 0.3094, 0.0616, 0.0262, 0.0639, 0.1446, 0.2433, 0.3202, 0.3780], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.1974, 0.1947, 0.2111, 0.2399, 0.2577, 0.2860, 0.3186, 0.3203, 0.3039, 0.2968, 0.3085, 0.3318, 0.3581, 0.3835,
0:         0.3712, 0.3082, 0.2598, 0.2458, 0.1424, 0.1646, 0.1889, 0.2167, 0.2443, 0.2682, 0.2886], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.9243, -0.9557, -0.9908, -1.0348, -1.0873, -1.1389, -1.1768, -1.1842, -1.1581, -1.1021, -1.0419, -0.9929,
0:         -0.9720, -0.9830, -1.0017, -1.0170, -1.0148, -0.9858, -0.9311, -0.8568, -0.7745, -0.6943, -0.6359, -0.6120,
0:         -0.6118], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1401, -0.1593, -0.1821, -0.1929, -0.2020, -0.1946, -0.1861, -0.1745, -0.1540, -0.1430, -0.1667, -0.1782,
0:         -0.1937, -0.1993, -0.1949, -0.1828, -0.1701, -0.1521, -0.1533, -0.1652, -0.1796, -0.1871, -0.1924, -0.1890,
0:         -0.1773], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0080, -0.0035,  0.0090, -0.0159, -0.0071, -0.0112, -0.0050, -0.0013, -0.0060, -0.0109, -0.0097, -0.0096,
0:         -0.0093,  0.0057,  0.0124, -0.0084,  0.0056, -0.0038, -0.0275,  0.0173, -0.0092, -0.0303,  0.0043,  0.0011,
0:          0.0139], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 47 [1/5 (20%)]	Loss: 0.29188 : 0.21771 :: 0.02296 (1.83 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 47 [2/5 (40%)]	Loss: 0.27853 : 0.21450 :: 0.02168 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 47 [3/5 (60%)]	Loss: 0.26584 : 0.21425 :: 0.02146 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 47 [4/5 (80%)]	Loss: 0.19748 : 0.17503 :: 0.02150 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 47 : 0.20549778640270233
0: validation loss for velocity_u : 0.0032821418717503548
0: validation loss for velocity_v : 0.004623408894985914
0: validation loss for specific_humidity : 0.006792234256863594
0: validation loss for velocity_z : 0.10633447766304016
0: validation loss for temperature : 0.023080091923475266
0: validation loss for total_precip : 0.29596906900405884
0: validation loss for t2m : 0.9984031915664673
1: 48 : 05:01:56 :: batch_size = 96, lr = 1e-05
0: 48 : 05:01:56 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 48, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.1660, 0.1660, 0.1594, 0.1543, 0.1549, 0.1532, 0.1426, 0.1221, 0.0940, 0.0721, 0.0620, 0.0569, 0.0483, 0.0332,
1:         0.0228, 0.0266, 0.0385, 0.0504, 0.0877, 0.1102, 0.1215, 0.1247, 0.1254, 0.1223, 0.1147], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.1515,  0.0521,  0.0609,  0.1021, -0.0227,  0.0338,  0.0586, -0.0068,  0.0297, -0.1372, -0.0226, -0.0228,
1:          0.0178, -0.0401, -0.0427, -0.0329,  0.0043, -0.0806, -0.0604, -0.0298, -0.0437, -0.0812,  0.0405, -0.0553,
1:          0.0341], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0658,  0.0946,  0.1157,  0.1280,  0.1306,  0.1322,  0.1335,  0.1337,  0.1359,  0.1272,  0.1157,  0.1013,
1:          0.0835,  0.0556,  0.0355,  0.0105,  0.0026, -0.0036, -0.0066,  0.0069,  0.0145,  0.0051,  0.0045, -0.0044,
1:         -0.0054], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.2587, -1.2593, -1.2524, -1.2381, -1.2109, -1.1805, -1.1529, -1.1284, -1.1027, -1.0729, -1.0402, -1.0077,
1:         -0.9777, -0.9504, -0.9225, -0.8950, -0.8660, -0.8356, -0.8027, -0.7674, -0.7337, -0.7011, -0.6643, -0.6234,
1:         -0.5773], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1441, -0.1419, -0.1408, -0.1965, -0.1564, -0.0661, -0.1408, -0.1731, -0.2188, -0.1062, -0.1062, -0.1252,
1:         -0.1709, -0.1241, -0.0427, -0.2121, -0.2255, -0.2278,  0.0365, -0.0828, -0.1698, -0.2010, -0.1988, -0.1609,
1:         -0.1675], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 48, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.8413,     nan,     nan,
1:             nan, -0.8519,     nan,     nan,     nan,     nan,     nan,     nan, -0.8480,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 48, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.3496, 0.3678, 0.3895, 0.4145, 0.4416, 0.4717, 0.5005, 0.5318, 0.5630, 0.5968, 0.6362, 0.6823, 0.7318, 0.7803,
1:         0.8316, 0.8812, 0.9246, 0.9675, 0.3804, 0.4019, 0.4251, 0.4493, 0.4767, 0.5068, 0.5396], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.0156, -0.0091, -0.0349, -0.0536, -0.0619, -0.0593, -0.0494, -0.0391, -0.0306, -0.0260, -0.0254, -0.0290,
1:         -0.0362, -0.0472, -0.0594, -0.0679, -0.0726, -0.0716,  0.0086, -0.0148, -0.0385, -0.0564, -0.0626, -0.0591,
1:         -0.0511], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.7487, -0.7488, -0.7484, -0.7492, -0.7494, -0.7500, -0.7502, -0.7507, -0.7507, -0.7503, -0.7494, -0.7498,
1:         -0.7500, -0.7522, -0.7551, -0.7577, -0.7611, -0.7627, -0.7500, -0.7497, -0.7495, -0.7498, -0.7510, -0.7519,
1:         -0.7526], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.4680, -0.3645, -0.2901, -0.2132, -0.1444, -0.1392, -0.1054,  0.0060,  0.1350,  0.2659,  0.4593,  0.7266,
1:          1.0412,  1.4274,  1.8644,  2.2816,  2.6337,  2.7614, -0.5600, -0.4784, -0.4014, -0.2676, -0.1275, -0.0496,
1:          0.0756], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.0122, -0.0080, -0.0132, -0.0286, -0.0513, -0.0767, -0.1016, -0.1199, -0.1311, -0.1348, -0.1303, -0.1183,
1:         -0.0989, -0.0720, -0.0355,  0.0070,  0.0536,  0.0978,  0.1383,  0.1729,  0.2011,  0.2259,  0.2462,  0.2619,
1:          0.2754], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2401, -0.2421, -0.2416, -0.2418, -0.2340, -0.2309, -0.2269, -0.2218, -0.2120, -0.2362, -0.2394, -0.2385,
1:         -0.2418, -0.2374, -0.2344, -0.2318, -0.2247, -0.2225, -0.2325, -0.2349, -0.2343, -0.2366, -0.2361, -0.2368,
1:         -0.2345], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0109, -0.0003, -0.0032, -0.0154,  0.0104, -0.0019,  0.0198, -0.0096, -0.0169,  0.0128,  0.0185, -0.0132,
1:          0.0119,  0.0237,  0.0213,  0.0127,  0.0157,  0.0211,  0.0181,  0.0037,  0.0097,  0.0147,  0.0295,  0.0196,
1:         -0.0069], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 48, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.1660, 0.1660, 0.1594, 0.1543, 0.1549, 0.1532, 0.1426, 0.1221, 0.0940, 0.0721, 0.0620, 0.0569, 0.0483, 0.0332,
0:         0.0228, 0.0266, 0.0385, 0.0504, 0.0877, 0.1102, 0.1215, 0.1247, 0.1254, 0.1223, 0.1147], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6743, -0.5830, -0.4968, -0.4004, -0.3043, -0.2181, -0.1465, -0.0935, -0.0582, -0.0371, -0.0176,  0.0113,
0:          0.0491,  0.0912,  0.1266,  0.1539,  0.1836,  0.2192, -0.5927, -0.5168, -0.4341, -0.3405, -0.2505, -0.1745,
0:         -0.1150], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 1.0583,  0.9346,  0.5505,  0.1230, -0.0333,  0.0448,  0.0731, -0.0159, -0.0658,  0.0557,  0.2749,  0.4181,
0:          0.4485,  0.2966, -0.0051, -0.0940,  0.0644,  0.1316,  1.2992,  1.0062,  0.5874,  0.2011,  0.1056,  0.2944,
0:          0.3704], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1441, -0.1419, -0.1408, -0.1965, -0.1564, -0.0661, -0.1408, -0.1731, -0.2188, -0.1062, -0.1062, -0.1252,
0:         -0.1709, -0.1241, -0.0427, -0.2121, -0.2255, -0.2278,  0.0365, -0.0828, -0.1698, -0.2010, -0.1988, -0.1609,
0:         -0.1675], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 48, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([0.8094,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 1.1055,
0:            nan,    nan, 1.0507,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 48, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.4584, -0.4302, -0.4041, -0.3791, -0.3515, -0.3286, -0.3100, -0.2941, -0.2822, -0.2710, -0.2614, -0.2521,
0:         -0.2475, -0.2461, -0.2449, -0.2446, -0.2436, -0.2336, -0.4664, -0.4334, -0.4042, -0.3785, -0.3530, -0.3327,
0:         -0.3114], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.2880, 0.3376, 0.3927, 0.4508, 0.5107, 0.5707, 0.6284, 0.6855, 0.7379, 0.7848, 0.8207, 0.8488, 0.8723, 0.9015,
0:         0.9422, 1.0020, 1.0781, 1.1638, 0.2555, 0.3046, 0.3574, 0.4144, 0.4705, 0.5279, 0.5841], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.7796, -0.7797, -0.7801, -0.7817, -0.7835, -0.7848, -0.7839, -0.7837, -0.7829, -0.7815, -0.7787, -0.7735,
0:         -0.7627, -0.7458, -0.7231, -0.6971, -0.6712, -0.6484, -0.7799, -0.7794, -0.7799, -0.7808, -0.7827, -0.7834,
0:         -0.7836], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 1.0058e+00,  8.8512e-01,  6.6271e-01,  3.9505e-01,  1.7350e-01,  5.5419e-02,  6.4354e-03,  1.7040e-03,
0:         -4.1783e-02, -1.8686e-01, -3.5118e-01, -4.1072e-01, -4.3215e-01, -5.7602e-01, -8.9818e-01, -1.3564e+00,
0:         -1.9090e+00, -2.3405e+00,  1.1735e+00,  9.5911e-01,  6.4380e-01,  2.7037e-01, -4.4921e-02, -2.0204e-01,
0:         -2.4622e-01], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.4143, 0.4205, 0.4279, 0.4337, 0.4406, 0.4472, 0.4522, 0.4554, 0.4563, 0.4555, 0.4525, 0.4468, 0.4384, 0.4276,
0:         0.4145, 0.3968, 0.3754, 0.3485, 0.3174, 0.2835, 0.2480, 0.2137, 0.1806, 0.1488, 0.1169], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2293, -0.2302, -0.2299, -0.2294, -0.2252, -0.2300, -0.2327, -0.2354, -0.2305, -0.2287, -0.2290, -0.2269,
0:         -0.2291, -0.2265, -0.2278, -0.2293, -0.2296, -0.2320, -0.2284, -0.2312, -0.2285, -0.2249, -0.2256, -0.2260,
0:         -0.2285], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0110, -0.0010,  0.0094,  0.0031,  0.0019, -0.0052,  0.0051, -0.0026, -0.0010,  0.0105,  0.0095, -0.0053,
0:          0.0281,  0.0231,  0.0165,  0.0178,  0.0263,  0.0013, -0.0249,  0.0141,  0.0191,  0.0103,  0.0061,  0.0127,
0:          0.0114], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 48 [1/5 (20%)]	Loss: 0.24790 : 0.18809 :: 0.02291 (1.65 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 48 [2/5 (40%)]	Loss: 0.24480 : 0.17546 :: 0.02088 (8.46 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 48 [3/5 (60%)]	Loss: 0.30544 : 0.22825 :: 0.02209 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 48 [4/5 (80%)]	Loss: 0.29451 : 0.21015 :: 0.02252 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 48 : 0.20169025659561157
0: validation loss for velocity_u : 0.0038026487454771996
0: validation loss for velocity_v : 0.005264368373900652
0: validation loss for specific_humidity : 0.006492095999419689
0: validation loss for velocity_z : 0.11878542602062225
0: validation loss for temperature : 0.018315903842449188
0: validation loss for total_precip : 0.28156769275665283
0: validation loss for t2m : 0.9776034355163574
1: 49 : 05:08:06 :: batch_size = 96, lr = 1e-05
0: 49 : 05:08:06 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 49, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.7397, -0.7214, -0.7169, -0.7264, -0.7487, -0.7799, -0.8179, -0.8563, -0.8781, -0.8897, -0.9107, -0.9369,
1:         -0.9594, -0.9700, -0.9552, -0.9422, -0.9449, -0.9407, -0.7656, -0.7490, -0.7309, -0.7159, -0.7093, -0.7374,
1:         -0.7944], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 4.5478e-02, -1.3360e-01, -2.9483e-03, -1.4226e-01, -5.5163e-02,  4.7272e-02,  1.0991e-01,  4.2698e-02,
1:         -2.8932e-02, -9.4084e-02, -4.7813e-02,  9.9077e-02,  4.1323e-02,  5.5009e-02, -5.9922e-02,  1.2502e-01,
1:          1.3868e-01, -1.1542e-04,  2.4181e-01, -1.0958e-02, -1.9633e-01,  6.6928e-03,  1.8418e-01,  6.9797e-02,
1:         -3.5309e-02], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6561, -0.6517, -0.6494, -0.6462, -0.6410, -0.6380, -0.6341, -0.6325, -0.6308, -0.6309, -0.6334, -0.6379,
1:         -0.6433, -0.6485, -0.6509, -0.6547, -0.6625, -0.6667, -0.6501, -0.6482, -0.6453, -0.6387, -0.6324, -0.6278,
1:         -0.6275], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([ 0.8253,  0.7480,  0.7282,  0.7325,  0.7159,  0.6727,  0.6522,  0.6992,  0.8436,  0.9997,  1.1123,  1.1993,
1:          1.1954,  1.1766,  1.2101,  1.1722,  1.0535,  0.9477,  0.8525,  0.7393,  0.6180,  0.4728,  0.3026,  0.1378,
1:         -0.0119], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608,
1:         -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608, -0.2608,
1:         -0.2608], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 49, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan, -1.5540, -1.5044,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.3154,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 49, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.4738, -0.4728, -0.4778, -0.4900, -0.5093, -0.5336, -0.5571, -0.5806, -0.6039, -0.6275, -0.6506, -0.6703,
1:         -0.6858, -0.6965, -0.7014, -0.7065, -0.7130, -0.7214, -0.4696, -0.4714, -0.4782, -0.4928, -0.5141, -0.5400,
1:         -0.5670], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.3033, -0.2392, -0.1653, -0.0844, -0.0033,  0.0748,  0.1419,  0.1931,  0.2213,  0.2288,  0.2201,  0.2046,
1:          0.1838,  0.1657,  0.1478,  0.1325,  0.1219,  0.1115, -0.2866, -0.2216, -0.1472, -0.0671,  0.0121,  0.0887,
1:          0.1539], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.3680, -0.2971, -0.2274, -0.1532, -0.0783, -0.0045,  0.0566,  0.0915,  0.1201,  0.1500,  0.1874,  0.2378,
1:          0.3307,  0.4471,  0.5910,  0.7406,  0.8915,  1.0056, -0.3597, -0.2974, -0.2264, -0.1521, -0.0902, -0.0324,
1:          0.0067], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.4903, 0.6839, 0.7071, 0.5215, 0.2841, 0.1210, 0.0728, 0.1042, 0.1532, 0.2658, 0.4191, 0.5738, 0.7005, 0.6706,
1:         0.5270, 0.4194, 0.3800, 0.3834, 0.4346, 0.6683, 0.7419, 0.5888, 0.3772, 0.2293, 0.1597], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.5712, -0.5510, -0.5196, -0.4712, -0.4039, -0.3200, -0.2287, -0.1344, -0.0452,  0.0279,  0.0771,  0.0945,
1:          0.0788,  0.0478,  0.0233,  0.0305,  0.0899,  0.1937,  0.3184,  0.4295,  0.4974,  0.5176,  0.5039,  0.4799,
1:          0.4615], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.0280, -0.0890, -0.1663, -0.2206, -0.2462, -0.2581, -0.2549, -0.2520, -0.2426, -0.0040, -0.0699, -0.1422,
1:         -0.1991, -0.2409, -0.2615, -0.2643, -0.2647, -0.2601, -0.0022, -0.0677, -0.1290, -0.1847, -0.2287, -0.2545,
1:         -0.2648], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0142,  0.0090,  0.0070,  0.0071,  0.0057,  0.0132,  0.0232, -0.0025, -0.0267,  0.0020,  0.0148, -0.0066,
1:          0.0407,  0.0156,  0.0327,  0.0062,  0.0183,  0.0126,  0.0146,  0.0094,  0.0158,  0.0046,  0.0275,  0.0297,
1:          0.0063], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 49, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.7787, -0.7719, -0.7691, -0.7677, -0.7680, -0.7675, -0.7678, -0.7680, -0.7695, -0.7731, -0.7784, -0.7868,
0:         -0.7968, -0.8093, -0.8222, -0.8346, -0.8451, -0.8550, -0.7398, -0.7351, -0.7334, -0.7319, -0.7309, -0.7303,
0:         -0.7320], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2273, 0.2417, 0.2558, 0.2702, 0.2866, 0.3048, 0.3237, 0.3411, 0.3545, 0.3637, 0.3679, 0.3687, 0.3687, 0.3683,
0:         0.3700, 0.3711, 0.3715, 0.3706, 0.2503, 0.2627, 0.2753, 0.2887, 0.3036, 0.3182, 0.3312], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.0063,  0.0269, -0.0303, -0.0429, -0.1046, -0.2304, -0.2555, -0.3538, -0.2887, -0.2955, -0.2567, -0.2509,
0:         -0.2349, -0.1412, -0.1286, -0.0212, -0.0737, -0.0509,  0.0029,  0.0303, -0.0292, -0.0486, -0.1126, -0.2281,
0:         -0.2441], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2223, -0.2151, -0.2235, -0.2356, -0.2380, -0.2428, -0.2416, -0.2464, -0.2440, -0.2283, -0.2271, -0.2356,
0:         -0.2368, -0.2428, -0.2440, -0.2428, -0.2464, -0.2452, -0.2428, -0.2404, -0.2404, -0.2392, -0.2416, -0.2452,
0:         -0.2452], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 49, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan, 0.9805,    nan, 1.0750, 1.0824,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 49, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.5839, -0.5355, -0.4868, -0.4467, -0.4139, -0.3939, -0.3861, -0.3897, -0.4037, -0.4247, -0.4478, -0.4668,
0:         -0.4812, -0.4939, -0.5094, -0.5338, -0.5643, -0.5956, -0.5575, -0.4944, -0.4347, -0.3873, -0.3520, -0.3303,
0:         -0.3221], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.2582, 0.2547, 0.2504, 0.2444, 0.2392, 0.2361, 0.2320, 0.2317, 0.2321, 0.2323, 0.2273, 0.2209, 0.2145, 0.2080,
0:         0.2039, 0.2066, 0.2118, 0.2189, 0.2366, 0.2322, 0.2281, 0.2254, 0.2222, 0.2183, 0.2166], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.4784, -0.4956, -0.5139, -0.5330, -0.5496, -0.5629, -0.5716, -0.5780, -0.5815, -0.5832, -0.5840, -0.5858,
0:         -0.5858, -0.5849, -0.5837, -0.5811, -0.5799, -0.5778, -0.4988, -0.5156, -0.5349, -0.5521, -0.5673, -0.5795,
0:         -0.5874], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.3282, 0.3530, 0.3389, 0.2983, 0.2535, 0.2136, 0.1965, 0.1741, 0.1277, 0.0820, 0.0664, 0.0654, 0.0647, 0.0833,
0:         0.0933, 0.0727, 0.0556, 0.0420, 0.3720, 0.3695, 0.3472, 0.3210, 0.2843, 0.2403, 0.2029], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.3105, -0.4245, -0.5525, -0.7094, -0.9065, -1.1234, -1.3133, -1.4017, -1.3220, -1.0617, -0.6648, -0.2167,
0:          0.1787,  0.4498,  0.5800,  0.5916,  0.5286,  0.4086,  0.2380,  0.0121, -0.2341, -0.4397, -0.5431, -0.5137,
0:         -0.3800], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2513, -0.2523, -0.2537, -0.2593, -0.2598, -0.2576, -0.2561, -0.2553, -0.2536, -0.2493, -0.2520, -0.2487,
0:         -0.2509, -0.2504, -0.2505, -0.2493, -0.2515, -0.2520, -0.2497, -0.2528, -0.2471, -0.2440, -0.2433, -0.2428,
0:         -0.2482], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0161,  0.0237,  0.0075,  0.0147,  0.0254,  0.0050,  0.0282, -0.0051, -0.0002,  0.0182,  0.0173, -0.0027,
0:         -0.0027,  0.0066,  0.0355,  0.0145,  0.0182,  0.0030, -0.0164,  0.0210,  0.0148, -0.0116,  0.0006,  0.0144,
0:          0.0077], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 49 [1/5 (20%)]	Loss: 0.25742 : 0.18909 :: 0.02145 (1.84 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 49 [2/5 (40%)]	Loss: 0.32038 : 0.23037 :: 0.02119 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 49 [3/5 (60%)]	Loss: 0.37707 : 0.26834 :: 0.02212 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 49 [4/5 (80%)]	Loss: 0.29065 : 0.21536 :: 0.02255 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 49 : 0.1970670223236084
0: validation loss for velocity_u : 0.003403496230021119
0: validation loss for velocity_v : 0.00472113024443388
0: validation loss for specific_humidity : 0.006441048346459866
0: validation loss for velocity_z : 0.10286372900009155
0: validation loss for temperature : 0.021218013018369675
0: validation loss for total_precip : 0.24646154046058655
0: validation loss for t2m : 0.9943603277206421
1: 50 : 05:14:09 :: batch_size = 96, lr = 1e-05
0: 50 : 05:14:09 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 50, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.1349, -1.1296, -1.1242, -1.1184, -1.1123, -1.1059, -1.0993, -1.0922, -1.0849, -1.0774, -1.0696, -1.0615,
0:         -1.0533, -1.0447, -1.0360, -1.0271, -1.0182, -1.0090, -1.0767, -1.0744, -1.0716, -1.0685, -1.0650, -1.0610,
0:         -1.0566], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.5314, 1.5416, 1.5516, 1.5609, 1.5703, 1.5790, 1.5875, 1.5957, 1.6036, 1.6110, 1.6185, 1.6255, 1.6323, 1.6389,
0:         1.6452, 1.6516, 1.6578, 1.6639, 1.5486, 1.5630, 1.5773, 1.5909, 1.6040, 1.6168, 1.6289], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2637, -0.2724, -0.2810, -0.2896, -0.2982, -0.3069, -0.3155, -0.3241, -0.3328, -0.3414, -0.3479, -0.3522,
0:         -0.3586, -0.3608, -0.3651, -0.3651, -0.3651, -0.3651, -0.1300, -0.1343, -0.1386, -0.1408, -0.1472, -0.1515,
0:         -0.1580], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2159, -0.2181, -0.2203, -0.2181, -0.2181, -0.2203, -0.2203, -0.2203, -0.2203, -0.2203, -0.2203, -0.2203,
0:         -0.2226, -0.2226, -0.2226, -0.2226, -0.2248, -0.2248, -0.2226, -0.2226, -0.2226, -0.2226, -0.2226, -0.2226,
0:         -0.2248], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 50, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan, -0.4667, -0.4725,     nan,     nan, -0.4797,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.6360])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 50, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.4648, -0.4670, -0.4728, -0.4815, -0.4914, -0.4992, -0.5064, -0.5104, -0.5127, -0.5145, -0.5156, -0.5180,
0:         -0.5207, -0.5220, -0.5231, -0.5228, -0.5191, -0.5145, -0.4900, -0.4940, -0.4988, -0.5074, -0.5170, -0.5272,
0:         -0.5358], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.8961, 0.8964, 0.8952, 0.8952, 0.8969, 0.9025, 0.9084, 0.9120, 0.9147, 0.9143, 0.9146, 0.9140, 0.9160, 0.9186,
0:         0.9188, 0.9223, 0.9254, 0.9266, 0.8821, 0.8796, 0.8766, 0.8752, 0.8765, 0.8806, 0.8879], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.3573, -0.3567, -0.3561, -0.3558, -0.3553, -0.3559, -0.3539, -0.3550, -0.3545, -0.3543, -0.3545, -0.3539,
0:         -0.3525, -0.3474, -0.3408, -0.3328, -0.3278, -0.3250, -0.3317, -0.3289, -0.3297, -0.3294, -0.3297, -0.3296,
0:         -0.3295], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.1108, -0.0879, -0.0766, -0.0598, -0.0375, -0.0301, -0.0261, -0.0271, -0.0299, -0.0181, -0.0122, -0.0186,
0:         -0.0152, -0.0120, -0.0079,  0.0026,  0.0039,  0.0037, -0.0761, -0.0823, -0.0844, -0.0721, -0.0514, -0.0414,
0:         -0.0371], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.0489, 0.0541, 0.0596, 0.0677, 0.0766, 0.0872, 0.0971, 0.1053, 0.1114, 0.1158, 0.1188, 0.1236, 0.1304, 0.1387,
0:         0.1485, 0.1582, 0.1683, 0.1794, 0.1912, 0.2023, 0.2124, 0.2226, 0.2353, 0.2501, 0.2658], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2294, -0.2283, -0.2237, -0.2248, -0.2236, -0.2249, -0.2252, -0.2262, -0.2294, -0.2316, -0.2311, -0.2260,
0:         -0.2234, -0.2194, -0.2235, -0.2232, -0.2266, -0.2316, -0.2336, -0.2334, -0.2291, -0.2247, -0.2219, -0.2200,
0:         -0.2267], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0047,  0.0095, -0.0019,  0.0122,  0.0077,  0.0048,  0.0158, -0.0104, -0.0041,  0.0101,  0.0225, -0.0059,
0:          0.0012,  0.0040,  0.0385,  0.0128,  0.0061,  0.0109, -0.0109,  0.0054,  0.0187, -0.0200, -0.0107,  0.0159,
0:          0.0211], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 50, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.7012, -0.7274, -0.7609, -0.7937, -0.8210, -0.8424, -0.8609, -0.8799, -0.8937, -0.8939, -0.8809, -0.8600,
1:         -0.8360, -0.8167, -0.8067, -0.8064, -0.8134, -0.8210, -0.6876, -0.7118, -0.7442, -0.7790, -0.8121, -0.8438,
1:         -0.8763], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.1345, -0.0009, -0.0438,  0.0528, -0.0792, -0.0307, -0.0786,  0.0963,  0.0558,  0.0404,  0.0032,  0.1873,
1:         -0.0139, -0.0335,  0.0723,  0.0437,  0.0045, -0.0145, -0.0177,  0.1092, -0.2224,  0.0341, -0.0332, -0.1055,
1:         -0.0124], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.2011, -0.2051, -0.2201, -0.2588, -0.3066, -0.3407, -0.3635, -0.3545, -0.3235, -0.2825, -0.2384, -0.2200,
1:         -0.2136, -0.2394, -0.2780, -0.3166, -0.3637, -0.4171, -0.1674, -0.1705, -0.1811, -0.2198, -0.2726, -0.3252,
1:         -0.3572], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.1253, -0.1363, -0.1459, -0.1678, -0.2105, -0.2729, -0.3536, -0.4553, -0.5786, -0.7140, -0.8432, -0.9493,
1:         -1.0244, -1.0680, -1.0863, -1.0913, -1.0940, -1.1027, -1.1248, -1.1671, -1.2312, -1.3084, -1.3856, -1.4537,
1:         -1.5038], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2359, -0.2359, -0.2359, -0.2359, -0.2359, -0.2359, -0.2359, -0.1849, -0.1362, -0.2359, -0.2359, -0.2359,
1:         -0.2359, -0.2359, -0.2270, -0.2270, -0.2226, -0.1340, -0.2359, -0.2359, -0.2359, -0.2359, -0.2292, -0.2137,
1:         -0.1761], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 50, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan, 1.0229,    nan,    nan,    nan, 1.5334,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 50, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.2907, -0.2490, -0.1981, -0.1433, -0.0856, -0.0333,  0.0169,  0.0638,  0.1078,  0.1528,  0.1979,  0.2463,
1:          0.2923,  0.3337,  0.3733,  0.4091,  0.4436,  0.4780, -0.3516, -0.3130, -0.2612, -0.2068, -0.1487, -0.0929,
1:         -0.0383], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([2.1635, 2.2303, 2.3050, 2.3816, 2.4582, 2.5346, 2.6052, 2.6721, 2.7334, 2.7868, 2.8316, 2.8626, 2.8788, 2.8767,
1:         2.8579, 2.8220, 2.7820, 2.7374, 2.1066, 2.1640, 2.2343, 2.3098, 2.3861, 2.4664, 2.5438], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([0.1322, 0.1580, 0.1825, 0.1955, 0.2001, 0.2001, 0.1979, 0.1984, 0.1991, 0.1993, 0.1962, 0.1857, 0.1707, 0.1561,
1:         0.1440, 0.1354, 0.1214, 0.1099, 0.1111, 0.1466, 0.1716, 0.1809, 0.1839, 0.1803, 0.1726], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.5104,  0.5416,  0.5100,  0.4064,  0.2764,  0.1204,  0.0657,  0.0724,  0.0208, -0.0334, -0.0985, -0.1740,
1:         -0.1409, -0.1113, -0.1354, -0.1134, -0.0249,  0.1063,  0.5999,  0.8115,  0.7841,  0.5926,  0.3933,  0.1749,
1:          0.0481], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.1999, -0.2005, -0.2020, -0.2086, -0.2178, -0.2324, -0.2520, -0.2799, -0.3139, -0.3502, -0.3819, -0.4057,
1:         -0.4206, -0.4283, -0.4277, -0.4230, -0.4185, -0.4205, -0.4319, -0.4560, -0.4881, -0.5231, -0.5577, -0.5918,
1:         -0.6303], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([ 0.0580,  0.5173,  1.0862,  1.6063,  1.9001,  1.8634,  1.6014,  1.2110,  0.8253, -0.0178,  0.4747,  1.0305,
1:          1.5742,  1.8513,  1.8153,  1.5391,  1.1360,  0.7365,  0.0051,  0.4090,  0.8910,  1.3105,  1.5432,  1.5219,
1:          1.2600], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0061,  0.0252, -0.0087,  0.0111,  0.0083,  0.0125,  0.0133, -0.0054,  0.0047,  0.0118,  0.0186,  0.0073,
1:          0.0012,  0.0003,  0.0346,  0.0019,  0.0195,  0.0182, -0.0043, -0.0048, -0.0004,  0.0134,  0.0036,  0.0249,
1:          0.0011], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 50 [1/5 (20%)]	Loss: 0.29534 : 0.22460 :: 0.02267 (1.76 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 50 [2/5 (40%)]	Loss: 0.23992 : 0.17710 :: 0.02187 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 50 [3/5 (60%)]	Loss: 0.29923 : 0.24310 :: 0.02158 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 50 [4/5 (80%)]	Loss: 0.23231 : 0.17759 :: 0.02125 (8.43 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 50 : 0.20361202955245972
0: validation loss for velocity_u : 0.003422686131671071
0: validation loss for velocity_v : 0.004839634522795677
0: validation loss for specific_humidity : 0.006612424738705158
0: validation loss for velocity_z : 0.10726171731948853
0: validation loss for temperature : 0.019218532368540764
0: validation loss for total_precip : 0.2797074317932129
0: validation loss for t2m : 1.004221796989441
1: 51 : 05:20:20 :: batch_size = 96, lr = 1e-05
0: 51 : 05:20:20 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 51, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.8305, -0.7962, -0.7516, -0.7200, -0.6938, -0.6636, -0.6435, -0.6242, -0.5906, -0.5468, -0.5161, -0.5150,
1:         -0.5163, -0.4995, -0.4771, -0.4575, -0.4448, -0.4358, -0.8287, -0.7982, -0.7683, -0.7386, -0.7151, -0.6976,
1:         -0.6769], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0342,  0.0198,  0.0918, -0.0298, -0.0240, -0.0208,  0.0641,  0.0429,  0.0682,  0.1660,  0.0960,  0.1444,
1:          0.0431, -0.0245, -0.0095, -0.0837,  0.0686, -0.0549,  0.1142,  0.1897,  0.0396,  0.0085, -0.0246, -0.0296,
1:          0.1761], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.1000, -0.1064,  0.0713,  0.1382,  0.3204,  0.5604,  0.5502,  1.0631,  1.1807,  1.0072,  0.8094,  0.9662,
1:          1.1685,  1.5268,  1.3761,  0.8448,  0.8516,  1.0639,  0.1320,  0.2185,  0.2494,  0.2304,  0.3003,  0.4972,
1:          0.7937], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.3243, 1.2919, 1.2653, 1.3071, 1.2289, 1.1097, 1.0307, 0.8586, 0.8888, 1.1856, 1.3317, 1.3657, 1.3399, 1.1609,
1:         1.1185, 1.1974, 1.1077, 1.0014, 0.9403, 0.7571, 0.6234, 0.6533, 0.5947, 0.4617, 0.4721], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([1.7453, 0.8034, 0.3970, 0.2518, 0.3191, 0.3493, 0.9869, 0.3970, 0.4260, 2.9335, 3.0902, 2.4747, 1.6292, 0.8766,
1:         0.3853, 0.4887, 0.2587, 0.1623, 3.7058, 4.0914, 4.0589, 2.6791, 1.3203, 0.7361, 0.5224], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 51, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan, 1.3110,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan, 1.3711,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 51, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.0656, -0.0594, -0.0544, -0.0532, -0.0526, -0.0535, -0.0542, -0.0543, -0.0552, -0.0577, -0.0625, -0.0688,
1:         -0.0778, -0.0899, -0.1010, -0.1128, -0.1236, -0.1355, -0.0851, -0.0797, -0.0759, -0.0739, -0.0740, -0.0762,
1:         -0.0778], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.4987, 0.4815, 0.4564, 0.4241, 0.3826, 0.3380, 0.2931, 0.2545, 0.2234, 0.1972, 0.1749, 0.1494, 0.1159, 0.0805,
1:         0.0479, 0.0259, 0.0166, 0.0199, 0.4814, 0.4630, 0.4365, 0.4057, 0.3681, 0.3253, 0.2814], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([ 0.2354,  0.2256,  0.2027,  0.1602,  0.0942,  0.0188, -0.0523, -0.0904, -0.0795, -0.0265,  0.0681,  0.1759,
1:          0.2812,  0.3747,  0.4642,  0.5544,  0.6603,  0.7716,  0.1927,  0.1857,  0.1640,  0.1261,  0.0711,  0.0040,
1:         -0.0577], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.0273,  0.0097,  0.0226, -0.0192, -0.0984, -0.1345, -0.1428, -0.0933, -0.0093,  0.0714,  0.1580,  0.1974,
1:          0.2051,  0.2131,  0.2088,  0.2187,  0.2296,  0.1722,  0.0165,  0.0119,  0.0251, -0.0138, -0.0843, -0.1163,
1:         -0.1307], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-2.3563, -2.3486, -2.3079, -2.2293, -2.1201, -1.9939, -1.8797, -1.8031, -1.7848, -1.8239, -1.9080, -2.0142,
1:         -2.1178, -2.2019, -2.2659, -2.3145, -2.3554, -2.3889, -2.4143, -2.4292, -2.4392, -2.4493, -2.4668, -2.4900,
1:         -2.5144], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2560, -0.2617, -0.2607, -0.2626, -0.2602, -0.2588, -0.2570, -0.2544, -0.2536, -0.2623, -0.2666, -0.2664,
1:         -0.2671, -0.2639, -0.2647, -0.2634, -0.2595, -0.2579, -0.2623, -0.2654, -0.2689, -0.2681, -0.2663, -0.2631,
1:         -0.2652], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0152,  0.0061,  0.0024, -0.0089,  0.0023, -0.0049,  0.0314, -0.0159, -0.0121,  0.0119,  0.0118,  0.0002,
1:          0.0070,  0.0164,  0.0223,  0.0004,  0.0176,  0.0211, -0.0051, -0.0275, -0.0077, -0.0134, -0.0060,  0.0111,
1:         -0.0141], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 51, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.8305, -0.7962, -0.7516, -0.7200, -0.6938, -0.6636, -0.6435, -0.6242, -0.5906, -0.5468, -0.5161, -0.5150,
0:         -0.5163, -0.4995, -0.4771, -0.4575, -0.4448, -0.4358, -0.8287, -0.7982, -0.7683, -0.7386, -0.7151, -0.6976,
0:         -0.6769], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.0059,  0.0101,  0.0249,  0.0159,  0.0319,  0.0736,  0.0867,  0.0931,  0.1081,  0.1259,  0.1538,  0.1758,
0:          0.1916,  0.2052,  0.2041,  0.2005,  0.2026,  0.2024, -0.0262, -0.0262, -0.0165, -0.0112,  0.0036,  0.0313,
0:          0.0569], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6682, -0.7815, -0.9791, -0.8803, -0.5672, -0.4606, -0.3518, -0.2852, -0.6038, -1.1501, -2.0461, -2.8355,
0:         -2.6401, -2.0106, -1.3311, -0.6771, -0.8958, -1.7874, -0.5650, -0.6005, -0.8448, -0.8603, -0.5816, -0.4173,
0:         -0.2941], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([1.7453, 0.8034, 0.3970, 0.2518, 0.3191, 0.3493, 0.9869, 0.3970, 0.4260, 2.9335, 3.0902, 2.4747, 1.6292, 0.8766,
0:         0.3853, 0.4887, 0.2587, 0.1623, 3.7058, 4.0914, 4.0589, 2.6791, 1.3203, 0.7361, 0.5224], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 51, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -1.1441])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 51, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.8443, -0.8443, -0.8459, -0.8488, -0.8522, -0.8553, -0.8606, -0.8675, -0.8762, -0.8879, -0.9001, -0.9136,
0:         -0.9289, -0.9461, -0.9658, -0.9911, -1.0198, -1.0488, -0.8678, -0.8694, -0.8723, -0.8756, -0.8796, -0.8833,
0:         -0.8859], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([ 0.2917,  0.2803,  0.2668,  0.2527,  0.2344,  0.2146,  0.1935,  0.1694,  0.1417,  0.1111,  0.0782,  0.0411,
0:          0.0027, -0.0333, -0.0663, -0.0896, -0.1057, -0.1098,  0.3124,  0.3068,  0.2986,  0.2866,  0.2696,  0.2502,
0:          0.2268], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([0.5360, 0.5496, 0.5602, 0.5585, 0.5468, 0.5231, 0.4848, 0.4422, 0.3978, 0.3599, 0.3329, 0.3132, 0.3075, 0.3066,
0:         0.3094, 0.3182, 0.3273, 0.3416, 0.4101, 0.4149, 0.4146, 0.4021, 0.3782, 0.3431, 0.2973], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.3499,  0.2854,  0.2387,  0.2106,  0.1805,  0.1625,  0.1358,  0.0729, -0.0167, -0.0836, -0.1162, -0.1427,
0:         -0.1564, -0.1506, -0.1449, -0.1640, -0.1989, -0.2378,  0.3404,  0.2870,  0.2531,  0.2320,  0.2126,  0.1909,
0:          0.1507], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-2.5022, -2.5099, -2.5206, -2.5291, -2.5323, -2.5156, -2.4832, -2.4392, -2.4003, -2.3790, -2.3810, -2.3997,
0:         -2.4236, -2.4430, -2.4484, -2.4458, -2.4349, -2.4160, -2.3869, -2.3419, -2.2767, -2.1806, -2.0451, -1.8672,
0:         -1.6519], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1981, -0.2086, -0.2175, -0.2208, -0.2185, -0.2094, -0.1997, -0.1920, -0.1789, -0.1839, -0.2008, -0.2093,
0:         -0.2167, -0.2162, -0.2113, -0.2039, -0.1996, -0.1843, -0.1643, -0.1841, -0.2055, -0.2083, -0.2143, -0.2091,
0:         -0.2035], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0183,  0.0132, -0.0004,  0.0004,  0.0090, -0.0128,  0.0071,  0.0083, -0.0114,  0.0103,  0.0192, -0.0243,
0:          0.0041,  0.0149,  0.0265, -0.0028,  0.0107,  0.0052, -0.0084,  0.0104,  0.0089, -0.0317, -0.0082, -0.0026,
0:         -0.0037], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 51 [1/5 (20%)]	Loss: 0.24554 : 0.19084 :: 0.02067 (1.59 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 51 [2/5 (40%)]	Loss: 0.24552 : 0.18806 :: 0.02171 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 51 [3/5 (60%)]	Loss: 0.31664 : 0.22479 :: 0.02157 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 51 [4/5 (80%)]	Loss: 0.26875 : 0.21247 :: 0.02213 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 51 : 0.19818413257598877
0: validation loss for velocity_u : 0.0034576039761304855
0: validation loss for velocity_v : 0.00489913672208786
0: validation loss for specific_humidity : 0.007048581726849079
0: validation loss for velocity_z : 0.11316031962633133
0: validation loss for temperature : 0.021019693464040756
0: validation loss for total_precip : 0.27197420597076416
0: validation loss for t2m : 0.9657291173934937
1: 52 : 05:26:30 :: batch_size = 96, lr = 1e-05
0: 52 : 05:26:30 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 52, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.6980, -0.6940, -0.6983, -0.7184, -0.7438, -0.7729, -0.8147, -0.8449, -0.8405, -0.8264, -0.8071, -0.7837,
0:         -0.7591, -0.7591, -0.7722, -0.7284, -0.7494, -0.8509, -0.7010, -0.6968, -0.7031, -0.7288, -0.7408, -0.7564,
0:         -0.8044], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2572, -0.2436, -0.2486, -0.2265, -0.1869, -0.1633, -0.1138, -0.0725, -0.0742, -0.0934, -0.1059, -0.1168,
0:         -0.1600, -0.2038, -0.2269, -0.2461, -0.2401, -0.2142, -0.2968, -0.2810, -0.2776, -0.2217, -0.1779, -0.1852,
0:         -0.1451], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 1.3254,  1.2254,  1.4796,  1.6600,  1.4210,  1.4145,  1.3428,  1.2298,  1.4079,  1.5731,  1.1211,  0.9495,
0:          1.1689,  1.3167,  1.6078, -0.4629, -2.7140, -0.0414,  1.2319,  1.2558,  1.6317,  1.4384,  1.0777,  1.3384,
0:          1.2667], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1966, -0.2035, -0.2001, -0.1920, -0.2001, -0.2104, -0.2185, -0.2208, -0.2185, -0.2162, -0.2127, -0.2127,
0:         -0.2162, -0.2185, -0.2058, -0.2150, -0.2208, -0.2277, -0.2070, -0.2116, -0.2173, -0.2242, -0.2254, -0.2219,
0:         -0.2208], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 52, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan, 0.3847,    nan,    nan,    nan, 0.0092,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan,    nan,    nan,    nan,    nan,    nan, 0.0188,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 52, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.7983, -0.7671, -0.7323, -0.6986, -0.6680, -0.6383, -0.6084, -0.5774, -0.5558, -0.5510, -0.5703, -0.6132,
0:         -0.6722, -0.7328, -0.7852, -0.8214, -0.8367, -0.8349, -0.8104, -0.7897, -0.7614, -0.7304, -0.6978, -0.6652,
0:         -0.6327], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.0714, 0.1123, 0.1535, 0.1905, 0.2233, 0.2489, 0.2662, 0.2742, 0.2724, 0.2594, 0.2310, 0.1905, 0.1443, 0.1003,
0:         0.0707, 0.0590, 0.0643, 0.0744, 0.1582, 0.2009, 0.2405, 0.2689, 0.2889, 0.2980, 0.3016], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([2.2564, 2.1903, 2.1262, 2.0865, 2.0717, 2.0832, 2.1114, 2.1555, 2.2000, 2.2529, 2.3050, 2.3520, 2.3932, 2.4141,
0:         2.4125, 2.3876, 2.3404, 2.2874, 2.2433, 2.2011, 2.1641, 2.1391, 2.1318, 2.1384, 2.1478], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.6220, -0.7462, -0.7276, -0.5888, -0.4788, -0.4403, -0.4197, -0.4071, -0.4930, -0.5180, -0.4000, -0.4142,
0:         -0.4788, -0.4209, -0.3673, -0.2612, -0.1705, -0.2516, -0.6631, -0.7396, -0.7363, -0.6287, -0.5014, -0.4365,
0:         -0.4322], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.3784, -0.4990, -0.6437, -0.7725, -0.8459, -0.8402, -0.7709, -0.6636, -0.5537, -0.4547, -0.3632, -0.2638,
0:         -0.1496, -0.0325,  0.0785,  0.1757,  0.2618,  0.3339,  0.3833,  0.3926,  0.3565,  0.3002,  0.2628,  0.2842,
0:          0.3737], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([4.6189, 5.0954, 5.3975, 5.4163, 5.0307, 4.2313, 3.2906, 2.3762, 1.6698, 5.0162, 5.3612, 5.3414, 4.9925, 4.3376,
0:         3.4091, 2.4387, 1.6806, 1.0249, 4.9564, 4.9319, 4.5733, 3.8822, 3.0966, 2.2042, 1.4179], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0079,  0.0070,  0.0141, -0.0007, -0.0036, -0.0038,  0.0114,  0.0180, -0.0053, -0.0052,  0.0154,  0.0021,
0:          0.0002,  0.0113,  0.0267, -0.0138, -0.0035,  0.0018,  0.0053, -0.0214, -0.0053, -0.0219, -0.0079,  0.0179,
0:         -0.0058], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 52, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6980, -0.6940, -0.6983, -0.7184, -0.7438, -0.7729, -0.8147, -0.8449, -0.8405, -0.8264, -0.8071, -0.7837,
1:         -0.7591, -0.7591, -0.7722, -0.7284, -0.7494, -0.8509, -0.7010, -0.6968, -0.7031, -0.7288, -0.7408, -0.7564,
1:         -0.8044], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.1256, -0.0990,  0.0304,  0.0450, -0.0451,  0.0636,  0.1303, -0.0764, -0.0786,  0.1782, -0.0488, -0.0511,
1:         -0.0152, -0.1083, -0.1709, -0.1300,  0.0024, -0.2211,  0.0164,  0.1243,  0.1130, -0.1077,  0.0240, -0.1480,
1:         -0.0315], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.4811, 0.4984, 0.5281, 0.5902, 0.7198, 0.9718, 1.4238, 1.5052, 1.5557, 1.4857, 1.4632, 1.5116, 1.4108, 1.1785,
1:         1.0407, 1.4670, 1.2728, 0.9397, 0.4960, 0.5070, 0.5180, 0.5772, 1.1408, 0.7969, 1.1005], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.9701, 1.0443, 1.1913, 1.2965, 1.3436, 1.3434, 1.2499, 1.1375, 1.0242, 0.9375, 0.8780, 0.7663, 0.7059, 0.7383,
1:         0.8054, 1.0403, 1.2551, 1.0995, 0.8781, 0.8700, 0.8425, 0.7636, 0.7048, 0.6158, 0.5622], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1966, -0.2035, -0.2001, -0.1920, -0.2001, -0.2104, -0.2185, -0.2208, -0.2185, -0.2162, -0.2127, -0.2127,
1:         -0.2162, -0.2185, -0.2058, -0.2150, -0.2208, -0.2277, -0.2070, -0.2116, -0.2173, -0.2242, -0.2254, -0.2219,
1:         -0.2208], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 52, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 1.3511,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 52, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.6000, -0.5959, -0.5887, -0.5777, -0.5606, -0.5435, -0.5262, -0.5144, -0.5089, -0.5077, -0.5100, -0.5104,
1:         -0.5099, -0.5101, -0.5113, -0.5148, -0.5210, -0.5295, -0.6187, -0.6171, -0.6140, -0.6034, -0.5882, -0.5700,
1:         -0.5560], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.0790,  0.0703,  0.0572,  0.0401,  0.0208,  0.0034, -0.0108, -0.0139, -0.0084,  0.0013,  0.0179,  0.0345,
1:          0.0430,  0.0522,  0.0637,  0.0822,  0.1094,  0.1396,  0.1049,  0.0997,  0.0874,  0.0736,  0.0538,  0.0378,
1:          0.0248], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([1.8935, 1.8636, 1.8367, 1.8144, 1.7963, 1.7844, 1.7691, 1.7558, 1.7417, 1.7194, 1.6913, 1.6425, 1.5738, 1.4865,
1:         1.3870, 1.2921, 1.2129, 1.1687, 1.9418, 1.9267, 1.9158, 1.9067, 1.8962, 1.8734, 1.8325], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-2.4760, -3.0870, -3.7974, -3.7006, -2.1791, -0.7671, -1.5620, -2.1670, -0.7515,  0.2313, -0.0480, -0.1122,
1:          0.4967,  0.4943, -0.2071, -0.4810, -0.5044, -0.6217, -2.7623, -2.9583, -3.4847, -4.0095, -3.6785, -2.4619,
1:         -2.2813], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.0069, 0.9545, 0.8979, 0.8492, 0.8071, 0.7730, 0.7457, 0.7371, 0.7422, 0.7619, 0.7937, 0.8308, 0.8807, 0.9365,
1:         0.9900, 1.0276, 1.0322, 0.9981, 0.9334, 0.8520, 0.7603, 0.6712, 0.5868, 0.5202, 0.4883], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-2.2477e-01, -2.4079e-01, -2.5396e-01, -2.6117e-01, -2.5836e-01, -2.4178e-01, -2.6342e-01, -2.6848e-01,
1:         -2.6314e-01, -2.0668e-01, -1.9856e-01, -1.9769e-01, -1.5050e-01, -1.5373e-01, -1.5159e-01, -1.6887e-01,
1:         -1.8150e-01, -2.0234e-01, -1.9960e-01, -1.5125e-01, -1.1118e-01, -4.2997e-02,  2.2790e-04,  1.0583e-02,
1:         -2.7270e-02], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 1.1025e-02,  8.7294e-03,  1.1863e-02, -8.1658e-03, -9.6972e-04, -3.1214e-03,  1.9930e-02,  1.5219e-02,
1:         -1.4769e-02,  2.8805e-03,  2.4813e-02,  7.6285e-03, -9.5941e-05,  1.0082e-02,  1.5808e-02,  4.3175e-03,
1:          1.7398e-02,  2.3599e-02, -9.1898e-03, -7.2688e-03, -1.5522e-03, -8.9491e-03,  1.6179e-02,  7.3289e-03,
1:         -8.5545e-03], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 52 [1/5 (20%)]	Loss: 0.27050 : 0.21454 :: 0.02194 (1.81 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 52 [2/5 (40%)]	Loss: 0.28892 : 0.20548 :: 0.02155 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 52 [3/5 (60%)]	Loss: 0.26133 : 0.21197 :: 0.02170 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 52 [4/5 (80%)]	Loss: 0.26246 : 0.23448 :: 0.02190 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 52 : 0.21376372873783112
0: validation loss for velocity_u : 0.0037195044569671154
0: validation loss for velocity_v : 0.005206667818129063
0: validation loss for specific_humidity : 0.006333182565867901
0: validation loss for velocity_z : 0.11422614753246307
0: validation loss for temperature : 0.01913810893893242
0: validation loss for total_precip : 0.2963777184486389
0: validation loss for t2m : 1.051344633102417
1: 53 : 05:32:30 :: batch_size = 96, lr = 1e-05
0: 53 : 05:32:30 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 53, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.7166, 1.7369, 1.7842, 1.8380, 1.8843, 1.9364, 1.9876, 2.0241, 2.0391, 2.0372, 2.0315, 2.0189, 2.0100, 2.0106,
0:         1.9986, 1.9688, 1.9326, 1.9198, 1.8075, 1.8739, 1.9318, 1.9721, 1.9936, 2.0152, 2.0336], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.6959, 1.7294, 1.7566, 1.7583, 1.7435, 1.7275, 1.7221, 1.7206, 1.7277, 1.7604, 1.7928, 1.7882, 1.7633, 1.7421,
0:         1.7179, 1.6888, 1.6441, 1.5757, 1.6670, 1.7119, 1.7371, 1.7315, 1.7111, 1.6938, 1.6934], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-3.9583, -3.5680, -3.3529, -3.8285, -4.3330, -4.7189, -4.1678, -2.1422, -0.1043,  0.7915,  0.8093,  0.4567,
0:          0.0343, -0.1731,  0.3015,  1.0997,  0.1795, -2.7287, -3.0569, -2.2275, -1.2596, -0.4691,  0.1906,  0.5365,
0:          0.8481], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2495, -0.2495, -0.2495,  0.1152,  2.1369,  2.2113,  1.4914,  0.4224, -0.2111, -0.2495, -0.2423, -0.2399,
0:         -0.2471,  0.0696,  0.0720,  0.0732, -0.2471, -0.2351,  1.3942,  0.7775, -0.0971, -0.1355, -0.2471, -0.2471,
0:         -0.2483], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 53, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:          0.6366,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1125,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 53, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.4633, 0.4439, 0.4237, 0.4012, 0.3772, 0.3526, 0.3294, 0.3081, 0.2920, 0.2801, 0.2725, 0.2657, 0.2596, 0.2527,
0:         0.2443, 0.2380, 0.2352, 0.2373, 0.4169, 0.3952, 0.3737, 0.3515, 0.3300, 0.3093, 0.2896], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.2478, -0.2268, -0.2030, -0.1751, -0.1488, -0.1253, -0.1031, -0.0813, -0.0578, -0.0274,  0.0108,  0.0554,
0:          0.1022,  0.1499,  0.1954,  0.2448,  0.2983,  0.3588, -0.2147, -0.1899, -0.1639, -0.1380, -0.1143, -0.0951,
0:         -0.0768], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6443, -0.5540, -0.4357, -0.3026, -0.1624, -0.0219,  0.1134,  0.2363,  0.3433,  0.4234,  0.4566,  0.4335,
0:          0.3520,  0.2281,  0.0971, -0.0257, -0.1104, -0.1575, -0.6012, -0.4889, -0.3458, -0.1885, -0.0433,  0.0940,
0:          0.2079], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.9087, -0.8338, -0.4095, -0.3030, -1.1738, -1.9889, -1.4336, -0.8517, -1.1215, -1.1795, -1.1745, -0.7486,
0:          0.1554, -0.0758, -0.4392,  0.3926,  0.6101, -0.1976, -0.9687, -0.8724, -0.6847, -0.6339, -1.0937, -1.7321,
0:         -1.3391], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.2426, -0.2792, -0.3305, -0.3899, -0.4493, -0.4926, -0.5099, -0.5022, -0.4728, -0.4318, -0.3887, -0.3461,
0:         -0.3069, -0.2747, -0.2455, -0.2230, -0.2035, -0.1861, -0.1684, -0.1536, -0.1418, -0.1335, -0.1275, -0.1228,
0:         -0.1202], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2395, -0.2433, -0.2455, -0.2485, -0.2503, -0.2536, -0.2599, -0.2625, -0.2608, -0.2425, -0.2450, -0.2461,
0:         -0.2495, -0.2475, -0.2541, -0.2598, -0.2642, -0.2678, -0.2437, -0.2479, -0.2450, -0.2423, -0.2495, -0.2499,
0:         -0.2593], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0137,  0.0098,  0.0079,  0.0221,  0.0128, -0.0084, -0.0011,  0.0113,  0.0023,  0.0077,  0.0235,  0.0057,
0:          0.0169, -0.0023,  0.0246,  0.0007, -0.0008,  0.0160, -0.0097,  0.0070,  0.0019, -0.0304, -0.0087,  0.0027,
0:          0.0040], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 53, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.7166, 1.7369, 1.7842, 1.8380, 1.8843, 1.9364, 1.9876, 2.0241, 2.0391, 2.0372, 2.0315, 2.0189, 2.0100, 2.0106,
1:         1.9986, 1.9688, 1.9326, 1.9198, 1.8075, 1.8739, 1.9318, 1.9721, 1.9936, 2.0152, 2.0336], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0274, -0.0044,  0.1326, -0.1099, -0.1259, -0.0712,  0.0768,  0.1508,  0.0340,  0.1054, -0.1212,  0.0598,
1:          0.2487, -0.0973, -0.1860,  0.1972, -0.0756, -0.0524,  0.1096, -0.0089, -0.1824, -0.1693,  0.2086, -0.0935,
1:         -0.1203], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.8066, 0.8033, 0.7026, 0.5262, 0.4914, 0.4663, 0.5052, 0.5335, 0.5450, 0.5522, 0.5293, 0.5714, 0.6223, 0.6512,
1:         0.6551, 0.6473, 0.6595, 0.6783, 0.7053, 0.6698, 0.6108, 0.6011, 0.6017, 0.5902, 0.5830], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., 0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0., -0., -0., 0., 0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.9320, -1.9083, -1.8465, -1.7689, -1.7288, -1.7059, -1.7303, -1.7911, -1.8199, -1.8210, -1.8036, -1.7599,
1:         -1.7281, -1.7282, -1.7307, -1.7287, -1.6886, -1.5804, -1.5419, -1.6110, -1.6424, -1.6694, -1.7258, -1.7223,
1:         -1.7173], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2495, -0.2495, -0.2495,  0.1152,  2.1369,  2.2113,  1.4914,  0.4224, -0.2111, -0.2495, -0.2423, -0.2399,
1:         -0.2471,  0.0696,  0.0720,  0.0732, -0.2471, -0.2351,  1.3942,  0.7775, -0.0971, -0.1355, -0.2471, -0.2471,
1:         -0.2483], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 53, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan, -1.2314,     nan, -1.2921,     nan,     nan,     nan,     nan, -1.2420,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 53, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([1.8226, 1.8307, 1.8376, 1.8369, 1.8294, 1.8123, 1.7950, 1.7730, 1.7563, 1.7435, 1.7355, 1.7302, 1.7200, 1.6991,
1:         1.6708, 1.6384, 1.6031, 1.5721, 1.8089, 1.8131, 1.8132, 1.8097, 1.7988, 1.7806, 1.7586], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([1.2149, 1.2205, 1.2213, 1.2154, 1.1963, 1.1671, 1.1313, 1.0977, 1.0713, 1.0464, 1.0286, 1.0086, 0.9845, 0.9563,
1:         0.9285, 0.8973, 0.8652, 0.8352, 1.1990, 1.1985, 1.1914, 1.1780, 1.1571, 1.1254, 1.0916], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.4669, -0.4661, -0.4673, -0.4724, -0.4769, -0.4781, -0.4765, -0.4751, -0.4721, -0.4647, -0.4570, -0.4500,
1:         -0.4441, -0.4393, -0.4351, -0.4304, -0.4237, -0.4168, -0.4639, -0.4659, -0.4720, -0.4789, -0.4827, -0.4839,
1:         -0.4839], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 1.0617,  1.0451,  0.9849,  0.8892,  0.7919,  0.8102,  0.8714,  0.9234,  0.9965,  0.9573,  0.7812,  0.5800,
1:          0.3284,  0.1086,  0.0040, -0.0047,  0.0843,  0.1810,  1.2878,  1.1869,  1.0356,  0.9119,  0.7977,  0.8030,
1:          0.8355], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.7353, -1.6384, -1.3763, -0.9749, -0.5599, -0.2929, -0.2870, -0.5219, -0.8589, -1.1273, -1.2190, -1.1642,
1:         -1.0638, -1.0192, -1.0454, -1.0914, -1.0892, -1.0055, -0.8578, -0.6880, -0.5284, -0.3852, -0.2559, -0.1341,
1:         -0.0341], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2478, -0.2504, -0.2489, -0.2496, -0.2513, -0.2536, -0.2568, -0.2572, -0.2555, -0.2513, -0.2533, -0.2506,
1:         -0.2529, -0.2517, -0.2560, -0.2568, -0.2578, -0.2567, -0.2522, -0.2521, -0.2493, -0.2490, -0.2484, -0.2500,
1:         -0.2558], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0187,  0.0206,  0.0190,  0.0081, -0.0050,  0.0054,  0.0242,  0.0066,  0.0032,  0.0016,  0.0199,  0.0015,
1:          0.0202,  0.0127,  0.0126, -0.0058,  0.0092,  0.0160,  0.0031, -0.0075, -0.0203, -0.0056, -0.0066,  0.0065,
1:         -0.0111], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 53 [1/5 (20%)]	Loss: 0.25623 : 0.20360 :: 0.02166 (1.82 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 53 [2/5 (40%)]	Loss: 0.22101 : 0.17306 :: 0.02151 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 53 [3/5 (60%)]	Loss: 0.26530 : 0.18946 :: 0.02113 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 53 [4/5 (80%)]	Loss: 0.24139 : 0.19471 :: 0.02164 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 53 : 0.20457002520561218
0: validation loss for velocity_u : 0.003662374336272478
0: validation loss for velocity_v : 0.0050223893485963345
0: validation loss for specific_humidity : 0.00648454437032342
0: validation loss for velocity_z : 0.1140206903219223
0: validation loss for temperature : 0.01871836557984352
0: validation loss for total_precip : 0.2949821650981903
0: validation loss for t2m : 0.9890992641448975
1: 54 : 05:38:34 :: batch_size = 96, lr = 1e-05
0: 54 : 05:38:34 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 54, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.3108, 1.2972, 1.2807, 1.2628, 1.2438, 1.2249, 1.2078, 1.1925, 1.1779, 1.1631, 1.1448, 1.1205, 1.0908, 1.0586,
0:         1.0254, 0.9925, 0.9595, 0.9270, 1.3432, 1.3343, 1.3225, 1.3083, 1.2916, 1.2726, 1.2534], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.9043, -0.9112, -0.9185, -0.9255, -0.9316, -0.9368, -0.9418, -0.9474, -0.9551, -0.9665, -0.9798, -0.9921,
0:         -1.0023, -1.0087, -1.0104, -1.0094, -1.0064, -1.0031, -0.9324, -0.9395, -0.9476, -0.9555, -0.9624, -0.9673,
0:         -0.9705], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.3520,  0.3082,  0.2150,  0.1405,  0.0966,  0.0516,  0.0056, -0.0437, -0.1029, -0.1588, -0.2126, -0.2882,
0:         -0.3540, -0.3617, -0.3003, -0.1852, -0.0689, -0.0295,  0.0802,  0.0966,  0.1043,  0.1437,  0.1898,  0.1898,
0:          0.1437], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([ 0.2277,  0.0931, -0.0209, -0.0506, -0.0415, -0.0871, -0.1510, -0.1578, -0.1715,  0.2893,  0.2117,  0.2323,
0:          0.1889,  0.1524,  0.0201, -0.0894, -0.1099, -0.1213,  0.5037,  0.4079,  0.4558,  0.3851,  0.2802,  0.1638,
0:          0.0612], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 54, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan, -0.9836,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.5170,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 54, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([1.6187, 1.6287, 1.6353, 1.6391, 1.6442, 1.6530, 1.6626, 1.6753, 1.6855, 1.6956, 1.7043, 1.7163, 1.7284, 1.7472,
0:         1.7693, 1.7942, 1.8168, 1.8311, 1.6652, 1.6733, 1.6777, 1.6789, 1.6853, 1.6940, 1.7063], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.9403, -0.9720, -1.0035, -1.0372, -1.0852, -1.1526, -1.2375, -1.3344, -1.4321, -1.5201, -1.5956, -1.6551,
0:         -1.7028, -1.7319, -1.7468, -1.7533, -1.7472, -1.7289, -1.0403, -1.0784, -1.1101, -1.1337, -1.1581, -1.2032,
0:         -1.2627], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.0048, -0.0086, -0.0152, -0.0245, -0.0401, -0.0575, -0.0800, -0.1048, -0.1308, -0.1561, -0.1827, -0.2040,
0:         -0.2231, -0.2387, -0.2499, -0.2617, -0.2719, -0.2850, -0.0169, -0.0195, -0.0253, -0.0337, -0.0451, -0.0582,
0:         -0.0756], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.5395, 0.5380, 0.5741, 0.6310, 0.6633, 0.6803, 0.6809, 0.6830, 0.6777, 0.6535, 0.6399, 0.6378, 0.6295, 0.6054,
0:         0.5719, 0.5507, 0.5333, 0.5452, 0.7067, 0.6644, 0.6620, 0.6913, 0.7117, 0.7423, 0.7519], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.2488, -0.2410, -0.2349, -0.2303, -0.2264, -0.2238, -0.2255, -0.2301, -0.2370, -0.2449, -0.2545, -0.2664,
0:         -0.2794, -0.2912, -0.3013, -0.3066, -0.3085, -0.3067, -0.3022, -0.2962, -0.2884, -0.2802, -0.2708, -0.2603,
0:         -0.2504], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1511, -0.1257, -0.1031, -0.0837, -0.0633, -0.0608, -0.0637, -0.0737, -0.0747, -0.1422, -0.1261, -0.1079,
0:         -0.0976, -0.0856, -0.0874, -0.0890, -0.1005, -0.1037, -0.1152, -0.1204, -0.1084, -0.1037, -0.0993, -0.1000,
0:         -0.1177], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0018,  0.0002,  0.0191,  0.0129, -0.0191, -0.0094,  0.0040,  0.0103, -0.0055, -0.0072,  0.0308, -0.0208,
0:          0.0052,  0.0089,  0.0246,  0.0096, -0.0049,  0.0112, -0.0152,  0.0072, -0.0009, -0.0354, -0.0235, -0.0090,
0:          0.0046], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 54, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.3108, 1.2972, 1.2807, 1.2628, 1.2438, 1.2249, 1.2078, 1.1925, 1.1779, 1.1631, 1.1448, 1.1205, 1.0908, 1.0586,
1:         1.0254, 0.9925, 0.9595, 0.9270, 1.3432, 1.3343, 1.3225, 1.3083, 1.2916, 1.2726, 1.2534], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0945,  0.0467,  0.0264,  0.1805,  0.0222, -0.1487,  0.1431, -0.0539, -0.1489,  0.0463,  0.0166, -0.0648,
1:         -0.2146,  0.0406, -0.0501, -0.0648, -0.1465, -0.0370,  0.0201, -0.0131,  0.0299,  0.1183, -0.1008,  0.0214,
1:          0.2144], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3678, -0.3442, -0.3412, -0.3331, -0.3415, -0.3690, -0.3967, -0.4352, -0.4689, -0.5031, -0.5132, -0.4855,
1:         -0.4570, -0.4054, -0.3590, -0.3163, -0.3047, -0.3275, -0.4373, -0.3993, -0.3623, -0.3320, -0.3237, -0.3213,
1:         -0.3305], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.6419, -0.6302, -0.6202, -0.6131, -0.6084, -0.6056, -0.6042, -0.6043, -0.6049, -0.6055, -0.6066, -0.6104,
1:         -0.6189, -0.6324, -0.6493, -0.6673, -0.6851, -0.7027, -0.7215, -0.7426, -0.7651, -0.7865, -0.8045, -0.8163,
1:         -0.8222], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([ 0.2277,  0.0931, -0.0209, -0.0506, -0.0415, -0.0871, -0.1510, -0.1578, -0.1715,  0.2893,  0.2117,  0.2323,
1:          0.1889,  0.1524,  0.0201, -0.0894, -0.1099, -0.1213,  0.5037,  0.4079,  0.4558,  0.3851,  0.2802,  0.1638,
1:          0.0612], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 54, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,  0.0294,     nan,     nan,     nan,     nan, -0.3602,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan, -0.8130, -0.8532,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 54, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([1.1306, 1.1246, 1.1209, 1.1173, 1.1144, 1.1067, 1.0978, 1.0877, 1.0775, 1.0683, 1.0616, 1.0594, 1.0569, 1.0551,
1:         1.0535, 1.0525, 1.0491, 1.0526, 1.1365, 1.1307, 1.1268, 1.1266, 1.1256, 1.1251, 1.1216], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.3023, -0.3051, -0.3269, -0.3777, -0.4573, -0.5582, -0.6716, -0.7901, -0.9038, -1.0173, -1.1224, -1.2242,
1:         -1.3194, -1.4083, -1.4950, -1.5727, -1.6446, -1.7041, -0.2907, -0.2822, -0.2931, -0.3330, -0.4013, -0.4946,
1:         -0.5950], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6718, -0.6808, -0.6888, -0.6945, -0.6983, -0.7011, -0.7039, -0.7079, -0.7106, -0.7117, -0.7122, -0.7113,
1:         -0.7108, -0.7092, -0.7062, -0.7026, -0.6981, -0.6931, -0.6538, -0.6644, -0.6734, -0.6792, -0.6848, -0.6898,
1:         -0.6944], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.6292, -0.6182, -0.6122, -0.5626, -0.5377, -0.5209, -0.4842, -0.4540, -0.4278, -0.4434, -0.4556, -0.4322,
1:         -0.4318, -0.4241, -0.4035, -0.4047, -0.3954, -0.3738, -0.6206, -0.6192, -0.6365, -0.6115, -0.6019, -0.5768,
1:         -0.5154], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.1082, -1.0629, -1.0076, -0.9447, -0.8761, -0.8074, -0.7472, -0.6992, -0.6658, -0.6423, -0.6237, -0.6075,
1:         -0.5916, -0.5760, -0.5611, -0.5442, -0.5256, -0.5048, -0.4830, -0.4630, -0.4463, -0.4296, -0.4125, -0.3929,
1:         -0.3738], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.1880, -0.1972, -0.2018, -0.2090, -0.2083, -0.2068, -0.2070, -0.2007, -0.1916, -0.1822, -0.1926, -0.2023,
1:         -0.2122, -0.2157, -0.2186, -0.2146, -0.2110, -0.1983, -0.1641, -0.1763, -0.1847, -0.1984, -0.2046, -0.2103,
1:         -0.2084], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0010,  0.0009,  0.0137,  0.0055,  0.0008,  0.0045,  0.0153, -0.0132,  0.0084, -0.0090,  0.0163, -0.0078,
1:          0.0034,  0.0132,  0.0236, -0.0013,  0.0037,  0.0268, -0.0068, -0.0035, -0.0038,  0.0109,  0.0013, -0.0010,
1:         -0.0098], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 54 [1/5 (20%)]	Loss: 0.24497 : 0.19468 :: 0.02189 (1.61 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 54 [2/5 (40%)]	Loss: 0.28001 : 0.22793 :: 0.02170 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 54 [3/5 (60%)]	Loss: 0.28010 : 0.21795 :: 0.02381 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 54 [4/5 (80%)]	Loss: 0.28261 : 0.20570 :: 0.01980 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 54 : 0.20646727085113525
0: validation loss for velocity_u : 0.003563069272786379
0: validation loss for velocity_v : 0.005084923002868891
0: validation loss for specific_humidity : 0.005963155068457127
0: validation loss for velocity_z : 0.10978369414806366
0: validation loss for temperature : 0.017652224749326706
0: validation loss for total_precip : 0.27777475118637085
0: validation loss for t2m : 1.025449275970459
1: 55 : 05:44:36 :: batch_size = 96, lr = 1e-05
0: 55 : 05:44:36 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 55, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.2815, -0.2988, -0.3138, -0.3206, -0.3195, -0.3173, -0.3168, -0.3155, -0.3097, -0.3005, -0.2886, -0.2718,
1:         -0.2474, -0.2173, -0.1874, -0.1618, -0.1397, -0.1193, -0.3437, -0.3581, -0.3719, -0.3788, -0.3790, -0.3763,
1:         -0.3719], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.1127,  0.0841,  0.1691, -0.1273,  0.1027,  0.0240,  0.0210,  0.1164, -0.0486,  0.0757, -0.0342,  0.0079,
1:          0.0529,  0.0149,  0.0267,  0.0431, -0.0333, -0.0783, -0.0561,  0.1632,  0.1026,  0.2351, -0.0475, -0.1624,
1:         -0.1598], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.3714, 0.3498, 0.3409, 0.3327, 0.3379, 0.3910, 0.4748, 0.4929, 0.4906, 0.4897, 0.4783, 0.4364, 0.4035, 0.3663,
1:         0.3457, 0.3250, 0.2926, 0.2865, 0.1325, 0.1461, 0.1431, 0.1286, 0.1355, 0.2561, 0.3549], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.5303, 0.5372, 0.5428, 0.5449, 0.5461, 0.5515, 0.5639, 0.5822, 0.6001, 0.6099, 0.6073, 0.5953, 0.5822, 0.5759,
1:         0.5796, 0.5890, 0.5963, 0.5978, 0.5982, 0.6062, 0.6255, 0.6507, 0.6718, 0.6822, 0.6819], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2550, -0.2503, -0.2480, -0.2503, -0.2562, -0.2515, -0.2503, -0.2375, -0.2375, -0.2562, -0.2562, -0.2562,
1:         -0.2550, -0.2480, -0.2422, -0.2422, -0.2224, -0.2235, -0.2562, -0.2562, -0.2562, -0.2387, -0.2235, -0.2107,
1:         -0.2060], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 55, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1382,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 55, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.0951, 0.1059, 0.1181, 0.1327, 0.1465, 0.1587, 0.1720, 0.1840, 0.1942, 0.2058, 0.2162, 0.2283, 0.2405, 0.2514,
1:         0.2642, 0.2774, 0.2916, 0.3059, 0.0608, 0.0682, 0.0787, 0.0914, 0.1046, 0.1181, 0.1315], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.6560, 0.7446, 0.8352, 0.9201, 0.9866, 1.0438, 1.0867, 1.1261, 1.1730, 1.2357, 1.3154, 1.4109, 1.5128, 1.6136,
1:         1.7060, 1.7844, 1.8507, 1.9098, 0.5799, 0.6715, 0.7738, 0.8710, 0.9576, 1.0287, 1.0897], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.5810, -0.5826, -0.5836, -0.5846, -0.5816, -0.5741, -0.5618, -0.5461, -0.5246, -0.5013, -0.4756, -0.4537,
1:         -0.4317, -0.4138, -0.4001, -0.3839, -0.3642, -0.3427, -0.5664, -0.5708, -0.5786, -0.5850, -0.5900, -0.5918,
1:         -0.5865], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-3.2212e-01, -2.4208e-01, -1.3875e-01, -4.7333e-02, -2.7214e-03,  5.9169e-03, -1.8729e-03, -1.0851e-02,
1:         -3.3056e-02, -5.6767e-02, -7.4439e-02, -5.2909e-02, -9.6943e-03, -1.4425e-03,  2.4643e-04,  3.3864e-02,
1:          5.8620e-02,  6.5441e-02, -3.3605e-01, -2.5489e-01, -1.7579e-01, -1.1251e-01, -7.5752e-02, -7.9010e-02,
1:         -1.0599e-01], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.5240, 0.5564, 0.5839, 0.6065, 0.6279, 0.6518, 0.6789, 0.7088, 0.7398, 0.7671, 0.7851, 0.7903, 0.7801, 0.7568,
1:         0.7227, 0.6808, 0.6366, 0.5942, 0.5553, 0.5205, 0.4938, 0.4767, 0.4692, 0.4702, 0.4757], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2583, -0.2667, -0.2657, -0.2665, -0.2660, -0.2656, -0.2641, -0.2624, -0.2562, -0.2610, -0.2643, -0.2656,
1:         -0.2678, -0.2668, -0.2653, -0.2664, -0.2660, -0.2617, -0.2604, -0.2627, -0.2640, -0.2657, -0.2630, -0.2640,
1:         -0.2638], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0086,  0.0051,  0.0172,  0.0012,  0.0010,  0.0038, -0.0006,  0.0033, -0.0131, -0.0156,  0.0271, -0.0180,
1:          0.0066, -0.0002,  0.0061, -0.0015,  0.0019,  0.0301, -0.0087, -0.0327, -0.0149, -0.0066, -0.0023, -0.0136,
1:         -0.0054], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 55, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2815, -0.2988, -0.3138, -0.3206, -0.3195, -0.3173, -0.3168, -0.3155, -0.3097, -0.3005, -0.2886, -0.2718,
0:         -0.2474, -0.2173, -0.1874, -0.1618, -0.1397, -0.1193, -0.3437, -0.3581, -0.3719, -0.3788, -0.3790, -0.3763,
0:         -0.3719], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.5086, 1.5030, 1.4960, 1.4821, 1.4582, 1.4253, 1.3869, 1.3442, 1.2990, 1.2546, 1.2153, 1.1806, 1.1462, 1.1097,
0:         1.0730, 1.0384, 1.0041, 0.9652, 1.4706, 1.4642, 1.4582, 1.4478, 1.4279, 1.3982, 1.3617], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1643,  0.0872,  0.1400, -0.0498, -0.3676, -0.6237, -0.6776, -0.5304, -0.3014, -0.1352, -0.1104, -0.2115,
0:         -0.3384, -0.3732, -0.2632, -0.0925, -0.0273, -0.1621, -0.3586, -0.1677, -0.2115, -0.3564, -0.4305, -0.3642,
0:         -0.1655], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2550, -0.2503, -0.2480, -0.2503, -0.2562, -0.2515, -0.2503, -0.2375, -0.2375, -0.2562, -0.2562, -0.2562,
0:         -0.2550, -0.2480, -0.2422, -0.2422, -0.2224, -0.2235, -0.2562, -0.2562, -0.2562, -0.2387, -0.2235, -0.2107,
0:         -0.2060], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 55, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,  0.2698,     nan,     nan,     nan,     nan,     nan, -0.7835,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 55, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.1065, 0.1140, 0.1232, 0.1366, 0.1543, 0.1769, 0.2009, 0.2242, 0.2486, 0.2682, 0.2816, 0.2908, 0.2967, 0.3021,
0:         0.3076, 0.3095, 0.3052, 0.2944, 0.0925, 0.1025, 0.1139, 0.1287, 0.1471, 0.1677, 0.1905], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([1.2510, 1.2689, 1.3031, 1.3409, 1.3762, 1.3998, 1.4145, 1.4211, 1.4284, 1.4327, 1.4382, 1.4380, 1.4347, 1.4220,
0:         1.4028, 1.3837, 1.3654, 1.3459, 1.2682, 1.2871, 1.3185, 1.3525, 1.3845, 1.4040, 1.4144], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.2467, -0.2660, -0.2975, -0.3362, -0.3792, -0.4229, -0.4666, -0.5019, -0.5330, -0.5556, -0.5733, -0.5873,
0:         -0.5995, -0.6109, -0.6185, -0.6244, -0.6266, -0.6248, -0.2655, -0.2843, -0.3137, -0.3497, -0.3911, -0.4343,
0:         -0.4773], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.1409,  0.0506, -0.0903, -0.2061, -0.2526, -0.2093, -0.1421, -0.1202, -0.1266, -0.1364, -0.1584, -0.1838,
0:         -0.1784, -0.1652, -0.1553, -0.1399, -0.1264, -0.1198,  0.2095,  0.1499,  0.0094, -0.1338, -0.2187, -0.2163,
0:         -0.1625], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.7545, 0.7842, 0.8074, 0.8235, 0.8343, 0.8440, 0.8537, 0.8655, 0.8790, 0.8923, 0.9017, 0.9040, 0.8990, 0.8872,
0:         0.8688, 0.8444, 0.8142, 0.7807, 0.7452, 0.7116, 0.6832, 0.6621, 0.6504, 0.6484, 0.6525], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2872, -0.2889, -0.2809, -0.2657, -0.2609, -0.2691, -0.2713, -0.2802, -0.2799, -0.2419, -0.2464, -0.2445,
0:         -0.2370, -0.2456, -0.2545, -0.2663, -0.2821, -0.2799, -0.1528, -0.1746, -0.1951, -0.1979, -0.2205, -0.2390,
0:         -0.2586], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0083, -0.0130,  0.0146, -0.0014, -0.0020,  0.0022,  0.0054,  0.0028, -0.0018, -0.0136,  0.0091, -0.0005,
0:          0.0091, -0.0061,  0.0127, -0.0113, -0.0052,  0.0071, -0.0222, -0.0081, -0.0109, -0.0216, -0.0132, -0.0250,
0:          0.0162], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 55 [1/5 (20%)]	Loss: 0.25088 : 0.20385 :: 0.02168 (1.66 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 55 [2/5 (40%)]	Loss: 0.27849 : 0.20231 :: 0.02208 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 55 [3/5 (60%)]	Loss: 0.24746 : 0.19306 :: 0.02260 (8.49 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 55 [4/5 (80%)]	Loss: 0.27870 : 0.21485 :: 0.02214 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 55 : 0.21546012163162231
0: validation loss for velocity_u : 0.00357623677700758
0: validation loss for velocity_v : 0.0052115218713879585
0: validation loss for specific_humidity : 0.00531657412648201
0: validation loss for velocity_z : 0.11270371824502945
0: validation loss for temperature : 0.016027670353651047
0: validation loss for total_precip : 0.3302670121192932
0: validation loss for t2m : 1.0351181030273438
1: 56 : 05:50:52 :: batch_size = 96, lr = 1e-05
0: 56 : 05:50:52 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 56, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.5746, 1.5811, 1.5778, 1.5654, 1.5467, 1.5272, 1.5139, 1.5072, 1.5048, 1.5036, 1.5006, 1.4947, 1.4843, 1.4676,
1:         1.4438, 1.4116, 1.3711, 1.3251, 1.5691, 1.5779, 1.5787, 1.5725, 1.5610, 1.5485, 1.5400], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0015,  0.0298, -0.0109, -0.1236, -0.1775,  0.0869, -0.1122,  0.0088, -0.0267,  0.0567,  0.1588,  0.0981,
1:         -0.0225,  0.1273,  0.1582, -0.1055, -0.0310, -0.0629, -0.0675,  0.1743, -0.0693,  0.0138,  0.0002,  0.0060,
1:         -0.0546], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.9025, 0.9067, 0.8892, 0.8785, 0.8525, 0.8217, 0.7936, 0.7578, 0.7274, 0.6955, 0.6535, 0.6240, 0.5856, 0.5554,
1:         0.5277, 0.5151, 0.4978, 0.4855, 0.8396, 0.8569, 0.8639, 0.8565, 0.8411, 0.8204, 0.7936], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.3206, 0.3246, 0.3351, 0.3519, 0.3713, 0.3899, 0.4064, 0.4204, 0.4322, 0.4438, 0.4564, 0.4702, 0.4843, 0.4951,
1:         0.5007, 0.5025, 0.5031, 0.5052, 0.5105, 0.5199, 0.5347, 0.5536, 0.5737, 0.5941, 0.6127], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2265, -0.2383, -0.1909, -0.1743, -0.1577, -0.1600, -0.1387, -0.1956, -0.2360, -0.1790, -0.2431, -0.2478,
1:         -0.2336, -0.2549, -0.2502, -0.2122, -0.1980, -0.2122, -0.2051, -0.2431, -0.2597, -0.2597, -0.2597, -0.2597,
1:         -0.2597], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 56, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan, -0.2361,     nan,     nan,     nan,     nan,     nan, -0.3094,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:         -0.2985])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 56, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([1.3417, 1.3460, 1.3487, 1.3520, 1.3554, 1.3605, 1.3701, 1.3818, 1.3948, 1.4071, 1.4179, 1.4257, 1.4303, 1.4337,
1:         1.4375, 1.4447, 1.4497, 1.4550, 1.4144, 1.4129, 1.4118, 1.4096, 1.4084, 1.4103, 1.4169], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.7945, -0.8046, -0.8142, -0.8240, -0.8340, -0.8420, -0.8494, -0.8565, -0.8611, -0.8678, -0.8735, -0.8748,
1:         -0.8773, -0.8771, -0.8740, -0.8661, -0.8528, -0.8278, -0.7531, -0.7658, -0.7791, -0.7928, -0.8075, -0.8226,
1:         -0.8345], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.4941, -0.4933, -0.4954, -0.5010, -0.5110, -0.5222, -0.5313, -0.5421, -0.5525, -0.5610, -0.5639, -0.5631,
1:         -0.5557, -0.5425, -0.5267, -0.5056, -0.4816, -0.4556, -0.4788, -0.4689, -0.4629, -0.4657, -0.4719, -0.4828,
1:         -0.4949], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.0413, -0.0166,  0.0451,  0.0763,  0.1804,  0.2379,  0.1926,  0.1512,  0.0660, -0.0372, -0.0655, -0.0067,
1:          0.1376,  0.4053,  0.7270,  1.0123,  1.1787,  1.0953,  0.0258, -0.0029,  0.0554,  0.1622,  0.3859,  0.5669,
1:          0.6284], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.4624, 0.4674, 0.4701, 0.4742, 0.4799, 0.4854, 0.4891, 0.4933, 0.4979, 0.5057, 0.5166, 0.5305, 0.5445, 0.5575,
1:         0.5681, 0.5762, 0.5797, 0.5792, 0.5730, 0.5603, 0.5415, 0.5207, 0.5013, 0.4879, 0.4875], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2271, -0.2392, -0.2461, -0.2518, -0.2375, -0.2155, -0.1970, -0.1660, -0.1240, -0.2378, -0.2458, -0.2486,
1:         -0.2369, -0.2219, -0.2001, -0.1637, -0.1378, -0.0972, -0.1864, -0.1994, -0.2030, -0.1960, -0.1741, -0.1465,
1:         -0.1106], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0044,  0.0078,  0.0161, -0.0036,  0.0090,  0.0130,  0.0004,  0.0004,  0.0065, -0.0079,  0.0050,  0.0038,
1:          0.0205, -0.0051,  0.0081, -0.0029,  0.0083,  0.0308, -0.0064, -0.0177, -0.0058, -0.0068,  0.0122, -0.0164,
1:          0.0038], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 56, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.5746, 1.5811, 1.5778, 1.5654, 1.5467, 1.5272, 1.5139, 1.5072, 1.5048, 1.5036, 1.5006, 1.4947, 1.4843, 1.4676,
0:         1.4438, 1.4116, 1.3711, 1.3251, 1.5691, 1.5779, 1.5787, 1.5725, 1.5610, 1.5485, 1.5400], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1563, -0.1039, -0.0673, -0.0514, -0.0529, -0.0622, -0.0685, -0.0651, -0.0483, -0.0166,  0.0253,  0.0734,
0:          0.1257,  0.1795,  0.2335,  0.2873,  0.3385,  0.3859, -0.1147, -0.0877, -0.0734, -0.0715, -0.0786, -0.0900,
0:         -0.0974], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1896, -0.0714, -0.0615, -0.1554, -0.2150, -0.2371, -0.2250, -0.1598, -0.1178, -0.1079, -0.1023, -0.1344,
0:         -0.1730, -0.1962, -0.2493, -0.2802, -0.2548, -0.2261, -0.1620, -0.0935, -0.0780, -0.1322, -0.1620, -0.1775,
0:         -0.1885], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2265, -0.2383, -0.1909, -0.1743, -0.1577, -0.1600, -0.1387, -0.1956, -0.2360, -0.1790, -0.2431, -0.2478,
0:         -0.2336, -0.2549, -0.2502, -0.2122, -0.1980, -0.2122, -0.2051, -0.2431, -0.2597, -0.2597, -0.2597, -0.2597,
0:         -0.2597], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 56, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan, 0.9124,    nan,    nan, 0.7691,    nan, 0.5740,    nan,    nan,    nan,
0:            nan,    nan, 0.3184,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.6309])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 56, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([1.3661, 1.3826, 1.4010, 1.4225, 1.4464, 1.4712, 1.4974, 1.5278, 1.5562, 1.5871, 1.6146, 1.6399, 1.6641, 1.6852,
0:         1.7063, 1.7249, 1.7415, 1.7553, 1.4530, 1.4697, 1.4860, 1.5073, 1.5261, 1.5466, 1.5659], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([2.5814, 2.5680, 2.5227, 2.4471, 2.3384, 2.2052, 2.0479, 1.8728, 1.6820, 1.4827, 1.2854, 1.0970, 0.9147, 0.7542,
0:         0.6133, 0.4863, 0.3783, 0.2810, 2.5953, 2.5779, 2.5261, 2.4469, 2.3382, 2.2047, 2.0483], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6909, -0.7011, -0.7088, -0.7131, -0.7142, -0.7140, -0.7101, -0.7058, -0.7001, -0.6913, -0.6811, -0.6670,
0:         -0.6474, -0.6263, -0.6046, -0.5805, -0.5572, -0.5363, -0.6748, -0.6860, -0.6955, -0.7015, -0.7048, -0.7061,
0:         -0.7053], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-1.7089, -1.4446, -1.1578, -0.8417, -0.6467, -0.5735, -0.5756, -0.5904, -0.5502, -0.4664, -0.3629, -0.3066,
0:         -0.2970, -0.3111, -0.3644, -0.4506, -0.5186, -0.5742, -1.8488, -1.6445, -1.3895, -1.0837, -0.8474, -0.6877,
0:         -0.6123], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.8364, 0.8323, 0.8251, 0.8181, 0.8140, 0.8111, 0.8030, 0.7900, 0.7705, 0.7471, 0.7224, 0.6988, 0.6794, 0.6629,
0:         0.6494, 0.6365, 0.6236, 0.6127, 0.6042, 0.5978, 0.5941, 0.5907, 0.5875, 0.5859, 0.5855], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([0.3841, 0.3463, 0.2973, 0.2633, 0.2508, 0.2670, 0.2911, 0.3221, 0.3586, 0.5112, 0.4939, 0.4566, 0.4060, 0.4007,
0:         0.4105, 0.4246, 0.4519, 0.4565, 0.5504, 0.5444, 0.5401, 0.5058, 0.4839, 0.5013, 0.5100], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0124,  0.0089,  0.0187, -0.0157,  0.0113, -0.0019,  0.0194,  0.0075,  0.0005, -0.0037,  0.0007, -0.0142,
0:          0.0174, -0.0078,  0.0180,  0.0155, -0.0030,  0.0087, -0.0026, -0.0141,  0.0031, -0.0387, -0.0058, -0.0204,
0:          0.0053], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 56 [1/5 (20%)]	Loss: 0.25803 : 0.20290 :: 0.02185 (1.86 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 56 [2/5 (40%)]	Loss: 0.25425 : 0.19259 :: 0.02120 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 56 [3/5 (60%)]	Loss: 0.25813 : 0.20087 :: 0.02175 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 56 [4/5 (80%)]	Loss: 0.27919 : 0.20618 :: 0.02152 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 56 : 0.213171124458313
0: validation loss for velocity_u : 0.0034753030631691217
0: validation loss for velocity_v : 0.004756483249366283
0: validation loss for specific_humidity : 0.006082926876842976
0: validation loss for velocity_z : 0.1073480173945427
0: validation loss for temperature : 0.020255163311958313
0: validation loss for total_precip : 0.33938172459602356
0: validation loss for t2m : 1.0108981132507324
1: 57 : 05:56:56 :: batch_size = 96, lr = 1e-05
0: 57 : 05:56:56 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 57, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1: Created sparse mask for t2m with 10.0% data retained
0:      first 25 values: tensor([0.8198, 0.8275, 0.8343, 0.8397, 0.8439, 0.8465, 0.8480, 0.8480, 0.8470, 0.8447, 0.8412, 0.8368, 0.8312, 0.8245,
0:         0.8171, 0.8092, 0.8009, 0.7925, 0.9358, 0.9482, 0.9599, 0.9705, 0.9801, 0.9883, 0.9951], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2836, -0.3017, -0.3187, -0.3342, -0.3485, -0.3614, -0.3727, -0.3825, -0.3903, -0.3967, -0.4014, -0.4046,
0:         -0.4065, -0.4073, -0.4076, -0.4073, -0.4069, -0.4067, -0.2165, -0.2407, -0.2643, -0.2877, -0.3102, -0.3319,
0:         -0.3525], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.3601, 0.3702, 0.3758, 0.3781, 0.3815, 0.3849, 0.3871, 0.3837, 0.3713, 0.3511, 0.3218, 0.2891, 0.2564, 0.2271,
0:         0.2035, 0.1855, 0.1708, 0.1584, 0.3071, 0.3206, 0.3285, 0.3364, 0.3466, 0.3578, 0.3668], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.0677, -0.0714, -0.0786, -0.0871, -0.0932, -0.0992, -0.1017, -0.1041, -0.1089, -0.0350, -0.0386, -0.0411,
0:         -0.0423, -0.0411, -0.0411, -0.0435, -0.0459, -0.0508, -0.0423, -0.0435, -0.0447, -0.0423, -0.0398, -0.0386,
0:         -0.0374], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 57, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([ 0.2811,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -0.1655,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 57, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([1.2722, 1.2720, 1.2663, 1.2581, 1.2491, 1.2404, 1.2295, 1.2154, 1.1998, 1.1770, 1.1512, 1.1208, 1.0874, 1.0553,
0:         1.0237, 0.9957, 0.9750, 0.9634, 1.2519, 1.2558, 1.2545, 1.2506, 1.2462, 1.2407, 1.2345], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.5628, -0.5666, -0.5735, -0.5830, -0.5932, -0.6029, -0.6106, -0.6144, -0.6162, -0.6178, -0.6229, -0.6314,
0:         -0.6452, -0.6615, -0.6793, -0.6927, -0.7057, -0.7165, -0.6022, -0.6140, -0.6258, -0.6367, -0.6466, -0.6550,
0:         -0.6604], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.5328, -0.5437, -0.5555, -0.5694, -0.5837, -0.5963, -0.6118, -0.6245, -0.6393, -0.6496, -0.6585, -0.6660,
0:         -0.6719, -0.6753, -0.6766, -0.6763, -0.6750, -0.6743, -0.4917, -0.5040, -0.5174, -0.5314, -0.5459, -0.5624,
0:         -0.5784], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.0693,  0.0655,  0.0212, -0.0135, -0.0309, -0.0791, -0.1143, -0.1407, -0.1790, -0.2096, -0.2326, -0.2438,
0:         -0.2378, -0.2107, -0.1809, -0.1593, -0.1282, -0.1229,  0.0749,  0.0684,  0.0158, -0.0255, -0.0386, -0.0828,
0:         -0.1202], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-1.5416, -1.5301, -1.5122, -1.4920, -1.4730, -1.4541, -1.4343, -1.4112, -1.3868, -1.3628, -1.3434, -1.3286,
0:         -1.3176, -1.3084, -1.3002, -1.2939, -1.2906, -1.2878, -1.2840, -1.2806, -1.2745, -1.2671, -1.2585, -1.2481,
0:         -1.2384], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1498, -0.1441, -0.1408, -0.1403, -0.1415, -0.1437, -0.1554, -0.1626, -0.1640, -0.1468, -0.1501, -0.1483,
0:         -0.1410, -0.1414, -0.1479, -0.1573, -0.1688, -0.1693, -0.1485, -0.1529, -0.1571, -0.1513, -0.1535, -0.1577,
0:         -0.1638], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0013,  0.0011,  0.0101, -0.0111,  0.0093, -0.0086,  0.0049, -0.0103,  0.0076, -0.0080,  0.0098,  0.0081,
0:          0.0097, -0.0118,  0.0327, -0.0012,  0.0008,  0.0108, -0.0258,  0.0016, -0.0002, -0.0271, -0.0019, -0.0157,
0:          0.0051], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 57, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.8198, 0.8275, 0.8343, 0.8397, 0.8439, 0.8465, 0.8480, 0.8480, 0.8470, 0.8447, 0.8412, 0.8368, 0.8312, 0.8245,
1:         0.8171, 0.8092, 0.8009, 0.7925, 0.9358, 0.9482, 0.9599, 0.9705, 0.9801, 0.9883, 0.9951], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0490,  0.0271,  0.0153,  0.0097, -0.0476,  0.0797, -0.0017,  0.0022, -0.0025,  0.0089, -0.0338,  0.0278,
1:          0.1595, -0.0311, -0.0759, -0.1094,  0.0514, -0.0336,  0.1508, -0.0403,  0.0238,  0.0626, -0.0396,  0.0692,
1:         -0.1135], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6119, -0.6145, -0.6179, -0.6214, -0.6231, -0.6250, -0.6289, -0.6329, -0.6365, -0.6402, -0.6407, -0.6409,
1:         -0.6407, -0.6408, -0.6426, -0.6445, -0.6447, -0.6449, -0.5956, -0.5982, -0.5992, -0.5994, -0.6002, -0.6022,
1:         -0.6062], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.0964, -1.1058, -1.1153, -1.1256, -1.1361, -1.1475, -1.1598, -1.1730, -1.1870, -1.2015, -1.2167, -1.2318,
1:         -1.2473, -1.2630, -1.2787, -1.2946, -1.3100, -1.3254, -1.3398, -1.3534, -1.3655, -1.3764, -1.3859, -1.3939,
1:         -1.4006], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.0677, -0.0714, -0.0786, -0.0871, -0.0932, -0.0992, -0.1017, -0.1041, -0.1089, -0.0350, -0.0386, -0.0411,
1:         -0.0423, -0.0411, -0.0411, -0.0435, -0.0459, -0.0508, -0.0423, -0.0435, -0.0447, -0.0423, -0.0398, -0.0386,
1:         -0.0374], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 57, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan, -1.1157,     nan,     nan,     nan, -0.9035,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  0.0143,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 57, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.7015, 0.6832, 0.6625, 0.6415, 0.6220, 0.6043, 0.5926, 0.5847, 0.5817, 0.5792, 0.5766, 0.5772, 0.5777, 0.5807,
1:         0.5853, 0.5884, 0.5843, 0.5796, 0.8183, 0.7999, 0.7783, 0.7562, 0.7337, 0.7125, 0.6950], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-1.1892, -1.2030, -1.2243, -1.2537, -1.2868, -1.3193, -1.3484, -1.3821, -1.4238, -1.4662, -1.5084, -1.5327,
1:         -1.5471, -1.5530, -1.5559, -1.5544, -1.5445, -1.5269, -1.2454, -1.2698, -1.2975, -1.3394, -1.3810, -1.4150,
1:         -1.4420], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.2249, -0.2351, -0.2491, -0.2649, -0.2816, -0.2971, -0.3083, -0.3153, -0.3190, -0.3161, -0.3120, -0.3042,
1:         -0.2988, -0.2948, -0.2953, -0.2966, -0.3017, -0.3053, -0.2174, -0.2232, -0.2332, -0.2467, -0.2626, -0.2773,
1:         -0.2918], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.0059, -0.0787, -0.1468, -0.1883, -0.2021, -0.1991, -0.1458, -0.0497,  0.0130,  0.0306,  0.0458,  0.0816,
1:          0.1134,  0.1000,  0.0505,  0.0194, -0.0322, -0.0369, -0.0515, -0.1179, -0.1612, -0.1641, -0.1424, -0.1067,
1:         -0.0364], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.6056, -0.6920, -0.7863, -0.8832, -0.9767, -1.0632, -1.1412, -1.2099, -1.2715, -1.3241, -1.3680, -1.4099,
1:         -1.4525, -1.4972, -1.5517, -1.6134, -1.6816, -1.7517, -1.8183, -1.8768, -1.9239, -1.9581, -1.9853, -2.0091,
1:         -2.0298], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2191, -0.2181, -0.2247, -0.2251, -0.2209, -0.2231, -0.2309, -0.2324, -0.2251, -0.2234, -0.2288, -0.2276,
1:         -0.2270, -0.2251, -0.2333, -0.2315, -0.2359, -0.2368, -0.2295, -0.2286, -0.2308, -0.2265, -0.2282, -0.2298,
1:         -0.2347], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0090,  0.0073,  0.0242, -0.0002, -0.0077,  0.0155,  0.0062, -0.0121,  0.0022, -0.0143,  0.0027,  0.0026,
1:          0.0262,  0.0035,  0.0123,  0.0122,  0.0240,  0.0263, -0.0060, -0.0115, -0.0011, -0.0131, -0.0029, -0.0168,
1:          0.0102], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 57 [1/5 (20%)]	Loss: 0.28090 : 0.20947 :: 0.02279 (1.78 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 57 [2/5 (40%)]	Loss: 0.29069 : 0.21507 :: 0.02077 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 57 [3/5 (60%)]	Loss: 0.23683 : 0.18228 :: 0.02198 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 57 [4/5 (80%)]	Loss: 0.23965 : 0.17459 :: 0.02157 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 57 : 0.19458410143852234
0: validation loss for velocity_u : 0.0037894761189818382
0: validation loss for velocity_v : 0.005050715059041977
0: validation loss for specific_humidity : 0.006613075267523527
0: validation loss for velocity_z : 0.11409125477075577
0: validation loss for temperature : 0.020777491852641106
0: validation loss for total_precip : 0.22518205642700195
0: validation loss for t2m : 0.9865845441818237
1: 58 : 06:03:04 :: batch_size = 96, lr = 1e-05
0: 58 : 06:03:04 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 58, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.7916, 1.7853, 1.7797, 1.7748, 1.7702, 1.7656, 1.7610, 1.7564, 1.7513, 1.7463, 1.7426, 1.7396, 1.7381, 1.7381,
0:         1.7396, 1.7416, 1.7439, 1.7467, 1.8500, 1.8467, 1.8434, 1.8403, 1.8375, 1.8352, 1.8324], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.4198, -0.4146, -0.4044, -0.3901, -0.3716, -0.3497, -0.3258, -0.3004, -0.2740, -0.2478, -0.2222, -0.1973,
0:         -0.1732, -0.1505, -0.1297, -0.1101, -0.0916, -0.0746, -0.4240, -0.4285, -0.4275, -0.4219, -0.4113, -0.3951,
0:         -0.3741], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.8444, -0.8072, -0.7830, -0.7545, -0.7304, -0.7129, -0.6888, -0.6734, -0.6866, -0.6997, -0.6975, -0.7129,
0:         -0.7523, -0.7721, -0.7808, -0.8028, -0.8115, -0.7962, -0.8992, -0.8510, -0.8094, -0.7655, -0.7480, -0.7545,
0:         -0.7458], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1738, -0.1738, -0.1692, -0.1601, -0.1601, -0.1692, -0.1715, -0.1715, -0.1692, -0.1031, -0.1236, -0.1304,
0:         -0.1304, -0.1418, -0.1555, -0.1624, -0.1647, -0.1669,  0.1319,  0.0589,  0.0361,  0.0224, -0.0164, -0.0438,
0:         -0.0164], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 58, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([-1.1003,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 58, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([2.3342, 2.2826, 2.2271, 2.1688, 2.1094, 2.0482, 1.9861, 1.9258, 1.8585, 1.7912, 1.7205, 1.6480, 1.5713, 1.4887,
0:         1.4093, 1.3362, 1.2733, 1.2219, 2.1001, 2.0321, 1.9575, 1.8795, 1.8033, 1.7292, 1.6599], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([4.0491, 4.1226, 4.2025, 4.2936, 4.3880, 4.4786, 4.5330, 4.5276, 4.4453, 4.2859, 4.0680, 3.8105, 3.5589, 3.3441,
0:         3.1960, 3.1264, 3.1132, 3.1346, 4.0871, 4.1477, 4.2191, 4.3057, 4.4034, 4.4959, 4.5553], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.4856, -0.4876, -0.4851, -0.4792, -0.4712, -0.4614, -0.4533, -0.4472, -0.4437, -0.4413, -0.4402, -0.4388,
0:         -0.4376, -0.4363, -0.4333, -0.4292, -0.4244, -0.4209, -0.4890, -0.4903, -0.4879, -0.4796, -0.4694, -0.4582,
0:         -0.4484], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.1961,  0.0414, -0.0657, -0.1470, -0.1727, -0.1277, -0.1025, -0.0650, -0.0219, -0.0483, -0.0706, -0.0617,
0:         -0.0832, -0.0936, -0.0974, -0.0690,  0.0097,  0.0100,  0.1429, -0.0013, -0.1297, -0.2562, -0.3183, -0.3118,
0:         -0.3019], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.7904, -0.7732, -0.7548, -0.7363, -0.7175, -0.7000, -0.6817, -0.6632, -0.6436, -0.6246, -0.6092, -0.5993,
0:         -0.5916, -0.5807, -0.5624, -0.5422, -0.5216, -0.5078, -0.5003, -0.4969, -0.4939, -0.4887, -0.4844, -0.4833,
0:         -0.4859], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.0293,  0.0083,  0.0352,  0.0604,  0.0606,  0.0600,  0.0466,  0.0387,  0.0231, -0.0842, -0.0618, -0.0339,
0:         -0.0114, -0.0122, -0.0238, -0.0286, -0.0380, -0.0404, -0.1492, -0.1458, -0.1369, -0.1064, -0.1045, -0.1106,
0:         -0.1248], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0161,  0.0094,  0.0131,  0.0041,  0.0102,  0.0002, -0.0104, -0.0149,  0.0041, -0.0108, -0.0070, -0.0102,
0:          0.0187, -0.0203, -0.0041, -0.0015,  0.0017,  0.0033, -0.0225, -0.0032, -0.0006, -0.0149, -0.0036, -0.0145,
0:          0.0161], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 58, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.7916, 1.7853, 1.7797, 1.7748, 1.7702, 1.7656, 1.7610, 1.7564, 1.7513, 1.7463, 1.7426, 1.7396, 1.7381, 1.7381,
1:         1.7396, 1.7416, 1.7439, 1.7467, 1.8500, 1.8467, 1.8434, 1.8403, 1.8375, 1.8352, 1.8324], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0803,  0.0730,  0.0421,  0.0365,  0.0584,  0.0150, -0.2028, -0.0992, -0.0589,  0.0086,  0.0439,  0.0998,
1:          0.0473,  0.0425, -0.0828, -0.0903, -0.0328,  0.0419,  0.0450, -0.1344,  0.0349,  0.0698,  0.0163, -0.0336,
1:         -0.0223], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3217, -0.3355, -0.3311, -0.3178, -0.3032, -0.2849, -0.2630, -0.2401, -0.2181, -0.1992, -0.1811, -0.1656,
1:         -0.1526, -0.1397, -0.1264, -0.1103, -0.0938, -0.0751, -0.1112, -0.1859, -0.2327, -0.2717, -0.2817, -0.2865,
1:         -0.2817], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.3344, 0.3494, 0.3613, 0.3702, 0.3764, 0.3799, 0.3804, 0.3787, 0.3749, 0.3694, 0.3638, 0.3582, 0.3528, 0.3474,
1:         0.3417, 0.3362, 0.3309, 0.3245, 0.3180, 0.3119, 0.3063, 0.3003, 0.2928, 0.2846, 0.2761], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1738, -0.1738, -0.1692, -0.1601, -0.1601, -0.1692, -0.1715, -0.1715, -0.1692, -0.1031, -0.1236, -0.1304,
1:         -0.1304, -0.1418, -0.1555, -0.1624, -0.1647, -0.1669,  0.1319,  0.0589,  0.0361,  0.0224, -0.0164, -0.0438,
1:         -0.0164], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 58, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan, -0.1819,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,  0.3708,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 58, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([1.9174, 1.9298, 1.9494, 1.9722, 1.9930, 2.0125, 2.0341, 2.0541, 2.0736, 2.0877, 2.1000, 2.1111, 2.1211, 2.1322,
1:         2.1464, 2.1608, 2.1733, 2.1857, 1.9977, 2.0127, 2.0341, 2.0566, 2.0777, 2.0953, 2.1142], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 0.0320,  0.0144, -0.0046, -0.0281, -0.0537, -0.0757, -0.0943, -0.1076, -0.1180, -0.1244, -0.1300, -0.1334,
1:         -0.1344, -0.1335, -0.1327, -0.1349, -0.1381, -0.1413,  0.0469,  0.0267,  0.0094, -0.0138, -0.0390, -0.0612,
1:         -0.0805], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6335, -0.6347, -0.6327, -0.6324, -0.6333, -0.6316, -0.6305, -0.6291, -0.6311, -0.6342, -0.6396, -0.6463,
1:         -0.6528, -0.6556, -0.6543, -0.6508, -0.6419, -0.6322, -0.6475, -0.6474, -0.6468, -0.6457, -0.6462, -0.6476,
1:         -0.6467], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-2.3602, -2.2951, -2.3624, -2.4293, -2.3886, -2.1845, -1.8491, -1.5266, -1.3899, -1.4434, -1.5369, -1.5646,
1:         -1.4841, -1.3672, -1.2616, -1.0531, -0.7905, -0.6676, -1.5060, -1.5315, -1.7262, -1.8952, -1.9186, -1.6874,
1:         -1.3287], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.9035, -1.8821, -1.8616, -1.8422, -1.8204, -1.8002, -1.7833, -1.7678, -1.7524, -1.7345, -1.7175, -1.7075,
1:         -1.7049, -1.7032, -1.7017, -1.6936, -1.6812, -1.6675, -1.6544, -1.6430, -1.6284, -1.6076, -1.5795, -1.5447,
1:         -1.5082], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.0335, -0.0448, -0.0640, -0.0740, -0.0917, -0.0990, -0.1081, -0.1087, -0.1039, -0.0311, -0.0507, -0.0680,
1:         -0.0885, -0.1110, -0.1264, -0.1305, -0.1338, -0.1284, -0.0465, -0.0660, -0.0851, -0.1127, -0.1318, -0.1545,
1:         -0.1562], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 1.1415e-03,  2.1653e-03,  2.0817e-02, -4.5152e-03,  1.6198e-02,  8.4501e-03, -1.3799e-02, -1.9252e-02,
1:         -4.0356e-03, -2.5365e-02, -6.7362e-05, -2.8892e-02,  1.7351e-02, -1.2164e-02, -1.1334e-02,  3.6948e-03,
1:          1.4609e-02,  2.0058e-03, -6.1548e-03, -2.0962e-02, -1.8196e-03, -6.3208e-03, -2.0281e-03, -1.7825e-02,
1:          6.3497e-03], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 58 [1/5 (20%)]	Loss: 0.29810 : 0.21730 :: 0.02077 (1.70 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 58 [2/5 (40%)]	Loss: 0.22619 : 0.20132 :: 0.02192 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 58 [3/5 (60%)]	Loss: 0.27617 : 0.21713 :: 0.02277 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 58 [4/5 (80%)]	Loss: 0.21446 : 0.16606 :: 0.02121 (8.37 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 58 : 0.20663952827453613
0: validation loss for velocity_u : 0.0034007392823696136
0: validation loss for velocity_v : 0.004665331449359655
0: validation loss for specific_humidity : 0.006399361416697502
0: validation loss for velocity_z : 0.10495132207870483
0: validation loss for temperature : 0.02015611156821251
0: validation loss for total_precip : 0.3012004494667053
0: validation loss for t2m : 1.0057034492492676
1: 59 : 06:09:13 :: batch_size = 96, lr = 1e-05
0: 59 : 06:09:13 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 59, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.3399, 0.3362, 0.3307, 0.3457, 0.3812, 0.4230, 0.4559, 0.4732, 0.4796, 0.4859, 0.4972, 0.5121, 0.5284, 0.5476,
1:         0.5690, 0.5900, 0.6108, 0.6308, 0.2877, 0.2802, 0.2887, 0.3255, 0.3763, 0.4198, 0.4483], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.2014, -0.0501,  0.0310,  0.0325,  0.0383, -0.1163, -0.0122, -0.1023, -0.0157,  0.1077, -0.0850,  0.0684,
1:          0.0324, -0.0518, -0.0322,  0.0085, -0.1775, -0.0158,  0.2024,  0.0672, -0.1286, -0.1621, -0.0146, -0.0253,
1:          0.0801], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.7056, -0.7024, -0.6997, -0.6906, -0.6851, -0.6756, -0.6574, -0.6414, -0.6347, -0.6321, -0.6315, -0.6326,
1:         -0.6354, -0.6393, -0.6460, -0.6536, -0.6616, -0.6693, -0.7148, -0.7196, -0.7125, -0.7000, -0.6781, -0.6648,
1:         -0.6463], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.8724, -0.8866, -0.9200, -0.9651, -1.0066, -1.0450, -1.0757, -1.0923, -1.1016, -1.1110, -1.1210, -1.1322,
1:         -1.1448, -1.1562, -1.1670, -1.1788, -1.1905, -1.2042, -1.2217, -1.2383, -1.2537, -1.2670, -1.2770, -1.2839,
1:         -1.2871], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2151, -0.2384, -0.2384, -0.2439, -0.2439, -0.2439, -0.2439, -0.2439, -0.2439, -0.2251, -0.2384, -0.2406,
1:         -0.2439, -0.2439, -0.2439, -0.2439, -0.2439, -0.2439, -0.2306, -0.2439, -0.2439, -0.2439, -0.2439, -0.2439,
1:         -0.2439], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 59, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan, -0.4745,     nan, -0.4823,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 59, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.3429, 0.3250, 0.3057, 0.2840, 0.2591, 0.2361, 0.2171, 0.2006, 0.1862, 0.1719, 0.1582, 0.1441, 0.1326, 0.1208,
1:         0.1126, 0.1071, 0.1008, 0.0966, 0.3394, 0.3188, 0.2949, 0.2678, 0.2397, 0.2137, 0.1910], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.7018, 0.6938, 0.6834, 0.6645, 0.6385, 0.6041, 0.5663, 0.5295, 0.4939, 0.4573, 0.4144, 0.3583, 0.2900, 0.2176,
1:         0.1526, 0.0926, 0.0415, 0.0026, 0.6343, 0.6154, 0.5990, 0.5811, 0.5604, 0.5345, 0.5082], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.1747, -0.1806, -0.1896, -0.2002, -0.2125, -0.2231, -0.2329, -0.2452, -0.2576, -0.2709, -0.2886, -0.3105,
1:         -0.3332, -0.3566, -0.3766, -0.3923, -0.4016, -0.4090, -0.1764, -0.1794, -0.1858, -0.1963, -0.2063, -0.2158,
1:         -0.2265], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.2776, -0.3143, -0.2234,  0.0333,  0.2829,  0.4851,  0.5467,  0.1271, -1.0646, -2.5059, -3.2101, -2.9909,
1:         -2.0995, -0.9744, -0.0829,  0.4019,  0.5658,  0.5391, -0.1178, -0.2380, -0.2199,  0.0329,  0.2039,  0.4039,
1:          0.6151], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.4080, -0.3742, -0.3405, -0.3125, -0.2865, -0.2601, -0.2318, -0.2017, -0.1735, -0.1502, -0.1380, -0.1402,
1:         -0.1568, -0.1820, -0.2094, -0.2306, -0.2458, -0.2519, -0.2468, -0.2276, -0.1944, -0.1504, -0.1036, -0.0652,
1:         -0.0405], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([0.0842, 0.1907, 0.2857, 0.5317, 0.8815, 1.2543, 1.6359, 2.0112, 2.3489, 0.1669, 0.2080, 0.3169, 0.4534, 0.7837,
1:         1.2223, 1.6677, 2.1653, 2.5194, 0.2678, 0.2363, 0.3427, 0.4543, 0.7510, 1.2527, 1.7658], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0057,  0.0019,  0.0061, -0.0027, -0.0028,  0.0139, -0.0239, -0.0444, -0.0065, -0.0190, -0.0226, -0.0195,
1:          0.0067, -0.0328,  0.0048,  0.0030,  0.0234,  0.0071, -0.0249, -0.0239, -0.0008,  0.0150,  0.0040, -0.0233,
1:          0.0048], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 59, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.3399, 0.3362, 0.3307, 0.3457, 0.3812, 0.4230, 0.4559, 0.4732, 0.4796, 0.4859, 0.4972, 0.5121, 0.5284, 0.5476,
0:         0.5690, 0.5900, 0.6108, 0.6308, 0.2877, 0.2802, 0.2887, 0.3255, 0.3763, 0.4198, 0.4483], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.2047, 1.2248, 1.2382, 1.2290, 1.1987, 1.1643, 1.1429, 1.1363, 1.1332, 1.1255, 1.1158, 1.1077, 1.1030, 1.1019,
0:         1.1032, 1.1083, 1.1174, 1.1304, 1.3372, 1.3337, 1.3075, 1.2603, 1.2131, 1.1798, 1.1612], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.0758, 1.0177, 0.8246, 0.6995, 0.7296, 0.7419, 0.7174, 0.7419, 0.6939, 0.5566, 0.5175, 0.5510, 0.5454, 0.5945,
0:         0.7040, 0.7274, 0.6749, 0.6057, 0.9105, 0.5398, 0.2316, 0.2908, 0.6113, 0.7620, 0.6615], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2151, -0.2384, -0.2384, -0.2439, -0.2439, -0.2439, -0.2439, -0.2439, -0.2439, -0.2251, -0.2384, -0.2406,
0:         -0.2439, -0.2439, -0.2439, -0.2439, -0.2439, -0.2439, -0.2306, -0.2439, -0.2439, -0.2439, -0.2439, -0.2439,
0:         -0.2439], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 59, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan, -1.4314,     nan,     nan,     nan,     nan, -1.5956,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 59, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.3338, 0.3296, 0.3371, 0.3488, 0.3620, 0.3713, 0.3810, 0.3987, 0.4276, 0.4640, 0.5049, 0.5502, 0.5917, 0.6325,
0:         0.6760, 0.7161, 0.7554, 0.7856, 0.3977, 0.3895, 0.3888, 0.3998, 0.4128, 0.4252, 0.4335], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.0997, 0.1071, 0.1113, 0.1124, 0.1049, 0.0925, 0.0806, 0.0696, 0.0563, 0.0437, 0.0321, 0.0192, 0.0124, 0.0091,
0:         0.0126, 0.0185, 0.0287, 0.0426, 0.1673, 0.1745, 0.1780, 0.1758, 0.1636, 0.1478, 0.1304], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.3927, -0.3921, -0.3912, -0.3917, -0.3929, -0.3955, -0.3972, -0.4001, -0.4018, -0.4031, -0.4068, -0.4103,
0:         -0.4148, -0.4173, -0.4194, -0.4198, -0.4211, -0.4205, -0.4043, -0.4020, -0.4000, -0.3982, -0.3976, -0.3973,
0:         -0.3965], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.0982, -0.1347, -0.1292, -0.1294, -0.1293, -0.1349, -0.1434, -0.1343, -0.0916, -0.0447, -0.0277, -0.0379,
0:         -0.0646, -0.0849, -0.1058, -0.1410, -0.1272, -0.0983, -0.0118, -0.0520, -0.0743, -0.0974, -0.1003, -0.1103,
0:         -0.1264], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.1281, -0.1236, -0.1058, -0.0751, -0.0351,  0.0090,  0.0498,  0.0817,  0.1043,  0.1157,  0.1157,  0.1095,
0:          0.1024,  0.0979,  0.1022,  0.1156,  0.1385,  0.1690,  0.2046,  0.2404,  0.2752,  0.3064,  0.3347,  0.3607,
0:          0.3834], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.0584,  0.0012,  0.0531,  0.1397,  0.2159,  0.2830,  0.3250,  0.3394,  0.3296, -0.0843, -0.0559, -0.0034,
0:          0.0593,  0.1156,  0.1658,  0.2064,  0.2121,  0.2196, -0.1018, -0.0981, -0.0695, -0.0329,  0.0059,  0.0325,
0:          0.0555], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0199,  0.0227,  0.0106, -0.0023,  0.0116, -0.0030, -0.0217, -0.0248,  0.0189, -0.0227, -0.0182, -0.0174,
0:          0.0066, -0.0194, -0.0055,  0.0024,  0.0128, -0.0099, -0.0238,  0.0097, -0.0121, -0.0017,  0.0007, -0.0262,
0:          0.0107], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 59 [1/5 (20%)]	Loss: 0.22922 : 0.19900 :: 0.02080 (1.90 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 59 [2/5 (40%)]	Loss: 0.27280 : 0.20993 :: 0.02089 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 59 [3/5 (60%)]	Loss: 0.31444 : 0.21592 :: 0.02062 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 59 [4/5 (80%)]	Loss: 0.25385 : 0.19194 :: 0.02234 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 59 : 0.20570871233940125
0: validation loss for velocity_u : 0.003421664936468005
0: validation loss for velocity_v : 0.004788137972354889
0: validation loss for specific_humidity : 0.00592266209423542
0: validation loss for velocity_z : 0.10699397325515747
0: validation loss for temperature : 0.017207428812980652
0: validation loss for total_precip : 0.26756158471107483
0: validation loss for t2m : 1.0340653657913208
1: 60 : 06:15:23 :: batch_size = 96, lr = 1e-05
0: 60 : 06:15:23 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 60, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.2783, -1.2805, -1.2823, -1.2837, -1.2848, -1.2854, -1.2854, -1.2844, -1.2828, -1.2803, -1.2773, -1.2733,
0:         -1.2687, -1.2631, -1.2567, -1.2492, -1.2406, -1.2315, -1.2390, -1.2440, -1.2489, -1.2533, -1.2576, -1.2611,
0:         -1.2638], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.2880, -1.2872, -1.2876, -1.2891, -1.2919, -1.2955, -1.3002, -1.3060, -1.3129, -1.3208, -1.3300, -1.3398,
0:         -1.3503, -1.3610, -1.3719, -1.3829, -1.3938, -1.4047, -1.2818, -1.2797, -1.2786, -1.2784, -1.2788, -1.2799,
0:         -1.2818], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.3299, 0.3198, 0.3108, 0.3063, 0.3040, 0.3029, 0.2973, 0.2860, 0.2703, 0.2534, 0.2399, 0.2309, 0.2263, 0.2252,
0:         0.2241, 0.2241, 0.2252, 0.2286, 0.2826, 0.2838, 0.2883, 0.2928, 0.2939, 0.2871, 0.2736], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2415, -0.2403, -0.2403, -0.2391, -0.2391, -0.2380, -0.2345, -0.2310, -0.2286, -0.2415, -0.2415, -0.2415,
0:         -0.2415, -0.2403, -0.2391, -0.2380, -0.2345, -0.2321, -0.2426, -0.2426, -0.2426, -0.2426, -0.2426, -0.2415,
0:         -0.2403], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 60, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan, -1.5168,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -1.1164,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 60, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-1.0073, -1.0202, -1.0309, -1.0373, -1.0436, -1.0471, -1.0512, -1.0532, -1.0555, -1.0600, -1.0659, -1.0732,
0:         -1.0819, -1.0920, -1.1040, -1.1173, -1.1319, -1.1467, -0.9319, -0.9467, -0.9577, -0.9685, -0.9780, -0.9870,
0:         -0.9942], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-1.7989, -1.8030, -1.8054, -1.8060, -1.8043, -1.8051, -1.8066, -1.8102, -1.8136, -1.8179, -1.8212, -1.8257,
0:         -1.8261, -1.8244, -1.8178, -1.8072, -1.7962, -1.7844, -1.7933, -1.7966, -1.7990, -1.7992, -1.8018, -1.8032,
0:         -1.8067], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6689, -0.6685, -0.6657, -0.6640, -0.6625, -0.6616, -0.6605, -0.6595, -0.6569, -0.6541, -0.6525, -0.6491,
0:         -0.6450, -0.6415, -0.6396, -0.6358, -0.6337, -0.6298, -0.6557, -0.6531, -0.6504, -0.6490, -0.6476, -0.6460,
0:         -0.6447], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.5270, 0.4954, 0.4700, 0.4919, 0.5322, 0.5801, 0.6406, 0.7217, 0.8136, 0.8927, 0.9288, 0.9164, 0.9206, 0.9126,
0:         0.8786, 0.8822, 0.8664, 0.8358, 0.5890, 0.5278, 0.5112, 0.5274, 0.5647, 0.6054, 0.6470], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-1.1384, -1.1500, -1.1607, -1.1744, -1.1875, -1.1976, -1.2048, -1.2097, -1.2130, -1.2159, -1.2204, -1.2271,
0:         -1.2347, -1.2447, -1.2542, -1.2641, -1.2734, -1.2837, -1.2956, -1.3078, -1.3210, -1.3323, -1.3427, -1.3507,
0:         -1.3590], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2207, -0.2199, -0.2209, -0.2254, -0.2313, -0.2378, -0.2447, -0.2526, -0.2487, -0.2250, -0.2259, -0.2237,
0:         -0.2305, -0.2270, -0.2352, -0.2401, -0.2502, -0.2542, -0.2325, -0.2313, -0.2309, -0.2250, -0.2274, -0.2306,
0:         -0.2361], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0144, -0.0056,  0.0038,  0.0249, -0.0001, -0.0066, -0.0325, -0.0248,  0.0081, -0.0105, -0.0107, -0.0131,
0:          0.0026, -0.0105, -0.0140,  0.0038, -0.0059,  0.0038, -0.0222, -0.0014,  0.0104, -0.0090, -0.0056, -0.0318,
0:          0.0127], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 60, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.2783, -1.2805, -1.2823, -1.2837, -1.2848, -1.2854, -1.2854, -1.2844, -1.2828, -1.2803, -1.2773, -1.2733,
1:         -1.2687, -1.2631, -1.2567, -1.2492, -1.2406, -1.2315, -1.2390, -1.2440, -1.2489, -1.2533, -1.2576, -1.2611,
1:         -1.2638], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0220,  0.0018, -0.0933, -0.0976, -0.1125, -0.0791,  0.1871, -0.0321,  0.0489,  0.0224, -0.0011,  0.0680,
1:         -0.1381, -0.1583, -0.0230,  0.1918, -0.0167,  0.0301, -0.0591, -0.0438, -0.0273, -0.0023, -0.0896,  0.0609,
1:         -0.0109], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6822, -0.6808, -0.6773, -0.6740, -0.6707, -0.6663, -0.6608, -0.6555, -0.6500, -0.6443, -0.6383, -0.6322,
1:         -0.6266, -0.6228, -0.6188, -0.6147, -0.6125, -0.6120, -0.6893, -0.6891, -0.6886, -0.6873, -0.6860, -0.6827,
1:         -0.6780], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.5585, -1.5342, -1.5085, -1.4825, -1.4552, -1.4270, -1.3984, -1.3690, -1.3393, -1.3093, -1.2789, -1.2488,
1:         -1.2186, -1.1887, -1.1586, -1.1293, -1.1001, -1.0717, -1.0438, -1.0164, -0.9899, -0.9635, -0.9378, -0.9128,
1:         -0.8884], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2415, -0.2403, -0.2403, -0.2391, -0.2391, -0.2380, -0.2345, -0.2310, -0.2286, -0.2415, -0.2415, -0.2415,
1:         -0.2415, -0.2403, -0.2391, -0.2380, -0.2345, -0.2321, -0.2426, -0.2426, -0.2426, -0.2426, -0.2426, -0.2415,
1:         -0.2403], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 60, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan, -0.4864,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 60, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.9236, -0.9128, -0.8986, -0.8836, -0.8663, -0.8525, -0.8417, -0.8351, -0.8284, -0.8272, -0.8270, -0.8323,
1:         -0.8413, -0.8533, -0.8671, -0.8808, -0.8964, -0.9066, -0.9224, -0.9116, -0.8965, -0.8800, -0.8607, -0.8467,
1:         -0.8339], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-1.4962, -1.5556, -1.6120, -1.6641, -1.7086, -1.7463, -1.7774, -1.8049, -1.8298, -1.8547, -1.8761, -1.8946,
1:         -1.9155, -1.9363, -1.9570, -1.9772, -1.9936, -2.0039, -1.4479, -1.5039, -1.5580, -1.6082, -1.6553, -1.6974,
1:         -1.7358], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6816, -0.6996, -0.7114, -0.7213, -0.7272, -0.7293, -0.7298, -0.7286, -0.7245, -0.7208, -0.7169, -0.7129,
1:         -0.7073, -0.7034, -0.7016, -0.6999, -0.7008, -0.7035, -0.6401, -0.6612, -0.6763, -0.6877, -0.6962, -0.7027,
1:         -0.7065], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.5502, -0.5723, -0.5800, -0.4749, -0.3059, -0.0789,  0.1968,  0.4337,  0.6522,  0.8158,  0.8602,  0.8023,
1:          0.6869,  0.5470,  0.4261,  0.3654,  0.3399,  0.3032, -0.6842, -0.7408, -0.8384, -0.8548, -0.8465, -0.7854,
1:         -0.6067], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.7157, -0.7236, -0.7243, -0.7191, -0.7083, -0.6968, -0.6863, -0.6803, -0.6782, -0.6781, -0.6772, -0.6731,
1:         -0.6666, -0.6627, -0.6624, -0.6664, -0.6741, -0.6851, -0.6962, -0.7068, -0.7167, -0.7233, -0.7270, -0.7314,
1:         -0.7392], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.1886, -0.1895, -0.1850, -0.1802, -0.1701, -0.1668, -0.1638, -0.1618, -0.1574, -0.1853, -0.1843, -0.1832,
1:         -0.1779, -0.1700, -0.1670, -0.1570, -0.1642, -0.1614, -0.1789, -0.1787, -0.1763, -0.1717, -0.1634, -0.1641,
1:         -0.1574], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0089,  0.0046,  0.0078,  0.0120, -0.0171,  0.0089, -0.0178, -0.0338, -0.0048, -0.0144, -0.0203, -0.0205,
1:         -0.0103, -0.0012,  0.0030, -0.0061,  0.0085,  0.0049, -0.0291, -0.0213,  0.0127,  0.0089, -0.0008, -0.0221,
1:          0.0123], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 60 [1/5 (20%)]	Loss: 0.23709 : 0.19340 :: 0.02215 (1.64 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 60 [2/5 (40%)]	Loss: 0.28712 : 0.23195 :: 0.02226 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 60 [3/5 (60%)]	Loss: 0.28339 : 0.21981 :: 0.02101 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 60 [4/5 (80%)]	Loss: 0.25294 : 0.22096 :: 0.02201 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 60 : 0.19997760653495789
0: validation loss for velocity_u : 0.0035804405342787504
0: validation loss for velocity_v : 0.005150517448782921
0: validation loss for specific_humidity : 0.0065038809552788734
0: validation loss for velocity_z : 0.11182624101638794
0: validation loss for temperature : 0.01730552688241005
0: validation loss for total_precip : 0.27448540925979614
0: validation loss for t2m : 0.9809908270835876
1: 61 : 06:21:27 :: batch_size = 96, lr = 1e-05
0: 61 : 06:21:27 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 61, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.3080, -0.3022, -0.2961, -0.2902, -0.2842, -0.2781, -0.2719, -0.2658, -0.2598, -0.2536, -0.2475, -0.2413,
0:         -0.2352, -0.2290, -0.2228, -0.2168, -0.2105, -0.2043, -0.3849, -0.3790, -0.3729, -0.3669, -0.3608, -0.3546,
0:         -0.3484], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.5279, 0.5266, 0.5250, 0.5232, 0.5217, 0.5199, 0.5182, 0.5164, 0.5144, 0.5125, 0.5105, 0.5083, 0.5061, 0.5039,
0:         0.5017, 0.4992, 0.4966, 0.4942, 0.5783, 0.5772, 0.5761, 0.5748, 0.5737, 0.5724, 0.5710], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.1891, 0.1913, 0.1947, 0.1969, 0.1980, 0.1980, 0.1980, 0.1980, 0.1958, 0.1936, 0.1902, 0.1869, 0.1836, 0.1791,
0:         0.1758, 0.1725, 0.1692, 0.1658, 0.1370, 0.1403, 0.1425, 0.1447, 0.1470, 0.1481, 0.1481], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2270, -0.2258, -0.2258, -0.2258, -0.2258, -0.2258, -0.2247, -0.2247, -0.2247, -0.2348, -0.2337, -0.2337,
0:         -0.2326, -0.2326, -0.2314, -0.2314, -0.2303, -0.2303, -0.2337, -0.2337, -0.2348, -0.2359, -0.2359, -0.2371,
0:         -0.2382], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 61, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan, -1.1764,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 61, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.4766, -0.4627, -0.4494, -0.4393, -0.4315, -0.4246, -0.4170, -0.4107, -0.4034, -0.3999, -0.4013, -0.4038,
0:         -0.4059, -0.4048, -0.4009, -0.3923, -0.3860, -0.3815, -0.5799, -0.5661, -0.5509, -0.5387, -0.5294, -0.5200,
0:         -0.5113], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([1.7973, 1.7891, 1.7784, 1.7670, 1.7551, 1.7442, 1.7322, 1.7160, 1.6951, 1.6713, 1.6477, 1.6246, 1.6019, 1.5825,
0:         1.5608, 1.5383, 1.5142, 1.4897, 1.8055, 1.7948, 1.7809, 1.7659, 1.7527, 1.7383, 1.7243], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.0033,  0.0117,  0.0299,  0.0487,  0.0665,  0.0843,  0.0980,  0.1103,  0.1205,  0.1319,  0.1417,  0.1509,
0:          0.1629,  0.1751,  0.1856,  0.1912,  0.1911,  0.1837, -0.0175, -0.0037,  0.0120,  0.0300,  0.0465,  0.0602,
0:          0.0736], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.0939, -0.0895, -0.0857, -0.0872, -0.0763, -0.0712, -0.0716, -0.0751, -0.0758, -0.0752, -0.0847, -0.0858,
0:         -0.0703, -0.0586, -0.0420, -0.0260, -0.0131, -0.0097, -0.1039, -0.0995, -0.1036, -0.0994, -0.0873, -0.0909,
0:         -0.0892], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.5859, 1.5864, 1.5827, 1.5783, 1.5736, 1.5695, 1.5635, 1.5574, 1.5501, 1.5418, 1.5349, 1.5293, 1.5250, 1.5208,
0:         1.5162, 1.5115, 1.5071, 1.5045, 1.5001, 1.4950, 1.4875, 1.4796, 1.4728, 1.4691, 1.4680], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2011, -0.2082, -0.2168, -0.2220, -0.2306, -0.2176, -0.2209, -0.2233, -0.2111, -0.2041, -0.2105, -0.2243,
0:         -0.2326, -0.2249, -0.2242, -0.2229, -0.2233, -0.2107, -0.2121, -0.2169, -0.2276, -0.2248, -0.2190, -0.2233,
0:         -0.2128], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0131, -0.0045,  0.0056,  0.0080, -0.0100, -0.0141, -0.0226, -0.0238,  0.0065, -0.0039,  0.0076, -0.0262,
0:         -0.0055, -0.0096,  0.0059,  0.0017,  0.0093, -0.0045, -0.0199, -0.0063, -0.0073, -0.0245, -0.0105, -0.0215,
0:          0.0116], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 61, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3080, -0.3022, -0.2961, -0.2902, -0.2842, -0.2781, -0.2719, -0.2658, -0.2598, -0.2536, -0.2475, -0.2413,
1:         -0.2352, -0.2290, -0.2228, -0.2168, -0.2105, -0.2043, -0.3849, -0.3790, -0.3729, -0.3669, -0.3608, -0.3546,
1:         -0.3484], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0131,  0.0837,  0.1465,  0.1738, -0.0011, -0.1055,  0.3095,  0.0078,  0.1548,  0.0545,  0.0954, -0.0038,
1:         -0.1176, -0.2804, -0.2053, -0.1250,  0.0726,  0.0998, -0.0104,  0.2071, -0.1398, -0.0158,  0.0569,  0.0781,
1:         -0.3271], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3098, -0.3085, -0.3080, -0.3076, -0.3072, -0.3067, -0.3063, -0.3058, -0.3054, -0.3049, -0.3044, -0.3039,
1:         -0.3033, -0.3027, -0.3020, -0.3015, -0.3008, -0.3002, -0.3294, -0.3277, -0.3260, -0.3244, -0.3228, -0.3213,
1:         -0.3197], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., 0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., 0., -0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.1692, 1.1703, 1.1713, 1.1724, 1.1731, 1.1740, 1.1748, 1.1755, 1.1764, 1.1772, 1.1779, 1.1786, 1.1793, 1.1800,
1:         1.1805, 1.1811, 1.1816, 1.1820, 1.1827, 1.1831, 1.1838, 1.1842, 1.1845, 1.1850, 1.1853], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2270, -0.2258, -0.2258, -0.2258, -0.2258, -0.2258, -0.2247, -0.2247, -0.2247, -0.2348, -0.2337, -0.2337,
1:         -0.2326, -0.2326, -0.2314, -0.2314, -0.2303, -0.2303, -0.2337, -0.2337, -0.2348, -0.2359, -0.2359, -0.2371,
1:         -0.2382], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 61, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:         -1.4482,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 61, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.0879, -0.0776, -0.0694, -0.0623, -0.0559, -0.0501, -0.0430, -0.0355, -0.0289, -0.0239, -0.0208, -0.0182,
1:         -0.0134, -0.0086, -0.0039,  0.0025,  0.0051,  0.0052, -0.1695, -0.1634, -0.1526, -0.1454, -0.1375, -0.1295,
1:         -0.1204], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([1.5612, 1.5724, 1.5790, 1.5788, 1.5699, 1.5523, 1.5294, 1.4984, 1.4687, 1.4366, 1.4076, 1.3783, 1.3505, 1.3226,
1:         1.2983, 1.2774, 1.2588, 1.2409, 1.4843, 1.4935, 1.4981, 1.4950, 1.4866, 1.4698, 1.4510], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([0.8547, 0.8526, 0.8435, 0.8321, 0.8210, 0.8118, 0.8023, 0.7999, 0.7959, 0.7868, 0.7780, 0.7707, 0.7715, 0.7800,
1:         0.7977, 0.8204, 0.8457, 0.8684, 0.8468, 0.8418, 0.8274, 0.8114, 0.7978, 0.7873, 0.7883], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.0355, 0.0671, 0.0766, 0.0793, 0.0809, 0.0872, 0.0961, 0.1037, 0.1217, 0.1398, 0.1379, 0.1467, 0.1526, 0.1298,
1:         0.1104, 0.1037, 0.0938, 0.0639, 0.0372, 0.0641, 0.0572, 0.0481, 0.0454, 0.0538, 0.0770], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.7657, 1.7546, 1.7467, 1.7413, 1.7385, 1.7341, 1.7277, 1.7184, 1.7077, 1.6964, 1.6851, 1.6766, 1.6713, 1.6690,
1:         1.6664, 1.6629, 1.6568, 1.6489, 1.6391, 1.6292, 1.6205, 1.6137, 1.6097, 1.6092, 1.6079], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2022, -0.2056, -0.2063, -0.2106, -0.2098, -0.2145, -0.2206, -0.2264, -0.2248, -0.2151, -0.2141, -0.2189,
1:         -0.2178, -0.2187, -0.2216, -0.2284, -0.2323, -0.2327, -0.2235, -0.2257, -0.2255, -0.2275, -0.2259, -0.2296,
1:         -0.2270], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0183,  0.0006,  0.0094, -0.0014, -0.0020,  0.0138, -0.0163, -0.0259, -0.0018, -0.0153, -0.0072, -0.0332,
1:          0.0070, -0.0165, -0.0115, -0.0109, -0.0008,  0.0076, -0.0088, -0.0179,  0.0099,  0.0105,  0.0114, -0.0213,
1:          0.0065], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 61 [1/5 (20%)]	Loss: 0.25186 : 0.20541 :: 0.02186 (1.64 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 61 [2/5 (40%)]	Loss: 0.25924 : 0.19111 :: 0.02115 (8.27 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 61 [3/5 (60%)]	Loss: 0.28613 : 0.22513 :: 0.02158 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 61 [4/5 (80%)]	Loss: 0.26435 : 0.20777 :: 0.02180 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 61 : 0.22578474879264832
0: validation loss for velocity_u : 0.0035848738625645638
0: validation loss for velocity_v : 0.005081608891487122
0: validation loss for specific_humidity : 0.006647307425737381
0: validation loss for velocity_z : 0.12124492228031158
0: validation loss for temperature : 0.019635729491710663
0: validation loss for total_precip : 0.3773753046989441
0: validation loss for t2m : 1.0469236373901367
1: 62 : 06:27:54 :: batch_size = 96, lr = 1e-05
0: 62 : 06:27:54 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 62, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.0914, -1.1264, -1.1562, -1.1816, -1.2004, -1.2001, -1.2127, -1.2533, -1.2720, -1.2708, -1.2689, -1.2617,
1:         -1.2530, -1.2389, -1.2196, -1.1985, -1.1831, -1.1778, -1.1113, -1.1459, -1.1713, -1.1967, -1.2211, -1.2227,
1:         -1.2356], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0346,  0.1445, -0.0284,  0.0460,  0.0102,  0.0097,  0.1061, -0.0602, -0.0502, -0.0274,  0.0135, -0.0736,
1:          0.0151,  0.1597, -0.0819,  0.0365,  0.0855, -0.0227, -0.0285, -0.0505,  0.0021,  0.0815,  0.1347, -0.1599,
1:         -0.0540], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.4623, -0.4859, -0.5003, -0.5123, -0.5199, -0.5267, -0.5343, -0.5566, -0.5744, -0.5802, -0.5916, -0.6052,
1:         -0.6133, -0.6215, -0.6226, -0.6239, -0.6267, -0.6318, -0.4964, -0.5079, -0.5131, -0.5301, -0.5449, -0.5537,
1:         -0.5656], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., 0., -0., -0., 0., -0., 0., 0., -0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.2759, 0.3345, 0.3728, 0.3926, 0.3636, 0.1760, 0.0705, 0.1754, 0.2255, 0.2415, 0.2996, 0.3252, 0.3460, 0.3796,
1:         0.4234, 0.4940, 0.5648, 0.6054, 0.6230, 0.6131, 0.5779, 0.5530, 0.5413, 0.5549, 0.5835], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([ 0.1142, -0.2123, -0.2592, -0.2592, -0.2592, -0.2592, -0.2592, -0.2592, -0.2592, -0.0438, -0.2592, -0.2592,
1:         -0.2592, -0.2592, -0.2592, -0.2592, -0.2592, -0.2592, -0.2486, -0.2592, -0.2592, -0.2592, -0.2592, -0.2592,
1:         -0.2592], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 62, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan, 0.4336,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.9078,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.2228,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 62, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-1.3620, -1.3602, -1.3580, -1.3592, -1.3604, -1.3595, -1.3572, -1.3501, -1.3412, -1.3286, -1.3111, -1.2893,
1:         -1.2628, -1.2307, -1.1960, -1.1594, -1.1260, -1.0989, -1.3609, -1.3586, -1.3588, -1.3603, -1.3614, -1.3618,
1:         -1.3586], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.0477, -0.0308, -0.0109,  0.0127,  0.0363,  0.0606,  0.0789,  0.0973,  0.1150,  0.1343,  0.1545,  0.1766,
1:          0.1963,  0.2149,  0.2260,  0.2335,  0.2344,  0.2294, -0.0640, -0.0544, -0.0397, -0.0187,  0.0058,  0.0312,
1:          0.0534], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.7280, -0.7260, -0.7267, -0.7295, -0.7328, -0.7381, -0.7398, -0.7418, -0.7426, -0.7425, -0.7446, -0.7500,
1:         -0.7558, -0.7624, -0.7691, -0.7732, -0.7763, -0.7751, -0.7363, -0.7337, -0.7340, -0.7365, -0.7401, -0.7431,
1:         -0.7447], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.3592,  0.3140,  0.2535,  0.2376,  0.2766,  0.3261,  0.3168,  0.5047,  0.8673,  1.0513,  0.6947, -1.0359,
1:         -3.1093, -2.8933, -1.0406,  0.3935,  1.0942,  0.9962,  0.3285,  0.3359,  0.3370,  0.3575,  0.3639,  0.3569,
1:          0.2739], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.8801, 0.8746, 0.8672, 0.8575, 0.8394, 0.8180, 0.7943, 0.7681, 0.7402, 0.7098, 0.6714, 0.6233, 0.5614, 0.4786,
1:         0.3847, 0.2809, 0.1832, 0.1077, 0.0691, 0.0750, 0.1300, 0.2287, 0.3553, 0.4880, 0.6104], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([ 0.2430,  0.2419,  0.2317,  0.2174,  0.2362,  0.2693,  0.2989,  0.3427,  0.3758,  0.0556,  0.0387,  0.0101,
1:         -0.0162, -0.0150,  0.0195,  0.0477,  0.1048,  0.1598, -0.0995, -0.1257, -0.1478, -0.1784, -0.2021, -0.1838,
1:         -0.1536], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0092, -0.0111,  0.0066,  0.0096, -0.0048,  0.0002,  0.0007, -0.0208,  0.0032, -0.0087, -0.0042, -0.0174,
1:         -0.0024, -0.0087, -0.0026, -0.0181, -0.0100,  0.0232, -0.0112, -0.0249,  0.0114,  0.0236,  0.0120, -0.0047,
1:         -0.0023], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 62, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.2767,  0.2252,  0.2414,  0.2878,  0.3014,  0.2580,  0.1716,  0.1190,  0.1348,  0.1871,  0.2341,  0.2299,
0:          0.1804,  0.1182,  0.0412, -0.0578, -0.1569, -0.2029,  0.3249,  0.2626,  0.2658,  0.3016,  0.3303,  0.3113,
0:          0.2357], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.1034, -1.1188, -1.1076, -1.0915, -1.0708, -1.0668, -1.0789, -1.0884, -1.0862, -1.0285, -0.8893, -0.6906,
0:         -0.4761, -0.2891, -0.1479, -0.0704, -0.0446, -0.0340, -1.1968, -1.2212, -1.2052, -1.1794, -1.1589, -1.1587,
0:         -1.1699], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.5298, -0.5076,  0.1659,  0.7340,  1.1312,  1.2122,  0.8649,  0.5687,  0.2724, -0.0460, -0.1803, -0.2613,
0:         -0.3756, -0.6064, -0.8627, -0.9049, -0.7029, -0.2480, -0.0738, -0.3478,  0.0128,  0.5787,  1.1701,  1.4053,
0:          0.9870], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2505, -0.2505, -0.2505, -0.2505, -0.2505, -0.2505, -0.2505, -0.2505, -0.2460, -0.2505, -0.2505, -0.2505,
0:         -0.2505, -0.2505, -0.2505, -0.2505, -0.2505, -0.2505, -0.2505, -0.2505, -0.2505, -0.2505, -0.2505, -0.2505,
0:         -0.2505], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 62, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan, -0.3661,     nan,     nan,     nan, -0.5258,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 62, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.6711, -0.6555, -0.6449, -0.6344, -0.6203, -0.5995, -0.5728, -0.5421, -0.5077, -0.4720, -0.4383, -0.4084,
0:         -0.3878, -0.3751, -0.3712, -0.3742, -0.3783, -0.3824, -0.6902, -0.6815, -0.6750, -0.6666, -0.6491, -0.6237,
0:         -0.5941], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.2337, -0.2560, -0.2976, -0.3564, -0.4230, -0.4826, -0.5239, -0.5406, -0.5297, -0.4984, -0.4485, -0.3899,
0:         -0.3264, -0.2577, -0.1900, -0.1232, -0.0634, -0.0040, -0.2205, -0.2408, -0.2831, -0.3481, -0.4154, -0.4739,
0:         -0.5078], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([4.5194, 4.4610, 4.4088, 4.3411, 4.2665, 4.1826, 4.1139, 4.0542, 4.0186, 4.0039, 3.9907, 3.9661, 3.9309, 3.8628,
0:         3.7614, 3.6476, 3.5215, 3.3970, 4.4917, 4.4659, 4.4278, 4.3609, 4.2681, 4.1673, 4.0611], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.3823, -0.2795, -0.1304,  0.0454,  0.1021, -0.0139, -0.1190, -0.1297,  0.0437,  0.0379, -0.0511,  0.2729,
0:          0.0026, -1.1271, -1.4413, -0.5174,  0.4930,  0.9065, -0.2966, -0.2144, -0.1293, -0.0227,  0.0362, -0.0065,
0:         -0.0092], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.3663, 1.3807, 1.3374, 1.2670, 1.1988, 1.1546, 1.1443, 1.1716, 1.2181, 1.2622, 1.2873, 1.2947, 1.2835, 1.2496,
0:         1.1789, 1.0639, 0.9108, 0.7484, 0.6105, 0.5170, 0.4856, 0.5173, 0.6154, 0.7684, 0.9529], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([2.3465, 2.6071, 3.1204, 3.8645, 4.7706, 5.5938, 6.3586, 6.6620, 6.5947, 2.6336, 3.0454, 3.7055, 4.4942, 5.3749,
0:         6.1961, 6.8657, 7.1116, 6.9317, 3.1001, 3.5951, 4.2939, 5.0787, 5.8692, 6.5044, 6.8339], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0190, -0.0037,  0.0063,  0.0086, -0.0022,  0.0204, -0.0093, -0.0042,  0.0058,  0.0007,  0.0157, -0.0027,
0:         -0.0160, -0.0070, -0.0142, -0.0024,  0.0128,  0.0157, -0.0240, -0.0124, -0.0048,  0.0037, -0.0067, -0.0129,
0:          0.0134], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 62 [1/5 (20%)]	Loss: 0.22029 : 0.17517 :: 0.02129 (1.76 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 62 [2/5 (40%)]	Loss: 0.34557 : 0.25095 :: 0.02127 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 62 [3/5 (60%)]	Loss: 0.24282 : 0.19269 :: 0.02104 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 62 [4/5 (80%)]	Loss: 0.27565 : 0.22743 :: 0.01990 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 62 : 0.2136102169752121
0: validation loss for velocity_u : 0.003676167456433177
0: validation loss for velocity_v : 0.0051079848781228065
0: validation loss for specific_humidity : 0.006460069678723812
0: validation loss for velocity_z : 0.11008746922016144
0: validation loss for temperature : 0.019593345001339912
0: validation loss for total_precip : 0.27699506282806396
0: validation loss for t2m : 1.0733511447906494
1: 63 : 06:34:15 :: batch_size = 96, lr = 1e-05
0: 63 : 06:34:15 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 63, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.1203, 1.1974, 1.2677, 1.3289, 1.3789, 1.4153, 1.4353, 1.4386, 1.4282, 1.4088, 1.3857, 1.3658, 1.3532, 1.3469,
0:         1.3409, 1.3238, 1.2862, 1.2286, 1.1094, 1.1931, 1.2704, 1.3406, 1.4036, 1.4582, 1.5000], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.6149, 1.5229, 1.4225, 1.3204, 1.2207, 1.1265, 1.0421, 0.9694, 0.9075, 0.8522, 0.7997, 0.7496, 0.7017, 0.6581,
0:         0.6253, 0.6078, 0.6020, 0.5948, 1.7673, 1.6562, 1.5295, 1.3953, 1.2609, 1.1335, 1.0202], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 1.6288,  1.3852,  1.1482,  0.9649,  0.7615,  0.5938,  0.5401,  0.5111,  0.4731,  0.4842,  0.4954,  0.4462,
0:          0.3434,  0.1780, -0.0389, -0.2758, -0.4949, -0.6335,  2.0402,  1.8747,  1.6400,  1.3829,  1.0990,  0.7995,
0:          0.5535], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2430, -0.2478, -0.2526, -0.2526, -0.2526, -0.2526, -0.2526, -0.2526, -0.2526, -0.1829, -0.1541, -0.1565,
0:         -0.2093, -0.2189, -0.2189, -0.2502, -0.2526, -0.2526, -0.1565, -0.0749, -0.0773, -0.1421, -0.1517, -0.1613,
0:         -0.1925], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 63, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan, 0.4713,    nan, 0.4595,    nan,    nan,    nan,    nan,    nan,    nan, 0.3525,    nan,    nan,    nan,
0:         0.3929,    nan, 0.6550,    nan, 0.9788,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 63, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.5387, 0.5638, 0.5846, 0.6031, 0.6192, 0.6346, 0.6504, 0.6641, 0.6768, 0.6871, 0.6941, 0.7002, 0.7050, 0.7159,
0:         0.7300, 0.7507, 0.7739, 0.7997, 0.5308, 0.5536, 0.5749, 0.5933, 0.6102, 0.6255, 0.6410], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.0359, 0.0817, 0.1343, 0.1924, 0.2500, 0.3061, 0.3631, 0.4229, 0.4820, 0.5398, 0.5937, 0.6460, 0.6973, 0.7503,
0:         0.8067, 0.8630, 0.9189, 0.9737, 0.0306, 0.0790, 0.1362, 0.1996, 0.2664, 0.3287, 0.3893], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.0010,  0.0069,  0.0124,  0.0152,  0.0057, -0.0143, -0.0446, -0.0865, -0.1383, -0.1966, -0.2610, -0.3281,
0:         -0.3969, -0.4598, -0.5122, -0.5498, -0.5700, -0.5708,  0.0311,  0.0335,  0.0277,  0.0143, -0.0095, -0.0438,
0:         -0.0932], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.6225,  0.6041,  0.5985,  0.5860,  0.5709,  0.5575,  0.4929,  0.4091,  0.3415,  0.2892,  0.2517,  0.1952,
0:          0.1216,  0.0780,  0.0504,  0.0081, -0.0269, -0.0681,  0.7502,  0.7291,  0.7131,  0.6778,  0.6311,  0.5923,
0:          0.5098], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.7559, -0.7644, -0.7597, -0.7448, -0.7216, -0.6940, -0.6625, -0.6312, -0.6011, -0.5753, -0.5553, -0.5409,
0:         -0.5282, -0.5163, -0.5046, -0.4955, -0.4891, -0.4850, -0.4843, -0.4872, -0.4915, -0.4947, -0.4937, -0.4872,
0:         -0.4738], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([1.8701, 2.0279, 2.0550, 2.0504, 2.0155, 1.9347, 1.8760, 1.8328, 1.7798, 1.6240, 1.7286, 1.7725, 1.7851, 1.7977,
0:         1.8180, 1.8442, 1.8952, 1.9285, 1.1413, 1.1993, 1.2492, 1.3131, 1.4152, 1.5764, 1.7611], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0156, -0.0215,  0.0028,  0.0098,  0.0037,  0.0101, -0.0024,  0.0106,  0.0070,  0.0013,  0.0082, -0.0089,
0:         -0.0067, -0.0123, -0.0091, -0.0054, -0.0231, -0.0010, -0.0070, -0.0164,  0.0263,  0.0097, -0.0098, -0.0090,
0:          0.0144], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 63, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.1203, 1.1974, 1.2677, 1.3289, 1.3789, 1.4153, 1.4353, 1.4386, 1.4282, 1.4088, 1.3857, 1.3658, 1.3532, 1.3469,
1:         1.3409, 1.3238, 1.2862, 1.2286, 1.1094, 1.1931, 1.2704, 1.3406, 1.4036, 1.4582, 1.5000], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0084, -0.0644,  0.2636,  0.1297,  0.1354, -0.0982,  0.0339, -0.0972, -0.0846, -0.0713,  0.3728,  0.0338,
1:          0.1572, -0.0364, -0.0480, -0.1195, -0.3191,  0.1701,  0.0883, -0.0827,  0.0075,  0.0648,  0.0598,  0.1298,
1:         -0.0668], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6699, -0.6664, -0.6609, -0.6560, -0.6495, -0.6441, -0.6472, -0.6489, -0.6561, -0.6642, -0.6752, -0.6833,
1:         -0.6831, -0.6881, -0.6895, -0.6616, -0.6137, -0.4027, -0.6653, -0.6638, -0.6584, -0.6519, -0.6432, -0.6370,
1:         -0.6308], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.0882, -1.1093, -1.1238, -1.1297, -1.1280, -1.1197, -1.1070, -1.0890, -1.0589, -1.0100, -0.9419, -0.8573,
1:         -0.7646, -0.6792, -0.6174, -0.5944, -0.6232, -0.6950, -0.7766, -0.8363, -0.8711, -0.9030, -0.9569, -1.0337,
1:         -1.1087], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2430, -0.2478, -0.2526, -0.2526, -0.2526, -0.2526, -0.2526, -0.2526, -0.2526, -0.1829, -0.1541, -0.1565,
1:         -0.2093, -0.2189, -0.2189, -0.2502, -0.2526, -0.2526, -0.1565, -0.0749, -0.0773, -0.1421, -0.1517, -0.1613,
1:         -0.1925], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 63, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan, -0.3856,     nan,     nan,     nan,     nan,     nan, -0.2339,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan, -0.1278,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 63, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.7084, 0.6890, 0.6658, 0.6428, 0.6213, 0.5986, 0.5784, 0.5552, 0.5316, 0.5065, 0.4796, 0.4529, 0.4240, 0.3957,
1:         0.3707, 0.3465, 0.3225, 0.3021, 0.7193, 0.6994, 0.6773, 0.6568, 0.6386, 0.6201, 0.6010], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.0491, -0.1362, -0.2133, -0.2841, -0.3616, -0.4674, -0.6137, -0.8005, -1.0245, -1.2615, -1.5009, -1.7327,
1:         -1.9520, -2.1561, -2.3358, -2.4947, -2.6120, -2.6767, -0.1931, -0.2924, -0.3714, -0.4433, -0.5269, -0.6367,
1:         -0.7847], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.3582, -0.3228, -0.2818, -0.2377, -0.1953, -0.1519, -0.1143, -0.0791, -0.0497, -0.0235, -0.0034,  0.0157,
1:          0.0304,  0.0446,  0.0575,  0.0677,  0.0790,  0.0885, -0.3146, -0.2732, -0.2283, -0.1845, -0.1403, -0.0991,
1:         -0.0624], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.1979, -0.0842,  0.0227,  0.0260,  0.1099,  0.2663,  0.4573,  0.7057,  0.7587,  0.4298, -0.1136, -0.6272,
1:         -0.9636, -1.0985, -1.0663, -0.9171, -0.7985, -0.7451, -0.0914, -0.0543, -0.0229, -0.0933, -0.0434,  0.1560,
1:          0.3890], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-2.4919, -2.5586, -2.6270, -2.7019, -2.7785, -2.8516, -2.9179, -2.9676, -3.0042, -3.0287, -3.0475, -3.0645,
1:         -3.0735, -3.0701, -3.0473, -2.9971, -2.9193, -2.8081, -2.6665, -2.4992, -2.3123, -2.1195, -1.9354, -1.7713,
1:         -1.6327], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([ 0.8392,  0.8263,  0.7685,  0.6686,  0.5693,  0.4474,  0.3481,  0.2706,  0.2383,  0.0746,  0.0154, -0.0101,
1:         -0.0685, -0.1193, -0.1475, -0.2116, -0.2013, -0.1555, -0.4598, -0.5026, -0.4838, -0.4778, -0.4806, -0.4807,
1:         -0.4778], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0022,  0.0001, -0.0118, -0.0006, -0.0020,  0.0150,  0.0082, -0.0224,  0.0085,  0.0005,  0.0124, -0.0019,
1:         -0.0031, -0.0007, -0.0029, -0.0052,  0.0018,  0.0218, -0.0045, -0.0277,  0.0186,  0.0097,  0.0083,  0.0035,
1:          0.0065], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 63 [1/5 (20%)]	Loss: 0.28041 : 0.24194 :: 0.02000 (1.61 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 63 [2/5 (40%)]	Loss: 0.23194 : 0.18751 :: 0.02060 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 63 [3/5 (60%)]	Loss: 0.26521 : 0.22511 :: 0.02132 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 63 [4/5 (80%)]	Loss: 0.23701 : 0.19706 :: 0.02041 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 63 : 0.19586992263793945
0: validation loss for velocity_u : 0.0033733006566762924
0: validation loss for velocity_v : 0.00466226227581501
0: validation loss for specific_humidity : 0.006549220997840166
0: validation loss for velocity_z : 0.1053280234336853
0: validation loss for temperature : 0.021062105894088745
0: validation loss for total_precip : 0.2905515134334564
0: validation loss for t2m : 0.9395632743835449
1: 64 : 06:40:29 :: batch_size = 96, lr = 1e-05
0: 64 : 06:40:29 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 64, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 64, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.3504, -0.3384, -0.3259, -0.3128, -0.2991, -0.2845, -0.2689, -0.2520, -0.2341, -0.2153, -0.1958, -0.1755,
0:         -0.1543, -0.1326, -0.1105, -0.0881, -0.0657, -0.0433, -0.2499, -0.2372, -0.2238, -0.2095, -0.1944, -0.1782,
0:         -0.1607], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.4047, -1.3748, -1.3431, -1.3090, -1.2733, -1.2361, -1.1985, -1.1603, -1.1221, -1.0830, -1.0435, -1.0034,
0:         -0.9635, -0.9243, -0.8858, -0.8480, -0.8102, -0.7724, -1.3201, -1.2875, -1.2535, -1.2180, -1.1812, -1.1438,
0:         -1.1060], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0777, -0.0904, -0.0950, -0.1031, -0.1295, -0.1710, -0.2159, -0.2459, -0.2516, -0.2378, -0.2182, -0.2033,
0:         -0.1929, -0.1768, -0.1457, -0.0984, -0.0455,  0.0006, -0.0938, -0.1192, -0.1422, -0.1756, -0.2263, -0.2874,
0:         -0.3369], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1554, -0.1505, -0.1469, -0.1457, -0.1444, -0.1457, -0.1493, -0.1481, -0.1444, -0.1115, -0.1030, -0.0994,
0:         -0.1030, -0.1042, -0.1042, -0.1091, -0.1140, -0.1323, -0.0774, -0.0738, -0.0689, -0.0738, -0.0786, -0.0933,
0:         -0.1152], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 64, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 64, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.6007, -0.5977, -0.5970, -0.6049, -0.6187, -0.6428, -0.6717, -0.7064, -0.7406, -0.7699, -0.7905, -0.8020,
0:         -0.8068, -0.8022, -0.7953, -0.7846, -0.7735, -0.7606, -0.6265, -0.6171, -0.6159, -0.6233, -0.6396, -0.6643,
0:         -0.6971], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-1.1590, -1.1375, -1.1274, -1.1242, -1.1298, -1.1378, -1.1470, -1.1552, -1.1634, -1.1703, -1.1765, -1.1853,
0:         -1.1972, -1.2109, -1.2256, -1.2440, -1.2625, -1.2787, -1.2165, -1.1950, -1.1852, -1.1858, -1.1944, -1.2083,
0:         -1.2211], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6644, -0.6561, -0.6459, -0.6351, -0.6242, -0.6135, -0.6058, -0.5991, -0.5942, -0.5920, -0.5909, -0.5909,
0:         -0.5923, -0.5944, -0.5955, -0.5964, -0.5969, -0.5968, -0.6515, -0.6419, -0.6315, -0.6202, -0.6099, -0.6000,
0:         -0.5928], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.4140, -0.3488, -0.3044, -0.2559, -0.1899, -0.1512, -0.1416, -0.1181, -0.0727, -0.0192,  0.0404,  0.0881,
0:          0.1038,  0.1005,  0.0687,  0.0277,  0.0153, -0.0196, -0.2693, -0.1478,  0.0019,  0.1453,  0.2571,  0.3102,
0:          0.2854], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.9352, -0.9512, -0.9634, -0.9735, -0.9840, -0.9960, -1.0085, -1.0220, -1.0308, -1.0356, -1.0377, -1.0400,
0:         -1.0410, -1.0410, -1.0392, -1.0361, -1.0312, -1.0260, -1.0216, -1.0200, -1.0212, -1.0261, -1.0347, -1.0463,
0:         -1.0619], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1873, -0.1439, -0.0921, -0.0438, -0.0017,  0.0261,  0.0320,  0.0193,  0.0062, -0.1672, -0.1320, -0.0724,
0:         -0.0243,  0.0253,  0.0533,  0.0518,  0.0411,  0.0210, -0.1500, -0.1193, -0.0696, -0.0162,  0.0269,  0.0459,
0:          0.0522], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0046, -0.0251,  0.0145,  0.0090,  0.0006,  0.0027, -0.0106,  0.0090,  0.0008, -0.0006,  0.0107, -0.0095,
0:         -0.0029,  0.0101, -0.0217, -0.0138, -0.0138,  0.0061, -0.0220, -0.0194,  0.0073, -0.0163, -0.0020,  0.0074,
0:          0.0152], device='cuda:0', grad_fn=<SliceBackward0>)
1:      first 25 values: tensor([-0.3504, -0.3384, -0.3259, -0.3128, -0.2991, -0.2845, -0.2689, -0.2520, -0.2341, -0.2153, -0.1958, -0.1755,
1:         -0.1543, -0.1326, -0.1105, -0.0881, -0.0657, -0.0433, -0.2499, -0.2372, -0.2238, -0.2095, -0.1944, -0.1782,
1:         -0.1607], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0178,  0.0519,  0.0557,  0.1815,  0.0383,  0.0621, -0.0832,  0.0657, -0.0641, -0.0883, -0.0157, -0.0749,
1:          0.0641, -0.2224,  0.1508, -0.0567, -0.1465,  0.0978,  0.0227,  0.1005, -0.0015, -0.0174,  0.0397, -0.0509,
1:          0.0391], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6381, -0.6384, -0.6384, -0.6392, -0.6402, -0.6417, -0.6441, -0.6460, -0.6475, -0.6501, -0.6526, -0.6546,
1:         -0.6567, -0.6596, -0.6629, -0.6663, -0.6692, -0.6708, -0.6533, -0.6541, -0.6553, -0.6572, -0.6589, -0.6604,
1:         -0.6628], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., 0., 0., 0., 0., 0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.1237, -1.1269, -1.1301, -1.1334, -1.1368, -1.1402, -1.1434, -1.1465, -1.1493, -1.1517, -1.1538, -1.1556,
1:         -1.1568, -1.1576, -1.1579, -1.1576, -1.1569, -1.1556, -1.1538, -1.1517, -1.1490, -1.1459, -1.1426, -1.1392,
1:         -1.1358], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1554, -0.1505, -0.1469, -0.1457, -0.1444, -0.1457, -0.1493, -0.1481, -0.1444, -0.1115, -0.1030, -0.0994,
1:         -0.1030, -0.1042, -0.1042, -0.1091, -0.1140, -0.1323, -0.0774, -0.0738, -0.0689, -0.0738, -0.0786, -0.0933,
1:         -0.1152], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 64, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([-0.2090,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.5571,     nan,     nan,
1:             nan, -0.6540,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 64, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.2047, 0.2264, 0.2437, 0.2607, 0.2761, 0.2910, 0.3087, 0.3248, 0.3354, 0.3407, 0.3419, 0.3389, 0.3367, 0.3374,
1:         0.3383, 0.3418, 0.3435, 0.3443, 0.2788, 0.2977, 0.3126, 0.3231, 0.3301, 0.3397, 0.3509], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-1.3401, -1.3333, -1.3352, -1.3416, -1.3551, -1.3700, -1.3829, -1.3939, -1.4046, -1.4175, -1.4345, -1.4539,
1:         -1.4780, -1.5012, -1.5209, -1.5340, -1.5374, -1.5362, -1.3700, -1.3656, -1.3661, -1.3768, -1.3917, -1.4069,
1:         -1.4229], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6814, -0.6781, -0.6738, -0.6702, -0.6666, -0.6620, -0.6579, -0.6529, -0.6458, -0.6396, -0.6331, -0.6292,
1:         -0.6280, -0.6281, -0.6281, -0.6261, -0.6242, -0.6218, -0.6744, -0.6694, -0.6633, -0.6579, -0.6540, -0.6502,
1:         -0.6465], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.1259, -0.1295, -0.0984, -0.1055, -0.0686,  0.0191,  0.0732,  0.1364,  0.2408,  0.3056,  0.3519,  0.4301,
1:          0.5104,  0.6045,  0.7045,  0.7167,  0.4967,  0.0998, -0.2132, -0.2119, -0.2186, -0.2611, -0.1984,  0.0098,
1:          0.2455], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.8260, -0.8186, -0.8104, -0.8037, -0.8006, -0.8000, -0.8018, -0.8067, -0.8131, -0.8201, -0.8283, -0.8374,
1:         -0.8483, -0.8607, -0.8724, -0.8817, -0.8872, -0.8887, -0.8877, -0.8880, -0.8910, -0.8972, -0.9071, -0.9221,
1:         -0.9383], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2200, -0.2198, -0.2132, -0.2157, -0.2123, -0.2154, -0.2135, -0.2161, -0.2171, -0.2273, -0.2257, -0.2192,
1:         -0.2193, -0.2158, -0.2187, -0.2195, -0.2222, -0.2244, -0.2315, -0.2326, -0.2287, -0.2228, -0.2203, -0.2221,
1:         -0.2257], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0056, -0.0247,  0.0095,  0.0220, -0.0170,  0.0155,  0.0043, -0.0062, -0.0035, -0.0065, -0.0069, -0.0168,
1:         -0.0061,  0.0076, -0.0074, -0.0145, -0.0193,  0.0169,  0.0028, -0.0275,  0.0105,  0.0060,  0.0201, -0.0060,
1:          0.0037], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 64 [1/5 (20%)]	Loss: 0.29276 : 0.21497 :: 0.02175 (1.94 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 64 [2/5 (40%)]	Loss: 0.25425 : 0.18876 :: 0.02302 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 64 [3/5 (60%)]	Loss: 0.21735 : 0.16489 :: 0.02107 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 64 [4/5 (80%)]	Loss: 0.31107 : 0.22285 :: 0.02133 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 64 : 0.18381287157535553
0: validation loss for velocity_u : 0.0034687486477196217
0: validation loss for velocity_v : 0.0048525575548410416
0: validation loss for specific_humidity : 0.00550595810636878
0: validation loss for velocity_z : 0.09846683591604233
0: validation loss for temperature : 0.01526910625398159
0: validation loss for total_precip : 0.17600232362747192
0: validation loss for t2m : 0.9831243753433228
0: 65 : 06:46:50 :: batch_size = 96, lr = 1e-05
1: 65 : 06:47:01 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 65, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.4492, -0.4574, -0.4770, -0.4997, -0.5157, -0.5243, -0.5260, -0.5206, -0.5054, -0.4801, -0.4498, -0.4208,
0:         -0.3966, -0.3802, -0.3708, -0.3605, -0.3483, -0.3334, -0.4552, -0.4608, -0.4760, -0.4951, -0.5135, -0.5338,
0:         -0.5502], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.5462, 0.5521, 0.5636, 0.5700, 0.5785, 0.5874, 0.5977, 0.6039, 0.5908, 0.5609, 0.5145, 0.4590, 0.4058, 0.3547,
0:         0.3063, 0.2554, 0.1975, 0.1400, 0.5442, 0.5474, 0.5537, 0.5603, 0.5735, 0.5918, 0.6185], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2140, 0.2460, 0.1970, 0.1353, 0.0991, 0.1331, 0.2183, 0.3184, 0.3695, 0.3950, 0.4099, 0.3588, 0.2545, 0.1395,
0:         0.0629, 0.0671, 0.0927, 0.1374, 0.0693, 0.0863, 0.0586, 0.0608, 0.0714, 0.1544, 0.2460], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390,
0:         -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390, -0.2390,
0:         -0.2390], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 65, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.4785,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 65, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.9711, -0.9565, -0.9429, -0.9385, -0.9455, -0.9654, -0.9982, -1.0386, -1.0882, -1.1383, -1.1855, -1.2274,
0:         -1.2631, -1.2961, -1.3249, -1.3515, -1.3698, -1.3808, -1.0013, -0.9848, -0.9728, -0.9716, -0.9820, -1.0050,
0:         -1.0371], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.4261, 0.4331, 0.4409, 0.4477, 0.4536, 0.4555, 0.4521, 0.4421, 0.4293, 0.4106, 0.3954, 0.3779, 0.3560, 0.3235,
0:         0.2769, 0.2162, 0.1451, 0.0739, 0.4177, 0.4289, 0.4357, 0.4442, 0.4499, 0.4535, 0.4521], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([3.7519, 3.7678, 3.6707, 3.4538, 3.1857, 2.8896, 2.7113, 2.6647, 2.7686, 2.9778, 3.1766, 3.2572, 3.1666, 2.8865,
0:         2.4929, 2.0717, 1.7043, 1.4617, 4.1015, 4.1436, 4.0377, 3.7921, 3.4654, 3.1439, 2.9253], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.1598, -0.1572, -0.1603, -0.1220, -0.0620,  0.0469,  0.1684,  0.2289,  0.2737,  0.3316,  0.3486,  0.3316,
0:          0.3411,  0.3448,  0.3251,  0.3044,  0.3031,  0.2965, -0.1564, -0.1363, -0.1545, -0.1322, -0.0974, -0.0074,
0:          0.1100], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.0160,  0.1258,  0.2451,  0.3008,  0.2752,  0.1811,  0.0490, -0.0791, -0.1694, -0.2123, -0.2201, -0.2159,
0:         -0.2236, -0.2595, -0.3215, -0.4017, -0.4804, -0.5431, -0.5826, -0.6020, -0.6088, -0.6147, -0.6286, -0.6526,
0:         -0.6794], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([0.3707, 0.3995, 0.4242, 0.4212, 0.3873, 0.3217, 0.2267, 0.1296, 0.0660, 0.4330, 0.4565, 0.4798, 0.4758, 0.4322,
0:         0.3662, 0.2630, 0.1635, 0.0798, 0.4723, 0.4874, 0.4984, 0.4959, 0.4562, 0.3790, 0.2835], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0003, -0.0051, -0.0084,  0.0055,  0.0086,  0.0221,  0.0095, -0.0056,  0.0243,  0.0112,  0.0082, -0.0079,
0:         -0.0107,  0.0133, -0.0221, -0.0181, -0.0256,  0.0164, -0.0147, -0.0012,  0.0175, -0.0026,  0.0031,  0.0014,
0:          0.0149], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 65, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.4960, 0.5037, 0.5109, 0.5182, 0.5263, 0.5358, 0.5462, 0.5572, 0.5683, 0.5794, 0.5906, 0.6031, 0.6176, 0.6339,
1:         0.6518, 0.6702, 0.6877, 0.7030, 0.4954, 0.5004, 0.5039, 0.5069, 0.5107, 0.5149, 0.5190], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0326, -0.0180, -0.1406,  0.0959,  0.0110,  0.0163,  0.1994, -0.0554,  0.1335, -0.0256, -0.0862,  0.0479,
1:         -0.0090,  0.0886, -0.0324, -0.0890,  0.0641, -0.0503, -0.1356,  0.0347,  0.0778, -0.0143, -0.0824, -0.0991,
1:         -0.2019], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.3599, 1.3639, 1.3825, 1.3805, 1.3787, 1.3598, 1.3412, 1.3488, 1.3593, 1.3459, 1.3324, 1.3333, 1.3342, 1.3466,
1:         1.3108, 1.2894, 1.2680, 1.2583, 1.1748, 1.1791, 1.1996, 1.2202, 1.2346, 1.2466, 1.2563], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.4334, 1.4081, 1.3822, 1.3555, 1.3287, 1.3025, 1.2780, 1.2564, 1.2374, 1.2208, 1.2063, 1.1944, 1.1848, 1.1784,
1:         1.1747, 1.1728, 1.1720, 1.1703, 1.1678, 1.1640, 1.1595, 1.1543, 1.1477, 1.1395, 1.1292], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1317, -0.1676, -0.1878, -0.2080, -0.2259, -0.2349, -0.2416, -0.2438, -0.2438, -0.1340, -0.1676, -0.1900,
1:         -0.2125, -0.2394, -0.2416, -0.2438, -0.2438, -0.2438, -0.0914, -0.1384, -0.1676, -0.1945, -0.2214, -0.2282,
1:         -0.2326], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 65, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -1.2709,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.9106,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 65, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.8640, 0.8757, 0.8894, 0.9041, 0.9210, 0.9369, 0.9517, 0.9663, 0.9811, 0.9942, 1.0066, 1.0193, 1.0306, 1.0401,
1:         1.0488, 1.0555, 1.0583, 1.0608, 0.7998, 0.8112, 0.8241, 0.8376, 0.8530, 0.8675, 0.8809], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([1.7429, 1.7508, 1.7487, 1.7391, 1.7204, 1.6969, 1.6710, 1.6460, 1.6207, 1.5915, 1.5572, 1.5173, 1.4700, 1.4226,
1:         1.3730, 1.3259, 1.2795, 1.2380, 1.6881, 1.6969, 1.6989, 1.6926, 1.6823, 1.6709, 1.6611], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([ 0.3675,  0.1523, -0.0832, -0.2919, -0.4667, -0.5937, -0.6548, -0.6811, -0.6778, -0.6366, -0.5939, -0.5569,
1:         -0.5267, -0.5140, -0.5304, -0.5420, -0.5562, -0.5639,  0.7624,  0.5907,  0.3843,  0.1706, -0.0349, -0.2316,
1:         -0.3822], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.1472, -0.1172, -0.0910, -0.0408,  0.0084,  0.0559,  0.1133,  0.1644,  0.2111,  0.2432,  0.2547,  0.2724,
1:          0.2887,  0.3013,  0.3185,  0.3238,  0.3271,  0.3055, -0.1469, -0.1175, -0.0896, -0.0496, -0.0004,  0.0541,
1:          0.1130], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.1908, 1.2129, 1.2365, 1.2622, 1.2885, 1.3192, 1.3523, 1.3887, 1.4245, 1.4581, 1.4894, 1.5155, 1.5390, 1.5609,
1:         1.5810, 1.5965, 1.6078, 1.6128, 1.6089, 1.5965, 1.5755, 1.5535, 1.5344, 1.5203, 1.5133], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.1478, -0.1301, -0.0859, -0.0067,  0.0861,  0.2143,  0.3328,  0.4196,  0.4759, -0.1989, -0.1890, -0.1620,
1:         -0.1216, -0.0536,  0.0497,  0.1435,  0.2361,  0.3029, -0.2239, -0.2289, -0.2211, -0.2069, -0.1770, -0.1289,
1:         -0.0603], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 3.4751e-03, -1.1110e-02, -9.7353e-03,  1.6556e-02, -1.1014e-02,  2.4538e-02, -5.6553e-05, -9.2112e-03,
1:          2.0225e-03,  7.3736e-03,  1.9087e-02, -8.9038e-04, -5.5659e-03,  7.4410e-03, -1.1930e-02,  7.6739e-04,
1:         -1.4037e-02,  2.0367e-02, -1.9749e-03, -1.8889e-02,  1.1303e-02,  1.7227e-02,  1.2978e-02,  3.0100e-03,
1:          1.6105e-02], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 65 [1/5 (20%)]	Loss: 0.22164 : 0.18470 :: 0.02137 (1.37 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 65 [2/5 (40%)]	Loss: 0.22611 : 0.17960 :: 0.02218 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 65 [3/5 (60%)]	Loss: 0.19607 : 0.15519 :: 0.02174 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 65 [4/5 (80%)]	Loss: 0.24159 : 0.20603 :: 0.02076 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 65 : 0.21775782108306885
0: validation loss for velocity_u : 0.00384861440397799
0: validation loss for velocity_v : 0.005462057888507843
0: validation loss for specific_humidity : 0.007029888220131397
0: validation loss for velocity_z : 0.1287367194890976
0: validation loss for temperature : 0.018946902826428413
0: validation loss for total_precip : 0.3779969811439514
0: validation loss for t2m : 0.9822834730148315
1: 66 : 06:53:10 :: batch_size = 96, lr = 1e-05
0: 66 : 06:53:10 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 66, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.7676, -0.7737, -0.7632, -0.7164, -0.6638, -0.6300, -0.6283, -0.6549, -0.6990, -0.7572, -0.8102, -0.8431,
1:         -0.8453, -0.8330, -0.8249, -0.8332, -0.8402, -0.8269, -0.7905, -0.8005, -0.7924, -0.7464, -0.6928, -0.6569,
1:         -0.6446], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.1395,  0.1502,  0.0801, -0.0464,  0.0308,  0.0823,  0.1559,  0.0778,  0.0495, -0.1039,  0.0937, -0.0768,
1:          0.0455,  0.0031, -0.0106,  0.0503, -0.0272, -0.0794, -0.1416,  0.1481,  0.0812, -0.0004, -0.0262,  0.0012,
1:         -0.0186], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([2.9635, 3.0066, 3.0390, 2.9966, 3.0041, 2.9475, 2.8414, 2.8111, 2.8406, 2.8688, 2.8837, 2.9465, 2.9759, 2.9772,
1:         3.0010, 3.0229, 2.9501, 2.7651, 2.7974, 2.8485, 2.8986, 2.8911, 2.8950, 2.8989, 2.8255], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([ 0.1953,  0.1758,  0.0693,  0.0814, -0.1080, -0.2952, -0.5182, -0.8202, -1.0875, -1.2788, -1.2766, -1.2740,
1:         -1.1901, -1.0100, -0.9262, -0.9241, -0.8888, -0.8339, -0.8551, -0.8185, -0.8373, -0.8623, -0.7832, -0.7469,
1:         -0.7393], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([1.0654, 0.9980, 0.8349, 1.1132, 1.4851, 1.2481, 0.8718, 1.4221, 2.4986, 0.5478, 0.9023, 0.6892, 1.4829, 1.6134,
1:         0.9349, 0.5413, 0.6152, 1.0828, 0.0998, 0.7305, 0.7783, 1.2763, 1.6200, 0.9588, 0.0367], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 66, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan, -1.1680,     nan,     nan,     nan, -1.3555,     nan,     nan,     nan,     nan,
1:             nan,  0.2164,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  1.6241,     nan,     nan,
1:          1.1854])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 66, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.7327, -0.7118, -0.6920, -0.6750, -0.6595, -0.6444, -0.6286, -0.6118, -0.5977, -0.5866, -0.5792, -0.5692,
1:         -0.5576, -0.5425, -0.5266, -0.5097, -0.4931, -0.4760, -0.7355, -0.7153, -0.6937, -0.6790, -0.6664, -0.6549,
1:         -0.6437], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.2816, 0.2650, 0.2429, 0.2167, 0.1843, 0.1480, 0.1165, 0.0941, 0.0864, 0.0895, 0.0981, 0.1016, 0.1017, 0.0952,
1:         0.0857, 0.0741, 0.0630, 0.0541, 0.2752, 0.2560, 0.2340, 0.2070, 0.1771, 0.1424, 0.1127], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([ 0.0136,  0.0131,  0.0034, -0.0119, -0.0301, -0.0527, -0.0761, -0.0944, -0.1080, -0.1167, -0.1190, -0.1193,
1:         -0.1184, -0.1193, -0.1242, -0.1322, -0.1444, -0.1577, -0.0663, -0.0622, -0.0650, -0.0757, -0.0908, -0.1093,
1:         -0.1291], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.2790,  0.2015,  0.2290,  0.1804,  0.0052, -0.0242,  0.0625,  0.0923,  0.0713,  0.1198,  0.0527, -0.2038,
1:          0.1355,  0.5992,  0.2719,  0.0732,  0.2806,  0.2751,  0.2253,  0.1127,  0.0542,  0.0170, -0.0664, -0.0548,
1:          0.0284], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.3057, -0.2915, -0.2600, -0.2332, -0.2246, -0.2342, -0.2477, -0.2510, -0.2393, -0.2249, -0.2236, -0.2544,
1:         -0.3199, -0.4096, -0.5146, -0.6294, -0.7457, -0.8586, -0.9532, -1.0078, -1.0014, -0.9211, -0.7796, -0.6117,
1:         -0.4601], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2156, -0.2308, -0.2370, -0.2372, -0.2318, -0.2272, -0.2145, -0.2028, -0.1850, -0.2281, -0.2353, -0.2384,
1:         -0.2418, -0.2463, -0.2361, -0.2308, -0.2197, -0.2057, -0.2308, -0.2402, -0.2404, -0.2412, -0.2495, -0.2503,
1:         -0.2433], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0128, -0.0087,  0.0030,  0.0086,  0.0070,  0.0308, -0.0063,  0.0077, -0.0024,  0.0079,  0.0007,  0.0015,
1:         -0.0045, -0.0007, -0.0145, -0.0010,  0.0046,  0.0098, -0.0129, -0.0151,  0.0131,  0.0338,  0.0150,  0.0023,
1:          0.0057], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 66, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0041, -0.0123, -0.0191, -0.0242, -0.0275, -0.0290, -0.0288, -0.0270, -0.0236, -0.0188, -0.0126, -0.0049,
0:          0.0038,  0.0133,  0.0234,  0.0343,  0.0456,  0.0580, -0.0599, -0.0634, -0.0653, -0.0655, -0.0639, -0.0604,
0:         -0.0555], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.1235, 0.1390, 0.1561, 0.1744, 0.1938, 0.2139, 0.2346, 0.2562, 0.2793, 0.3036, 0.3295, 0.3565, 0.3843, 0.4126,
0:         0.4415, 0.4708, 0.5004, 0.5306, 0.1451, 0.1641, 0.1846, 0.2064, 0.2292, 0.2532, 0.2778], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2463, 0.2174, 0.1929, 0.1773, 0.1696, 0.1651, 0.1595, 0.1551, 0.1584, 0.1762, 0.2063, 0.2374, 0.2586, 0.2630,
0:         0.2586, 0.2552, 0.2641, 0.2853, 0.1796, 0.1495, 0.1284, 0.1195, 0.1150, 0.1084, 0.0972], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574,
0:         -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574, -0.2574,
0:         -0.2574], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 66, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan,     nan, -0.4621,     nan, -0.4721, -0.4810,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 66, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.7671, -0.7711, -0.7683, -0.7625, -0.7542, -0.7426, -0.7288, -0.7100, -0.6868, -0.6625, -0.6410, -0.6198,
0:         -0.6035, -0.5873, -0.5723, -0.5587, -0.5468, -0.5426, -0.7690, -0.7785, -0.7817, -0.7828, -0.7803, -0.7738,
0:         -0.7644], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-1.7710, -1.7854, -1.7917, -1.7929, -1.7871, -1.7832, -1.7792, -1.7749, -1.7667, -1.7575, -1.7429, -1.7273,
0:         -1.7144, -1.7015, -1.6880, -1.6711, -1.6502, -1.6275, -1.6784, -1.6896, -1.6933, -1.6894, -1.6815, -1.6760,
0:         -1.6741], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.7764, -0.7761, -0.7749, -0.7752, -0.7751, -0.7752, -0.7751, -0.7762, -0.7766, -0.7746, -0.7733, -0.7704,
0:         -0.7682, -0.7660, -0.7646, -0.7623, -0.7602, -0.7582, -0.7736, -0.7735, -0.7736, -0.7740, -0.7746, -0.7745,
0:         -0.7743], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([ 0.0510, -0.0117, -0.0407, -0.1064, -0.1741, -0.2739, -0.3808, -0.4222, -0.4495, -0.4447, -0.4003, -0.3425,
0:         -0.3149, -0.3165, -0.2982, -0.2315, -0.0492,  0.1860, -0.0748, -0.1485, -0.1847, -0.2398, -0.2725, -0.3264,
0:         -0.3784], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-1.0606, -1.0635, -1.0690, -1.0781, -1.0895, -1.1033, -1.1184, -1.1329, -1.1465, -1.1590, -1.1713, -1.1852,
0:         -1.2016, -1.2177, -1.2351, -1.2519, -1.2682, -1.2827, -1.2962, -1.3069, -1.3152, -1.3201, -1.3233, -1.3268,
0:         -1.3299], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2579, -0.2629, -0.2599, -0.2616, -0.2619, -0.2625, -0.2627, -0.2624, -0.2583, -0.2591, -0.2621, -0.2585,
0:         -0.2606, -0.2564, -0.2599, -0.2591, -0.2599, -0.2595, -0.2578, -0.2606, -0.2601, -0.2560, -0.2565, -0.2558,
0:         -0.2532], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0037, -0.0099,  0.0044,  0.0169, -0.0037, -0.0015, -0.0062,  0.0096,  0.0146,  0.0126,  0.0041,  0.0015,
0:         -0.0113,  0.0003, -0.0050, -0.0190, -0.0256, -0.0055, -0.0251, -0.0063,  0.0191,  0.0040, -0.0070, -0.0151,
0:          0.0085], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 66 [1/5 (20%)]	Loss: 0.25273 : 0.19787 :: 0.02053 (1.63 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 66 [2/5 (40%)]	Loss: 0.27612 : 0.23170 :: 0.02175 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 66 [3/5 (60%)]	Loss: 0.25203 : 0.19345 :: 0.01999 (8.45 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 66 [4/5 (80%)]	Loss: 0.25578 : 0.19827 :: 0.02171 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 66 : 0.19669637084007263
0: validation loss for velocity_u : 0.003583813551813364
0: validation loss for velocity_v : 0.005208831280469894
0: validation loss for specific_humidity : 0.00604532565921545
0: validation loss for velocity_z : 0.10364891588687897
0: validation loss for temperature : 0.01833324320614338
0: validation loss for total_precip : 0.25330445170402527
0: validation loss for t2m : 0.9867500066757202
1: 67 : 06:59:22 :: batch_size = 96, lr = 1e-05
0: 67 : 06:59:22 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 67, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.7604, 1.7705, 1.7804, 1.7904, 1.8003, 1.8103, 1.8201, 1.8298, 1.8396, 1.8493, 1.8589, 1.8685, 1.8780, 1.8875,
0:         1.8970, 1.9065, 1.9158, 1.9252, 1.7502, 1.7603, 1.7704, 1.7803, 1.7902, 1.8000, 1.8100], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([3.0676, 3.0543, 3.0409, 3.0274, 3.0139, 3.0003, 2.9866, 2.9729, 2.9591, 2.9452, 2.9315, 2.9173, 2.9034, 2.8892,
0:         2.8751, 2.8609, 2.8466, 2.8322, 3.1106, 3.0971, 3.0836, 3.0698, 3.0561, 3.0424, 3.0286], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.2981, -0.3003, -0.3003, -0.3003, -0.3003, -0.3003, -0.3003, -0.3024, -0.3024, -0.3024, -0.3024, -0.3024,
0:         -0.3024, -0.3024, -0.3024, -0.3024, -0.3024, -0.3046, -0.1637, -0.1637, -0.1637, -0.1637, -0.1637, -0.1637,
0:         -0.1637], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241,
0:         -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2263, -0.2263, -0.2263, -0.2263, -0.2263, -0.2263,
0:         -0.2263], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 67, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan, -0.1893,     nan,     nan,     nan,     nan,     nan,     nan, -0.2249,     nan,
0:             nan, -0.2347,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 67, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.6904, 0.7090, 0.7213, 0.7283, 0.7307, 0.7363, 0.7392, 0.7430, 0.7479, 0.7537, 0.7614, 0.7703, 0.7803, 0.7919,
0:         0.8027, 0.8094, 0.8129, 0.8116, 0.5675, 0.5846, 0.5948, 0.6024, 0.6082, 0.6135, 0.6210], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([1.6955, 1.6994, 1.7032, 1.7043, 1.7033, 1.7044, 1.7077, 1.7111, 1.7165, 1.7200, 1.7204, 1.7200, 1.7174, 1.7150,
0:         1.7100, 1.7046, 1.7015, 1.7002, 1.7131, 1.7112, 1.7126, 1.7131, 1.7141, 1.7169, 1.7189], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.4292, -0.4265, -0.4223, -0.4195, -0.4182, -0.4171, -0.4188, -0.4196, -0.4198, -0.4188, -0.4183, -0.4158,
0:         -0.4151, -0.4143, -0.4138, -0.4133, -0.4109, -0.4082, -0.4491, -0.4445, -0.4405, -0.4370, -0.4349, -0.4334,
0:         -0.4336], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-1.8770, -1.8469, -1.7809, -1.7429, -1.7572, -1.7555, -1.7714, -1.8179, -1.8375, -1.8324, -1.8026, -1.7742,
0:         -1.7414, -1.7430, -1.7945, -1.8327, -1.8417, -1.8078, -2.1442, -2.0942, -2.0471, -2.0059, -2.0140, -2.0035,
0:         -2.0050], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([1.9176, 1.9273, 1.9391, 1.9533, 1.9710, 1.9907, 2.0116, 2.0302, 2.0459, 2.0599, 2.0724, 2.0851, 2.0986, 2.1109,
0:         2.1222, 2.1333, 2.1447, 2.1556, 2.1650, 2.1712, 2.1751, 2.1792, 2.1862, 2.1989, 2.2149], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([0.5806, 0.6098, 0.6244, 0.6150, 0.6000, 0.5646, 0.5157, 0.4542, 0.4072, 0.3067, 0.3250, 0.3332, 0.3141, 0.3099,
0:         0.2937, 0.2610, 0.2331, 0.2030, 0.0555, 0.0517, 0.0459, 0.0472, 0.0312, 0.0308, 0.0263], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0039, -0.0225,  0.0004,  0.0280, -0.0122,  0.0037,  0.0003,  0.0044,  0.0050,  0.0066,  0.0077, -0.0119,
0:         -0.0092,  0.0044, -0.0168, -0.0013, -0.0055, -0.0027, -0.0020,  0.0027,  0.0184,  0.0084,  0.0025, -0.0044,
0:          0.0019], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 67, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.7604, 1.7705, 1.7804, 1.7904, 1.8003, 1.8103, 1.8201, 1.8298, 1.8396, 1.8493, 1.8589, 1.8685, 1.8780, 1.8875,
1:         1.8970, 1.9065, 1.9158, 1.9252, 1.7502, 1.7603, 1.7704, 1.7803, 1.7902, 1.8000, 1.8100], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0547, -0.1590,  0.0401,  0.1365,  0.0709,  0.1277,  0.2011, -0.0260, -0.0528, -0.0221, -0.0851, -0.0886,
1:         -0.1469, -0.1229,  0.0239,  0.0030,  0.1994,  0.0158,  0.0090, -0.0124,  0.1029, -0.2532,  0.0423, -0.2533,
1:         -0.0514], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.7038, -0.7037, -0.7036, -0.7035, -0.7033, -0.7032, -0.7031, -0.7030, -0.7029, -0.7028, -0.7028, -0.7027,
1:         -0.7026, -0.7025, -0.7024, -0.7023, -0.7022, -0.7021, -0.6794, -0.6791, -0.6786, -0.6783, -0.6780, -0.6776,
1:         -0.6775], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.9369, 0.9383, 0.9400, 0.9414, 0.9432, 0.9448, 0.9463, 0.9477, 0.9494, 0.9508, 0.9525, 0.9539, 0.9554, 0.9569,
1:         0.9583, 0.9600, 0.9614, 0.9628, 0.9643, 0.9657, 0.9671, 0.9686, 0.9700, 0.9712, 0.9727], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241,
1:         -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2241, -0.2263, -0.2263, -0.2263, -0.2263, -0.2263, -0.2263,
1:         -0.2263], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 67, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.7921,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 67, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([2.2480, 2.2590, 2.2705, 2.2829, 2.2937, 2.3045, 2.3178, 2.3307, 2.3444, 2.3544, 2.3636, 2.3727, 2.3773, 2.3797,
1:         2.3823, 2.3849, 2.3863, 2.3860, 2.2155, 2.2257, 2.2353, 2.2442, 2.2537, 2.2619, 2.2736], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([2.4038, 2.4129, 2.4157, 2.4109, 2.3998, 2.3847, 2.3705, 2.3578, 2.3492, 2.3388, 2.3290, 2.3166, 2.2994, 2.2841,
1:         2.2686, 2.2554, 2.2416, 2.2290, 2.4002, 2.4100, 2.4127, 2.4101, 2.4037, 2.3962, 2.3880], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.2028, -0.2045, -0.2063, -0.2069, -0.2055, -0.2016, -0.1978, -0.1943, -0.1915, -0.1889, -0.1877, -0.1863,
1:         -0.1836, -0.1788, -0.1747, -0.1678, -0.1619, -0.1574, -0.1891, -0.1937, -0.1962, -0.1961, -0.1947, -0.1918,
1:         -0.1873], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-1.9288, -1.9340, -1.8929, -1.8574, -1.8402, -1.8047, -1.7459, -1.7154, -1.7018, -1.6685, -1.6435, -1.6378,
1:         -1.5950, -1.5274, -1.4717, -1.4238, -1.4270, -1.4182, -1.8331, -1.8497, -1.8278, -1.7785, -1.7407, -1.6917,
1:         -1.6296], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([1.4358, 1.4421, 1.4487, 1.4583, 1.4656, 1.4701, 1.4719, 1.4713, 1.4709, 1.4727, 1.4764, 1.4819, 1.4863, 1.4893,
1:         1.4914, 1.4918, 1.4933, 1.4946, 1.4960, 1.4979, 1.4991, 1.5019, 1.5040, 1.5056, 1.5105], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2298, -0.2288, -0.2249, -0.2227, -0.2229, -0.2202, -0.2209, -0.2171, -0.2136, -0.2360, -0.2349, -0.2303,
1:         -0.2276, -0.2275, -0.2264, -0.2229, -0.2228, -0.2174, -0.2359, -0.2356, -0.2326, -0.2299, -0.2273, -0.2268,
1:         -0.2250], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0005, -0.0096,  0.0140,  0.0109, -0.0051,  0.0102,  0.0006, -0.0019,  0.0175, -0.0008,  0.0121,  0.0005,
1:         -0.0171,  0.0076, -0.0092, -0.0142, -0.0043,  0.0103, -0.0050, -0.0163,  0.0065,  0.0213,  0.0195,  0.0022,
1:         -0.0008], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 67 [1/5 (20%)]	Loss: 0.23338 : 0.19732 :: 0.02137 (1.78 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 67 [2/5 (40%)]	Loss: 0.26935 : 0.20738 :: 0.02010 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 67 [3/5 (60%)]	Loss: 0.24173 : 0.19760 :: 0.02056 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 67 [4/5 (80%)]	Loss: 0.33910 : 0.24936 :: 0.02091 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 67 : 0.21154116094112396
0: validation loss for velocity_u : 0.00344604579731822
0: validation loss for velocity_v : 0.004991200752556324
0: validation loss for specific_humidity : 0.006603830493986607
0: validation loss for velocity_z : 0.10638678073883057
0: validation loss for temperature : 0.018739618360996246
0: validation loss for total_precip : 0.3155145049095154
0: validation loss for t2m : 1.0251059532165527
1: 68 : 07:05:21 :: batch_size = 96, lr = 1e-05
0: 68 : 07:05:21 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 68, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.5679, -1.5724, -1.5786, -1.5847, -1.5902, -1.5943, -1.5962, -1.5978, -1.5983, -1.5991, -1.5988, -1.5977,
0:         -1.5950, -1.5905, -1.5852, -1.5764, -1.5658, -1.5521, -1.5449, -1.5502, -1.5567, -1.5631, -1.5686, -1.5719,
0:         -1.5737], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0843, -0.0487, -0.0126,  0.0232,  0.0570,  0.0885,  0.1173,  0.1445,  0.1703,  0.1955,  0.2198,  0.2427,
0:          0.2649,  0.2852,  0.3038,  0.3207,  0.3347,  0.3478, -0.0800, -0.0428, -0.0064,  0.0289,  0.0631,  0.0946,
0:          0.1228], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.0459,  0.0914,  0.1080,  0.1335,  0.1147,  0.0781,  0.0138, -0.0305, -0.0195, -0.0793, -0.0616, -0.1070,
0:         -0.1170, -0.0959, -0.0915, -0.0283, -0.0317, -0.0062,  0.0238,  0.0592,  0.0714,  0.0792,  0.0559,  0.0082,
0:         -0.0571], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1804, -0.2050, -0.2463, -0.2463, -0.2463, -0.2463, -0.2451, -0.2440, -0.2318, -0.2139, -0.2318, -0.2463,
0:         -0.2463, -0.2463, -0.2451, -0.2094, -0.2105, -0.2217, -0.2340, -0.2451, -0.2463, -0.2463, -0.2396, -0.2351,
0:         -0.1581], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 68, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 68, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.4684, 0.4550, 0.4398, 0.4235, 0.4076, 0.3943, 0.3795, 0.3647, 0.3516, 0.3388, 0.3297, 0.3238, 0.3223, 0.3250,
0:         0.3280, 0.3299, 0.3299, 0.3260, 0.5253, 0.5176, 0.5042, 0.4902, 0.4760, 0.4614, 0.4478], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([ 0.0044,  0.0293,  0.0570,  0.0858,  0.1148,  0.1435,  0.1733,  0.2032,  0.2347,  0.2663,  0.2995,  0.3335,
0:          0.3701,  0.4091,  0.4481,  0.4884,  0.5245,  0.5577, -0.0022,  0.0230,  0.0530,  0.0859,  0.1192,  0.1521,
0:          0.1841], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.2776, -0.2740, -0.2725, -0.2701, -0.2651, -0.2563, -0.2445, -0.2286, -0.2089, -0.1885, -0.1750, -0.1757,
0:         -0.2027, -0.2617, -0.3475, -0.4571, -0.5742, -0.6775, -0.3006, -0.2947, -0.2919, -0.2839, -0.2765, -0.2655,
0:         -0.2526], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.3046, 0.3289, 0.3423, 0.3685, 0.3933, 0.4067, 0.4176, 0.4242, 0.4300, 0.4372, 0.4473, 0.4660, 0.4992, 0.5456,
0:         0.5956, 0.6524, 0.7121, 0.7391, 0.1149, 0.1354, 0.1587, 0.1891, 0.2238, 0.2570, 0.2927], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.8513, -0.8019, -0.7651, -0.7411, -0.7303, -0.7286, -0.7365, -0.7503, -0.7696, -0.7931, -0.8185, -0.8469,
0:         -0.8759, -0.9044, -0.9288, -0.9464, -0.9531, -0.9453, -0.9215, -0.8804, -0.8198, -0.7409, -0.6477, -0.5463,
0:         -0.4433], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1447, -0.1048, -0.0608, -0.0104,  0.0402,  0.0782,  0.0867,  0.0786,  0.0608, -0.1806, -0.1398, -0.0810,
0:         -0.0245,  0.0312,  0.0640,  0.0690,  0.0587,  0.0464, -0.1983, -0.1662, -0.1031, -0.0418,  0.0180,  0.0499,
0:          0.0568], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0218, -0.0183,  0.0034,  0.0091, -0.0003,  0.0190, -0.0153,  0.0158,  0.0074,  0.0153,  0.0283, -0.0028,
0:         -0.0062,  0.0050,  0.0109, -0.0163, -0.0120, -0.0120, -0.0065,  0.0126,  0.0154,  0.0032,  0.0132,  0.0122,
0:          0.0087], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 68, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.5679, -1.5724, -1.5786, -1.5847, -1.5902, -1.5943, -1.5962, -1.5978, -1.5983, -1.5991, -1.5988, -1.5977,
1:         -1.5950, -1.5905, -1.5852, -1.5764, -1.5658, -1.5521, -1.5449, -1.5502, -1.5567, -1.5631, -1.5686, -1.5719,
1:         -1.5737], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 8.3824e-02, -5.1817e-02, -4.6253e-02, -1.4688e-02,  9.2850e-02, -2.1728e-02,  5.1325e-02, -1.3442e-04,
1:          3.2820e-02, -1.1965e-01,  6.1388e-02, -2.7189e-02, -1.7632e-02, -1.0787e-01, -7.1030e-03, -1.5294e-01,
1:         -3.8785e-02, -2.1218e-03, -2.1319e-02,  8.4523e-03,  1.3124e-02, -1.5492e-01,  6.8903e-02, -9.8551e-02,
1:         -5.6177e-02], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.4640, -0.4704, -0.4788, -0.4865, -0.4911, -0.4944, -0.4978, -0.5009, -0.5049, -0.5089, -0.5131, -0.5166,
1:         -0.5205, -0.5245, -0.5275, -0.5300, -0.5303, -0.5310, -0.4704, -0.4801, -0.4888, -0.4950, -0.4978, -0.5003,
1:         -0.5014], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.4520, 0.5123, 0.5496, 0.5693, 0.5838, 0.5819, 0.5872, 0.5953, 0.6021, 0.6201, 0.6284, 0.6389, 0.6494, 0.6570,
1:         0.6716, 0.6757, 0.6839, 0.6903, 0.6926, 0.7075, 0.7168, 0.7354, 0.7560, 0.7715, 0.7974], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1804, -0.2050, -0.2463, -0.2463, -0.2463, -0.2463, -0.2451, -0.2440, -0.2318, -0.2139, -0.2318, -0.2463,
1:         -0.2463, -0.2463, -0.2451, -0.2094, -0.2105, -0.2217, -0.2340, -0.2451, -0.2463, -0.2463, -0.2396, -0.2351,
1:         -0.1581], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 68, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.2260,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.1029,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 68, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-1.1756, -1.1607, -1.1446, -1.1257, -1.1040, -1.0797, -1.0534, -1.0244, -0.9946, -0.9658, -0.9361, -0.9085,
1:         -0.8813, -0.8544, -0.8278, -0.7981, -0.7638, -0.7259, -1.1518, -1.1350, -1.1173, -1.0967, -1.0750, -1.0508,
1:         -1.0241], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-1.7543e-01, -1.3539e-01, -9.2661e-02, -4.8406e-02, -4.9758e-03,  3.7252e-02,  7.6309e-02,  1.1492e-01,
1:          1.5182e-01,  1.9047e-01,  2.2890e-01,  2.6758e-01,  3.0765e-01,  3.4561e-01,  3.8332e-01,  4.1922e-01,
1:          4.5432e-01,  4.8749e-01, -2.0617e-01, -1.6850e-01, -1.2642e-01, -8.4755e-02, -4.2665e-02,  2.7128e-04,
1:          4.1435e-02], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.4872, -0.4735, -0.4609, -0.4496, -0.4387, -0.4288, -0.4224, -0.4178, -0.4133, -0.4075, -0.3975, -0.3797,
1:         -0.3544, -0.3186, -0.2766, -0.2314, -0.1898, -0.1564, -0.4838, -0.4704, -0.4581, -0.4482, -0.4373, -0.4280,
1:         -0.4225], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.3047, -0.2871, -0.2876, -0.2696, -0.2884, -0.3096, -0.3369, -0.3659, -0.3577, -0.3798, -0.3678, -0.2644,
1:         -0.1312,  0.0840,  0.3231,  0.5146,  0.6905,  0.7362, -0.1488, -0.1367, -0.1469, -0.1357, -0.1632, -0.1586,
1:         -0.1544], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.4766, -0.5443, -0.5986, -0.6484, -0.7069, -0.7789, -0.8651, -0.9577, -1.0496, -1.1392, -1.2322, -1.3358,
1:         -1.4582, -1.5965, -1.7496, -1.9066, -2.0511, -2.1636, -2.2286, -2.2349, -2.1804, -2.0765, -1.9429, -1.8030,
1:         -1.6711], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2003, -0.2032, -0.2166, -0.2264, -0.2262, -0.2197, -0.2134, -0.1956, -0.1791, -0.2037, -0.2126, -0.2241,
1:         -0.2357, -0.2415, -0.2376, -0.2282, -0.2149, -0.1946, -0.2052, -0.2195, -0.2297, -0.2421, -0.2482, -0.2445,
1:         -0.2377], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 0.0215, -0.0143,  0.0080,  0.0051, -0.0088,  0.0248,  0.0022, -0.0043, -0.0049, -0.0035,  0.0202, -0.0098,
1:         -0.0009,  0.0207,  0.0066, -0.0096,  0.0097,  0.0099,  0.0053, -0.0092,  0.0170,  0.0190,  0.0171,  0.0102,
1:         -0.0022], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 68 [1/5 (20%)]	Loss: 0.28914 : 0.20578 :: 0.02124 (1.77 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 68 [2/5 (40%)]	Loss: 0.21282 : 0.15971 :: 0.02042 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 68 [3/5 (60%)]	Loss: 0.21920 : 0.18096 :: 0.02001 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 68 [4/5 (80%)]	Loss: 0.24936 : 0.19036 :: 0.02102 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 68 : 0.19887524843215942
0: validation loss for velocity_u : 0.003336789784952998
0: validation loss for velocity_v : 0.004541113041341305
0: validation loss for specific_humidity : 0.005971219390630722
0: validation loss for velocity_z : 0.09565480053424835
0: validation loss for temperature : 0.019764859229326248
0: validation loss for total_precip : 0.24584969878196716
0: validation loss for t2m : 1.0170084238052368
1: 69 : 07:11:36 :: batch_size = 96, lr = 1e-05
0: 69 : 07:11:36 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 69, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 69, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.9398, -1.9124, -1.8871, -1.8620, -1.8343, -1.8065, -1.7816, -1.7602, -1.7394, -1.7216, -1.7148, -1.7075,
1:         -1.6899, -1.6719, -1.6541, -1.6347, -1.6144, -1.5936, -1.8797, -1.8555, -1.8322, -1.8091, -1.7825, -1.7551,
1:         -1.7305], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0834,  0.0943,  0.0530,  0.1054, -0.0199,  0.1109,  0.0681, -0.0151, -0.1061, -0.0043, -0.0102, -0.1002,
1:          0.1044,  0.0821, -0.1408,  0.0599,  0.0270,  0.1149, -0.1646,  0.0362, -0.1831,  0.1266, -0.0516,  0.0384,
1:         -0.0366], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.4118, -0.3934, -0.3846, -0.3854, -0.3979, -0.4380, -0.4559, -0.4843, -0.4925, -0.4935, -0.4870, -0.4767,
1:         -0.4645, -0.4501, -0.4341, -0.4167, -0.4024, -0.3895, -0.5212, -0.5155, -0.5142, -0.5173, -0.5269, -0.5317,
1:         -0.5491], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.4329, -0.5092, -0.5465, -0.5554, -0.5168, -0.4339, -0.3193, -0.1905, -0.1055, -0.0935, -0.1246, -0.1919,
1:         -0.2669, -0.3296, -0.4007, -0.4761, -0.5468, -0.6049, -0.6515, -0.6822, -0.6963, -0.6988, -0.7057, -0.7158,
1:         -0.7343], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2505, -0.2319, -0.2075, -0.1159, -0.0358, -0.0404, -0.1333, -0.0694,  0.0118, -0.1878, -0.1507, -0.1414,
1:         -0.0857, -0.0056, -0.0068, -0.0950, -0.1240, -0.0915, -0.0903, -0.0126, -0.0486, -0.0451, -0.0555, -0.0555,
1:         -0.0555], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 69, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan, -0.1780,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,  0.8205,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 69, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-1.1436, -1.1201, -1.0875, -1.0518, -1.0129, -0.9685, -0.9184, -0.8625, -0.8027, -0.7445, -0.6858, -0.6297,
1:         -0.5755, -0.5237, -0.4781, -0.4414, -0.4194, -0.4127, -1.0620, -1.0322, -0.9929, -0.9500, -0.9039, -0.8535,
1:         -0.7953], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.0896, -0.0958, -0.0995, -0.0970, -0.0955, -0.0964, -0.1023, -0.1142, -0.1329, -0.1533, -0.1669, -0.1734,
1:         -0.1721, -0.1619, -0.1466, -0.1259, -0.1024, -0.0741, -0.0991, -0.1031, -0.1044, -0.1035, -0.1022, -0.1036,
1:         -0.1091], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([2.3432, 2.3349, 2.3274, 2.3174, 2.2994, 2.2732, 2.2326, 2.1653, 2.0775, 1.9872, 1.9154, 1.8768, 1.8982, 1.9855,
1:         2.1131, 2.2763, 2.4275, 2.5375, 2.2861, 2.3148, 2.3559, 2.3881, 2.4097, 2.3989, 2.3514], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.6525,  0.6122,  0.5235,  0.6102,  0.7032,  0.6792,  0.6310,  0.5829,  0.5268,  0.4733,  0.3750,  0.3090,
1:          0.3721,  0.3726,  0.1318, -0.2356, -0.7834, -1.3444,  0.5495,  0.5068,  0.4463,  0.5541,  0.6484,  0.6366,
1:          0.6295], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([ 0.8057,  0.8312,  0.8728,  0.9339,  1.0156,  1.0988,  1.1526,  1.1498,  1.0840,  0.9567,  0.7812,  0.5696,
1:          0.3391,  0.1066, -0.0913, -0.2262, -0.2680, -0.2214, -0.1048,  0.0529,  0.2296,  0.4189,  0.6111,  0.7976,
1:          0.9673], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2577, -0.2556, -0.2533, -0.2541, -0.2457, -0.2408, -0.2392, -0.2360, -0.2339, -0.2613, -0.2587, -0.2594,
1:         -0.2564, -0.2545, -0.2541, -0.2491, -0.2534, -0.2474, -0.2653, -0.2627, -0.2590, -0.2592, -0.2578, -0.2574,
1:         -0.2604], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 1.5807e-02, -1.3606e-02, -1.2573e-02, -3.4525e-03, -9.8939e-03,  1.2825e-02, -7.6435e-03, -7.3919e-05,
1:          2.6110e-03,  1.1706e-03,  5.8655e-03,  5.8220e-03, -1.3842e-02,  1.4459e-02,  1.2587e-02, -1.3701e-02,
1:          3.5713e-03,  5.4106e-03, -1.4776e-03, -4.3547e-03,  2.9666e-03,  1.7254e-02,  7.6819e-03, -1.3928e-02,
1:         -1.2029e-03], device='cuda:0', grad_fn=<SliceBackward0>)
0:      first 25 values: tensor([-1.9398, -1.9124, -1.8871, -1.8620, -1.8343, -1.8065, -1.7816, -1.7602, -1.7394, -1.7216, -1.7148, -1.7075,
0:         -1.6899, -1.6719, -1.6541, -1.6347, -1.6144, -1.5936, -1.8797, -1.8555, -1.8322, -1.8091, -1.7825, -1.7551,
0:         -1.7305], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1387, -0.1469, -0.1519, -0.1523, -0.1512, -0.1478, -0.1413, -0.1340, -0.1344, -0.1441, -0.1525, -0.1603,
0:         -0.1694, -0.1756, -0.1804, -0.1843, -0.1869, -0.1912, -0.1471, -0.1607, -0.1685, -0.1687, -0.1635, -0.1547,
0:         -0.1445], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.2096,  0.1164,  0.0331,  0.0220, -0.0701,  0.0309,  0.0265,  0.0120,  0.2395,  0.2118,  0.2273,  0.4093,
0:          0.4360,  0.4837,  0.5303,  0.5136,  0.5569,  0.5425,  0.4271,  0.3472,  0.3361,  0.3194,  0.2307,  0.2950,
0:          0.2029], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2505, -0.2319, -0.2075, -0.1159, -0.0358, -0.0404, -0.1333, -0.0694,  0.0118, -0.1878, -0.1507, -0.1414,
0:         -0.0857, -0.0056, -0.0068, -0.0950, -0.1240, -0.0915, -0.0903, -0.0126, -0.0486, -0.0451, -0.0555, -0.0555,
0:         -0.0555], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 69, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.7126, 0.7296,    nan,    nan,    nan,    nan,
0:            nan,    nan, 0.7610,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 69, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-1.1339, -1.1401, -1.1459, -1.1499, -1.1583, -1.1725, -1.1913, -1.2152, -1.2367, -1.2535, -1.2634, -1.2645,
0:         -1.2618, -1.2541, -1.2463, -1.2438, -1.2471, -1.2568, -1.1399, -1.1476, -1.1561, -1.1629, -1.1728, -1.1892,
0:         -1.2089], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.2791, -0.2833, -0.2831, -0.2780, -0.2647, -0.2431, -0.2151, -0.1788, -0.1339, -0.0819, -0.0247,  0.0372,
0:          0.1003,  0.1625,  0.2220,  0.2820,  0.3358,  0.3868, -0.2980, -0.2991, -0.2928, -0.2805, -0.2581, -0.2286,
0:         -0.1908], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([2.8419, 2.6402, 2.3822, 2.1130, 1.8606, 1.6597, 1.5229, 1.4514, 1.4304, 1.4314, 1.4341, 1.4397, 1.4391, 1.4323,
0:         1.4070, 1.3578, 1.2871, 1.1991, 2.8258, 2.6283, 2.3708, 2.0973, 1.8385, 1.6392, 1.5170], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.1915, -0.1680, -0.1353, -0.0991, -0.0680, -0.0617, -0.0453, -0.0128, -0.0252, -0.0501, -0.0460, -0.0523,
0:         -0.1022, -0.1524, -0.1906, -0.2484, -0.2905, -0.3299, -0.1482, -0.1099, -0.0686, -0.0578, -0.0614, -0.0550,
0:         -0.0401], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([ 1.1805,  0.9529,  0.7243,  0.5140,  0.3174,  0.1416, -0.0151, -0.1308, -0.1935, -0.2072, -0.1908, -0.1689,
0:         -0.1544, -0.1526, -0.1296, -0.0727,  0.0284,  0.1556,  0.2771,  0.3530,  0.3471,  0.2533,  0.0625, -0.2051,
0:         -0.5071], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2134, -0.1516, -0.1070, -0.0722, -0.0571, -0.0566, -0.0717, -0.0745, -0.0713, -0.2526, -0.2086, -0.1593,
0:         -0.1199, -0.1131, -0.0998, -0.1331, -0.1454, -0.1285, -0.2520, -0.2172, -0.1772, -0.1584, -0.1438, -0.1500,
0:         -0.1754], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 6.4668e-03, -2.1537e-02, -1.2456e-02, -3.0964e-03, -1.7672e-03, -1.0560e-03, -2.1813e-03,  5.9010e-03,
0:         -4.4344e-03,  1.0334e-05,  1.1071e-02, -4.9226e-03, -2.1165e-02,  7.9988e-03,  4.3241e-03, -2.3592e-02,
0:         -1.2599e-03, -8.0807e-04, -3.0156e-03,  1.5104e-02,  1.5710e-02,  4.4205e-04, -2.7930e-03, -1.4103e-03,
0:          1.5680e-03], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 69 [1/5 (20%)]	Loss: 0.27278 : 0.19773 :: 0.02185 (1.89 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 69 [2/5 (40%)]	Loss: 0.28285 : 0.21855 :: 0.02143 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 69 [3/5 (60%)]	Loss: 0.27469 : 0.20829 :: 0.02101 (8.49 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 69 [4/5 (80%)]	Loss: 0.27152 : 0.22666 :: 0.01939 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 69 : 0.19940310716629028
0: validation loss for velocity_u : 0.0034725565928965807
0: validation loss for velocity_v : 0.004790583625435829
0: validation loss for specific_humidity : 0.0055138953030109406
0: validation loss for velocity_z : 0.10135851055383682
0: validation loss for temperature : 0.01782558485865593
0: validation loss for total_precip : 0.2855522632598877
0: validation loss for t2m : 0.9773087501525879
1: 70 : 07:17:42 :: batch_size = 96, lr = 1e-05
0: 70 : 07:17:42 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 70, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.3997, -0.4150, -0.4301, -0.4451, -0.4600, -0.4747, -0.4893, -0.5036, -0.5178, -0.5317, -0.5454, -0.5587,
1:         -0.5719, -0.5848, -0.5973, -0.6095, -0.6213, -0.6327, -0.2813, -0.2957, -0.3101, -0.3244, -0.3386, -0.3527,
1:         -0.3667], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0394,  0.0282, -0.1055, -0.0193,  0.0166, -0.0670,  0.0166, -0.0271, -0.0880,  0.1279, -0.0483, -0.0045,
1:          0.0554,  0.0852, -0.0331,  0.1606, -0.1336, -0.0476,  0.0077, -0.0303,  0.0498,  0.0469, -0.1034,  0.0409,
1:         -0.1350], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.6696, -0.6699, -0.6701, -0.6704, -0.6706, -0.6709, -0.6712, -0.6711, -0.6710, -0.6709, -0.6708, -0.6707,
1:         -0.6706, -0.6703, -0.6701, -0.6698, -0.6693, -0.6689, -0.6701, -0.6705, -0.6708, -0.6710, -0.6713, -0.6716,
1:         -0.6720], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., -0., -0., 0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.0880, -1.0944, -1.1007, -1.1070, -1.1131, -1.1190, -1.1248, -1.1305, -1.1363, -1.1418, -1.1474, -1.1529,
1:         -1.1583, -1.1636, -1.1690, -1.1742, -1.1792, -1.1844, -1.1896, -1.1946, -1.1995, -1.2043, -1.2091, -1.2137,
1:         -1.2183], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.1892, -0.1868, -0.1845, -0.1810, -0.1787, -0.1751, -0.1716, -0.1646, -0.1565, -0.1833, -0.1810, -0.1775,
1:         -0.1751, -0.1716, -0.1681, -0.1646, -0.1611, -0.1565, -0.1751, -0.1728, -0.1705, -0.1681, -0.1658, -0.1635,
1:         -0.1588], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 70, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.7697,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 70, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.8503, -0.8583, -0.8645, -0.8708, -0.8805, -0.8912, -0.9009, -0.9098, -0.9158, -0.9227, -0.9279, -0.9320,
1:         -0.9378, -0.9424, -0.9423, -0.9398, -0.9364, -0.9290, -0.7239, -0.7302, -0.7348, -0.7397, -0.7452, -0.7540,
1:         -0.7629], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.7008, -0.6869, -0.6769, -0.6682, -0.6605, -0.6533, -0.6446, -0.6366, -0.6274, -0.6198, -0.6116, -0.6028,
1:         -0.5941, -0.5845, -0.5711, -0.5556, -0.5389, -0.5177, -0.6518, -0.6400, -0.6326, -0.6243, -0.6166, -0.6084,
1:         -0.5977], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6407, -0.6462, -0.6484, -0.6499, -0.6516, -0.6504, -0.6508, -0.6492, -0.6449, -0.6411, -0.6356, -0.6287,
1:         -0.6216, -0.6139, -0.6056, -0.5919, -0.5745, -0.5550, -0.6260, -0.6299, -0.6322, -0.6352, -0.6349, -0.6334,
1:         -0.6302], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([0.2947, 0.3308, 0.3441, 0.3726, 0.4042, 0.4404, 0.4588, 0.4809, 0.5078, 0.5138, 0.5201, 0.5129, 0.4995, 0.4890,
1:         0.4824, 0.4715, 0.4439, 0.4037, 0.1563, 0.1956, 0.2108, 0.2628, 0.3227, 0.3839, 0.4183], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.7901, -0.7910, -0.7911, -0.7895, -0.7881, -0.7848, -0.7806, -0.7733, -0.7669, -0.7614, -0.7577, -0.7548,
1:         -0.7515, -0.7488, -0.7463, -0.7463, -0.7483, -0.7521, -0.7563, -0.7591, -0.7605, -0.7616, -0.7643, -0.7684,
1:         -0.7728], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([ 0.0185,  0.0284,  0.0313,  0.0259,  0.0232,  0.0083, -0.0146, -0.0335, -0.0491,  0.0266,  0.0293,  0.0253,
1:          0.0212,  0.0122, -0.0097, -0.0234, -0.0411, -0.0606,  0.0163,  0.0184,  0.0051, -0.0051, -0.0142, -0.0332,
1:         -0.0401], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0102, -0.0223, -0.0235, -0.0088, -0.0243,  0.0047, -0.0169, -0.0174, -0.0126, -0.0144, -0.0122,  0.0022,
1:         -0.0126, -0.0060,  0.0026, -0.0217,  0.0028, -0.0022, -0.0049,  0.0002, -0.0104,  0.0032,  0.0126, -0.0180,
1:         -0.0097], device='cuda:0', grad_fn=<SliceBackward0>)
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 70, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.3997, -0.4150, -0.4301, -0.4451, -0.4600, -0.4747, -0.4893, -0.5036, -0.5178, -0.5317, -0.5454, -0.5587,
0:         -0.5719, -0.5848, -0.5973, -0.6095, -0.6213, -0.6327, -0.2813, -0.2957, -0.3101, -0.3244, -0.3386, -0.3527,
0:         -0.3667], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-2.2881, -2.2677, -2.2468, -2.2260, -2.2047, -2.1832, -2.1615, -2.1395, -2.1174, -2.0948, -2.0721, -2.0491,
0:         -2.0259, -2.0022, -1.9786, -1.9546, -1.9303, -1.9056, -2.3492, -2.3281, -2.3071, -2.2858, -2.2641, -2.2424,
0:         -2.2204], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.0614,  0.0603,  0.0592,  0.0592,  0.0592,  0.0580,  0.0580,  0.0558,  0.0535,  0.0501,  0.0445,  0.0388,
0:          0.0309,  0.0230,  0.0139,  0.0037, -0.0064, -0.0166, -0.0076, -0.0087, -0.0087, -0.0064, -0.0042, -0.0019,
0:         -0.0008], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1892, -0.1868, -0.1845, -0.1810, -0.1787, -0.1751, -0.1716, -0.1646, -0.1565, -0.1833, -0.1810, -0.1775,
0:         -0.1751, -0.1716, -0.1681, -0.1646, -0.1611, -0.1565, -0.1751, -0.1728, -0.1705, -0.1681, -0.1658, -0.1635,
0:         -0.1588], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 70, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
0:            nan, 0.0486,    nan,    nan,    nan,    nan, 0.1067,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 70, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.9246, 0.9362, 0.9448, 0.9533, 0.9584, 0.9660, 0.9757, 0.9878, 1.0017, 1.0148, 1.0253, 1.0324, 1.0357, 1.0392,
0:         1.0481, 1.0594, 1.0750, 1.0911, 1.0503, 1.0616, 1.0720, 1.0807, 1.0906, 1.0980, 1.1066], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-1.6589, -1.6654, -1.6684, -1.6729, -1.6744, -1.6808, -1.6862, -1.6920, -1.6939, -1.6978, -1.6996, -1.7021,
0:         -1.7081, -1.7112, -1.7158, -1.7183, -1.7234, -1.7252, -1.6873, -1.6917, -1.6958, -1.6981, -1.7002, -1.7038,
0:         -1.7099], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6557, -0.6598, -0.6626, -0.6618, -0.6589, -0.6557, -0.6517, -0.6472, -0.6419, -0.6366, -0.6318, -0.6265,
0:         -0.6198, -0.6138, -0.6065, -0.5982, -0.5907, -0.5842, -0.6644, -0.6675, -0.6700, -0.6690, -0.6673, -0.6643,
0:         -0.6617], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.6269, 0.6198, 0.5949, 0.5791, 0.5824, 0.5673, 0.5560, 0.5301, 0.4936, 0.4722, 0.4500, 0.4406, 0.4446, 0.4445,
0:         0.4252, 0.3909, 0.3671, 0.3484, 0.6817, 0.6755, 0.6494, 0.6270, 0.6341, 0.6177, 0.6066], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.8878, -0.8882, -0.8905, -0.8956, -0.9019, -0.9081, -0.9131, -0.9156, -0.9158, -0.9158, -0.9193, -0.9237,
0:         -0.9272, -0.9284, -0.9274, -0.9225, -0.9187, -0.9155, -0.9134, -0.9120, -0.9094, -0.9069, -0.9043, -0.9006,
0:         -0.8988], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1911, -0.1869, -0.1881, -0.1820, -0.1715, -0.1678, -0.1667, -0.1626, -0.1570, -0.1715, -0.1714, -0.1682,
0:         -0.1639, -0.1586, -0.1556, -0.1537, -0.1558, -0.1517, -0.1486, -0.1428, -0.1397, -0.1375, -0.1387, -0.1393,
0:         -0.1343], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0108, -0.0214, -0.0137, -0.0159, -0.0298,  0.0069, -0.0283, -0.0352, -0.0085,  0.0048,  0.0079, -0.0149,
0:         -0.0213, -0.0123, -0.0043, -0.0220, -0.0196, -0.0139, -0.0220,  0.0071, -0.0034, -0.0070, -0.0036, -0.0323,
0:         -0.0145], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 70 [1/5 (20%)]	Loss: 0.24135 : 0.17642 :: 0.02198 (1.61 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 70 [2/5 (40%)]	Loss: 0.27339 : 0.20622 :: 0.02091 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 70 [3/5 (60%)]	Loss: 0.28397 : 0.22990 :: 0.02079 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 70 [4/5 (80%)]	Loss: 0.28759 : 0.21599 :: 0.02005 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 70 : 0.21163398027420044
0: validation loss for velocity_u : 0.0035142493434250355
0: validation loss for velocity_v : 0.004958835430443287
0: validation loss for specific_humidity : 0.006384359672665596
0: validation loss for velocity_z : 0.1117425337433815
0: validation loss for temperature : 0.020654786378145218
0: validation loss for total_precip : 0.33533066511154175
0: validation loss for t2m : 0.9988526105880737
1: 71 : 07:24:05 :: batch_size = 96, lr = 1e-05
0: 71 : 07:24:05 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 71, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.4956, 0.4966, 0.4975, 0.4985, 0.4993, 0.5003, 0.5011, 0.5019, 0.5026, 0.5034, 0.5040, 0.5047, 0.5055, 0.5061,
1:         0.5068, 0.5074, 0.5081, 0.5087, 0.4357, 0.4375, 0.4392, 0.4410, 0.4428, 0.4446, 0.4464], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0384, -0.1078,  0.1002,  0.1761,  0.0333,  0.1014, -0.0126,  0.0146, -0.0147, -0.0648, -0.1011,  0.0333,
1:         -0.0772,  0.0244,  0.0472,  0.1193, -0.0148, -0.0745,  0.0490,  0.0756,  0.0603,  0.0823, -0.1559,  0.0379,
1:         -0.0699], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.2582, -0.2587, -0.2592, -0.2597, -0.2602, -0.2608, -0.2615, -0.2621, -0.2627, -0.2633, -0.2639, -0.2646,
1:         -0.2654, -0.2657, -0.2654, -0.2652, -0.2648, -0.2645, -0.2316, -0.2321, -0.2326, -0.2332, -0.2337, -0.2346,
1:         -0.2354], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., -0., -0., 0., 0., 0., 0., 0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.4062, 0.4044, 0.4025, 0.4002, 0.3982, 0.3958, 0.3935, 0.3910, 0.3882, 0.3855, 0.3825, 0.3791, 0.3760, 0.3726,
1:         0.3688, 0.3651, 0.3611, 0.3571, 0.3529, 0.3486, 0.3445, 0.3402, 0.3359, 0.3317, 0.3277], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([ 0.1893,  0.1871,  0.1837,  0.1803,  0.1780,  0.1780,  0.1792,  0.1792,  0.1803,  0.0459,  0.0471,  0.0482,
1:          0.0505,  0.0493,  0.0493,  0.0482,  0.0482,  0.0471, -0.0658, -0.0670, -0.0670, -0.0670, -0.0670, -0.0658,
1:         -0.0658], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 71, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan, -1.6197,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan, -1.4555,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 71, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.5040, 0.5079, 0.5102, 0.5132, 0.5157, 0.5186, 0.5215, 0.5277, 0.5312, 0.5351, 0.5350, 0.5354, 0.5339, 0.5325,
1:         0.5331, 0.5309, 0.5277, 0.5238, 0.4473, 0.4493, 0.4532, 0.4575, 0.4616, 0.4669, 0.4714], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-1.0611, -1.0397, -1.0151, -0.9883, -0.9607, -0.9344, -0.9053, -0.8776, -0.8458, -0.8141, -0.7786, -0.7393,
1:         -0.6978, -0.6559, -0.6124, -0.5706, -0.5291, -0.4849, -1.1604, -1.1453, -1.1289, -1.1084, -1.0854, -1.0596,
1:         -1.0319], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.2672, -0.2856, -0.3001, -0.3062, -0.3089, -0.3067, -0.3013, -0.2902, -0.2737, -0.2534, -0.2344, -0.2181,
1:         -0.2044, -0.1863, -0.1701, -0.1531, -0.1347, -0.1196, -0.2381, -0.2559, -0.2674, -0.2765, -0.2855, -0.2947,
1:         -0.2975], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.0976,  0.1197,  0.1065,  0.0709,  0.0391,  0.0079, -0.0173, -0.0108,  0.0047,  0.0081,  0.0161,  0.0270,
1:          0.0042, -0.0365, -0.0728, -0.1131, -0.1503, -0.1703,  0.1274,  0.1341,  0.1179,  0.0966,  0.0765,  0.0657,
1:          0.0629], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.5821, 0.5636, 0.5470, 0.5341, 0.5245, 0.5181, 0.5113, 0.5048, 0.4972, 0.4891, 0.4804, 0.4734, 0.4663, 0.4582,
1:         0.4475, 0.4352, 0.4218, 0.4084, 0.3961, 0.3852, 0.3750, 0.3646, 0.3521, 0.3392, 0.3272], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.1854, -0.1857, -0.1822, -0.1854, -0.1870, -0.1938, -0.2017, -0.2027, -0.1994, -0.1898, -0.1927, -0.1952,
1:         -0.1981, -0.2029, -0.2095, -0.2086, -0.2122, -0.2008, -0.1811, -0.1880, -0.2016, -0.2053, -0.2088, -0.2090,
1:         -0.2060], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0118, -0.0327, -0.0345, -0.0263, -0.0413,  0.0010, -0.0186, -0.0323, -0.0390, -0.0111, -0.0107, -0.0349,
1:         -0.0163, -0.0193, -0.0087, -0.0166,  0.0015, -0.0096, -0.0148, -0.0208, -0.0265, -0.0004, -0.0029, -0.0394,
1:         -0.0343], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 71, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.8134, -0.8024, -0.7916, -0.7895, -0.7905, -0.7932, -0.7903, -0.7819, -0.7742, -0.7665, -0.7648, -0.7683,
0:         -0.7750, -0.7762, -0.7709, -0.7673, -0.7690, -0.7715, -0.7997, -0.7906, -0.7821, -0.7811, -0.7859, -0.7891,
0:         -0.7863], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.3433, -0.3521, -0.3552, -0.3587, -0.3601, -0.3573, -0.3540, -0.3478, -0.3405, -0.3290, -0.3178, -0.3141,
0:         -0.3155, -0.3188, -0.3204, -0.3223, -0.3233, -0.3227, -0.3747, -0.3847, -0.3888, -0.3931, -0.3970, -0.3974,
0:         -0.3984], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.4131, -0.4761, -0.4435, -0.3968, -0.3414, -0.3175, -0.3316, -0.2719, -0.1752, -0.0796, -0.0068,  0.0269,
0:         -0.0263, -0.0459, -0.0383,  0.0062,  0.0823,  0.1486, -0.4185, -0.4185, -0.3860, -0.3501, -0.2730, -0.2556,
0:         -0.2404], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2338, -0.2338, -0.2281, -0.2122, -0.2122, -0.2258, -0.2134, -0.1963, -0.1657, -0.2395, -0.2383, -0.2054,
0:         -0.2054, -0.1997, -0.2281, -0.1850, -0.1010, -0.0840, -0.2395, -0.2315, -0.1907, -0.2043, -0.2088, -0.2077,
0:         -0.1805], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 71, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([ 0.7906,  0.6702,  0.4750,     nan,     nan,     nan,     nan,  0.2311,     nan,     nan,     nan,     nan,
0:         -0.1850,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.0523,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 71, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.7472, -0.7525, -0.7557, -0.7591, -0.7641, -0.7692, -0.7760, -0.7832, -0.7904, -0.7992, -0.8075, -0.8182,
0:         -0.8318, -0.8483, -0.8690, -0.8949, -0.9214, -0.9462, -0.8017, -0.8114, -0.8192, -0.8249, -0.8290, -0.8341,
0:         -0.8395], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.2176, 0.2473, 0.2792, 0.3149, 0.3497, 0.3845, 0.4186, 0.4494, 0.4763, 0.5005, 0.5193, 0.5331, 0.5451, 0.5575,
0:         0.5712, 0.5858, 0.6000, 0.6106, 0.2231, 0.2507, 0.2830, 0.3184, 0.3534, 0.3885, 0.4225], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.5390, -0.5469, -0.5527, -0.5575, -0.5634, -0.5723, -0.5876, -0.6058, -0.6263, -0.6447, -0.6596, -0.6670,
0:         -0.6679, -0.6638, -0.6561, -0.6450, -0.6318, -0.6211, -0.5393, -0.5429, -0.5450, -0.5444, -0.5485, -0.5562,
0:         -0.5725], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.5533, 0.5527, 0.5434, 0.5472, 0.5484, 0.5272, 0.4836, 0.4396, 0.4105, 0.3871, 0.3559, 0.3464, 0.3281, 0.3020,
0:         0.2935, 0.2778, 0.2329, 0.1182, 0.6493, 0.6176, 0.5969, 0.5935, 0.5886, 0.5835, 0.5636], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.3119, 0.3305, 0.3601, 0.3977, 0.4415, 0.4865, 0.5269, 0.5606, 0.5875, 0.6113, 0.6349, 0.6560, 0.6744, 0.6895,
0:         0.7019, 0.7168, 0.7357, 0.7549, 0.7706, 0.7789, 0.7801, 0.7802, 0.7823, 0.7893, 0.7984], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2661, -0.2549, -0.2372, -0.2113, -0.2003, -0.2036, -0.2108, -0.2217, -0.2197, -0.2567, -0.2490, -0.2139,
0:         -0.1952, -0.1794, -0.1726, -0.1828, -0.1986, -0.2068, -0.2488, -0.2276, -0.2048, -0.1797, -0.1640, -0.1632,
0:         -0.1663], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0149, -0.0432, -0.0351, -0.0247, -0.0388, -0.0123, -0.0302, -0.0208, -0.0343, -0.0054, -0.0062, -0.0187,
0:         -0.0174, -0.0249, -0.0049, -0.0261, -0.0133, -0.0296, -0.0306, -0.0087, -0.0161, -0.0241, -0.0214, -0.0337,
0:         -0.0262], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 71 [1/5 (20%)]	Loss: 0.24836 : 0.18136 :: 0.02081 (1.60 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 71 [2/5 (40%)]	Loss: 0.24391 : 0.19018 :: 0.02030 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 71 [3/5 (60%)]	Loss: 0.26209 : 0.18634 :: 0.02200 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 71 [4/5 (80%)]	Loss: 0.31652 : 0.23399 :: 0.02195 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 71 : 0.195002019405365
0: validation loss for velocity_u : 0.003677518106997013
0: validation loss for velocity_v : 0.005166437476873398
0: validation loss for specific_humidity : 0.005583116784691811
0: validation loss for velocity_z : 0.10811430960893631
0: validation loss for temperature : 0.016528895124793053
0: validation loss for total_precip : 0.22452902793884277
0: validation loss for t2m : 1.0014147758483887
1: 72 : 07:30:16 :: batch_size = 96, lr = 1e-05
0: 72 : 07:30:16 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 72, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.1615, -1.2092, -1.1969, -1.2146, -1.2141, -1.2018, -1.1854, -1.1428, -1.1231, -1.1207, -1.0857, -1.0484,
1:         -1.0712, -1.0762, -1.0629, -1.0655, -1.0676, -1.1017, -1.1976, -1.2238, -1.2152, -1.2164, -1.1856, -1.1630,
1:         -1.1374], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0555,  0.0295,  0.1570, -0.0644,  0.0553,  0.1458, -0.0407, -0.1098,  0.0183,  0.0163, -0.1400,  0.1104,
1:          0.1385,  0.0126,  0.0168, -0.0459,  0.1603, -0.1030,  0.0208,  0.0755,  0.0926, -0.0490,  0.0304,  0.0631,
1:          0.0078], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([3.3601, 2.9208, 2.5830, 2.3572, 2.1250, 1.9781, 2.1054, 2.7440, 1.4483, 1.2253, 1.1172, 1.0842, 1.1108, 1.2257,
1:         1.2503, 1.0705, 1.0616, 1.5387, 2.9234, 2.7709, 2.6787, 2.5152, 2.3737, 2.2585, 2.1961], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([ 0.7048,  0.9172,  1.1787,  1.3858,  1.5481,  1.6022,  1.3049,  1.0570,  1.2046,  1.3115,  1.4303,  1.8437,
1:          1.9708,  1.9032,  1.9948,  2.1030,  2.2834,  1.7717,  0.9211,  1.4543,  1.7714,  0.5311, -0.1191,  0.2264,
1:          0.4676], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([ 2.8356,  0.5261,  3.0162,  3.1423,  0.5522,  1.4308,  3.2510,  6.0695,  0.5130,  1.3481,  3.9035,  2.9727,
1:          0.8827,  1.8113,  4.9713,  8.5248, 14.6033,  5.7281,  4.0774,  5.2888,  3.7316,  0.4130,  1.4742,  2.1093,
1:          3.2641], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 72, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan, 0.8908,    nan, 1.0013,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan, 1.9957,    nan,    nan,    nan,    nan,    nan, 1.7476,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 72, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([-0.9367, -0.9477, -0.9654, -0.9878, -1.0155, -1.0475, -1.0777, -1.1067, -1.1302, -1.1498, -1.1646, -1.1729,
1:         -1.1743, -1.1711, -1.1630, -1.1542, -1.1503, -1.1513, -0.9221, -0.9313, -0.9467, -0.9687, -0.9988, -1.0319,
1:         -1.0667], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.0165, -0.0187, -0.0228, -0.0275, -0.0287, -0.0261, -0.0205, -0.0119,  0.0020,  0.0177,  0.0370,  0.0591,
1:          0.0801,  0.1016,  0.1201,  0.1361,  0.1494,  0.1628, -0.0566, -0.0584, -0.0596, -0.0589, -0.0546, -0.0484,
1:         -0.0395], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.7538, -0.7496, -0.7437, -0.7374, -0.7317, -0.7279, -0.7241, -0.7207, -0.7158, -0.7100, -0.7020, -0.6938,
1:         -0.6837, -0.6722, -0.6599, -0.6466, -0.6341, -0.6241, -0.7549, -0.7507, -0.7472, -0.7419, -0.7382, -0.7340,
1:         -0.7308], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-0.1318, -0.1531, -0.1840, -0.1005, -0.0207,  0.0293, -0.0076, -0.0916,  0.0094,  0.1292,  0.0653, -0.0196,
1:         -0.0454, -0.0244, -0.0750, -0.1695, -0.1816, -0.2203, -0.1692, -0.1214, -0.1419, -0.0874,  0.0113,  0.0792,
1:          0.0602], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.9806, -1.0363, -1.0859, -1.1095, -1.1018, -1.0714, -1.0436, -1.0367, -1.0600, -1.1087, -1.1686, -1.2268,
1:         -1.2721, -1.2999, -1.3103, -1.3119, -1.3141, -1.3258, -1.3483, -1.3799, -1.4151, -1.4488, -1.4783, -1.4947,
1:         -1.4938], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2366, -0.2365, -0.2397, -0.2413, -0.2457, -0.2478, -0.2510, -0.2537, -0.2512, -0.2305, -0.2323, -0.2361,
1:         -0.2399, -0.2426, -0.2472, -0.2497, -0.2500, -0.2544, -0.2236, -0.2286, -0.2337, -0.2374, -0.2414, -0.2426,
1:         -0.2473], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0063, -0.0190, -0.0162, -0.0185, -0.0326, -0.0014, -0.0052, -0.0333, -0.0323, -0.0182, -0.0020, -0.0136,
1:         -0.0059, -0.0149, -0.0052, -0.0171,  0.0043, -0.0002, -0.0202, -0.0178, -0.0359, -0.0011, -0.0041, -0.0263,
1:         -0.0284], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 72, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-1.1615, -1.2092, -1.1969, -1.2146, -1.2141, -1.2018, -1.1854, -1.1428, -1.1231, -1.1207, -1.0857, -1.0484,
0:         -1.0712, -1.0762, -1.0629, -1.0655, -1.0676, -1.1017, -1.1976, -1.2238, -1.2152, -1.2164, -1.1856, -1.1630,
0:         -1.1374], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.0089,  0.0079,  0.0027,  0.0117,  0.0019, -0.0280, -0.0457, -0.0768, -0.1298, -0.1425, -0.1371, -0.1474,
0:         -0.1534, -0.1341, -0.0925, -0.0772, -0.0701, -0.0433, -0.0560, -0.0544, -0.0346, -0.0098, -0.0165, -0.0405,
0:         -0.0705], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 1.8061,  0.3436, -0.4876,  0.4236,  0.3310,  0.6571, -0.1740, -1.1146,  0.0637,  1.0107, -0.6201,  0.3394,
0:          2.1996,  1.0338,  0.6592, -0.0394, -0.5191, -1.1925, -0.3718, -0.9905, -0.6412, -0.1299,  0.1837,  0.5940,
0:         -0.3213], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([ 2.8356,  0.5261,  3.0162,  3.1423,  0.5522,  1.4308,  3.2510,  6.0695,  0.5130,  1.3481,  3.9035,  2.9727,
0:          0.8827,  1.8113,  4.9713,  8.5248, 14.6033,  5.7281,  4.0774,  5.2888,  3.7316,  0.4130,  1.4742,  2.1093,
0:          3.2641], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 72, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 0.5120,    nan,    nan,    nan,    nan,
0:            nan,    nan, 1.1713,    nan,    nan,    nan,    nan,    nan,    nan,    nan, 1.4085])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 72, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.7564, -0.7655, -0.7750, -0.7777, -0.7744, -0.7691, -0.7609, -0.7557, -0.7518, -0.7507, -0.7524, -0.7537,
0:         -0.7571, -0.7567, -0.7575, -0.7570, -0.7561, -0.7548, -0.7295, -0.7350, -0.7393, -0.7390, -0.7343, -0.7287,
0:         -0.7231], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.0480, 0.0422, 0.0442, 0.0559, 0.0747, 0.0941, 0.1142, 0.1312, 0.1441, 0.1521, 0.1585, 0.1599, 0.1627, 0.1667,
0:         0.1762, 0.1889, 0.2021, 0.2111, 0.0248, 0.0159, 0.0151, 0.0262, 0.0459, 0.0685, 0.0892], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6605, -0.6603, -0.6624, -0.6676, -0.6768, -0.6858, -0.6959, -0.7020, -0.7060, -0.7092, -0.7092, -0.7102,
0:         -0.7099, -0.7111, -0.7133, -0.7146, -0.7160, -0.7139, -0.6693, -0.6689, -0.6719, -0.6779, -0.6861, -0.6961,
0:         -0.7033], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-1.7271, -1.4675, -1.1467, -0.8052, -0.6137, -0.5998, -0.4349, -0.2172, -0.1928, -0.1194,  0.0035,  0.0340,
0:          0.0646,  0.0832,  0.0846,  0.0780,  0.0604,  0.0535, -1.5266, -1.1977, -0.8480, -0.5839, -0.4836, -0.4646,
0:         -0.2719], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-1.1388, -1.1431, -1.1605, -1.1863, -1.2140, -1.2335, -1.2378, -1.2277, -1.2136, -1.2073, -1.2160, -1.2384,
0:         -1.2634, -1.2831, -1.2921, -1.2885, -1.2687, -1.2320, -1.1770, -1.1106, -1.0381, -0.9630, -0.8899, -0.8231,
0:         -0.7623], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2340, -0.2356, -0.2407, -0.2421, -0.2454, -0.2470, -0.2465, -0.2448, -0.2394, -0.2327, -0.2345, -0.2385,
0:         -0.2418, -0.2439, -0.2474, -0.2472, -0.2445, -0.2441, -0.2341, -0.2373, -0.2396, -0.2418, -0.2409, -0.2408,
0:         -0.2453], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-0.0213, -0.0213, -0.0109, -0.0244, -0.0088,  0.0034, -0.0272, -0.0373, -0.0291, -0.0156, -0.0159, -0.0169,
0:         -0.0005, -0.0204,  0.0073, -0.0179, -0.0120, -0.0189, -0.0143, -0.0004, -0.0117, -0.0086, -0.0071, -0.0296,
0:         -0.0172], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 72 [1/5 (20%)]	Loss: 0.26122 : 0.19999 :: 0.02124 (1.72 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 72 [2/5 (40%)]	Loss: 0.23856 : 0.18503 :: 0.01998 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 72 [3/5 (60%)]	Loss: 0.23159 : 0.20727 :: 0.02084 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 72 [4/5 (80%)]	Loss: 0.21655 : 0.17317 :: 0.02047 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 72 : 0.2008705884218216
0: validation loss for velocity_u : 0.003394360188394785
0: validation loss for velocity_v : 0.0046662818640470505
0: validation loss for specific_humidity : 0.006321265362203121
0: validation loss for velocity_z : 0.10176075994968414
0: validation loss for temperature : 0.019128061830997467
0: validation loss for total_precip : 0.22725971043109894
0: validation loss for t2m : 1.0435638427734375
1: 73 : 07:36:21 :: batch_size = 96, lr = 1e-05
0: 73 : 07:36:21 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 73, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2901, 0.2256, 0.2005, 0.2010, 0.2324, 0.3051, 0.4065, 0.4890, 0.5080, 0.4768, 0.4402, 0.4124, 0.3850, 0.3672,
0:         0.3717, 0.3925, 0.4267, 0.4854, 0.4105, 0.3405, 0.2992, 0.2869, 0.2987, 0.3469, 0.4476], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.2006, 0.2572, 0.3134, 0.3769, 0.4354, 0.4679, 0.4675, 0.4534, 0.4484, 0.4509, 0.4532, 0.4560, 0.4541, 0.4438,
0:         0.4285, 0.4061, 0.3755, 0.3448, 0.1643, 0.2237, 0.2882, 0.3604, 0.4293, 0.4708, 0.4698], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.6494,  0.8220,  0.3596,  0.2003,  0.2346,  0.1383, -0.0099, -0.6139, -1.5841, -2.0532, -1.8618, -1.2722,
0:         -0.3285,  0.3751,  0.2423, -0.1227,  0.1361,  0.7324,  0.4791,  0.7014,  0.4138,  0.1417, -0.0530, -0.1028,
0:          0.0686], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561,
0:         -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561,
0:         -0.2561], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 73, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -1.6423,     nan, -1.7146,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 73, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([-0.8891, -0.9154, -0.9410, -0.9598, -0.9661, -0.9591, -0.9386, -0.9081, -0.8705, -0.8339, -0.8002, -0.7707,
0:         -0.7454, -0.7216, -0.6986, -0.6750, -0.6527, -0.6328, -0.9370, -0.9584, -0.9775, -0.9886, -0.9884, -0.9777,
0:         -0.9558], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.8315, 0.8047, 0.7720, 0.7500, 0.7429, 0.7509, 0.7647, 0.7816, 0.7942, 0.8002, 0.8035, 0.8038, 0.8078, 0.8126,
0:         0.8175, 0.8171, 0.8057, 0.7861, 0.7512, 0.7162, 0.6708, 0.6372, 0.6223, 0.6291, 0.6579], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([1.5957, 1.4958, 1.3740, 1.2492, 1.1352, 1.0407, 0.9671, 0.9099, 0.8720, 0.8453, 0.8278, 0.8150, 0.8056, 0.7864,
0:         0.7642, 0.7401, 0.7092, 0.6654, 1.7132, 1.6000, 1.4608, 1.3235, 1.2022, 1.1123, 1.0453], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.4611, -0.2101,  0.2247,  0.0039, -0.3407, -0.0677,  0.0724, -0.2793, -0.2343,  0.3356,  0.3972, -0.0189,
0:          0.0243,  0.0448, -0.4105, -0.4005,  0.0064,  0.0273, -0.5495, -0.3111,  0.0675, -0.0974, -0.2988,  0.0552,
0:          0.2537], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.4255, -0.5242, -0.6299, -0.7131, -0.7738, -0.8137, -0.8587, -0.9200, -0.9997, -1.0994, -1.2080, -1.3110,
0:         -1.3892, -1.4362, -1.4496, -1.4479, -1.4466, -1.4649, -1.5024, -1.5507, -1.5838, -1.5857, -1.5497, -1.4800,
0:         -1.3873], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.0718, -0.1455, -0.1769, -0.2224, -0.2384, -0.2145, -0.2090, -0.1796, -0.1569,  0.0425, -0.0216, -0.0906,
0:         -0.1514, -0.1719, -0.1990, -0.1920, -0.1501, -0.1323,  0.2936,  0.1601,  0.0661, -0.0197, -0.1217, -0.1654,
0:         -0.1651], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-1.3146e-02, -1.6513e-02, -1.2228e-02, -1.8567e-02, -1.8031e-02, -3.8333e-03, -1.7473e-02, -2.1235e-02,
0:         -1.7160e-02,  8.8228e-03, -1.7083e-02, -2.2982e-02, -6.5221e-03, -1.2335e-02,  1.0023e-02, -1.0403e-02,
0:         -7.8828e-05, -2.0019e-02, -1.3786e-02, -4.5562e-03, -2.9931e-02, -3.0247e-03, -1.5132e-02, -2.9123e-02,
0:         -7.9241e-03], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 73, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0.2901, 0.2256, 0.2005, 0.2010, 0.2324, 0.3051, 0.4065, 0.4890, 0.5080, 0.4768, 0.4402, 0.4124, 0.3850, 0.3672,
1:         0.3717, 0.3925, 0.4267, 0.4854, 0.4105, 0.3405, 0.2992, 0.2869, 0.2987, 0.3469, 0.4476], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0395,  0.1636,  0.0168,  0.0404,  0.0760, -0.1440, -0.0596,  0.1527,  0.0908,  0.0470,  0.0389, -0.0007,
1:          0.2382, -0.0973,  0.0621,  0.1049,  0.1454, -0.1863,  0.2676, -0.1796,  0.0546,  0.0971,  0.0972,  0.0295,
1:          0.0650], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.2962, -0.3025, -0.3319, -0.3888, -0.4925, -0.5979, -0.6588, -0.6818, -0.6776, -0.6606, -0.5931, -0.5119,
1:         -0.4085, -0.3948, -0.4072, -0.3975, -0.4225, -0.4831, -0.4570, -0.4364, -0.4616, -0.5128, -0.5604, -0.6108,
1:         -0.6581], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([ 0.6502,  0.6749,  0.6858,  0.6978,  0.7150,  0.7118,  0.6606,  0.5691,  0.4678,  0.3649,  0.2635,  0.2004,
1:          0.2009,  0.2313,  0.2323,  0.1874,  0.1284,  0.0758,  0.0175, -0.0426, -0.1054, -0.1920, -0.2649, -0.2342,
1:         -0.0925], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561,
1:         -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561, -0.2561,
1:         -0.2561], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 73, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan, -0.4584, -0.6798,     nan,     nan,     nan, -0.5353,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 73, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.3715, 0.3569, 0.3473, 0.3471, 0.3577, 0.3713, 0.3850, 0.3905, 0.3818, 0.3655, 0.3475, 0.3369, 0.3353, 0.3426,
1:         0.3582, 0.3786, 0.3975, 0.4159, 0.3606, 0.3493, 0.3414, 0.3401, 0.3469, 0.3554, 0.3606], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([0.1837, 0.1904, 0.1991, 0.2090, 0.2157, 0.2169, 0.2116, 0.2014, 0.1916, 0.1786, 0.1702, 0.1636, 0.1532, 0.1439,
1:         0.1323, 0.1259, 0.1208, 0.1169, 0.1977, 0.2062, 0.2149, 0.2248, 0.2322, 0.2323, 0.2293], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.7414, -0.7343, -0.7153, -0.6897, -0.6744, -0.6831, -0.7097, -0.7216, -0.6949, -0.5925, -0.3971, -0.1133,
1:          0.2467,  0.6427,  1.0272,  1.3719,  1.6431,  1.8178, -0.7455, -0.7458, -0.7264, -0.6984, -0.6845, -0.6947,
1:         -0.7105], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([-2.4699e-02, -4.9369e-01, -7.8763e-01, -6.9362e-01, -4.4631e-01, -2.6235e-01, -2.2151e-01, -3.7688e-01,
1:         -5.1902e-01, -3.3675e-01,  7.4937e-04,  1.4151e-01,  1.8250e-01,  1.3817e-01, -3.4121e-03,  8.9017e-03,
1:          1.9482e-01,  4.0673e-01, -2.7283e-01, -6.7225e-01, -8.6453e-01, -5.6219e-01, -1.7236e-01, -2.5866e-02,
1:         -1.3044e-01], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.0692, -0.1784, -0.3194, -0.4671, -0.5943, -0.6786, -0.7070, -0.6809, -0.6156, -0.5422, -0.4857, -0.4589,
1:         -0.4616, -0.4701, -0.4534, -0.3972, -0.3021, -0.1998, -0.1266, -0.1132, -0.1649, -0.2537, -0.3494, -0.4199,
1:         -0.4385], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2545, -0.2557, -0.2565, -0.2578, -0.2562, -0.2540, -0.2530, -0.2491, -0.2487, -0.2536, -0.2526, -0.2543,
1:         -0.2534, -0.2512, -0.2536, -0.2561, -0.2521, -0.2553, -0.2549, -0.2539, -0.2536, -0.2522, -0.2536, -0.2528,
1:         -0.2567], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0148, -0.0126, -0.0095, -0.0186, -0.0137,  0.0061, -0.0007, -0.0344, -0.0185, -0.0128, -0.0019, -0.0136,
1:          0.0002,  0.0011, -0.0020, -0.0055, -0.0026,  0.0045,  0.0037, -0.0136, -0.0348, -0.0072,  0.0035, -0.0180,
1:         -0.0226], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 73 [1/5 (20%)]	Loss: 0.26173 : 0.19583 :: 0.01925 (1.80 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 73 [2/5 (40%)]	Loss: 0.23680 : 0.19412 :: 0.02022 (8.47 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 73 [3/5 (60%)]	Loss: 0.24031 : 0.21351 :: 0.02115 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 73 [4/5 (80%)]	Loss: 0.20820 : 0.18059 :: 0.02167 (8.47 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 73 : 0.19579122960567474
0: validation loss for velocity_u : 0.0032333247363567352
0: validation loss for velocity_v : 0.004613502882421017
0: validation loss for specific_humidity : 0.006307592615485191
0: validation loss for velocity_z : 0.10379143059253693
0: validation loss for temperature : 0.018722811713814735
0: validation loss for total_precip : 0.25556662678718567
0: validation loss for t2m : 0.9783034920692444
1: 74 : 07:42:26 :: batch_size = 96, lr = 1e-05
0: 74 : 07:42:26 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 74, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1: Created sparse mask for t2m with 10.0% data retained
0:      first 25 values: tensor([1.5179, 1.5565, 1.5973, 1.6338, 1.6675, 1.7029, 1.7374, 1.7781, 1.8280, 1.8792, 1.9357, 1.9954, 2.0462, 2.0909,
0:         2.1373, 2.1906, 2.2397, 2.2475, 1.5665, 1.6077, 1.6520, 1.6960, 1.7385, 1.7751, 1.8015], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0487, -0.0641, -0.0837, -0.1060, -0.1290, -0.1522, -0.1743, -0.1947, -0.2169, -0.2396, -0.2574, -0.2748,
0:         -0.2939, -0.3071, -0.3139, -0.3089, -0.2782, -0.2334, -0.0124, -0.0303, -0.0511, -0.0751, -0.1036, -0.1326,
0:         -0.1573], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.3176,  0.3360,  0.1461, -0.1773, -0.5713, -0.9772, -1.1367, -0.9500, -0.6722, -0.5778, -0.8448, -1.2029,
0:         -1.1454, -0.7221,  0.2080,  2.2494,  4.9486,  6.5744,  0.5281,  0.5086,  0.4511,  0.3165, -0.0785, -0.7297,
0:         -1.2203], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325,
0:         -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325,
0:         -0.2325], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 74, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([   nan,    nan,    nan,    nan,    nan, 0.7665,    nan,    nan, 1.0244,    nan,    nan,    nan,    nan,    nan,
0:         1.0563,    nan,    nan,    nan, 1.1776,    nan,    nan,    nan,    nan,    nan,    nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 74, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.7175, 0.7208, 0.7177, 0.7068, 0.6861, 0.6561, 0.6161, 0.5701, 0.5234, 0.4817, 0.4441, 0.4112, 0.3837, 0.3581,
0:         0.3323, 0.3044, 0.2870, 0.2708, 0.7359, 0.7349, 0.7291, 0.7202, 0.6977, 0.6686, 0.6295], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([0.1793, 0.2240, 0.2669, 0.3131, 0.3559, 0.4038, 0.4493, 0.4984, 0.5556, 0.6263, 0.7094, 0.8035, 0.9072, 1.0214,
0:         1.1445, 1.2725, 1.3994, 1.5063, 0.1887, 0.2330, 0.2810, 0.3265, 0.3718, 0.4139, 0.4538], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.4049, -0.3785, -0.3643, -0.3624, -0.3779, -0.4048, -0.4431, -0.4829, -0.5224, -0.5569, -0.5846, -0.6045,
0:         -0.6197, -0.6320, -0.6404, -0.6461, -0.6550, -0.6640, -0.4052, -0.3794, -0.3629, -0.3587, -0.3687, -0.3909,
0:         -0.4252], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-1.2269, -1.0142, -0.7660, -0.5401, -0.3835, -0.2831, -0.2726, -0.3572, -0.5044, -0.6147, -0.6185, -0.5041,
0:         -0.3323, -0.2278, -0.1512, -0.0652, -0.0530, -0.0304, -1.1079, -0.9057, -0.6664, -0.4704, -0.3587, -0.3029,
0:         -0.3394], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([0.8088, 0.7592, 0.6798, 0.5987, 0.5407, 0.5067, 0.5031, 0.5259, 0.5696, 0.6238, 0.6816, 0.7384, 0.7905, 0.8315,
0:         0.8740, 0.9188, 0.9698, 1.0283, 1.1003, 1.1836, 1.2634, 1.3264, 1.3581, 1.3541, 1.3270], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([0.6348, 0.5514, 0.4892, 0.5136, 0.6165, 0.7319, 0.8318, 0.8965, 0.9434, 0.7172, 0.6041, 0.5075, 0.4469, 0.4507,
0:         0.5110, 0.5951, 0.6763, 0.6873, 0.7690, 0.6053, 0.4578, 0.3466, 0.2737, 0.2661, 0.3058], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([-1.0074e-02, -8.1124e-03, -1.2907e-03, -4.3979e-04, -1.8142e-02,  3.6163e-04, -1.9421e-03, -1.8730e-02,
0:         -4.4836e-03, -4.0658e-03, -8.7603e-03,  2.3125e-03,  7.9074e-04, -1.2900e-02,  1.5400e-03,  2.2455e-03,
0:          1.6530e-02, -2.0136e-03, -6.2510e-03,  4.2696e-05, -9.2418e-03,  2.7681e-03, -1.0838e-02, -2.9501e-02,
0:         -3.5109e-03], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 74, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.5179, 1.5565, 1.5973, 1.6338, 1.6675, 1.7029, 1.7374, 1.7781, 1.8280, 1.8792, 1.9357, 1.9954, 2.0462, 2.0909,
1:         2.1373, 2.1906, 2.2397, 2.2475, 1.5665, 1.6077, 1.6520, 1.6960, 1.7385, 1.7751, 1.8015], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0030, -0.0985, -0.0851, -0.1042,  0.0912, -0.0508, -0.0171,  0.0243,  0.1931,  0.0772,  0.1659, -0.2023,
1:         -0.1160, -0.0114, -0.0072, -0.1047,  0.0776,  0.0268,  0.0003, -0.0017, -0.0403,  0.0275, -0.0423,  0.0569,
1:         -0.1898], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.5673, -0.5689, -0.5712, -0.5738, -0.5766, -0.5812, -0.5845, -0.5905, -0.5979, -0.6043, -0.6120, -0.6189,
1:         -0.6255, -0.6286, -0.6299, -0.6236, -0.6139, -0.6086, -0.5447, -0.5461, -0.5481, -0.5504, -0.5526, -0.5555,
1:         -0.5580], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., -0., -0., -0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.0439, -1.0550, -1.0675, -1.0866, -1.1159, -1.1530, -1.1863, -1.2141, -1.2335, -1.2491, -1.2748, -1.3032,
1:         -1.3307, -1.3629, -1.3855, -1.3956, -1.3739, -1.2709, -1.1366, -1.0908, -1.1465, -1.2114, -1.2314, -1.2233,
1:         -1.2193], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325,
1:         -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325, -0.2325,
1:         -0.2325], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 74, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan, -1.3136, -1.2735,     nan,     nan,
1:             nan,     nan,     nan, -1.2989,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 74, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([1.7686, 1.7622, 1.7602, 1.7623, 1.7575, 1.7460, 1.7320, 1.7227, 1.7154, 1.7119, 1.7061, 1.6955, 1.6762, 1.6526,
1:         1.6270, 1.5982, 1.5614, 1.5171, 1.8676, 1.8529, 1.8470, 1.8394, 1.8337, 1.8194, 1.8109], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([ 1.9581,  1.9852,  2.0023,  2.0111,  1.9997,  1.9572,  1.8665,  1.7219,  1.5127,  1.2414,  0.9353,  0.6104,
1:          0.2870, -0.0040, -0.2583, -0.4728, -0.6453, -0.7696,  1.9505,  1.9794,  1.9964,  1.9986,  1.9800,  1.9320,
1:          1.8379], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.6191, -0.5996, -0.5751, -0.5464, -0.5180, -0.4851, -0.4498, -0.4087, -0.3629, -0.3136, -0.2690, -0.2309,
1:         -0.2017, -0.1887, -0.1898, -0.2022, -0.2236, -0.2441, -0.6556, -0.6328, -0.6045, -0.5727, -0.5385, -0.5009,
1:         -0.4574], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.1221,  0.4967,  0.8619,  1.1926,  1.5591,  1.6517,  1.3679,  0.8380,  0.3100, -0.0111, -0.3111, -1.0505,
1:         -2.2952, -3.5168, -4.0428, -3.5342, -2.6310, -2.1193, -0.1385,  0.0919,  0.2972,  0.6430,  1.1887,  1.6158,
1:          1.7613], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([0.0594, 0.0850, 0.1042, 0.1118, 0.1120, 0.1110, 0.1131, 0.1191, 0.1277, 0.1356, 0.1444, 0.1523, 0.1602, 0.1645,
1:         0.1712, 0.1813, 0.1968, 0.2161, 0.2399, 0.2659, 0.2953, 0.3297, 0.3684, 0.4075, 0.4398], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([1.6189, 1.5824, 1.3956, 1.1290, 0.9820, 0.9059, 0.8968, 1.0995, 1.3403, 1.9151, 1.9196, 1.8283, 1.6356, 1.5302,
1:         1.5628, 1.6966, 1.9637, 2.2308, 2.0568, 2.1084, 2.1198, 2.0618, 2.1002, 2.3643, 2.7191], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([-0.0056, -0.0200, -0.0130, -0.0050, -0.0027,  0.0127,  0.0145, -0.0325, -0.0117, -0.0078, -0.0097,  0.0045,
1:          0.0041, -0.0065, -0.0160, -0.0118,  0.0191,  0.0108, -0.0005, -0.0081, -0.0053,  0.0081,  0.0039, -0.0073,
1:         -0.0279], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 74 [1/5 (20%)]	Loss: 0.30770 : 0.22671 :: 0.02175 (1.60 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 74 [2/5 (40%)]	Loss: 0.31160 : 0.22967 :: 0.02020 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 74 [3/5 (60%)]	Loss: 0.27235 : 0.21373 :: 0.02132 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 74 [4/5 (80%)]	Loss: 0.27530 : 0.20815 :: 0.02043 (8.48 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 74 : 0.21004916727542877
0: validation loss for velocity_u : 0.0036998363211750984
0: validation loss for velocity_v : 0.005114508792757988
0: validation loss for specific_humidity : 0.006036330480128527
0: validation loss for velocity_z : 0.11561152338981628
0: validation loss for temperature : 0.019319042563438416
0: validation loss for total_precip : 0.294219434261322
0: validation loss for t2m : 1.0263433456420898
1: 75 : 07:48:30 :: batch_size = 96, lr = 1e-05
0: 75 : 07:48:30 :: batch_size = 96, lr = 1e-05
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 75, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([1.2870, 1.3106, 1.3273, 1.3391, 1.3481, 1.3546, 1.3608, 1.3701, 1.3855, 1.4077, 1.4324, 1.4524, 1.4598, 1.4489,
0:         1.4188, 1.3726, 1.3221, 1.2824, 1.2354, 1.2732, 1.3030, 1.3269, 1.3465, 1.3587, 1.3669], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.8898, -1.0244, -1.1717, -1.3244, -1.4777, -1.6254, -1.7566, -1.8713, -1.9677, -2.0359, -2.0816, -2.1099,
0:         -2.1068, -2.0703, -2.0165, -1.9495, -1.8671, -1.7745, -0.7768, -0.8836, -1.0046, -1.1358, -1.2730, -1.4140,
0:         -1.5496], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0.9823, 1.1645, 1.2694, 1.3047, 1.2418, 1.1026, 0.9249, 0.6886, 0.4700, 0.3563, 0.3452, 0.4888, 0.7825, 1.1269,
0:         1.5156, 1.9053, 2.1979, 2.3701, 0.8244, 0.9580, 1.0397, 1.1104, 1.1225, 1.0872, 1.0143], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382,
0:         -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382,
0:         -0.2382], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 75, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan,     nan,     nan,     nan,     nan,     nan, -0.1898,     nan,     nan,     nan,     nan,
0:             nan,     nan,     nan,     nan, -0.4897, -0.5495,     nan,     nan,     nan,     nan, -1.1426,     nan,
0:             nan])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 75, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.6262, 0.5945, 0.5548, 0.5114, 0.4727, 0.4402, 0.4184, 0.4054, 0.4029, 0.4088, 0.4222, 0.4388, 0.4572, 0.4742,
0:         0.4924, 0.5084, 0.5191, 0.5280, 0.5315, 0.4976, 0.4587, 0.4205, 0.3869, 0.3621, 0.3476], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([1.9185, 1.8956, 1.8355, 1.7441, 1.6115, 1.4424, 1.2460, 1.0308, 0.8215, 0.6412, 0.4989, 0.3974, 0.3266, 0.2745,
0:         0.2254, 0.1839, 0.1410, 0.1054, 1.8200, 1.8032, 1.7559, 1.6672, 1.5407, 1.3683, 1.1618], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.4555, -0.4682, -0.4618, -0.4486, -0.4411, -0.4456, -0.4766, -0.5246, -0.5810, -0.6333, -0.6724, -0.6916,
0:         -0.6926, -0.6807, -0.6598, -0.6347, -0.6137, -0.5975, -0.4702, -0.4836, -0.4756, -0.4574, -0.4459, -0.4530,
0:         -0.4870], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([0.5990, 0.5010, 0.3664, 0.2312, 0.1249, 0.0897, 0.1462, 0.2624, 0.3999, 0.5462, 0.6573, 0.7258, 0.7996, 0.8657,
0:         0.9188, 0.9386, 0.9202, 0.9150, 0.6583, 0.5744, 0.4602, 0.3420, 0.2379, 0.1856, 0.2071], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-1.2061, -1.1956, -1.1919, -1.1931, -1.1972, -1.2016, -1.2039, -1.2068, -1.2167, -1.2375, -1.2722, -1.3158,
0:         -1.3609, -1.3960, -1.4117, -1.4040, -1.3742, -1.3260, -1.2681, -1.2077, -1.1522, -1.1028, -1.0560, -1.0096,
0:         -0.9616], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.1906, -0.1907, -0.1986, -0.1968, -0.1938, -0.1937, -0.1916, -0.1942, -0.1879, -0.1919, -0.2011, -0.2030,
0:         -0.2047, -0.2012, -0.2045, -0.2044, -0.2102, -0.1989, -0.1944, -0.1956, -0.2033, -0.2035, -0.1983, -0.1985,
0:         -0.2031], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 5.2606e-03, -1.5155e-02,  1.2381e-02,  1.7157e-02,  2.9511e-03, -2.2655e-04,  1.9724e-02, -4.2397e-03,
0:          2.5173e-02, -7.3219e-03,  5.6138e-03,  1.3065e-02,  5.4552e-03,  1.0848e-02,  6.3564e-03, -2.2532e-02,
0:          6.9070e-03,  1.2482e-02, -5.5692e-03,  1.2466e-02,  1.6663e-04,  1.1842e-06,  1.0369e-02, -1.3008e-02,
0:         -5.2564e-03], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 75, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.2870, 1.3106, 1.3273, 1.3391, 1.3481, 1.3546, 1.3608, 1.3701, 1.3855, 1.4077, 1.4324, 1.4524, 1.4598, 1.4489,
1:         1.4188, 1.3726, 1.3221, 1.2824, 1.2354, 1.2732, 1.3030, 1.3269, 1.3465, 1.3587, 1.3669], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0541,  0.0036, -0.0251, -0.0460,  0.0092,  0.3010, -0.2150, -0.0262,  0.0722, -0.0186, -0.3085,  0.0666,
1:          0.2351,  0.1473, -0.0535,  0.1588, -0.0051, -0.0061, -0.1352,  0.1064,  0.1424, -0.2499, -0.0581, -0.0006,
1:         -0.1006], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.5307, -0.5317, -0.5373, -0.5363, -0.5355, -0.5346, -0.5404, -0.5464, -0.5542, -0.5643, -0.5709, -0.5787,
1:         -0.5857, -0.5915, -0.5976, -0.6013, -0.6055, -0.6081, -0.4815, -0.5149, -0.5302, -0.5385, -0.5502, -0.5493,
1:         -0.5513], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., 0., 0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-1.0793e-03, -5.1023e-02, -1.0303e-01, -1.5110e-01, -1.9740e-01, -2.4207e-01, -2.8367e-01, -3.2903e-01,
1:         -3.7872e-01, -4.3166e-01, -4.9609e-01, -5.7701e-01, -6.7880e-01, -8.0255e-01, -9.3621e-01, -1.0669e+00,
1:         -1.1821e+00, -1.2741e+00, -1.3458e+00, -1.3977e+00, -1.4300e+00, -1.4460e+00, -1.4487e+00, -1.4442e+00,
1:         -1.4405e+00], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382,
1:         -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382, -0.2382,
1:         -0.2382], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 75, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([   nan,    nan,    nan, 1.0180,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,
1:            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 75, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([1.5525, 1.5675, 1.5868, 1.6066, 1.6270, 1.6439, 1.6599, 1.6711, 1.6787, 1.6796, 1.6795, 1.6759, 1.6701, 1.6612,
1:         1.6530, 1.6454, 1.6368, 1.6280, 1.6269, 1.6464, 1.6682, 1.6882, 1.7060, 1.7217, 1.7348], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.8541, -0.8224, -0.7930, -0.7645, -0.7386, -0.7151, -0.6928, -0.6744, -0.6602, -0.6447, -0.6266, -0.6033,
1:         -0.5768, -0.5489, -0.5231, -0.5020, -0.4860, -0.4745, -0.8705, -0.8428, -0.8155, -0.7886, -0.7602, -0.7299,
1:         -0.7014], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.0627, -0.0498, -0.0353, -0.0230, -0.0133, -0.0098, -0.0134, -0.0240, -0.0426, -0.0593, -0.0749, -0.0849,
1:         -0.0906, -0.0966, -0.1070, -0.1236, -0.1468, -0.1699, -0.0723, -0.0572, -0.0412, -0.0248, -0.0123, -0.0078,
1:         -0.0125], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.3554,  0.1322, -0.1115, -0.2806, -0.4855, -2.2104, -5.7022, -8.6245, -8.9944, -6.9503, -4.2451, -2.4735,
1:         -1.4770, -0.5371,  0.1032,  0.0968, -0.3635, -0.7593,  0.5328,  0.2722,  0.0229, -0.4422, -1.1283, -2.8589,
1:         -5.8008], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-1.2410, -1.3160, -1.3841, -1.4470, -1.5067, -1.5642, -1.6163, -1.6609, -1.6996, -1.7314, -1.7560, -1.7733,
1:         -1.7839, -1.7874, -1.7857, -1.7805, -1.7734, -1.7671, -1.7617, -1.7560, -1.7534, -1.7483, -1.7396, -1.7230,
1:         -1.6942], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2044, -0.2054, -0.2105, -0.2028, -0.2219, -0.2046, -0.1953, -0.1730, -0.0957, -0.2232, -0.2401, -0.2638,
1:         -0.2655, -0.2629, -0.2218, -0.1936, -0.1180, -0.0161, -0.1995, -0.2392, -0.2660, -0.2856, -0.2587, -0.2306,
1:         -0.1265], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 1.3298e-02, -2.1989e-02,  1.2620e-02,  3.3532e-03,  6.2409e-03,  2.1212e-02,  3.3586e-02, -5.6354e-03,
1:          4.7978e-03, -8.3641e-03,  7.6484e-03,  5.3589e-03,  2.8013e-03,  6.9486e-03,  8.1962e-04, -6.6479e-03,
1:          1.1156e-02,  2.7748e-02,  5.0741e-03,  1.8634e-03, -1.3445e-03,  5.0116e-03,  1.3580e-03, -1.2372e-02,
1:         -2.1729e-05], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 75 [1/5 (20%)]	Loss: 0.27494 : 0.19617 :: 0.02135 (1.66 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 75 [2/5 (40%)]	Loss: 0.21907 : 0.19343 :: 0.02097 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 75 [3/5 (60%)]	Loss: 0.30795 : 0.21938 :: 0.02072 (8.48 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 75 [4/5 (80%)]	Loss: 0.27097 : 0.20960 :: 0.01955 (8.46 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: validation loss for strategy=BERT at epoch 75 : 0.21455128490924835
0: validation loss for velocity_u : 0.0036925384774804115
0: validation loss for velocity_v : 0.005186495371162891
0: validation loss for specific_humidity : 0.006368061527609825
0: validation loss for velocity_z : 0.11427590250968933
0: validation loss for temperature : 0.017773304134607315
0: validation loss for total_precip : 0.351624995470047
0: validation loss for t2m : 1.0029376745224
1: 76 : 07:54:40 :: batch_size = 96, lr = 1e-05
0: 76 : 07:54:40 :: batch_size = 96, lr = 1e-05
1: Created sparse mask for t2m with 10.0% data retained
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 76, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.0914, -0.1034, -0.1063, -0.1166, -0.1409, -0.1763, -0.2164, -0.2573, -0.2944, -0.3186, -0.3249, -0.3182,
1:         -0.3047, -0.2884, -0.2740, -0.2599, -0.2406, -0.2155, -0.0778, -0.0907, -0.0968, -0.1049, -0.1199, -0.1441,
1:         -0.1768], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([ 0.0694, -0.0063,  0.0626, -0.0545,  0.0042, -0.0074, -0.1093, -0.0606, -0.0244, -0.1122,  0.0598,  0.0529,
1:          0.2997,  0.0058,  0.1017, -0.0282, -0.0322,  0.1128,  0.0026,  0.1123,  0.0794, -0.1352,  0.2198, -0.0220,
1:         -0.2211], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.5782, -0.5787, -0.5679, -0.5570, -0.5624, -0.5694, -0.5898, -0.6091, -0.6255, -0.6335, -0.6367, -0.6403,
1:         -0.6420, -0.6434, -0.6444, -0.6453, -0.6459, -0.6462, -0.5788, -0.5938, -0.5886, -0.5759, -0.5704, -0.5731,
1:         -0.5911], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.1090, 1.1186, 1.1195, 1.1148, 1.1085, 1.0993, 1.0819, 1.0572, 1.0270, 0.9915, 0.9550, 0.9203, 0.8854, 0.8522,
1:         0.8228, 0.7940, 0.7675, 0.7448, 0.7220, 0.6998, 0.6805, 0.6627, 0.6465, 0.6310, 0.6143], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366,
1:         -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366,
1:         -0.2366], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 76, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2247, 2187])
1:     First 25 batch values:
1: tensor([    nan, -0.9705,     nan,     nan,     nan,     nan,     nan, -1.0073,     nan,     nan,     nan,     nan,
1:             nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
1:             nan])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 76, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([26296, 972])
1:      first 25 pred values: tensor([0.1388, 0.1411, 0.1411, 0.1416, 0.1394, 0.1351, 0.1285, 0.1207, 0.1130, 0.1054, 0.1033, 0.1063, 0.1142, 0.1287,
1:         0.1481, 0.1680, 0.1873, 0.2057, 0.1125, 0.1170, 0.1219, 0.1251, 0.1280, 0.1277, 0.1261], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26192, 972])
1:      first 25 pred values: tensor([-0.4846, -0.4455, -0.4194, -0.4089, -0.4098, -0.4154, -0.4207, -0.4261, -0.4354, -0.4526, -0.4800, -0.5184,
1:         -0.5633, -0.6129, -0.6649, -0.7177, -0.7719, -0.8200, -0.5321, -0.4834, -0.4459, -0.4245, -0.4161, -0.4156,
1:         -0.4192], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([25402, 972])
1:      first 25 pred values: tensor([-0.5876, -0.5960, -0.6057, -0.6160, -0.6245, -0.6311, -0.6363, -0.6401, -0.6437, -0.6481, -0.6531, -0.6600,
1:         -0.6660, -0.6730, -0.6786, -0.6837, -0.6861, -0.6847, -0.5947, -0.6043, -0.6154, -0.6256, -0.6340, -0.6400,
1:         -0.6442], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([24877, 972])
1:      first 25 pred values: tensor([ 0.0454, -0.0596, -0.2182, -0.0678,  0.1519,  0.1684,  0.2439,  0.4145,  0.4430,  0.4535,  0.3597,  0.0685,
1:          0.0508,  0.2307,  0.2284,  0.0950,  0.0509,  0.2276, -0.3343, -0.1807, -0.3827, -0.3082,  0.1356,  0.2930,
1:          0.3345], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([11924, 2187])
1:      first 25 pred values: tensor([-0.3952, -0.4196, -0.4427, -0.4604, -0.4753, -0.4909, -0.5096, -0.5336, -0.5604, -0.5825, -0.5957, -0.5955,
1:         -0.5882, -0.5810, -0.5787, -0.5832, -0.5897, -0.5930, -0.5905, -0.5824, -0.5752, -0.5703, -0.5684, -0.5642,
1:         -0.5535], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([9766, 243])
1:      first 25 pred values: tensor([-0.2519, -0.2497, -0.2474, -0.2440, -0.2390, -0.2347, -0.2351, -0.2362, -0.2332, -0.2414, -0.2432, -0.2420,
1:         -0.2370, -0.2321, -0.2303, -0.2302, -0.2342, -0.2325, -0.2352, -0.2325, -0.2299, -0.2269, -0.2219, -0.2212,
1:         -0.2232], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2247, 2187])
1:      first 25 pred values: tensor([ 2.1312e-02, -5.7265e-03,  3.1716e-02,  1.6151e-02,  1.5197e-02,  2.1068e-02,  2.1269e-02, -9.5607e-05,
1:          1.0008e-02,  7.8253e-03,  1.6124e-02,  1.0167e-02,  3.1571e-02,  5.6320e-03,  2.7321e-02,  4.8553e-03,
1:          1.2915e-02,  4.1256e-02,  1.8655e-02,  1.0024e-02,  1.2790e-02,  2.0066e-02,  1.8263e-02,  1.0693e-02,
1:          5.0751e-03], device='cuda:0', grad_fn=<SliceBackward0>)
0: Created sparse mask for t2m with 10.0% data retained
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 76, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0914, -0.1034, -0.1063, -0.1166, -0.1409, -0.1763, -0.2164, -0.2573, -0.2944, -0.3186, -0.3249, -0.3182,
0:         -0.3047, -0.2884, -0.2740, -0.2599, -0.2406, -0.2155, -0.0778, -0.0907, -0.0968, -0.1049, -0.1199, -0.1441,
0:         -0.1768], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1587, -0.2027, -0.2490, -0.2927, -0.3201, -0.3266, -0.3185, -0.3035, -0.2937, -0.2988, -0.3144, -0.3266,
0:         -0.3268, -0.3177, -0.3057, -0.2937, -0.2825, -0.2736, -0.1572, -0.1885, -0.2401, -0.2978, -0.3412, -0.3632,
0:         -0.3628], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.5437, -0.2299, -0.0741, -0.0310, -0.0420, -0.0343,  0.0077, -0.0332, -0.0663,  0.0221,  0.0652,  0.0486,
0:          0.1171,  0.1569,  0.1072,  0.1138,  0.1237,  0.0420, -0.2365, -0.1680, -0.1956, -0.1669, -0.1083, -0.1127,
0:         -0.0895], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366,
0:         -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366, -0.2366,
0:         -0.2366], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 76, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2352, 2187])
0:     First 25 batch values:
0: tensor([    nan,     nan, -2.0980,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:             nan,     nan, -1.9117,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
0:         -2.0707])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 76, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([26194, 972])
0:      first 25 pred values: tensor([0.4472, 0.4542, 0.4612, 0.4761, 0.5028, 0.5464, 0.5989, 0.6558, 0.7104, 0.7560, 0.7964, 0.8384, 0.8814, 0.9280,
0:         0.9768, 1.0208, 1.0604, 1.0922, 0.4123, 0.4244, 0.4402, 0.4629, 0.4979, 0.5489, 0.6093], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([26053, 972])
0:      first 25 pred values: tensor([-0.2516, -0.2267, -0.2127, -0.2122, -0.2308, -0.2695, -0.3199, -0.3778, -0.4380, -0.4975, -0.5525, -0.6061,
0:         -0.6570, -0.7083, -0.7601, -0.8110, -0.8633, -0.9147, -0.2724, -0.2341, -0.2045, -0.1892, -0.1976, -0.2273,
0:         -0.2736], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([25586, 972])
0:      first 25 pred values: tensor([-0.6661, -0.6602, -0.6516, -0.6423, -0.6317, -0.6221, -0.6136, -0.6077, -0.6038, -0.5999, -0.5959, -0.5900,
0:         -0.5825, -0.5739, -0.5661, -0.5594, -0.5566, -0.5556, -0.6691, -0.6624, -0.6549, -0.6441, -0.6342, -0.6246,
0:         -0.6163], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25447, 972])
0:      first 25 pred values: tensor([-0.7737, -0.7374, -0.6856, -0.5982, -0.4855, -0.4768, -0.5489, -0.6502, -0.6988, -0.6987, -0.7244, -0.6928,
0:         -0.6340, -0.6045, -0.5416, -0.4024, -0.1949, -0.0801, -0.8192, -0.7500, -0.6704, -0.5974, -0.5112, -0.4971,
0:         -0.5105], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11408, 2187])
0:      first 25 pred values: tensor([-0.5636, -0.5802, -0.5944, -0.6031, -0.6065, -0.6061, -0.6005, -0.5887, -0.5702, -0.5454, -0.5192, -0.4934,
0:         -0.4711, -0.4525, -0.4351, -0.4172, -0.4001, -0.3885, -0.3884, -0.4039, -0.4383, -0.4845, -0.5332, -0.5712,
0:         -0.5889], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([11248, 243])
0:      first 25 pred values: tensor([-0.2373, -0.2378, -0.2400, -0.2397, -0.2362, -0.2386, -0.2409, -0.2390, -0.2350, -0.2303, -0.2337, -0.2368,
0:         -0.2373, -0.2333, -0.2335, -0.2357, -0.2367, -0.2339, -0.2251, -0.2274, -0.2278, -0.2264, -0.2273, -0.2290,
0:         -0.2294], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2352, 2187])
0:      first 25 pred values: tensor([ 0.0104,  0.0053,  0.0259,  0.0151,  0.0205,  0.0192,  0.0327,  0.0137,  0.0177,  0.0102,  0.0217,  0.0246,
0:          0.0261,  0.0118,  0.0122,  0.0025, -0.0006,  0.0314,  0.0097,  0.0348,  0.0223,  0.0054,  0.0251,  0.0117,
0:          0.0057], device='cuda:0', grad_fn=<SliceBackward0>)
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 76 [1/5 (20%)]	Loss: 0.25025 : 0.19251 :: 0.02120 (1.68 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 76 [2/5 (40%)]	Loss: 0.23425 : 0.20612 :: 0.02030 (8.43 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: epoch: 76 [3/5 (60%)]	Loss: 0.23376 : 0.18374 :: 0.01988 (8.44 s/sec)
0: Created sparse mask for t2m with 10.0% data retained
0: epoch: 76 [4/5 (80%)]	Loss: 0.25005 : 0.19853 :: 0.02059 (8.44 s/sec)
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
1: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
0: Created sparse mask for t2m with 10.0% data retained
