0: Wandb run: atmorep-h0il5hnz-18537245
0: l50115:547503:547503 [0] NCCL INFO Bootstrap : Using ib0:10.128.11.172<0>
0: l50115:547503:547503 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
0: l50115:547503:547503 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
0: l50115:547503:547503 [0] NCCL INFO NET/Plugin: Using internal network plugin.
0: l50115:547503:547503 [0] NCCL INFO cudaDriverVersion 12060
0: NCCL version 2.21.5+cuda12.4
1: l50118:3482289:3482289 [0] NCCL INFO cudaDriverVersion 12060
1: l50118:3482289:3482289 [0] NCCL INFO Bootstrap : Using ib0:10.128.11.174<0>
1: l50118:3482289:3482289 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
1: l50118:3482289:3482289 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
1: l50118:3482289:3482289 [0] NCCL INFO NET/Plugin: Using internal network plugin.
1: l50118:3482289:3482532 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:10.128.11.174<0>
1: l50118:3482289:3482532 [0] NCCL INFO Using non-device net plugin version 0
1: l50118:3482289:3482532 [0] NCCL INFO Using network IB
1: l50118:3482289:3482532 [0] NCCL INFO DMA-BUF is available on GPU device 0
0: l50115:547503:548029 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [RO]; OOB ib0:10.128.11.172<0>
0: l50115:547503:548029 [0] NCCL INFO Using non-device net plugin version 0
0: l50115:547503:548029 [0] NCCL INFO Using network IB
0: l50115:547503:548029 [0] NCCL INFO DMA-BUF is available on GPU device 0
0: l50115:547503:548029 [0] NCCL INFO ncclCommInitRank comm 0x55555f0e7d70 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 3000 commId 0xdfa221d39ba70c6a - Init START
1: l50118:3482289:3482532 [0] NCCL INFO ncclCommInitRank comm 0x55555ec9d2e0 rank 1 nranks 2 cudaDev 0 nvmlDev 0 busId 3000 commId 0xdfa221d39ba70c6a - Init START
0: l50115:547503:548029 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
1: l50118:3482289:3482532 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,00000000,00000000,ffff0000,00000000
0: l50115:547503:548029 [0] NCCL INFO comm 0x55555f0e7d70 rank 0 nRanks 2 nNodes 2 localRanks 1 localRank 0 MNNVL 0
0: l50115:547503:548029 [0] NCCL INFO Channel 00/04 :    0   1
0: l50115:547503:548029 [0] NCCL INFO Channel 01/04 :    0   1
0: l50115:547503:548029 [0] NCCL INFO Channel 02/04 :    0   1
0: l50115:547503:548029 [0] NCCL INFO Channel 03/04 :    0   1
0: l50115:547503:548029 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] -1/-1/-1->0->1 [3] -1/-1/-1->0->1
0: l50115:547503:548029 [0] NCCL INFO P2P Chunksize set to 131072
1: l50118:3482289:3482532 [0] NCCL INFO comm 0x55555ec9d2e0 rank 1 nRanks 2 nNodes 2 localRanks 1 localRank 0 MNNVL 0
1: l50118:3482289:3482532 [0] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] 0/-1/-1->1->-1 [3] 0/-1/-1->1->-1
1: l50118:3482289:3482532 [0] NCCL INFO P2P Chunksize set to 131072
0: l50115:547503:548029 [0] NCCL INFO Channel 00/0 : 1[0] -> 0[0] [receive] via NET/IB/0
0: l50115:547503:548029 [0] NCCL INFO Channel 01/0 : 1[0] -> 0[0] [receive] via NET/IB/1
0: l50115:547503:548029 [0] NCCL INFO Channel 02/0 : 1[0] -> 0[0] [receive] via NET/IB/0
0: l50115:547503:548029 [0] NCCL INFO Channel 03/0 : 1[0] -> 0[0] [receive] via NET/IB/1
0: l50115:547503:548029 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[0] [send] via NET/IB/0
0: l50115:547503:548029 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[0] [send] via NET/IB/1
0: l50115:547503:548029 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[0] [send] via NET/IB/0
1: l50118:3482289:3482532 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[0] [receive] via NET/IB/0
0: l50115:547503:548029 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[0] [send] via NET/IB/1
1: l50118:3482289:3482532 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[0] [receive] via NET/IB/1
1: l50118:3482289:3482532 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[0] [receive] via NET/IB/0
1: l50118:3482289:3482532 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[0] [receive] via NET/IB/1
1: l50118:3482289:3482532 [0] NCCL INFO Channel 00/0 : 1[0] -> 0[0] [send] via NET/IB/0
1: l50118:3482289:3482532 [0] NCCL INFO Channel 01/0 : 1[0] -> 0[0] [send] via NET/IB/1
1: l50118:3482289:3482532 [0] NCCL INFO Channel 02/0 : 1[0] -> 0[0] [send] via NET/IB/0
1: l50118:3482289:3482532 [0] NCCL INFO Channel 03/0 : 1[0] -> 0[0] [send] via NET/IB/1
1: l50118:3482289:3482535 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 250.
1: l50118:3482289:3482535 [0] NCCL INFO NCCL_IB_RETRY_CNT set by environment to 50.
0: l50115:547503:548032 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 250.
0: l50115:547503:548032 [0] NCCL INFO NCCL_IB_RETRY_CNT set by environment to 50.
0: l50115:547503:548029 [0] NCCL INFO Connected all rings
0: l50115:547503:548029 [0] NCCL INFO Connected all trees
1: l50118:3482289:3482532 [0] NCCL INFO Connected all rings
1: l50118:3482289:3482532 [0] NCCL INFO Connected all trees
1: l50118:3482289:3482532 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
1: l50118:3482289:3482532 [0] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
0: l50115:547503:548029 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
0: l50115:547503:548029 [0] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
1: l50118:3482289:3482532 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
1: l50118:3482289:3482532 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
1: l50118:3482289:3482532 [0] NCCL INFO ncclCommInitRank comm 0x55555ec9d2e0 rank 1 nranks 2 cudaDev 0 nvmlDev 0 busId 3000 commId 0xdfa221d39ba70c6a - Init COMPLETE
0: l50115:547503:548029 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
0: l50115:547503:548029 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
0: l50115:547503:548029 [0] NCCL INFO ncclCommInitRank comm 0x55555f0e7d70 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 3000 commId 0xdfa221d39ba70c6a - Init COMPLETE
0: with_ddp : True
0: num_accs_per_task : 1
0: par_rank : 0
0: par_size : 2
0: fields : [['velocity_u', [1, 1024, ['velocity_v', 'temperature'], 0, ['j8dwr5qj', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.5, 0.9, 0.2, 0.05]], ['velocity_v', [1, 1024, ['velocity_u', 'temperature'], 0, ['0tlnm5up', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.5, 0.9, 0.2, 0.05]], ['specific_humidity', [1, 1024, ['velocity_u', 'velocity_v', 'temperature'], 0, ['v63l01zu', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.5, 0.9, 0.2, 0.05]], ['velocity_z', [1, 1024, ['velocity_u', 'velocity_v', 'temperature'], 0, ['9l1errbo', -2]], [96, 105, 114, 123, 137], [12, 3, 6], [3, 18, 18], [0.5, 0.9, 0.2, 0.05]], ['temperature', [1, 1024, ['velocity_u', 'velocity_v', 'specific_humidity'], 0, ['7ojls62c', -2]], [96, 105, 114, 123, 137], [12, 2, 4], [3, 27, 27], [0.5, 0.9, 0.2, 0.05], 'Local'], ['total_precip', [1, 1024, ['velocity_u', 'velocity_v', 'velocity_z', 'specific_humidity'], 0], [0], [12, 6, 12], [3, 9, 9], [0.25, 0.9, 0.1, 0.05]], ['t2m', [1, 1024, ['velocity_u', '
0: velocity_v', 'velocity_z', 'specific_humidity'], 0], [0], [12, 2, 4], [3, 27, 27], [0.5, 0.9, 0.2, 0.05], 'Local']]
0: fields_prediction : [['velocity_u', 0.125], ['velocity_v', 0.125], ['specific_humidity', 0.05], ['velocity_z', 0.01], ['temperature', 0.1], ['total_precip', 0.01], ['t2m', 0.58]]
0: fields_targets : []
0: years_train : [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]
0: years_val : [2021]
0: month : None
0: geo_range_sampling : [[0.0, 360.0], [0.0, 360.0]]
0: time_sampling : 1
0: torch_seed : 5521420987310380410
0: batch_size_validation : 1
0: batch_size : 96
0: num_epochs : 128
0: num_samples_per_epoch : 480
0: num_samples_validate : 128
0: num_loader_workers : 5
0: size_token_info : 8
0: size_token_info_net : 16
0: grad_checkpointing : True
0: with_cls : False
0: with_mixed_precision : True
0: with_layernorm : True
0: coupling_num_heads_per_field : 1
0: dropout_rate : 0.05
0: with_qk_lnorm : True
0: encoder_num_layers : 6
0: encoder_num_heads : 16
0: encoder_num_mlp_layers : 2
0: encoder_att_type : dense
0: decoder_num_layers : 6
0: decoder_num_heads : 16
0: decoder_num_mlp_layers : 2
0: decoder_self_att : False
0: decoder_cross_att_ratio : 0.5
0: decoder_cross_att_rate : 1.0
0: decoder_att_type : dense
0: net_tail_num_nets : 16
0: net_tail_num_layers : 0
0: losses : ['mse_ensemble', 'stats']
0: optimizer_zero : False
0: lr_start : 1e-05
0: lr_max : 2e-05
0: lr_min : 1e-05
0: weight_decay : 0.025
0: lr_decay_rate : 1.025
0: lr_start_epochs : 3
0: model_log_frequency : 256
0: BERT_strategy : BERT
0: forecast_num_tokens : 2
0: BERT_fields_synced : False
0: BERT_mr_max : 2
0: log_test_num_ranks : 0
0: save_grads : False
0: profile : False
0: test_initial : False
0: attention : False
0: rng_seed : None
0: with_wandb : True
0: slurm_job_id : 18537245
0: wandb_id : h0il5hnz
0: file_path : /work/ab1412/atmorep/data/era5_y2010_2020_res25_with_t2m.zarr
0: n_size : [36, 13.5, 27.0]
0: model_id : wc5e2i3t
0: years_test : [2021]
1: Available keys in the Zarr dataset: ['data', 'data_sfc', 'lats', 'lons', 'time']
0: Available keys in the Zarr dataset: ['data', 'data_sfc', 'lats', 'lons', 'time']
0: self.ds['data'] : (105192, 7, 5, 721, 1440) :: (105192,)
1: self.ds['data'] : (105192, 7, 5, 721, 1440) :: (105192,)
0: self.lats : (721,)
1: self.lats : (721,)
1: self.lons : (1440,)
0: self.lons : (1440,)
1: Available keys in the Zarr dataset: ['data', 'data_sfc', 'lats', 'lons', 'time']
0: Available keys in the Zarr dataset: ['data', 'data_sfc', 'lats', 'lons', 'time']
1: self.ds['data'] : (105192, 7, 5, 721, 1440) :: (105192,)
1: self.lats : (721,)
1: self.lons : (1440,)
0: self.ds['data'] : (105192, 7, 5, 721, 1440) :: (105192,)
0: self.lats : (721,)
0: self.lons : (1440,)
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
0: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'] 0
1: Loaded AtmoRep: ignoring 208 elements: ['embeds_token_info.6.weight', 'embeds_token_info.6.bias', 'embeds.6.weight', 'embeds.6.bias', 'encoders.6.embed.weight', 'encoders.6.embed.bias', 'encoders.6.heads.0.proj_out.weight', 'encoders.6.heads.0.proj_heads.weight', 'encoders.6.heads.0.proj_heads_other.0.weight', 'encoders.6.heads.0.proj_heads_other.1.weight', 'encoders.6.heads.0.proj_heads_other.2.weight', 'encoders.6.heads.0.proj_heads_other.3.weight', 'encoders.6.heads.0.proj_heads_other.4.weight', 'encoders.6.heads.1.proj_out.weight', 'encoders.6.heads.1.proj_heads.weight', 'encoders.6.heads.1.proj_heads_other.0.weight', 'encoders.6.heads.1.proj_heads_other.1.weight', 'encoders.6.heads.1.proj_heads_other.2.weight', 'encoders.6.heads.1.proj_heads_other.3.weight', 'encoders.6.heads.1.proj_heads_other.4.weight', 'encoders.6.heads.2.proj_out.weight', 'encoders.6.heads.2.proj_heads.weight', 'encoders.6.heads.2.proj_heads_other.0.weight', 'encoders.6.heads.2.proj_heads_other.1.weight', 'encoders.6.heads.2.proj_hea
1: ds_other.2.weight', 'encoders.6.heads.2.proj_heads_other.3.weight', 'encoders.6.heads.2.proj_heads_other.4.weight', 'encoders.6.heads.3.proj_out.weight', 'encoders.6.heads.3.proj_heads.weight', 'encoders.6.heads.3.proj_heads_other.0.weight', 'encoders.6.heads.3.proj_heads_other.1.weight', 'encoders.6.heads.3.proj_heads_other.2.weight', 'encoders.6.heads.3.proj_heads_other.3.weight', 'encoders.6.heads.3.proj_heads_other.4.weight', 'encoders.6.heads.4.proj_out.weight', 'encoders.6.heads.4.proj_heads.weight', 'encoders.6.heads.4.proj_heads_other.0.weight', 'encoders.6.heads.4.proj_heads_other.1.weight', 'encoders.6.heads.4.proj_heads_other.2.weight', 'encoders.6.heads.4.proj_heads_other.3.weight', 'encoders.6.heads.4.proj_heads_other.4.weight', 'encoders.6.heads.5.proj_out.weight', 'encoders.6.heads.5.proj_heads.weight', 'encoders.6.heads.5.proj_heads_other.0.weight', 'encoders.6.heads.5.proj_heads_other.1.weight', 'encoders.6.heads.5.proj_heads_other.2.weight', 'encoders.6.heads.5.proj_heads_other.3.weight', 'e
1: ncoders.6.heads.5.proj_heads_other.4.weight', 'encoders.6.mlps.0.blocks.0.weight', 'encoders.6.mlps.0.blocks.0.bias', 'encoders.6.mlps.0.blocks.3.weight', 'encoders.6.mlps.0.blocks.3.bias', 'encoders.6.mlps.1.blocks.0.weight', 'encoders.6.mlps.1.blocks.0.bias', 'encoders.6.mlps.1.blocks.3.weight', 'encoders.6.mlps.1.blocks.3.bias', 'encoders.6.mlps.2.blocks.0.weight', 'encoders.6.mlps.2.blocks.0.bias', 'encoders.6.mlps.2.blocks.3.weight', 'encoders.6.mlps.2.blocks.3.bias', 'encoders.6.mlps.3.blocks.0.weight', 'encoders.6.mlps.3.blocks.0.bias', 'encoders.6.mlps.3.blocks.3.weight', 'encoders.6.mlps.3.blocks.3.bias', 'encoders.6.mlps.4.blocks.0.weight', 'encoders.6.mlps.4.blocks.0.bias', 'encoders.6.mlps.4.blocks.3.weight', 'encoders.6.mlps.4.blocks.3.bias', 'encoders.6.mlps.5.blocks.0.weight', 'encoders.6.mlps.5.blocks.0.bias', 'encoders.6.mlps.5.blocks.3.weight', 'encoders.6.mlps.5.blocks.3.bias', 'decoders.6.blocks.0.proj_heads.weight', 'decoders.6.blocks.0.proj_heads_o_q.weight', 'decoders.6.blocks.0.proj_he
1: ads_o_kv.weight', 'decoders.6.blocks.0.ln_q.weight', 'decoders.6.blocks.0.ln_q.bias', 'decoders.6.blocks.0.ln_k.weight', 'decoders.6.blocks.0.ln_k.bias', 'decoders.6.blocks.0.proj_out.weight', 'decoders.6.blocks.1.blocks.0.weight', 'decoders.6.blocks.1.blocks.0.bias', 'decoders.6.blocks.1.blocks.3.weight', 'decoders.6.blocks.1.blocks.3.bias', 'decoders.6.blocks.2.proj_heads.weight', 'decoders.6.blocks.2.proj_heads_o_q.weight', 'decoders.6.blocks.2.proj_heads_o_kv.weight', 'decoders.6.blocks.2.ln_q.weight', 'decoders.6.blocks.2.ln_q.bias', 'decoders.6.blocks.2.ln_k.weight', 'decoders.6.blocks.2.ln_k.bias', 'decoders.6.blocks.2.proj_out.weight', 'decoders.6.blocks.3.blocks.0.weight', 'decoders.6.blocks.3.blocks.0.bias', 'decoders.6.blocks.3.blocks.3.weight', 'decoders.6.blocks.3.blocks.3.bias', 'decoders.6.blocks.4.proj_heads.weight', 'decoders.6.blocks.4.proj_heads_o_q.weight', 'decoders.6.blocks.4.proj_heads_o_kv.weight', 'decoders.6.blocks.4.ln_q.weight', 'decoders.6.blocks.4.ln_q.bias', 'decoders.6.blocks.4
1: .ln_k.weight', 'decoders.6.blocks.4.ln_k.bias', 'decoders.6.blocks.4.proj_out.weight', 'decoders.6.blocks.5.blocks.0.weight', 'decoders.6.blocks.5.blocks.0.bias', 'decoders.6.blocks.5.blocks.3.weight', 'decoders.6.blocks.5.blocks.3.bias', 'decoders.6.blocks.6.proj_heads.weight', 'decoders.6.blocks.6.proj_heads_o_q.weight', 'decoders.6.blocks.6.proj_heads_o_kv.weight', 'decoders.6.blocks.6.ln_q.weight', 'decoders.6.blocks.6.ln_q.bias', 'decoders.6.blocks.6.ln_k.weight', 'decoders.6.blocks.6.ln_k.bias', 'decoders.6.blocks.6.proj_out.weight', 'decoders.6.blocks.7.blocks.0.weight', 'decoders.6.blocks.7.blocks.0.bias', 'decoders.6.blocks.7.blocks.3.weight', 'decoders.6.blocks.7.blocks.3.bias', 'decoders.6.blocks.8.proj_heads.weight', 'decoders.6.blocks.8.proj_heads_o_q.weight', 'decoders.6.blocks.8.proj_heads_o_kv.weight', 'decoders.6.blocks.8.ln_q.weight', 'decoders.6.blocks.8.ln_q.bias', 'decoders.6.blocks.8.ln_k.weight', 'decoders.6.blocks.8.ln_k.bias', 'decoders.6.blocks.8.proj_out.weight', 'decoders.6.blocks.
1: 9.blocks.0.weight', 'decoders.6.blocks.9.blocks.0.bias', 'decoders.6.blocks.9.blocks.3.weight', 'decoders.6.blocks.9.blocks.3.bias', 'decoders.6.blocks.10.proj_heads.weight', 'decoders.6.blocks.10.proj_heads_o_q.weight', 'decoders.6.blocks.10.proj_heads_o_kv.weight', 'decoders.6.blocks.10.ln_q.weight', 'decoders.6.blocks.10.ln_q.bias', 'decoders.6.blocks.10.ln_k.weight', 'decoders.6.blocks.10.ln_k.bias', 'decoders.6.blocks.10.proj_out.weight', 'decoders.6.blocks.11.blocks.0.weight', 'decoders.6.blocks.11.blocks.0.bias', 'decoders.6.blocks.11.blocks.3.weight', 'decoders.6.blocks.11.blocks.3.bias', 'tails.6.tail_nets.0.0.weight', 'tails.6.tail_nets.0.0.bias', 'tails.6.tail_nets.0.1.weight', 'tails.6.tail_nets.0.1.bias', 'tails.6.tail_nets.1.0.weight', 'tails.6.tail_nets.1.0.bias', 'tails.6.tail_nets.1.1.weight', 'tails.6.tail_nets.1.1.bias', 'tails.6.tail_nets.2.0.weight', 'tails.6.tail_nets.2.0.bias', 'tails.6.tail_nets.2.1.weight', 'tails.6.tail_nets.2.1.bias', 'tails.6.tail_nets.3.0.weight', 'tails.6.tail_ne
1: ts.3.0.bias', 'tails.6.tail_nets.3.1.weight', 'tails.6.tail_nets.3.1.bias', 'tails.6.tail_nets.4.0.weight', 'tails.6.tail_nets.4.0.bias', 'tails.6.tail_nets.4.1.weight', 'tails.6.tail_nets.4.1.bias', 'tails.6.tail_nets.5.0.weight', 'tails.6.tail_nets.5.0.bias', 'tails.6.tail_nets.5.1.weight', 'tails.6.tail_nets.5.1.bias', 'tails.6.tail_nets.6.0.weight', 'tails.6.tail_nets.6.0.bias', 'tails.6.tail_nets.6.1.weight', 'tails.6.tail_nets.6.1.bias', 'tails.6.tail_nets.7.0.weight', 'tails.6.tail_nets.7.0.bias', 'tails.6.tail_nets.7.1.weight', 'tails.6.tail_nets.7.1.bias', 'tails.6.tail_nets.8.0.weight', 'tails.6.tail_nets.8.0.bias', 'tails.6.tail_nets.8.1.weight', 'tails.6.tail_nets.8.1.bias', 'tails.6.tail_nets.9.0.weight', 'tails.6.tail_nets.9.0.bias', 'tails.6.tail_nets.9.1.weight', 'tails.6.tail_nets.9.1.bias', 'tails.6.tail_nets.10.0.weight', 'tails.6.tail_nets.10.0.bias', 'tails.6.tail_nets.10.1.weight', 'tails.6.tail_nets.10.1.bias', 'tails.6.tail_nets.11.0.weight', 'tails.6.tail_nets.11.0.bias', 'tails.6.tai
1: l_nets.11.1.weight', 'tails.6.tail_nets.11.1.bias', 'tails.6.tail_nets.12.0.weight', 'tails.6.tail_nets.12.0.bias', 'tails.6.tail_nets.12.1.weight', 'tails.6.tail_nets.12.1.bias', 'tails.6.tail_nets.13.0.weight', 'tails.6.tail_nets.13.0.bias', 'tails.6.tail_nets.13.1.weight', 'tails.6.tail_nets.13.1.bias', 'tails.6.tail_nets.14.0.weight', 'tails.6.tail_nets.14.0.bias', 'tails.6.tail_nets.14.1.weight', 'tails.6.tail_nets.14.1.bias', 'tails.6.tail_nets.15.0.weight', 'tails.6.tail_nets.15.0.bias', 'tails.6.tail_nets.15.1.weight', 'tails.6.tail_nets.15.1.bias']
0: Loaded AtmoRep: ignoring 208 elements: ['embeds_token_info.6.weight', 'embeds_token_info.6.bias', 'embeds.6.weight', 'embeds.6.bias', 'encoders.6.embed.weight', 'encoders.6.embed.bias', 'encoders.6.heads.0.proj_out.weight', 'encoders.6.heads.0.proj_heads.weight', 'encoders.6.heads.0.proj_heads_other.0.weight', 'encoders.6.heads.0.proj_heads_other.1.weight', 'encoders.6.heads.0.proj_heads_other.2.weight', 'encoders.6.heads.0.proj_heads_other.3.weight', 'encoders.6.heads.0.proj_heads_other.4.weight', 'encoders.6.heads.1.proj_out.weight', 'encoders.6.heads.1.proj_heads.weight', 'encoders.6.heads.1.proj_heads_other.0.weight', 'encoders.6.heads.1.proj_heads_other.1.weight', 'encoders.6.heads.1.proj_heads_other.2.weight', 'encoders.6.heads.1.proj_heads_other.3.weight', 'encoders.6.heads.1.proj_heads_other.4.weight', 'encoders.6.heads.2.proj_out.weight', 'encoders.6.heads.2.proj_heads.weight', 'encoders.6.heads.2.proj_heads_other.0.weight', 'encoders.6.heads.2.proj_heads_other.1.weight', 'encoders.6.heads.2.proj_hea
0: ds_other.2.weight', 'encoders.6.heads.2.proj_heads_other.3.weight', 'encoders.6.heads.2.proj_heads_other.4.weight', 'encoders.6.heads.3.proj_out.weight', 'encoders.6.heads.3.proj_heads.weight', 'encoders.6.heads.3.proj_heads_other.0.weight', 'encoders.6.heads.3.proj_heads_other.1.weight', 'encoders.6.heads.3.proj_heads_other.2.weight', 'encoders.6.heads.3.proj_heads_other.3.weight', 'encoders.6.heads.3.proj_heads_other.4.weight', 'encoders.6.heads.4.proj_out.weight', 'encoders.6.heads.4.proj_heads.weight', 'encoders.6.heads.4.proj_heads_other.0.weight', 'encoders.6.heads.4.proj_heads_other.1.weight', 'encoders.6.heads.4.proj_heads_other.2.weight', 'encoders.6.heads.4.proj_heads_other.3.weight', 'encoders.6.heads.4.proj_heads_other.4.weight', 'encoders.6.heads.5.proj_out.weight', 'encoders.6.heads.5.proj_heads.weight', 'encoders.6.heads.5.proj_heads_other.0.weight', 'encoders.6.heads.5.proj_heads_other.1.weight', 'encoders.6.heads.5.proj_heads_other.2.weight', 'encoders.6.heads.5.proj_heads_other.3.weight', 'e
0: ncoders.6.heads.5.proj_heads_other.4.weight', 'encoders.6.mlps.0.blocks.0.weight', 'encoders.6.mlps.0.blocks.0.bias', 'encoders.6.mlps.0.blocks.3.weight', 'encoders.6.mlps.0.blocks.3.bias', 'encoders.6.mlps.1.blocks.0.weight', 'encoders.6.mlps.1.blocks.0.bias', 'encoders.6.mlps.1.blocks.3.weight', 'encoders.6.mlps.1.blocks.3.bias', 'encoders.6.mlps.2.blocks.0.weight', 'encoders.6.mlps.2.blocks.0.bias', 'encoders.6.mlps.2.blocks.3.weight', 'encoders.6.mlps.2.blocks.3.bias', 'encoders.6.mlps.3.blocks.0.weight', 'encoders.6.mlps.3.blocks.0.bias', 'encoders.6.mlps.3.blocks.3.weight', 'encoders.6.mlps.3.blocks.3.bias', 'encoders.6.mlps.4.blocks.0.weight', 'encoders.6.mlps.4.blocks.0.bias', 'encoders.6.mlps.4.blocks.3.weight', 'encoders.6.mlps.4.blocks.3.bias', 'encoders.6.mlps.5.blocks.0.weight', 'encoders.6.mlps.5.blocks.0.bias', 'encoders.6.mlps.5.blocks.3.weight', 'encoders.6.mlps.5.blocks.3.bias', 'decoders.6.blocks.0.proj_heads.weight', 'decoders.6.blocks.0.proj_heads_o_q.weight', 'decoders.6.blocks.0.proj_he
0: ads_o_kv.weight', 'decoders.6.blocks.0.ln_q.weight', 'decoders.6.blocks.0.ln_q.bias', 'decoders.6.blocks.0.ln_k.weight', 'decoders.6.blocks.0.ln_k.bias', 'decoders.6.blocks.0.proj_out.weight', 'decoders.6.blocks.1.blocks.0.weight', 'decoders.6.blocks.1.blocks.0.bias', 'decoders.6.blocks.1.blocks.3.weight', 'decoders.6.blocks.1.blocks.3.bias', 'decoders.6.blocks.2.proj_heads.weight', 'decoders.6.blocks.2.proj_heads_o_q.weight', 'decoders.6.blocks.2.proj_heads_o_kv.weight', 'decoders.6.blocks.2.ln_q.weight', 'decoders.6.blocks.2.ln_q.bias', 'decoders.6.blocks.2.ln_k.weight', 'decoders.6.blocks.2.ln_k.bias', 'decoders.6.blocks.2.proj_out.weight', 'decoders.6.blocks.3.blocks.0.weight', 'decoders.6.blocks.3.blocks.0.bias', 'decoders.6.blocks.3.blocks.3.weight', 'decoders.6.blocks.3.blocks.3.bias', 'decoders.6.blocks.4.proj_heads.weight', 'decoders.6.blocks.4.proj_heads_o_q.weight', 'decoders.6.blocks.4.proj_heads_o_kv.weight', 'decoders.6.blocks.4.ln_q.weight', 'decoders.6.blocks.4.ln_q.bias', 'decoders.6.blocks.4
0: .ln_k.weight', 'decoders.6.blocks.4.ln_k.bias', 'decoders.6.blocks.4.proj_out.weight', 'decoders.6.blocks.5.blocks.0.weight', 'decoders.6.blocks.5.blocks.0.bias', 'decoders.6.blocks.5.blocks.3.weight', 'decoders.6.blocks.5.blocks.3.bias', 'decoders.6.blocks.6.proj_heads.weight', 'decoders.6.blocks.6.proj_heads_o_q.weight', 'decoders.6.blocks.6.proj_heads_o_kv.weight', 'decoders.6.blocks.6.ln_q.weight', 'decoders.6.blocks.6.ln_q.bias', 'decoders.6.blocks.6.ln_k.weight', 'decoders.6.blocks.6.ln_k.bias', 'decoders.6.blocks.6.proj_out.weight', 'decoders.6.blocks.7.blocks.0.weight', 'decoders.6.blocks.7.blocks.0.bias', 'decoders.6.blocks.7.blocks.3.weight', 'decoders.6.blocks.7.blocks.3.bias', 'decoders.6.blocks.8.proj_heads.weight', 'decoders.6.blocks.8.proj_heads_o_q.weight', 'decoders.6.blocks.8.proj_heads_o_kv.weight', 'decoders.6.blocks.8.ln_q.weight', 'decoders.6.blocks.8.ln_q.bias', 'decoders.6.blocks.8.ln_k.weight', 'decoders.6.blocks.8.ln_k.bias', 'decoders.6.blocks.8.proj_out.weight', 'decoders.6.blocks.
0: 9.blocks.0.weight', 'decoders.6.blocks.9.blocks.0.bias', 'decoders.6.blocks.9.blocks.3.weight', 'decoders.6.blocks.9.blocks.3.bias', 'decoders.6.blocks.10.proj_heads.weight', 'decoders.6.blocks.10.proj_heads_o_q.weight', 'decoders.6.blocks.10.proj_heads_o_kv.weight', 'decoders.6.blocks.10.ln_q.weight', 'decoders.6.blocks.10.ln_q.bias', 'decoders.6.blocks.10.ln_k.weight', 'decoders.6.blocks.10.ln_k.bias', 'decoders.6.blocks.10.proj_out.weight', 'decoders.6.blocks.11.blocks.0.weight', 'decoders.6.blocks.11.blocks.0.bias', 'decoders.6.blocks.11.blocks.3.weight', 'decoders.6.blocks.11.blocks.3.bias', 'tails.6.tail_nets.0.0.weight', 'tails.6.tail_nets.0.0.bias', 'tails.6.tail_nets.0.1.weight', 'tails.6.tail_nets.0.1.bias', 'tails.6.tail_nets.1.0.weight', 'tails.6.tail_nets.1.0.bias', 'tails.6.tail_nets.1.1.weight', 'tails.6.tail_nets.1.1.bias', 'tails.6.tail_nets.2.0.weight', 'tails.6.tail_nets.2.0.bias', 'tails.6.tail_nets.2.1.weight', 'tails.6.tail_nets.2.1.bias', 'tails.6.tail_nets.3.0.weight', 'tails.6.tail_ne
0: ts.3.0.bias', 'tails.6.tail_nets.3.1.weight', 'tails.6.tail_nets.3.1.bias', 'tails.6.tail_nets.4.0.weight', 'tails.6.tail_nets.4.0.bias', 'tails.6.tail_nets.4.1.weight', 'tails.6.tail_nets.4.1.bias', 'tails.6.tail_nets.5.0.weight', 'tails.6.tail_nets.5.0.bias', 'tails.6.tail_nets.5.1.weight', 'tails.6.tail_nets.5.1.bias', 'tails.6.tail_nets.6.0.weight', 'tails.6.tail_nets.6.0.bias', 'tails.6.tail_nets.6.1.weight', 'tails.6.tail_nets.6.1.bias', 'tails.6.tail_nets.7.0.weight', 'tails.6.tail_nets.7.0.bias', 'tails.6.tail_nets.7.1.weight', 'tails.6.tail_nets.7.1.bias', 'tails.6.tail_nets.8.0.weight', 'tails.6.tail_nets.8.0.bias', 'tails.6.tail_nets.8.1.weight', 'tails.6.tail_nets.8.1.bias', 'tails.6.tail_nets.9.0.weight', 'tails.6.tail_nets.9.0.bias', 'tails.6.tail_nets.9.1.weight', 'tails.6.tail_nets.9.1.bias', 'tails.6.tail_nets.10.0.weight', 'tails.6.tail_nets.10.0.bias', 'tails.6.tail_nets.10.1.weight', 'tails.6.tail_nets.10.1.bias', 'tails.6.tail_nets.11.0.weight', 'tails.6.tail_nets.11.0.bias', 'tails.6.tai
0: l_nets.11.1.weight', 'tails.6.tail_nets.11.1.bias', 'tails.6.tail_nets.12.0.weight', 'tails.6.tail_nets.12.0.bias', 'tails.6.tail_nets.12.1.weight', 'tails.6.tail_nets.12.1.bias', 'tails.6.tail_nets.13.0.weight', 'tails.6.tail_nets.13.0.bias', 'tails.6.tail_nets.13.1.weight', 'tails.6.tail_nets.13.1.bias', 'tails.6.tail_nets.14.0.weight', 'tails.6.tail_nets.14.0.bias', 'tails.6.tail_nets.14.1.weight', 'tails.6.tail_nets.14.1.bias', 'tails.6.tail_nets.15.0.weight', 'tails.6.tail_nets.15.0.bias', 'tails.6.tail_nets.15.1.weight', 'tails.6.tail_nets.15.1.bias']
0: Loaded model id = wc5e2i3t.
0: Loaded run 'wc5e2i3t' at epoch -2.
1: Loaded model id = wc5e2i3t.
1: Loaded run 'wc5e2i3t' at epoch -2.
1: -1 : 13:31:27 :: batch_size = 96, lr = 1e-05
0: Number of trainable parameters: 886,234,640
0: -1 : 13:31:27 :: batch_size = 96, lr = 1e-05
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch -1, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch -1, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.8297, -0.8372, -0.8446, -0.8519, -0.8589, -0.8658, -0.8726, -0.8792, -0.8855, -0.8917, -0.8977, -0.9033,
1:         -0.9089, -0.9142, -0.9192, -0.9242, -0.9289, -0.9332, -0.7967, -0.8046, -0.8125, -0.8202, -0.8277, -0.8350,
1:         -0.8422], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.9709, -0.9594, -0.9483, -0.9379, -0.9277, -0.9182, -0.9088, -0.8999, -0.8915, -0.8832, -0.8754, -0.8678,
1:         -0.8607, -0.8537, -0.8470, -0.8407, -0.8344, -0.8285, -1.0059, -0.9931, -0.9807, -0.9687, -0.9572, -0.9460,
1:         -0.9353], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.5185, -0.5175, -0.5164, -0.5153, -0.5142, -0.5130, -0.5119, -0.5107, -0.5107, -0.5107, -0.5107, -0.5107,
1:         -0.5107, -0.5107, -0.5107, -0.5110, -0.5120, -0.5129, -0.5191, -0.5180, -0.5167, -0.5153, -0.5140, -0.5126,
1:         -0.5112], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.2138, -0.2247, -0.2360, -0.2470, -0.2579, -0.2687, -0.2794, -0.2901, -0.3005, -0.3105, -0.3204, -0.3302,
1:         -0.3395, -0.3485, -0.3572, -0.3654, -0.3736, -0.3808, -0.3880, -0.3943, -0.4002, -0.4056, -0.4105, -0.4143,
1:         -0.4179], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2422, -0.2422, -0.2422, -0.2422, -0.2422, -0.2422, -0.2434, -0.2434, -0.2434, -0.2434, -0.2434, -0.2434,
1:         -0.2434, -0.2434, -0.2434, -0.2434, -0.2434, -0.2434, -0.2389, -0.2389, -0.2389, -0.2389, -0.2389, -0.2400,
1:         -0.2411], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([0.6176, 0.6477, 0.6824, 0.7178, 0.7519, 0.7864, 0.8206, 0.8544, 0.8943, 0.9339, 0.9731, 1.0128, 1.0512, 1.0897,
1:         1.1202, 1.1450, 1.1669, 1.1876, 1.2085, 1.2292, 1.2492, 1.2673, 1.2767, 1.2786, 1.2786], device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch -1, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2321, 2187])
1:     First 25 batch values:
1: tensor([0.0140, 0.0422, 0.0718, 0.0933, 0.1148, 0.1362, 0.1576, 0.1790, 0.1996, 0.2194, 0.2373, 0.2536, 0.2698, 0.2860,
1:         0.3021, 0.3181, 0.3320, 0.3422, 0.3521, 0.3625, 0.3723, 0.3819, 0.3914, 0.4009, 0.4148])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch -1, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([27003, 972])
1:      first 25 pred values: tensor([-1.3397, -1.3369, -1.3363, -1.3358, -1.3349, -1.3330, -1.3312, -1.3277, -1.3261, -1.3267, -1.3290, -1.3307,
1:         -1.3328, -1.3339, -1.3324, -1.3312, -1.3330, -1.3363, -1.3325, -1.3298, -1.3266, -1.3249, -1.3217, -1.3185,
1:         -1.3143], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26669, 972])
1:      first 25 pred values: tensor([0.2380, 0.2374, 0.2352, 0.2329, 0.2286, 0.2238, 0.2145, 0.2037, 0.1948, 0.1850, 0.1794, 0.1743, 0.1696, 0.1654,
1:         0.1640, 0.1644, 0.1700, 0.1776, 0.2261, 0.2259, 0.2248, 0.2247, 0.2236, 0.2221, 0.2168], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([26271, 972])
1:      first 25 pred values: tensor([-0.1562, -0.1516, -0.1499, -0.1515, -0.1568, -0.1629, -0.1708, -0.1768, -0.1815, -0.1835, -0.1841, -0.1837,
1:         -0.1849, -0.1864, -0.1873, -0.1889, -0.1889, -0.1900, -0.1673, -0.1667, -0.1660, -0.1671, -0.1708, -0.1758,
1:         -0.1800], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([27453, 972])
1:      first 25 pred values: tensor([0.2972, 0.2792, 0.2643, 0.2595, 0.2602, 0.2662, 0.2750, 0.2768, 0.2808, 0.2828, 0.2773, 0.2887, 0.2949, 0.2771,
1:         0.2680, 0.2616, 0.2578, 0.2612, 0.2320, 0.2366, 0.2418, 0.2519, 0.2531, 0.2419, 0.2472], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([12228, 2187])
1:      first 25 pred values: tensor([-0.3406, -0.3481, -0.3530, -0.3565, -0.3601, -0.3645, -0.3683, -0.3709, -0.3731, -0.3749, -0.3754, -0.3758,
1:         -0.3758, -0.3752, -0.3757, -0.3772, -0.3794, -0.3817, -0.3821, -0.3800, -0.3771, -0.3740, -0.3716, -0.3711,
1:         -0.3707], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([10099, 243])
1:      first 25 pred values: tensor([-0.2106, -0.2152, -0.2170, -0.2184, -0.2198, -0.2191, -0.2208, -0.2181, -0.2159, -0.2150, -0.2182, -0.2212,
1:         -0.2211, -0.2217, -0.2217, -0.2211, -0.2189, -0.2185, -0.2187, -0.2223, -0.2237, -0.2233, -0.2254, -0.2229,
1:         -0.2220], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2321, 2187])
1:      first 25 pred values: tensor([ 0.0088, -0.0484, -0.2600,  0.0369,  0.1388,  0.0146,  0.0770,  0.0220,  0.2452,  0.0875,  0.0721, -0.0541,
1:          0.0808, -0.0216, -0.4291, -0.2492, -0.1395,  0.1699,  0.0901, -0.0337, -0.1397, -0.2245, -0.2169, -0.1119,
1:          0.0823], device='cuda:0', grad_fn=<SliceBackward0>)
0:      first 25 values: tensor([ 0.0086, -0.0273, -0.0040, -0.0311, -0.1637,  0.1468,  0.0220,  0.0763,  0.0124, -0.0236,  0.0314,  0.0262,
0:         -0.0128, -0.0141, -0.1603, -0.0444,  0.2546, -0.1258, -0.0508, -0.0095, -0.0296, -0.0493,  0.0605,  0.2011,
0:          0.0798], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.9709, -0.9594, -0.9483, -0.9379, -0.9277, -0.9182, -0.9088, -0.8999, -0.8915, -0.8832, -0.8754, -0.8678,
0:         -0.8607, -0.8537, -0.8470, -0.8407, -0.8344, -0.8285, -1.0059, -0.9931, -0.9807, -0.9687, -0.9572, -0.9460,
0:         -0.9353], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0813, -0.0705, -0.0575, -0.0466, -0.0379, -0.0314, -0.0271, -0.0227, -0.0206, -0.0184, -0.0184, -0.0162,
0:         -0.0119, -0.0075, -0.0010,  0.0076,  0.0163,  0.0250, -0.1182, -0.1117, -0.1052, -0.0987, -0.0965, -0.0922,
0:         -0.0922], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.2422, -0.2422, -0.2422, -0.2422, -0.2422, -0.2422, -0.2434, -0.2434, -0.2434, -0.2434, -0.2434, -0.2434,
0:         -0.2434, -0.2434, -0.2434, -0.2434, -0.2434, -0.2434, -0.2389, -0.2389, -0.2389, -0.2389, -0.2389, -0.2400,
0:         -0.2411], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0.6176, 0.6477, 0.6824, 0.7178, 0.7519, 0.7864, 0.8206, 0.8544, 0.8943, 0.9339, 0.9731, 1.0128, 1.0512, 1.0897,
0:         1.1202, 1.1450, 1.1669, 1.1876, 1.2085, 1.2292, 1.2492, 1.2673, 1.2767, 1.2786, 1.2786], device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch -1, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2470, 2187])
0:     First 25 batch values:
0: tensor([0.8847, 0.8884, 0.8880, 0.8856, 0.8855, 0.8857, 0.8849, 0.8840, 0.8827, 0.8811, 0.8841, 0.8794, 0.8703, 0.8618,
0:         0.8524, 0.8428, 0.8331, 0.8295, 0.8316, 0.8201, 0.8085, 0.7969, 0.7851, 0.7725, 0.7606])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch -1, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([25704, 972])
0:      first 25 pred values: tensor([-0.8011, -0.8026, -0.8055, -0.8089, -0.8106, -0.8138, -0.8190, -0.8209, -0.8254, -0.8282, -0.8316, -0.8335,
0:         -0.8362, -0.8416, -0.8455, -0.8497, -0.8549, -0.8590, -0.9327, -0.9360, -0.9378, -0.9407, -0.9433, -0.9447,
0:         -0.9459], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([27299, 972])
0:      first 25 pred values: tensor([0.1470, 0.1608, 0.1723, 0.1794, 0.1843, 0.1896, 0.1930, 0.1963, 0.2016, 0.2039, 0.2033, 0.1999, 0.1959, 0.1920,
0:         0.1881, 0.1835, 0.1750, 0.1675, 0.1971, 0.2132, 0.2272, 0.2356, 0.2418, 0.2449, 0.2506], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([26497, 972])
0:      first 25 pred values: tensor([-0.4377, -0.4453, -0.4504, -0.4578, -0.4647, -0.4682, -0.4710, -0.4739, -0.4776, -0.4788, -0.4825, -0.4859,
0:         -0.4897, -0.4920, -0.4952, -0.4948, -0.4958, -0.4941, -0.4166, -0.4227, -0.4287, -0.4349, -0.4414, -0.4479,
0:         -0.4522], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25462, 972])
0:      first 25 pred values: tensor([ 0.0262,  0.0558,  0.0979,  0.1457,  0.1804,  0.2092,  0.2188,  0.2060,  0.2044,  0.1839,  0.1265,  0.0689,
0:          0.0063, -0.0595, -0.1156, -0.1751, -0.2016, -0.1921,  0.0402,  0.0427,  0.0524,  0.0723,  0.0889,  0.1008,
0:          0.0963], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11943, 2187])
0:      first 25 pred values: tensor([-0.2298, -0.2404, -0.2521, -0.2645, -0.2788, -0.2937, -0.3087, -0.3213, -0.3289, -0.3338, -0.3362, -0.3365,
0:         -0.3344, -0.3295, -0.3200, -0.3080, -0.2935, -0.2784, -0.2618, -0.2453, -0.2275, -0.2100, -0.1925, -0.1741,
0:         -0.1543], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([9443, 243])
0:      first 25 pred values: tensor([-0.2487, -0.2583, -0.2596, -0.2564, -0.2479, -0.2428, -0.2351, -0.2348, -0.2293, -0.2314, -0.2364, -0.2364,
0:         -0.2408, -0.2369, -0.2363, -0.2350, -0.2328, -0.2389, -0.1875, -0.1900, -0.1871, -0.1961, -0.2015, -0.2137,
0:         -0.2196], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2470, 2187])
0:      first 25 pred values: tensor([-0.0148,  0.0126, -0.2912, -0.0265,  0.1796,  0.1033,  0.2177, -0.0626,  0.0903,  0.1034,  0.1834, -0.1122,
0:          0.0023, -0.0542, -0.3769, -0.3248, -0.3032, -0.1145,  0.0916, -0.1597, -0.2191, -0.3905, -0.1613, -0.0884,
0:          0.1703], device='cuda:0', grad_fn=<SliceBackward0>)
0: epoch: -1 [1/5 (20%)]	Loss: 0.80256 : 0.21550 :: 0.07317 (1.49 s/sec)
0: epoch: -1 [2/5 (40%)]	Loss: 0.80386 : 0.21839 :: 0.08313 (8.21 s/sec)
0: epoch: -1 [3/5 (60%)]	Loss: 0.78147 : 0.22124 :: 0.08584 (8.21 s/sec)
0: epoch: -1 [4/5 (80%)]	Loss: 0.73746 : 0.21532 :: 0.09240 (8.21 s/sec)
0: validation loss for strategy=BERT at epoch -1 : 0.2349073588848114
0: validation loss for velocity_u : 0.004896979313343763
0: validation loss for velocity_v : 0.006493200547993183
0: validation loss for specific_humidity : 0.007781504187732935
0: validation loss for velocity_z : 0.13143786787986755
0: validation loss for temperature : 0.02226860821247101
0: validation loss for total_precip : 0.4582354426383972
0: validation loss for t2m : 1.0132379531860352
0: 0 : 13:38:03 :: batch_size = 96, lr = 1e-05
1: 0 : 13:38:13 :: batch_size = 96, lr = 1e-05
0: [DEBUG] TRAIN INPUT BATCH
0: Epoch 0, first input batch shapes / sample data:
0:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.1136, -0.1397, -0.0477, -0.1942, -0.3225,  0.0181, -0.0070, -0.0486, -0.1106, -0.1187,  0.0665,  0.0290,
0:         -0.0082, -0.1209,  0.1045,  0.1178, -0.0353, -0.1373,  0.0240, -0.1132,  0.2069, -0.1967,  0.1551, -0.1720,
0:          0.1401], device='cuda:0')
0:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0.0584, -0.0516, -0.0382, -0.0563, -0.1019, -0.1376, -0.1822, -0.2887, -0.4363, -0.5703, -0.6503, -0.6685,
0:         -0.6507, -0.6225, -0.6088, -0.6004, -0.5890, -0.5746, -0.1393, -0.1121, -0.0991, -0.1185, -0.1630, -0.2140,
0:         -0.2790], device='cuda:0')
0:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.],
0:        device='cuda:0')
0:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
0:      first 25 values: tensor([ 0.1966,  0.0538, -0.0631,  0.0300, -0.1172, -0.2773, -0.1886, -0.0869,  0.2161,  0.3394,  0.2637,  0.0451,
0:         -0.1064, -0.0999, -0.1843, -0.1410, -0.0826, -0.0285,  0.3654,  0.1209, -0.1020, -0.0523, -0.2297, -0.3488,
0:         -0.3920], device='cuda:0')
0:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
0:        device='cuda:0')
0:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
0:      first 25 values: tensor([-0.1992, -0.1715, -0.1369, -0.0977, -0.0977, -0.0746, -0.0585, -0.0816, -0.1139, -0.1854, -0.1900, -0.1600,
0:         -0.1139, -0.1185, -0.1531, -0.1508, -0.1600, -0.0977, -0.1531, -0.1577, -0.1277, -0.0677, -0.0493, -0.0608,
0:         -0.1577], device='cuda:0')
0:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
0:      first 25 values: tensor([ 0.1366,  0.0802, -0.0565, -0.1174, -0.0995, -0.1558, -0.2453, -0.2665, -0.2919, -0.2431, -0.2315, -0.3337,
0:         -0.4748, -0.3723, -0.2158,  0.1027,  0.2927,  0.3433,  0.1316, -0.0248,  0.0387,  0.2504,  0.5343,  0.6777,
0:          0.6770], device='cuda:0')
0: [DEBUG] TRAIN TARGET BATCH
0: Epoch 0, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2470, 2187])
0:     First 25 batch values:
0: tensor([-0.2794, -0.1798,  0.0033,  0.2013,  0.3174,  0.2385,  0.0992, -0.0616, -0.1892, -0.4094, -0.6114, -0.6155,
0:         -0.3514,  0.2931,  0.7266,  0.7800,  0.8963,  0.8070,  0.6222,  0.5245,  0.4523,  0.3968,  0.3932,  0.3639,
0:          0.5343])
0: [DEBUG] TRAIN PREDICTIONS BATCH
0: Epoch 0, first predictions sample:
0:   └─ Predictions for 'velocity_u' shape: torch.Size([25704, 972])
0:      first 25 pred values: tensor([-0.8167, -0.8149, -0.8117, -0.8047, -0.7983, -0.7943, -0.7952, -0.7995, -0.8062, -0.8122, -0.8166, -0.8180,
0:         -0.8197, -0.8177, -0.8139, -0.8106, -0.8070, -0.8068, -0.8260, -0.8235, -0.8222, -0.8169, -0.8133, -0.8126,
0:         -0.8152], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_v' shape: torch.Size([27299, 972])
0:      first 25 pred values: tensor([0.3599, 0.3692, 0.3718, 0.3659, 0.3575, 0.3497, 0.3469, 0.3499, 0.3564, 0.3693, 0.3815, 0.3978, 0.4154, 0.4335,
0:         0.4529, 0.4714, 0.4899, 0.5117, 0.3253, 0.3269, 0.3230, 0.3126, 0.2994, 0.2916, 0.2874], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'specific_humidity' shape: torch.Size([26497, 972])
0:      first 25 pred values: tensor([0.2428, 0.2422, 0.2445, 0.2427, 0.2430, 0.2386, 0.2333, 0.2282, 0.2174, 0.2106, 0.2033, 0.1973, 0.1881, 0.1777,
0:         0.1643, 0.1497, 0.1379, 0.1319, 0.2576, 0.2589, 0.2613, 0.2615, 0.2652, 0.2585, 0.2518], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'velocity_z' shape: torch.Size([25462, 972])
0:      first 25 pred values: tensor([ 0.4834,  0.3543,  0.2704,  0.1921,  0.0999,  0.0496,  0.0240,  0.0242,  0.0638,  0.0694,  0.0624,  0.0557,
0:          0.0256, -0.0015, -0.0026, -0.0108, -0.0110,  0.0175,  0.5078,  0.4082,  0.3365,  0.2774,  0.1898,  0.1301,
0:          0.0812], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'temperature' shape: torch.Size([11943, 2187])
0:      first 25 pred values: tensor([0.9412, 0.9740, 1.0075, 1.0377, 1.0508, 1.0463, 1.0271, 1.0026, 0.9846, 0.9808, 0.9929, 1.0177, 1.0530, 1.0939,
0:         1.1338, 1.1581, 1.1629, 1.1453, 1.1159, 1.0894, 1.0735, 1.0705, 1.0708, 1.0666, 1.0586], device='cuda:0',
0:        grad_fn=<SliceBackward0>)
0:   └─ Predictions for 'total_precip' shape: torch.Size([9443, 243])
0:      first 25 pred values: tensor([-0.2282, -0.2264, -0.2196, -0.2142, -0.2154, -0.2090, -0.2072, -0.2080, -0.2089, -0.2205, -0.2224, -0.2229,
0:         -0.2152, -0.2126, -0.2096, -0.2094, -0.2069, -0.2101, -0.2230, -0.2181, -0.2225, -0.2103, -0.2111, -0.2056,
0:         -0.2043], device='cuda:0', grad_fn=<SliceBackward0>)
0:   └─ Predictions for 't2m' shape: torch.Size([2470, 2187])
0:      first 25 pred values: tensor([ 0.0044, -0.0483, -0.3240, -0.2139, -0.0254,  0.1440,  0.1921, -0.0597, -0.0171,  0.0911,  0.1111, -0.0378,
0:          0.0366, -0.0223, -0.1890, -0.3073, -0.1439, -0.0719, -0.0032, -0.1102, -0.2538, -0.3973, -0.1960, -0.0419,
0:          0.1318], device='cuda:0', grad_fn=<SliceBackward0>)
1: [DEBUG] TRAIN INPUT BATCH
1: Epoch 0, first input batch shapes / sample data:
1:   └─ Field: 'velocity_u' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-1.9555, -1.9484, -1.9412, -1.9336, -1.9259, -1.9179, -1.9098, -1.9015, -1.8928, -1.8840, -1.8750, -1.8659,
1:         -1.8566, -1.8471, -1.8374, -1.8278, -1.8178, -1.8078, -1.8840, -1.8804, -1.8762, -1.8720, -1.8675, -1.8627,
1:         -1.8577], device='cuda:0')
1:   └─ Field: 'velocity_v' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([1.5077, 1.5154, 1.5231, 1.5304, 1.5374, 1.5443, 1.5509, 1.5571, 1.5633, 1.5691, 1.5747, 1.5798, 1.5849, 1.5896,
1:         1.5941, 1.5982, 1.6023, 1.6059, 1.5340, 1.5432, 1.5518, 1.5601, 1.5682, 1.5762, 1.5836], device='cuda:0')
1:   └─ Field: 'specific_humidity' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([-0.2661, -0.2663, -0.2684, -0.2721, -0.2774, -0.2839, -0.2905, -0.2971, -0.3039, -0.3107, -0.3175, -0.3244,
1:         -0.3314, -0.3376, -0.3435, -0.3535, -0.3651, -0.3766, -0.1727, -0.1688, -0.1649, -0.1612, -0.1631, -0.1650,
1:         -0.1671], device='cuda:0')
1:   └─ Field: 'velocity_z' shape: torch.Size([96, 5, 12, 3, 6, 3, 18, 18])
1:      first 25 values: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
1:        device='cuda:0')
1:   └─ Field: 'temperature' shape: torch.Size([96, 5, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([1.0345, 1.0464, 1.0584, 1.0710, 1.0839, 1.0971, 1.1106, 1.1243, 1.1389, 1.1537, 1.1684, 1.1839, 1.1993, 1.2151,
1:         1.2313, 1.2476, 1.2639, 1.2805, 1.2970, 1.3136, 1.3304, 1.3473, 1.3638, 1.3806, 1.3970], device='cuda:0')
1:   └─ Field: 'total_precip' shape: torch.Size([96, 1, 12, 6, 12, 3, 9, 9])
1:      first 25 values: tensor([-0.2392, -0.2392, -0.2392, -0.2392, -0.2380, -0.2380, -0.2380, -0.2369, -0.2369, -0.2380, -0.2380, -0.2380,
1:         -0.2380, -0.2369, -0.2369, -0.2357, -0.2357, -0.2357, -0.2380, -0.2369, -0.2369, -0.2369, -0.2369, -0.2357,
1:         -0.2357], device='cuda:0')
1:   └─ Field: 't2m' shape: torch.Size([96, 1, 12, 2, 4, 3, 27, 27])
1:      first 25 values: tensor([-0.0995, -0.0918, -0.0839, -0.0764, -0.0688, -0.0609, -0.0527, -0.0448, -0.0369, -0.0290, -0.0210, -0.0131,
1:         -0.0052,  0.0021,  0.0087,  0.0141,  0.0185,  0.0233,  0.0281,  0.0325,  0.0373,  0.0421,  0.0466,  0.0514,
1:          0.0560], device='cuda:0')
1: [DEBUG] TRAIN TARGET BATCH
1: Epoch 0, batch 0 - Sparse-masked 't2m' shape target data: torch.Size([2321, 2187])
1:     First 25 batch values:
1: tensor([-0.6892, -0.6866, -0.6839, -0.6811, -0.6783, -0.6755, -0.6725, -0.6693, -0.6602, -0.6506, -0.6390, -0.6270,
1:         -0.6148, -0.6030, -0.5906, -0.5786, -0.5662, -0.5540, -0.5406, -0.5245, -0.5084, -0.4917, -0.4746, -0.4576,
1:         -0.4407])
1: [DEBUG] TRAIN PREDICTIONS BATCH
1: Epoch 0, first predictions sample:
1:   └─ Predictions for 'velocity_u' shape: torch.Size([27003, 972])
1:      first 25 pred values: tensor([-1.4594, -1.4506, -1.4453, -1.4415, -1.4403, -1.4397, -1.4418, -1.4446, -1.4491, -1.4556, -1.4612, -1.4674,
1:         -1.4708, -1.4718, -1.4704, -1.4684, -1.4644, -1.4596, -1.4839, -1.4787, -1.4774, -1.4764, -1.4776, -1.4781,
1:         -1.4782], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_v' shape: torch.Size([26669, 972])
1:      first 25 pred values: tensor([-0.0224, -0.0315, -0.0390, -0.0434, -0.0476, -0.0497, -0.0521, -0.0583, -0.0683, -0.0772, -0.0887, -0.0976,
1:         -0.1040, -0.1106, -0.1171, -0.1275, -0.1393, -0.1496, -0.0205, -0.0336, -0.0442, -0.0562, -0.0623, -0.0662,
1:         -0.0692], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'specific_humidity' shape: torch.Size([26271, 972])
1:      first 25 pred values: tensor([-0.1394, -0.1564, -0.1781, -0.2038, -0.2260, -0.2482, -0.2696, -0.2929, -0.3158, -0.3378, -0.3552, -0.3759,
1:         -0.3908, -0.4060, -0.4112, -0.4117, -0.4057, -0.3954, -0.1044, -0.1186, -0.1352, -0.1539, -0.1687, -0.1847,
1:         -0.2013], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'velocity_z' shape: torch.Size([27453, 972])
1:      first 25 pred values: tensor([-0.1188, -0.1658, -0.1604, -0.1541, -0.1933, -0.2016, -0.1897, -0.1885, -0.1617, -0.1652, -0.1894, -0.1868,
1:         -0.1675, -0.1705, -0.1886, -0.1790, -0.1711, -0.1894, -0.0898, -0.1205, -0.1386, -0.1428, -0.1829, -0.2020,
1:         -0.2029], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'temperature' shape: torch.Size([12228, 2187])
1:      first 25 pred values: tensor([1.0307, 1.0428, 1.0486, 1.0477, 1.0423, 1.0380, 1.0363, 1.0343, 1.0312, 1.0268, 1.0238, 1.0216, 1.0219, 1.0229,
1:         1.0209, 1.0162, 1.0113, 1.0071, 1.0032, 0.9991, 0.9920, 0.9857, 0.9812, 0.9803, 0.9826], device='cuda:0',
1:        grad_fn=<SliceBackward0>)
1:   └─ Predictions for 'total_precip' shape: torch.Size([10099, 243])
1:      first 25 pred values: tensor([-0.1806, -0.1785, -0.1655, -0.1476, -0.1395, -0.1192, -0.1073, -0.0930, -0.0894, -0.1839, -0.1810, -0.1726,
1:         -0.1585, -0.1475, -0.1293, -0.1188, -0.1107, -0.0970, -0.1730, -0.1692, -0.1792, -0.1634, -0.1534, -0.1403,
1:         -0.1282], device='cuda:0', grad_fn=<SliceBackward0>)
1:   └─ Predictions for 't2m' shape: torch.Size([2321, 2187])
1:      first 25 pred values: tensor([ 0.1060, -0.0417, -0.2534, -0.0585,  0.1195,  0.1082,  0.0404,  0.0757,  0.1653,  0.0781,  0.0488,  0.0203,
1:          0.1113,  0.0224, -0.1979, -0.2077, -0.0298,  0.1470, -0.0629, -0.0418, -0.0974, -0.1874, -0.1453, -0.1302,
1:          0.0519], device='cuda:0', grad_fn=<SliceBackward0>)
0: epoch: 0 [1/5 (20%)]	Loss: 0.83483 : 0.23192 :: 0.08265 (1.57 s/sec)
0: epoch: 0 [2/5 (40%)]	Loss: 0.84330 : 0.22594 :: 0.08540 (8.01 s/sec)
0: epoch: 0 [3/5 (60%)]	Loss: 0.72119 : 0.18521 :: 0.07924 (8.11 s/sec)
0: > /work/ab1412/atmorep/pyenv/lib/python3.10/site-packages/torch/autograd/graph.py(825)_engine_run_backward()
0: -> return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
0: (Pdb) 
0: [1;34mwandb[0m:
0: [1;34mwandb[0m: You can sync this run to the cloud by running:
0: [1;34mwandb[0m: [1mwandb sync /work/ab1412/atmorep/wandb/offline-run-20250722_133031-h0il5hnz[0m
0: [1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250722_133031-h0il5hnz/logs[0m
0: l50115:547503:548032 [0] NCCL INFO [Service thread] Connection closed by localRank 0
0: l50115:547503:548819 [0] NCCL INFO comm 0x55555f0e7d70 rank 0 nranks 2 cudaDev 0 busId 3000 - Abort COMPLETE
